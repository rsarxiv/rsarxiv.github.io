<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>RSarXiv</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://rsarxiv.github.io/"/>
  <updated>2016-08-23T00:28:27.000Z</updated>
  <id>http://rsarxiv.github.io/</id>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://rsarxiv.github.io/2016/08/22/media/index/"/>
    <id>http://rsarxiv.github.io/2016/08/22/media/index/</id>
    <published>2016-08-23T00:36:41.645Z</published>
    <updated>2016-08-23T00:28:27.000Z</updated>
    
    <content type="html"><![CDATA[<hr>
<p>title: about</p>
<h2 id="date-2016-08-22-16-56-38"><a href="#date-2016-08-22-16-56-38" class="headerlink" title="date: 2016-08-22 16:56:38"></a>date: 2016-08-22 16:56:38</h2><h1 id="招人启事"><a href="#招人启事" class="headerlink" title="招人启事"></a>招人启事</h1><p>PaperWeekly每周会分享N篇当下最流行、最有趣的NLP paper，旨在用最精炼的话说明白paper的贡献和创新。目前运营在公众号和知乎专栏两个平台上，现在的形式是每周分享一篇NLP Paper周报，偶尔也会写一些NLP相关的博客，由于本人精力和水平有限，现邀请各位对NLP技术、NLP Paper感兴趣的童鞋加入一同运营，在推进国内NLP技术发展的路上贡献一点点绵薄之力。</p>
<p>微信公众号：PaperWeekly</p>
<img class="index/qrcode.jpg 350 350">
<p>知乎专栏：<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">PaperWeekly</a></p>
<p>微信交流群：</p>
<img class="index/paperweekly.jpg 350 350">
]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: about&lt;/p&gt;
&lt;h2 id=&quot;date-2016-08-22-16-56-38&quot;&gt;&lt;a href=&quot;#date-2016-08-22-16-56-38&quot; class=&quot;headerlink&quot; title=&quot;date: 2016-08-22 16
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>从api.ai工作原理来看构建简单场景chatbot的一般方法</title>
    <link href="http://rsarxiv.github.io/2016/08/21/%E4%BB%8Eapi-ai%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E6%9D%A5%E7%9C%8B%E6%9E%84%E5%BB%BA%E7%AE%80%E5%8D%95%E5%9C%BA%E6%99%AFchatbot%E7%9A%84%E4%B8%80%E8%88%AC%E6%96%B9%E6%B3%95/"/>
    <id>http://rsarxiv.github.io/2016/08/21/从api-ai工作原理来看构建简单场景chatbot的一般方法/</id>
    <published>2016-08-22T02:05:52.000Z</published>
    <updated>2016-08-23T00:29:20.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>chatbot无疑是当前非常火的一个研究领域和产品方向，简单地可以分为两类，开放域bot和封闭域bot，开放域bot倾向于解决所有的事情，而封闭域bot倾向于解决某一个细分领域中的事情，旨在用AI技术提高效率，提高生产力。现阶段的开放域bot我个人感觉更像是多个常用封闭域bot的叠加，当用户发起一个请求，系统会判断出属于哪个细分领域，然后转到相应的程序中去执行并给出反馈，顺着这个逻辑来看，研究简单场景下的chatbot是个重要的基础工作，这类研究或者产品的质量直接决定了复杂场景或者开放域bot的质量。当然逗乐型的bot并不属于本文讨论的范围。<br><img src="media/1.png" alt="1"><br>图片来自paper <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" target="_blank" rel="external">The Dialog State Tracking Challenge Series- A Review</a></p>
<p>chatbot是场交互革命，也是一个多技术融合的平台。上图给出了构建一个chatbot需要具备的组件，简单地说chatbot = NLU(Natural Language Understanding) + NLG(Natural Language Generation).(本文只关注NLP相关的技术，对语音识别并无讨论)</p>
<p>对于封闭域的chatbot，NLU的工作就是DST(Dialog State Tracker)，用户给出输入之后，系统可以给出下面的形式作为state：</p>
<p><b>Act(Slot=Value)</b></p>
<p>Act表示用户行为的类型，比如请求、查询、打招呼等等；Slot表示用户输入中包含的某种Act下的Entity，比如查询酒店的位置、价格这些实体；Value是指Slot中Entity对应的值，比如位置在北边，价格在500-800之间等等。每一句话中可能包括多个Act-Slot-Value对，chatbot需要做的事情就是准确地识别出Act，并且抽取出相应的Slot和Value。</p>
<p>紧接着是NLG的部分，前几天在<a href="http://rsarxiv.github.io/2016/08/16/PaperWeekly-%E7%AC%AC%E4%BA%8C%E6%9C%9F/">PaperWeekly第二期</a>中分享了三篇paper，其中两篇正是研究基于DST的NLG问题。</p>
<p>本文首先从<a href="api.ai">api.ai</a>这家企业提供的服务说起，通过研究其提供的封闭域bot构建技术，来提炼构建简单场景chatbot的一般方法，为构建复杂场景或者找出现有chatbot存在的技术问题和面临的技术难点打下基础。</p>
<h1 id="api-ai"><a href="#api-ai" class="headerlink" title="api.ai"></a>api.ai</h1><h2 id="api-ai公司介绍"><a href="#api-ai公司介绍" class="headerlink" title="api.ai公司介绍"></a>api.ai公司介绍</h2><blockquote>
<p>Api.ai provides developers and companies with the advanced tools they need to build conversational user interfaces for apps and hardware devices.</p>
</blockquote>
<p>这家公司是一家典型的B2D公司，提供了一些工具帮助开发者轻松地开发一款bot，并且可以轻松地发布到各种message平台上。商业模式也非常简单，免费用户有一定次数的调用权限，需要大量调用的话，则付费购买，不同的权限有不同的价格，该公司也提供高级定制化服务。</p>
<p>api.ai公司成立于2010年（数据来自<a href="https://www.crunchbase.com/organization/api-ai#/entity" target="_blank" rel="external">CrunchBase</a>），其早期业务不清楚，但可以从提供的服务中推断出早期攒了大量的用户数据，而且涉及的领域非常多，比如：<br><img src="media/2.png" alt="2"></p>
<p>每个领域都有一个知识库，如果你要开发某个常用领域内的chatbot，那么这个知识库将会非常有用。</p>
<h2 id="重要概念和工作原理"><a href="#重要概念和工作原理" class="headerlink" title="重要概念和工作原理"></a>重要概念和工作原理</h2><h3 id="重要概念"><a href="#重要概念" class="headerlink" title="重要概念"></a>重要概念</h3><p>1、Agents。这个是一个对外接口，与其他应用程序或你的app进行整合的部分。如下图：<br><img src="media/3.png" alt="3"></p>
<p>2、Entities。这里的实体和引言中提到的Slot类似，是指某个特定领域内的实体，是一类东西的抽象概括，比如HotelName这一实体，对应着很多的酒店名字，凯宾斯基、如家等等。有Entity，就一定有value，chatbot中重要的一步正是从user input中抽取出对应预先设定好entity的value，是一个典型的Named Entity Recognition任务。</p>
<p>这里经典的NER任务是识别出user input中的person、time、place等等几个基本元素，api.ai将这些常见的entity定义为system级的，即默认提供了训练好的识别器，当然不仅仅限于这几类基本的；而特定领域知识库的重要作用也正是在于识别该领域内的entity。除了system level的NER之外，需要developer自定义一些entity，比如菜名，而且要给定具体的菜名和相似的表达作为samples进行训练。</p>
<p>3、Intents。这个相当于是从user input到chatbot执行某个action之间的一个映射关系，用户输入一句话之后，chatbot就可以理解其意图，是在打招呼，还是查询，还是做些别的事情。这部分api.ai提供了训练器，但是需要developer定义一些标注好的examples，标注的形式如下：<br><img src="media/4.png" alt="4"></p>
<p>这里用户输入是book a ticket to Los Angeles on Monday，所谓标注包括两个level，一个是entity标注，一个是intent标注，前一个是为了训练NER工具，后一个是为了识别intent。这里因为LA是地名，Monday是时间，所以都会被api.ai的系统自动标注出来。</p>
<p>4、Actions。这个是由intents进行trigger的，actions就和引言中的Act类似，是一个具体的动作，比如说查询，但执行动作的时候一般都要带上具体的参数value，用户输入：“三里屯最近的阿迪达斯店在什么位置？”，chatbot首先会提取出place-&gt;三里屯，query-&gt;阿迪达斯店，然后转换为json丢给后台的查询服务，查询到结果后给出答案。这里的value抽取其实就是第二个概念提到的entity value。</p>
<p>5、Contexts。上下文是一个非常重要但却解决不是很好的点，api.ai提供的方式是自定义一些context condition，当condition满足时，自动trigger出context关联内容template，然后filling slots，生成response。</p>
<h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>以RSarXiv chatbot为例，简单介绍下工作原理。<br>（注：RSarXiv是我之前写的一个arxiv paper推荐系统）</p>
<p>step 1 自定义Entity，这里我定义了两个entities，一个是keywords和subject。keywords是为search功能提供value，而subject是为update new papers功能提供value。<br><img src="media/5.png" alt="5"><br>定义好subject entity之后，我给出了几个examples，同时也包括其synonyms，keywords entity类似。</p>
<p>step 2  自定义Intents，这里我定义了两个Intents，分别是update和search。下图是update的examples，是我自定义的几个例子。api.ai会根据我定义好的entity进行自动标注，比如cs.CL，today是系统默认的entity所以也进行了自动标注。自动标注是为了后台的机器学习算法对标注好的examples进行学习，以提高chatbot的NLU准确率。<br><img src="media/6.png" alt="6"></p>
<p>接下来，我需要定义下Actions，如下图：<br><img src="media/7.png" alt="7"><br>Action被称为update，必须包含的参数是subject，也就是我们上面讲到的一个entity，date参数并不是必须的。所以，这里如果用户的input被识别出是update intents的话，就必须包括subject参数，否则chatbot会trigger一个response，类似“请用户输入subject”这样的话。</p>
<p>step 3 简单测试，在界面的右侧有一个console，用来测试当前chatbot的效果，我输入update cs.CL，得到下面的效果：<br><img src="media/8.png" alt="8"><br>chatbot识别出Intent是Update，Action是update，Parameter是date和subject，并且subject的值是cs.CL，下面的Show JSON是api.ai为developer生成的，用来与developer自己的web service进行数据交换。</p>
<p>step 4 训练。训练包括两个部分，一是训练NER，二是训练Intent Classification。训练器是api.ai提供的，但是标注数据是developer自己提供的，当然训练数据越多，标注越准，分类器的准确率就越高，chatbot的NLU准确率越高。至于训练方法，docs中没有细说，我简单猜测一下，NER可以当做Sequence Labeling任务，和Intent Recognition类似，都可以看作是多分类问题，不管是传统的分类方法还是当下流行的deep learning方法都能得到不错的准确率。随着user logs的增多，训练数据会越来越多，chatbot通过学习就会变得越来越“聪明”。但这里有个问题，training data越多，需要标注或者修改标注的数据就会越多，也是一个麻烦事儿。</p>
<p>step 5 整合、发布。api.ai支持的平台非常多，包括当下流行的message平台，还有各种操作系统平台。在message平台上提供了一键整合的功能，在操作系统上提供了SDK。这里我用了slack平台，api.ai打通了和slack的接口，也提供了webhook，连接了我之前写好的web service，只需要按照它给定的消息接口进行定义即可。</p>
<h3 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h3><p>目前RSarXiv只提供两个简单的功能，一个是update今天最新的arxiv paper，你可以通过show me new papers in cs.CL等类似的话来获取cs.CL这个领域中最新的paper；一个是search功能，你可以通过search LSTM等类似的话来获取包括LSTM这个关键词的paper。由于是一个测试用的demo，就没做什么复杂的功能。<br><img src="media/10.png" alt="10"></p>
<p>大家如果感兴趣的话，可以留言给我或者发邮件给我(mcgrady150318@gmail.com/mcgrady150318@163.com)，我邀请大家到这个slack team中。</p>
<h1 id="简单场景chatbot构建方法"><a href="#简单场景chatbot构建方法" class="headerlink" title="简单场景chatbot构建方法"></a>简单场景chatbot构建方法</h1><p>介绍了下api.ai提供的服务，下面简单地提炼一下。</p>
<p>chatbot = NLU + NLG</p>
<p>api.ai解决的重点问题是NLU的问题，NLU也是Dialogue State Tracker(DST)的核心和基础，而DST是chatbot的核心。这里的NLU包括两个问题：</p>
<p>1、从user inputs中识别出user intent和对应的action。</p>
<p>2、从user inputs中抽取出预先设定好的entity value，作为action的parameter。</p>
<p>NLG在api.ai这里基本上通过developer在Intent中设定response，当识别出是哪个intent之后，response自然就有了，最多空一些slot，用结果进行填充。如果developer选择了webhook，即需要从自定义的web service中给定response。如下图：<br><img src="media/9.png" alt="9"></p>
<p>跑了一个简单场景的chatbot demo之后，简单归纳下构建方法：</p>
<p>1、从特定任务中归纳出Intents、Actions、Entities。</p>
<p>2、分别编写Intents、Entities的examples，两类examples是做DST的基础，用来训练chatbot准确地识别user intents和entity parameters，至于算法，自己写也可以，用api.ai也可以。</p>
<p>3、做好DST之后，chatbot就知道用户的意图和相应的参数，丢给后台的web service去执行，并得到执行的结果，然后填充预先定义好的templates，生成response，返回给用户。</p>
<h1 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h1><p>简单场景的chatbot关键之处在于做好DST，有一个叫Dialogue State Tracking Challenge的比赛正式为了解决这个问题而举办的。我们说，封闭域的chatbot涉及两个方面，一是NLU，一是NLG，前者通过大量的examples来学习一个分类器和抽取器，得到Dialogue State，而后者根据Dialogue State，生成合适的response。</p>
<p>NLU不是一个简单的事情，尤其是标注大量的examples不是那么容易；NLG同样也不是一个好解决的问题，预先定义的template会让chatbot受限制于template的多少，手工痕迹太重，需要一种更牛的解决方案来代替。（其实挺多paper都在做这件事情，PaperWeekly也分享过几篇相关的paper，data driven的NLG方案同样需要大量的examples做训练。）</p>
<p>Context是个挺难的事情，现有的、成熟的解决方案仍是手工来定义条件，然后根据条件来trigger。我在想，能否构建一个动态的DST，可以是一张动态hash table，也可以是一个动态graph，记录着某一个user方方面面的状态，而不仅仅是某一轮对话中抽取出的信息，而是多轮对话中的信息，不仅在intent识别中可以用到context，在生成response时也可以用到，多轮对话和个性化对话都将不是什么问题了。或者，用现在流行的表示学习思维来想这个问题的话，也许context可以是一个分布式表示，user profile也是一个表示，NLG时以context distribution为condition来做generatation。</p>
<p>本文介绍了构建简单场景下chatbot的一般方法，用api.ai确实很容易做一个chatbot，而对于复杂场景，我觉得用api.ai来开发也没有太大问题，最费时的可能是构建context trigger。api.ai因为是面向developer的，所以对于普通的用户并不适合，但对于有一定经验的developer来说，使用起来就非常简单，提供的web界面也很好用，如果说chatbot是一个平台的话，那么api.ai正像是一个开发工具，提高了开发chatbot的效率，虽然NLG和context这两个问题可以做的更好，但整体来说降低了开发chatbot的门槛，是个很有意义和钱景的服务。</p>
<h1 id="PaperWeekly招人广告"><a href="#PaperWeekly招人广告" class="headerlink" title="PaperWeekly招人广告"></a>PaperWeekly招人广告</h1>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引&quot;&gt;&lt;a href=&quot;#引&quot; class=&quot;headerlink&quot; title=&quot;引&quot;&gt;&lt;/a&gt;引&lt;/h1&gt;&lt;p&gt;chatbot无疑是当前非常火的一个研究领域和产品方向，简单地可以分为两类，开放域bot和封闭域bot，开放域bot倾向于解决所有的事情，而封闭域b
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="api.ai" scheme="http://rsarxiv.github.io/tags/api-ai/"/>
    
      <category term="chatbot" scheme="http://rsarxiv.github.io/tags/chatbot/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 第二期</title>
    <link href="http://rsarxiv.github.io/2016/08/16/PaperWeekly-%E7%AC%AC%E4%BA%8C%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/08/16/PaperWeekly-第二期/</id>
    <published>2016-08-16T23:53:50.000Z</published>
    <updated>2016-08-17T05:50:30.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p><img src="media/1.png" alt="1"><br>图片来自paper <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" target="_blank" rel="external">The Dialog State Tracking Challenge Series- A Review</a></p>
<p>人机对话系统通常包括上面的几个部分，task-oriented chatbot重点关注的是DST和NLG问题，其中DST是核心问题，没有太多关注这个比赛，但个人理解DST的作用类似于一张user conversation logs状态表，记录着用户当前的状态，以订机票为例，这张表的key是预先设定好的slots，比如目的地、出发地、出发时间等等，与系统背后的业务数据表中的attributes相关联，不断地从user conversation中抽取相应的values来填充这个表格，或者将其定义为一个多分类任务，不断地从对话中判断这句话中包括哪些slots和values（这里的values是多个分类结果），当状态表中的信息存在空白时，bot会根据空白的slots来提问并获取values，直到获取到足够的slots，给出用户suggestion，或者进行相应的服务。</p>
<p>DST的问题解决之后，就是NLG的问题。传统的NLG采用rule-based或者template-based的方法，需要很多的手动设置，横向扩展性较差，维护成本高。最近流行的end-to-end方案很适合解决这个问题，给定用户的query，结合着当前DST，自动生成response，完全的data driven，不需要什么人工干预。</p>
<p>生成response除了rule-based和end-to-end的方法之外，工业界中更加常见的是retrieve-based的方法，即从庞大的example base中进行retrieve，一方面避免了NLG生成response时常遇到的grammatical问题，另一方面当前的IR技术很容易集成到此类bot系统中，降低了门槛。</p>
<p>本期的三篇paper中前两篇都是关于task-oriented bot的NLG问题，第三篇是在retrieve-based bot的每个细小环节中应用了deep learning技术，并且将外部的非结构化文本作为数据源，从中select responses。</p>
<h1 id="Semantically-Conditioned-LSTM-based-Natural-Language-Generation-for-Spoken-Dialogue-Systems"><a href="#Semantically-Conditioned-LSTM-based-Natural-Language-Generation-for-Spoken-Dialogue-Systems" class="headerlink" title="Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems"></a><a href="http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP199.pdf" target="_blank" rel="external">Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems</a></h1><h2 id="关键词：NLG、bot、自定义LSTM"><a href="#关键词：NLG、bot、自定义LSTM" class="headerlink" title="关键词：NLG、bot、自定义LSTM"></a>关键词：NLG、bot、自定义LSTM</h2><h2 id="来源：EMNLP-2015"><a href="#来源：EMNLP-2015" class="headerlink" title="来源：EMNLP 2015"></a>来源：EMNLP 2015</h2><h2 id="问题：task-oriented-bot-NLG问题，给定了user-query和DST，如何生成一个更好的response？"><a href="#问题：task-oriented-bot-NLG问题，给定了user-query和DST，如何生成一个更好的response？" class="headerlink" title="问题：task-oriented bot NLG问题，给定了user query和DST，如何生成一个更好的response？"></a>问题：task-oriented bot NLG问题，给定了user query和DST，如何生成一个更好的response？</h2><h2 id="方法："><a href="#方法：" class="headerlink" title="方法："></a>方法：</h2><p>首先定义了两个概念delexicalisation和lexicalisation，前一个的意思是将句子中的slot-value用特定的token来替换，像是一种抽象，比如用food来代替对话中的各种食物名称；后一个的意思是将句子中的特定token还原回具体的value。</p>
<p>本文最大的亮点在于将传统的LSTM重新定义，针对这个具体问题在LSTM cell部分中添加了一层，Dialogue Act Cell，通过gate机制来保留合适的信息，比如slot keywords，如下图：</p>
<p><img src="media/2.png" alt="2"></p>
<p>这一层cell更像是一个keyword detectors，整个NLG仍是采用encoder-decoder框架。</p>
<h2 id="评论："><a href="#评论：" class="headerlink" title="评论："></a>评论：</h2><p>这层Dialogue Act Cell的目的是确保在decoding部分，不会遗漏任何一个slot，所以专门增加了一层cell来encoding act、slot-value信息，在生成时作为context vector。我觉得model的这个设计与attention机制有一点类似，只是attention更加地平滑，对每个word都有一个weight，而不是本文中的gate，非0即1。整体来说，自定义的cell是一个很有启发性的思路，针对具体问题的特点，修改现有的cell结构，也许会起到非常关键的作用。</p>
<h1 id="Natural-Language-Generation-in-Dialogue-using-Lexicalized-and-Delexicalized-Data"><a href="#Natural-Language-Generation-in-Dialogue-using-Lexicalized-and-Delexicalized-Data" class="headerlink" title="Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data"></a><a href="http://101.110.118.75/128.84.21.199/pdf/1606.03632v1.pdf" target="_blank" rel="external">Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data</a></h1><h2 id="关键词：NLG、bot、自定义LSTM-1"><a href="#关键词：NLG、bot、自定义LSTM-1" class="headerlink" title="关键词：NLG、bot、自定义LSTM"></a>关键词：NLG、bot、自定义LSTM</h2><h2 id="来源：arXiv-2016-06-11-cs-CL"><a href="#来源：arXiv-2016-06-11-cs-CL" class="headerlink" title="来源：arXiv 2016.06.11 cs.CL"></a>来源：arXiv 2016.06.11 cs.CL</h2><h2 id="问题：task-oriented-bot-NLG问题，是第一篇的升级版。"><a href="#问题：task-oriented-bot-NLG问题，是第一篇的升级版。" class="headerlink" title="问题：task-oriented bot NLG问题，是第一篇的升级版。"></a>问题：task-oriented bot NLG问题，是第一篇的升级版。</h2><h2 id="方法：-1"><a href="#方法：-1" class="headerlink" title="方法："></a>方法：</h2><p>本文是针对第一篇文章进行的改进版，改进的地方在于不仅仅利用了delexicalisation进行训练，而且利用了lexicalisation数据，从而提高了准确率，基本的模型框架与第一篇文章类似，不同的在于输入的处理，就是dialogue act的表示，如下图：</p>
<p><img src="media/3.png" alt="3"></p>
<p>每一个act representation由两部分组成，一部分是act、slots的one-hot表示，与文章一类似的结构，另一部分是由value的每个word embedding组合而成。</p>
<p>task-oriented bot NLG存在的一个更加现实的问题是data规模太小，cover的features太少，生成质量不高，本文针对这一问题，用相似domain的、大量的reviews或者其他相关数据作为corpus预训练出一个效果不错的LM，在decoding部分采用预训练好的LM模型权重进行NLG。</p>
<h2 id="评论：-1"><a href="#评论：-1" class="headerlink" title="评论："></a>评论：</h2><p>本文中最值得借鉴的地方在于transfer learning，虽然DL效果很好，但实际应用中常常遇到data规模太小的问题，DL难以发挥作用，但如果从大量相似的domain data中学习一些表示模型，然后迁移到待解决的问题上，这是一件幸事，也就是人们常说的举一反三。混合大量的相似domain数据，会cover到更丰富的features，为DL提供了广阔的舞台。</p>
<h1 id="DocChat-An-Information-Retrieval-Approach-for-Chatbot-Engines-Using-Unstructured-Documents"><a href="#DocChat-An-Information-Retrieval-Approach-for-Chatbot-Engines-Using-Unstructured-Documents" class="headerlink" title="DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents"></a><a href="http://aclweb.org/anthology/P16-1049" target="_blank" rel="external">DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents</a></h1><h2 id="关键词：Retrieve-Based-Bot，Unstructured-Documents"><a href="#关键词：Retrieve-Based-Bot，Unstructured-Documents" class="headerlink" title="关键词：Retrieve-Based Bot，Unstructured Documents"></a>关键词：Retrieve-Based Bot，Unstructured Documents</h2><h2 id="来源：ACL-2016"><a href="#来源：ACL-2016" class="headerlink" title="来源：ACL 2016"></a>来源：ACL 2016</h2><h2 id="问题：如何从大量非结构化文本中select出合适的response返回给用户？"><a href="#问题：如何从大量非结构化文本中select出合适的response返回给用户？" class="headerlink" title="问题：如何从大量非结构化文本中select出合适的response返回给用户？"></a>问题：如何从大量非结构化文本中select出合适的response返回给用户？</h2><h2 id="方法：-2"><a href="#方法：-2" class="headerlink" title="方法："></a>方法：</h2><p>本文研究的问题是给定大量的非结构化的documents和用户的query，从中选择并返回一个满意的response，典型的IR问题，作者将解决方案分为三步：</p>
<p>1、response检索，根据query，从documents中找到合适的N句话作为候选。</p>
<p>2、response排序，将候选中的utterances进行排序。</p>
<p>本文大多数的工作在ranking model上，提出了7种level的features来对candidate进行打分，通过实验发现sentence-level feature最有区分度。</p>
<p>3、response触发，并不是一定可以从documents找到合适的response，所以最后添加一个分类器，来判断最优的response是否合适，合适则输出，不合适则输出空。</p>
<h2 id="评论：-2"><a href="#评论：-2" class="headerlink" title="评论："></a>评论：</h2><p>本文解决的问题思路比较简单，但中间用到了很多复杂的DL model，个人感觉有点杀鸡用牛刀。本文的思路更加适合informative式的query，并不适合娱乐和闲聊。但用外部知识，尤其是大量的非结构化的、可能还带有噪声的资源来提供response，是一个很不错的思路，弥补了只用training data或者很有限的examples存在的局限性问题，如果可以将两者进行结合，是一个非常好的实用方案。</p>
<h1 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h1><p>引起大家的讨论是一件挺难的事情，所以这一期不再提出问题。之前有同学问如何读paper，这里简单分享一个简单的tip，后续的每一期可能都会分享一个tip。</p>
<p>1、如果刚刚进入一个领域，建议读一些这个领域的survey或review类型的paper，这类型的paper基本上会将最近的方法归类进行总结，从一个较高的层次来解读每一篇paper的贡献和优缺点，对快速了解一个领域很有帮助。如果你关注的这个领域没有survey，那么恭喜你，说明你可能走到了前沿，用关键词去google一篇或者几篇相关的new paper，读Related Work那一节，相信你会有所收获。（注：这个方法是从清华大学刘知远博士那里学来的）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引&quot;&gt;&lt;a href=&quot;#引&quot; class=&quot;headerlink&quot; title=&quot;引&quot;&gt;&lt;/a&gt;引&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;media/1.png&quot; alt=&quot;1&quot;&gt;&lt;br&gt;图片来自paper &lt;a href=&quot;https://www.microsof
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>pet,baby and bot</title>
    <link href="http://rsarxiv.github.io/2016/08/16/pat-baby-and-bot/"/>
    <id>http://rsarxiv.github.io/2016/08/16/pat-baby-and-bot/</id>
    <published>2016-08-16T16:06:36.000Z</published>
    <updated>2016-08-16T21:07:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文的想法来源于某一天对家里狗子Hare一些行为以及身边两个不到3岁的小朋友一些聪明行为的观察和思考，然后将这些行为和思考与当前流行的bot联系一下，形成了本文的内容。</p>
<p>首先，从pet聊起。我家养了一只聪明的小泰迪狗，心眼特别多，会撒娇会打滚会安慰人，非常聪明，他叫Hare。Hare从两个月大到了家里，从开始什么都不会，通过一天天地训练，学会了走、跑、跳、吃饭、喝水、上厕所、坐下、握手和哭。因为他的外婆（我的丈母娘）每天都和他说很多话，教他认识很多东西，所以他可以轻松地分辨出哪个玩具叫什么名字，可以轻松地理解我们说的很多话，不只是一些口令。当我说出门不带他玩的话，他会非常悲伤、可怜地开始哭泣（真的和小孩子哭一模一样）；当我说带他出去的时候，他就会非常兴奋地上蹿下跳；当我说我要出门办事不可以带他的时候，他就乖乖坐在门口目送你走，不哭不闹。所以，我在想Hare应该不是简单地通过观察我们的脸色和语气来识别我们的情绪，他可能真的听得明白很多的话，但一定不是全部，因为他的知识很有限，对这个世界的认识也很有限。Hare的学习绝大多数是监督学习，通过一些正例和负例进行训练，大多数的训练用正例效果非常明显，唯独训练他上厕所，用了不少负例，让他吃了不少苦头，这也带来不少的好处，监督学习很花费时间，样本的量级很重要，通过大量的训练+激励让Hare养成了良好的习惯，成为了一只听话的pet。</p>
<p>我一直在思考一个问题，pet在听主人说话的时候，是听懂了某些他可以理解的关键词还是他确实听懂了整句话，到底是字面意思还是semantic level呢？我想他应该有一定的自主学习能力，做到举一反三可能很难，但举一反二还是有可能的，而不仅仅是从大量的examples中进行学习，确实能够理解一些简单的话，同一个意思的不同说法他都可以理解。科学的解释需要做些实验来研究，这里我有一些简单的解释，第一，他有大脑，虽然没有人类发达，但智商可以和5、6岁的孩子相媲美；第二，他的监督学习不仅仅是从query-response pairs这样的examples中进行，而是更多的维度，包括每一次action之后的激励reward，做对一次动作之后赢得一个奖励，做错了受到惩罚，他不仅仅从主人的语言中来理解意思，还会结合别的因素，比如语调、语境、前一个时刻他的状态等等，而且他可以看到主人的表情和动作，这些因素都可以抽象成一种context。Hare如果前一秒刚刚犯了低级错误，这一秒如果我拿一个零食的叫他过来来吃的话，他就会明白，这其中一定有诈，他一定不会过来，虽然我并没有表现出生气的样子。</p>
<p>pet的事情我们先聊到这里，接下来聊一聊baby的事情。</p>
<p>身边正好可以接触到两个不到三岁的小宝宝，一个男孩一个女孩，他们有很多聪明的行为都让我感到吃惊。先从小男孩说起，小男孩每次来一起吃饭的时候，都会给大家表演他的绝技——认车牌。走在路上，你随意指一辆车，他几乎可以不出错地说出这辆车是本田还是丰田、还是起亚，这是一个典型的有监督多分类学习任务，他的父母有意无意地教他认识各种各样的车，经过一定时间和example的积累，他不断地将准确率提升，可能大脑的发育和将deep learning模型不断地复杂化道理类似吧。学习的过程是积累知识的过程，小男孩慢慢地认识了越来越多的车子，当然这需要不断地教和学，但无疑他本身就是一个知识库（knowledge base），而且认识很多我都不认识的车子，所以当我问他那是什么车的时候，他总是能够给我一个不错的答案。</p>
<p>说完小男孩的事情，再聊一聊小女孩的事情。小女孩语言能力很强，可以说很多的话，而且很多话都非常的funny。基本上和小女孩聊天，就是一个有趣的问答过程，这里的问答不只是我问她答，还有她问我答。小女孩经常和我妈妈在一起，妈妈会教她认识各种东西，因为妈妈信基督教，会教她做祷告，保佑自己一生平安，所以说她不仅仅可以回答一些基本的认知问题，而且有自己的特殊技能，表演“祷告”，而且做的有模有样。她是个求知欲非常强的问题宝宝，她总是指着一个东西，然后开始问我，“这是个什么东西？”，她主动学习的欲望很强，这意味着她的知识库积累地很快。以上都是比较常规的，最值得思考的是她的创造力。她认识很多的动物，也知道怎么称呼这些动物，她根据家里每一个人的名字，起了相应的动物外号，这个不是谁教她的，是她自己说出来的东西；之前提到的祷告词中，原话应该是希望上帝可以赐给她一些聪明智慧，那天在给我们“表演”的时候说出来的是“给她弄一些聪明智慧”，我想这个“弄一些”一定是其他的地方学来的，但她迁移到了这个语境中，这个迁移能力是值得思考的。我们都说理解一个东西不算厉害，如果能够掌握或者控制一个东西才算真正的厉害，她如果只是简单地重复已经学会的知识，也并不稀奇，但她偶尔会有意地装糊涂，故意地说一些错的东西看你能不能识别出来她的错误，她对一些信息的掌握程度很高。</p>
<p>小盆友的创造力让人惊奇，有很多值得思考的地方，相比于pet来说，baby的学习能力更强，带给人的惊喜度更大。chatbot，一个热门的topic，一个大家每天都在谈论的东西，确实还有很长的路要走，太多的地方不能令人满意。</p>
<p>1、最简单的一问一答现在都没有做的很好，example-based和rule-based虽然可以work，但限制太大，前者被example所限制，而后者被rule所限制，而paper中近一段时间流行的所谓generative式的bot看起来好像非常智能，读过paper之后会发现仍是基于example统计的，不管多么牛的模型，都是从example中学习features，example的规模和类型都会严重制约model，而且在生成response时面临着连贯性和语言学的问题，这也是被诟病最多的地方，也就是为什么example-based retrieve式的方法仍是主流的原因。</p>
<p>2、bot应该像人一样具有学习能力，尤其是主动学习能力。现在的bot有self-taught的能力，通常比较被动，并不具备主动学习的意识和能力。bot公司宣传的学习能力也通常是指对log的挖掘，从中找到一些有用的东西存在知识库里，丰富现有的example base。bot可以试着多提一些question，而不仅仅是做answer，主动地学习一些东西。</p>
<p>3、对context的利用和分析还有很长的路要走，context有很多种，如果是纯粹的语言bot，那么就是user之前说过的话，user的情绪，user的意图等等，如果不仅仅是语言的话，正如前面在说pet时提到的，context可以包括图像、语调等等。考虑的东西越多，bot的回答质量就会越高。</p>
<p>4、前几天看了几家科技媒体对新一代微软小冰的报道，说实话丢出挺多概念的，仔细看了下是用增强学习的思路来做，和训练pet比较类似，用一个reward作为牵引，带着bot学习programmer希望bot学习的action。</p>
<p>5、人会举一反三，聪明的动物会举一反二，迁移能力很重要，bot学习过类似的东西，就应该可以做类似的事情，而不是每次都需要重新从头开始学习，如何将已经学习到的知识迁移到新的领域也是一个非常有意义的topic。</p>
<p>从pet到baby，再到bot，从动物到人类，再到机器人，有着难以跨越的鸿沟，但pet、baby的行为可以带来启发和思考，给目前仍停留在初步阶段的bot带来一丝春风，一丝希望。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文的想法来源于某一天对家里狗子Hare一些行为以及身边两个不到3岁的小朋友一些聪明行为的观察和思考，然后将这些行为和思考与当前流行的bot联系一下，形成了本文的内容。&lt;/p&gt;
&lt;p&gt;首先，从pet聊起。我家养了一只聪明的小泰迪狗，心眼特别多，会撒娇会打滚会安慰人，非常聪明
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>PaperWeekly 2016.08.05 第一期</title>
    <link href="http://rsarxiv.github.io/2016/08/05/PaperWeekly-2016-08-05-%E7%AC%AC%E4%B8%80%E6%9C%9F/"/>
    <id>http://rsarxiv.github.io/2016/08/05/PaperWeekly-2016-08-05-第一期/</id>
    <published>2016-08-05T18:22:47.000Z</published>
    <updated>2016-08-06T00:03:20.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>学术界和工业界的需求和关注点不同，学术界更加注重未知领域的探索和方法的创新，研究的问题比较抽象，而工业界更加关注实际问题，方法不管是否创新，只要能够解决问题就是好方法，所面对的问题比paper中提炼出的数学问题更加具体，需要处理的细节更多。</p>
<p>paper的水平也是良莠不齐，尤其是arxiv上刷出来的paper更是水平各异。但整体来说，读paper会带来很多的启发，可以跟踪学术界对某一类问题的研究进展，不断地更新技术。关注工业界技术的应用和产品的更迭，可以不断地提炼出新的需求、新的数学问题，从而促进学术地发展，两者其实关系非常紧密。</p>
<p>本周开始，将paperweekly进行改版，从之前的每天一篇paper，改为每周一篇，内容包括多篇paper，这些paper可能相关、也可能不那么相关，但会说清每篇paper解决的问题和解决的方法，旨在拓宽视野，带来启发。本期是改版后的第一期，形式会一直不断地改进，希望工业界和学术界的朋友都能够有所收获。</p>
<h1 id="DeepIntent-Learning-Attentions-for-Online-Advertising-with-Recurrent-Neural-Networks"><a href="#DeepIntent-Learning-Attentions-for-Online-Advertising-with-Recurrent-Neural-Networks" class="headerlink" title="DeepIntent: Learning Attentions for Online Advertising with Recurrent Neural Networks"></a><a href="http://www.kdd.org/kdd2016/papers/files/rfp0289-zhaiA.pdf" target="_blank" rel="external">DeepIntent: Learning Attentions for Online Advertising with Recurrent Neural Networks</a></h1><h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>在线广告、RNN、Attention</p>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>kdd2016</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>如何用deep learning模型挖掘click logs来理解用户Intent？</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p><img src="media/1.png" alt="1"></p>
<p>对于一个(query,ad)数据对，分别用LSTM encode，然后用下图的方法计算一个attention，得到最终的query和ad vector，构造loss function，取logs中(query,ad)作为正例d+，将ad替换为其他无关ad作为负例d-，训练的目标是让d+的score尽量大，让d-的score尽量小。</p>
<p><img src="media/2.png" alt="2"></p>
<h2 id="评论"><a href="#评论" class="headerlink" title="评论"></a>评论</h2><p>工业界有着学术界无法比拟的数据，大规模的真实数据是做deep learning的基础，大型商业搜索引擎积累了大量的ad click logs，利用好这些logs可以赚到更多的钱。attention机制在2015年开始逐渐成为一种流行趋势，借鉴于人类的注意力机制，让model将更多的注意力放在需要注意的地方，而不是每一个地方。本文并没有太多model上的创新，只是简单地将流行的model应用了自己研究的领域中，对工业界更有参考价值。</p>
<h1 id="A-Neural-Knowledge-Language-Model"><a href="#A-Neural-Knowledge-Language-Model" class="headerlink" title="A Neural Knowledge Language Model"></a><a href="http://120.52.73.76/arxiv.org/pdf/1608.00318v1.pdf" target="_blank" rel="external">A Neural Knowledge Language Model</a></h1><h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>语言模型、知识图谱</p>
<h2 id="来源-1"><a href="#来源-1" class="headerlink" title="来源"></a>来源</h2><p>arXiv cs.CL 2016.08.01</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>在自然语言生成(NLG)问题中，出现次数非常少的entity该如何生成呢？</p>
<h2 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h2><p><img src="media/1-2.png" alt="1"></p>
<p>四个步骤：</p>
<p>1、Input Representation<br><img src="media/2-1.png" alt="2"></p>
<p>输入由三个部分拼接而成，第一部分是上一个time step的fact表示，第二部分是上一个time step的词表中的词表示，第三部分是上一个time step的fact description表示，这里fact就是(subject,relation,object)，知识图谱中的一条事实，而后两个部分一定会有一个全为0，因为是二选一的关系，但为了保证每一次的输入都是等长向量，所以用拼接来做。得到输入之后，用LSTM来encode。</p>
<p>2、Fact Prediction</p>
<p>通过1的结果来预测当前word可能相关的fact，得到的结果是一个index，然后从topic knowledge中获得相应的表示，这里的knowledge embedding都是用transE训练好的，在整个模型训练中并不更新。</p>
<p>3、Knowledge-Copy Switch</p>
<p>根据1和2的结果，共同来预测当前要生成的词是从词表中获取的高频词还是从knowledge中获取的entity，典型的二分类问题。</p>
<p>4、Word Generation</p>
<p>根据3的结果，来生成当前time step的词。对于词表中的高频词，和之前的生成方法一致；对于fact description中的entity词，通过预测词的position来copy这个词。</p>
<h2 id="评论-1"><a href="#评论-1" class="headerlink" title="评论"></a>评论</h2><p>语言模型是一个基本问题，传统的方法都有着一个尴尬之处是，会生成大量的<unk>出来，只要是涉及到NLU的问题，基本都会遇到这个问题。本文提供了一个很有启发性的方法，借助于知识图谱这种外部知识来帮助生成效果更好的话，单纯地靠model来提升效果是一件比较困难的事情，但增加一些外部信息进来则会带来更多的可能性。由于知识图谱的构建本身就是一件不易的事情，因此本文的学术意义远大于实际应用意义，为后续这种交叉式研究（知识图谱+深度学习）打开了一扇门，大家可以尝试更多的组合和可能。</unk></p>
<h1 id="Neural-Sentence-Ordering"><a href="#Neural-Sentence-Ordering" class="headerlink" title="Neural Sentence Ordering"></a><a href="https://arxiv.org/pdf/1607.06952v1.pdf" target="_blank" rel="external">Neural Sentence Ordering</a></h1><h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>句子排序</p>
<h2 id="来源-2"><a href="#来源-2" class="headerlink" title="来源"></a>来源</h2><p>arXiv cs.CL 2016.07.23</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>给定乱序的N句话，如何将其按照逻辑排列好？（貌似是英语考试中的一种题型）</p>
<h2 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h2><p><img src="media/1-3.png" alt="1"></p>
<p>本文定义的问题是给定n句话，找出最优排序，将这个问题降维到二维，就是如何排列两句话的顺序。上图给出了model的思路，对两句话分别进行encode，得到两个向量表示，然后进行打分，分数表示当前顺序是正确顺序的概率。这里的encode部分，分别用了每句话中word embeddings的加权平均、RNN和CNN来表示。</p>
<p>得到两两的排序之后，本文用beam search来得到整体最优的排序。</p>
<h2 id="评论-2"><a href="#评论-2" class="headerlink" title="评论"></a>评论</h2><p>多文档摘要问题中通用的一种做法是从每篇文档中都提取出一句或几句重要的话，然后进行排序。在英语考试中，有一种题型是给定你打乱顺序的几段话，然后根据逻辑将其排序。本文在学术上没有什么新的东西，但本文在构建neural model的时候，用到的数据集却非常容易构建，这意味着你在工程中应用这个方法来解决排序问题是可行的方案，所以本文更加适合有句子排序应用需求的工程人员来精读。</p>
<h1 id="提问"><a href="#提问" class="headerlink" title="提问"></a>提问</h1><p>计算机的会议非常多，各种level的都有，arXiv上每天都可以刷出一些paper，不同类型、不同level的paper适合不同需求的人来读，我觉得好东西的标准是适合而不是在某一个具体指标上达到最大，对你有用的东西才是适合你的好东西，有些特别牛逼的东西，有着极高学术价值的东西不见得适合工程人员来读，但也不应该是那种觉得学术上的东西离工程太远，没有什么具体用的态度，从各种各样的东西汲取养分，丰富和充实自己才是硬道理。读了一些paper，也该思考一些问题了，这里提出一些比较naive的问题，欢迎大家踊跃留言和讨论。</p>
<p>1、<unk>这种out-of-vocabulary的问题是一个非常常见的问题，有哪些不错的思路可以来解决这个问题呢？</unk></p>
<p>2、attention model几乎满大街都是，最早在机器翻译领域中开始用这种模型，虽然在其他nlp领域中都取得了不错的成绩，但目前的attention真的适合每一类具体问题吗？是不是有一点为了attention而attention的感觉？neural summarization和machine translation真的可以完全类比吗？或者说attention适合解决具有什么特征的问题呢？</p>
<p>3、信息越多，model的效果一定会越好。现在外部信息非常丰富，但是如何融合到当前流行的model中来呢？如何将特定领域内构建的知识图谱完美地与特定任务中的model进行结合呢？以task-oriented bot为例，能够将客户的领域知识与bot response功能结合起来，做成一个更加高级的bot呢？</p>
<p>这里，我抛个砖，引个玉，希望更多的人能够参与讨论和提出问题。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引&quot;&gt;&lt;a href=&quot;#引&quot; class=&quot;headerlink&quot; title=&quot;引&quot;&gt;&lt;/a&gt;引&lt;/h1&gt;&lt;p&gt;学术界和工业界的需求和关注点不同，学术界更加注重未知领域的探索和方法的创新，研究的问题比较抽象，而工业界更加关注实际问题，方法不管是否创新，只要能够
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
  </entry>
  
  <entry>
    <title>旧幕落下，新幕升起</title>
    <link href="http://rsarxiv.github.io/2016/08/02/%E6%97%A7%E5%B9%95%E8%90%BD%E4%B8%8B%EF%BC%8C%E6%96%B0%E5%B9%95%E5%8D%87%E8%B5%B7/"/>
    <id>http://rsarxiv.github.io/2016/08/02/旧幕落下，新幕升起/</id>
    <published>2016-08-02T18:54:22.000Z</published>
    <updated>2016-08-02T20:33:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>从过年那会筹划一些婚礼的想法开始，到拍婚纱照、找婚庆、跟拍、摄像、化妆、服装、场地、喜宴、安排接送车辆、亲朋住宿以及最近一个月疯狂地在淘宝上购买各种所需的东西，花费的所有时间和精力随着2016.07.31这一天这一场婚礼一起完美谢幕了，整个婚礼结束之后，我带着我的新娘子坐着地铁回家，想想大概也没有谁了。</p>
<p><img src="media/1.pic.jpg" alt="1.pi"></p>
<p>两天过去了，仍然没有从7.31的那场梦里醒来。感谢各位来宾，感谢各位工作人员，感谢保障小组的几位童鞋，感谢烁哥的乐队，感谢祝福我们的每一位！</p>
<p>当时家里不建议7.31结婚，因为他们很迷信地说8.1或者7.29更加适合结婚，而且我妈提前半个月就看天气预报说31号那天有大雨（我早就断定天气预报不准，而且提前那么早看根本没用），但我们仍然坚持就是7.31，不管那天什么天气，都一定是这一天，因为2015.7.31这一天我们正式在法律层面上成为了夫妻，当时离七夕很近，但我们觉得非节日的一天更加适合作为我们的纪念日，于是就在那天领了证，当时我就对韵韵说，明年的今天就是我们大婚的日子，我们要办最有意思、最不一样的婚礼，她点头答应。我们的坚持、我们的固执证明了7.31这一天就是属于我们的，非常棒的天气让整个婚礼进行的非常顺利，非常完美。</p>
<p><img src="media/3.pic.jpg" alt="3.pi"></p>
<p>回礼的准备花费了我们太多的时间和精力，直到婚礼前三天才准备好所有的回礼。长沙这边的一般做法都是准备一盒烟、一袋槟榔和一盒喜糖，当时我们就说要做的不一样，于是韵韵开始了每天长达两小时的淘宝生涯，并且乐此不疲，一盆多肉、一盒果酱和一盒手工喜糖。150份回礼，需要种150盆花，手工装150个喜糖盒子，装150个果酱盒，多亏了几位小同学的帮忙，才能顺利地准备好这些东西，韵韵喜欢兔子，所以袋子也是兔子，多肉的包装上贴着一张兔子贴纸，是我们这次婚礼的logo，是婚庆专门设计的。其实完全可以没必要这么累，直接买现成的就好，但是韵韵坚持要手工做每一个细节，希望每一个细节都做到完美，给宾客们带来不一样的感觉。她做到了！大家都非常喜欢这份回礼。</p>
<p><img src="media/2.pic.jpg" alt="2.pi"></p>
<p>婚礼主持人希望我们两个在婚礼现场可以真情告白一下，于是婚礼前的一周就没有踏实地睡好过，有一天夜里想着我们在一起的这一年多时间，点点滴滴都历历在目，又失眠了！那一晚想了很多很多，每一件事情的每一个细节都记忆犹新，想了很多想要对她说的话，平时也不会说什么深情的话，因为我也不是一个懂浪漫的人。她一直在忙着买各种各样必须的东西，所以直到婚礼前一天晚上在酒店里等我睡着了才开始准备告白的话，2点钟才睡觉，5点就起来准备化妆了。婚礼正式开始了，我之前准备好的词基本上都忘记了，确实有些紧张，但当我看到美丽的新娘站在我的面前时，我就一点都不紧张了，很自然地说出了我内心最真实的感动，以致于第一位伴娘哭的稀里哗啦的，韵韵的台风比我好，一句一句地讲出了我们在一起的美好！</p>
<p><img src="media/4.pic.jpg" alt="4.pi"></p>
<p>我和韵韵正式在一起是在马頔的演唱会上，是在2015.03.18，是我们认识后的第十天，一切看起来都很自然而然，没有任何刻意的安排。我一直有一个心愿就是能够办一场live concert，为我心爱的人献上她最爱的歌曲。于是，我决定在婚礼结束后，安排一场民谣风live concert，邀请喜欢唱歌的同学们一起来嗨。concert很成功，氛围非常好，烁哥的现场没的说，在座的每一位都沉浸在了当时的氛围中，我唱了马頔的《南山南》，韵韵唱了hebe的《小幸运》，一切都是那么地棒！</p>
<p><img src="media/6.pic_hd.jpg" alt="6.pic_hd"></p>
<p>韵韵说她最幸福的时刻就是每天早上醒来，看到身边的我和hare正在酣睡。hare是我们家的小狗，但全家都没有把他当做狗狗来养，我和韵韵是他的爸爸和妈妈，他还有外婆、爷爷和奶奶，每个人都特别爱他，他也是全家的开心果。如果说婚礼有遗憾的话，那就是hare没能来到现场见证他爸爸妈妈最幸福的一刻了。hare之所叫这个名字，是因为他刚刚来家里那会，我正对Air Jordan的Hare球鞋痴迷，Hare本是兔八哥的名字，所以就给他取了这个名字，后来不断地有了很多的名字，张甜心、张甜甜、小黑、心心等等好多的名字，他有一阵子有一些凌乱，突然不知道自己叫什么了。</p>
<p><img src="media/6.pic.jpg" alt="6.pi"></p>
<p>伴郎和伴娘都非常地帅气和美丽，他们给了我们很多的帮助和支持。伴娘都是韵韵的好闺蜜，有陪她一起长大的，有陪她一起工作的，有一个是这个世界上的另外一个她，她们相似的经历，让她们无话不谈，婚礼现场也就是她哭的最厉害了。伴郎都是我的小兄弟，他们替我扛了很多抢亲时的折磨，替我挡了很多的酒，三位伴郎在敬酒时毫无保留，最后通通倒下，有一点遗憾，没有能够参加最后的concert。感谢你们，因为你们，我和韵韵才会更加幸福！</p>
<p><img src="media/7.pic.jpg" alt="7.pi"></p>
<p>婚礼结束了，新的生活开始了！今年27岁，也该有一份自己的事业了，不管现在困难有多少，阻碍有多大，我和韵韵都要开始为我们的事业奋斗了！我一直觉得韵韵不仅仅是生活上的伴侣，更是心灵的伴侣，她最懂我的心，也不顾一切地支持我想做的事业，也愿意和我一起来奋斗这份事业。她细心、聪明、好学、热爱生活、眼光独到，所有美好的标签贴在她身上都不为过，她让我看到了更大的世界，让我明白了生活的意义，走进了我的内心深处让我不再孤独，她的勇敢、知性、独立都让我钦佩，给了我莫大的勇气，让我可以更加自信地活在这个世界上，去勇敢地挑战一些更难的事情。人生就是一场奇遇，感谢上帝让我遇见你！谢谢你，韵韵，我爱你！</p>
<p>旧的一幕已经落下，新的一幕正在升起。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从过年那会筹划一些婚礼的想法开始，到拍婚纱照、找婚庆、跟拍、摄像、化妆、服装、场地、喜宴、安排接送车辆、亲朋住宿以及最近一个月疯狂地在淘宝上购买各种所需的东西，花费的所有时间和精力随着2016.07.31这一天这一场婚礼一起完美谢幕了，整个婚礼结束之后，我带着我的新娘子坐着
    
    </summary>
    
    
      <category term="随笔" scheme="http://rsarxiv.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>如果我也做bot</title>
    <link href="http://rsarxiv.github.io/2016/07/25/%E5%A6%82%E6%9E%9C%E6%88%91%E4%B9%9F%E5%81%9Abot/"/>
    <id>http://rsarxiv.github.io/2016/07/25/如果我也做bot/</id>
    <published>2016-07-26T00:06:49.000Z</published>
    <updated>2016-07-26T00:55:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近初步地研究了下bot这个领域，有了一点浅薄的理解，于是开始想，如果我也做bot的话，解决好哪些问题才会做好这件事情？</p>
<p>1、创业是一件严肃的事情，不是儿戏，需要做好充足的准备，调研和积累都是非常重要的，只有做好100分的准备，才可能在面对各种未知的困难时不慌乱。所以，第一步就是调研，研究bot，从方方面面，比如：</p>
<p>（1）bot为什么会火？<br>（2）国内哪些企业在做bot？他们的产品有哪些优缺点？<br>（3）国外哪些企业在做bot？有哪些优缺点？<br>（4）投资情况如何？投资人怎么看待这个方向？<br>（5）bot需要哪些技术积累？</p>
<p>2、从媒体、投资人的观点来看，bot整个大方向没有错，那么到底应该做哪个子领域呢？是客服？还是技术支持？技术平台？垂直私人助理？平台上应用？可做的事情其实很多，16年开始才井喷式地炒作bot这个概念，所以今年可以当做是bot元年，既然是刚刚起步的一个领域，就有一个天然的好处，蛋糕足够大，品类足够多，看你想吃哪一块？当然也有一个天然的坏处，就是无章可循，大家都是摸着石头过河。</p>
<p>（1）国内的情况是，客服已经有很多家企业在做了，做的模式大同小异，技术方面各有特色吧，可能起步早的现在规模大一些，晚的小一些，但整体来看差异化不大。如果选择这个方向的话，必须做出差异化，研究现有方案的缺点，之前写过一篇文章，简单剖析了现有方案的缺点和可改进的点，让目前的客服bot更进一步，要么就是做一家客服bot，产品更完美、技术更好，和大家分一杯羹；要么就是提供技术支持，帮现有的bot企业更进一步，赚他们的钱。</p>
<p>（2）如果是做技术支持，典型的SaaS+B2B，用自己的技术服务来为别的企业提供支持，response generation、user modeling、context modeling、information extraction都是不错的方向，每一个做好了都有广阔的前景，以为技术支持不直接面对业务，而是帮助改进现有企业提升算法和建模能力，应用的面比较广，可以用在各种类型的bot上以及其他应用背景上。</p>
<p>（3）平台上的应用，比如slack上的bot，做一个有趣的小功能，提高team的工作效率。这个在国外非常地火，平台也很多，就像是现在ios上开发app一样，每个app都有自己的功能。我觉得这块要是做的话，很容易做出差异化，现在已经有各式各样的startups做着各式各样的bot。但整体来说，技术门槛比较低，有一点API整合的意思，但如果你将自己的技术封装成API，在上面做一个bot提供服务也是一种不错的尝试，而且产品周期特别短，但终究卖点应该还是你的技术支持，而不是这个bot。</p>
<p>（4）技术平台的话，类似的有很多帮助企业或个人构建bot在各种平台上跑，假如微信现在开放了这一块，技术平台一定大有用处，这个属于基础的工具类产品，将很复杂的技术做成人人可以轻松使用的工具是一件很有意义的事情，像是IDE的感觉，不管什么背景，只要是有想法，就可以通过这个工具来实现一个bot，如果复杂的，可能需要定制。</p>
<p>（5）特定任务的私人助理，比如帮忙管理日程、制定旅行计划之类的，术业有专攻嘛，这个最好是之前在其他平台上做类似功能的企业转型到bot这里来，有着足够的积淀，融入一些新的交互和技术来提升产品体验。</p>
<p>上面的每个子领域在国外都有模板可以参考，国内的话还比较少，所以是很大的机会，关键在于判断，在于具体情况具体分析。因为有些东西并不适合做成bot这种聊天式的交互方式，简单的几个按钮操作就可以轻松完成的事情，为什么非要打很多的字来做呢？</p>
<p>3、壁垒。你的核心竞争力是什么？什么是你会别人不会的？如果腾讯也做这个事情，你们该怎么办？你的企业增长点在哪里？如何做大？</p>
<p>这些问题是投资人最关注的问题，其实也是创业前最应该想明白的问题，如果自己都想不明白，或者很多问题难以回答的话，说明现在的情况还不适合创业或者拿投资。我认为，无论什么时候人都是最核心的竞争力，技术和交互形式日新月异，更迭很快，团队只要具有很强的学习能力，永远都不会落于下风。没有什么技术一定是只有你一人才会的，工程上的技术壁垒不应是你提出了一个举世无双、天下无敌的算法，而是你在这个领域内实践各种各样算法的经验积累。为什么说一定要专注地做好一个事情，只做这一件事情，将这件事情做到精，因为对这么细小的领域理解地如此之深的人没有几个，这是你的技术壁垒，也是企业的生存之道，也是其他大公司难以抄袭的重要原因。这个问题一定要想清楚，最重要的是人，在技术层面上，不要想着找到一个独门秘籍来打天下，而是对你所研究的问题有非常深入地理解和见解，这是最基本的也是最核心的；接下来才是如何发展和壮大的问题，这个问题需要讲故事的能力，描绘出一幅美好画面的能力。</p>
<p>我觉得人的能力是最根本的壁垒，当然会有不同看法。有的企业快速扩张，积累客户，可能觉得积累的数据和客户资源是壁垒，但我觉得如果一个新的更好用的技术出来了，而你的企业技术却没跟上的话，很容易就会被取代的，不管你是5w+，还是10w+的客户。</p>
<p>一点思考，欢迎交流。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近初步地研究了下bot这个领域，有了一点浅薄的理解，于是开始想，如果我也做bot的话，解决好哪些问题才会做好这件事情？&lt;/p&gt;
&lt;p&gt;1、创业是一件严肃的事情，不是儿戏，需要做好充足的准备，调研和积累都是非常重要的，只有做好100分的准备，才可能在面对各种未知的困难时不慌
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>bot,bot</title>
    <link href="http://rsarxiv.github.io/2016/07/25/bot-bot/"/>
    <id>http://rsarxiv.github.io/2016/07/25/bot-bot/</id>
    <published>2016-07-25T23:12:32.000Z</published>
    <updated>2016-07-26T00:05:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>科技媒体的文章有一个明显的好处，就是会报道很多不易被人发现、但却非常有意思的startups，帮助大家拓宽视野；同时也有一个明显的坏处，文章容易标题党，不够专业的编辑容易写出一些极端的结论，比如xxx一定会取代yyy，炒作概念。所以，这里借助了科技类媒体的优势，考察了下国外的bot startups所覆盖的业务和现状，总结如下：</p>
<p>1、外国的月亮比较圆。有一种常见的误区，也是由来很久的一种偏见，那就是国外的东西一定优质于国内的东西，单纯地从startups的主页来看，国外的风格整体更加清爽和小清新一点，而国内的主页整体来说，充满了一种网站模板没用心选的既视感，有些startups充满了乡土气息。但并不意味着，背后的技术一定比国内好，只是门脸做的不错，slogan喊得不错，每一个startup都有一个改变人类现有生活的理想，仔细看有可能只是一个驻扎在slack或者messenger平台上的小bot。</p>
<p>2、国外的bot startups种类比较多，各个level的企业都有，从最上面的应用层来说，slack、messenger、telegram、kik等各个message平台上都有大量的bot，包括各种各样的服务。这类bot门槛较低，缺乏核心技术，通常是一个idea来支撑整个企业，容易同质化，来源可能是各种bot比赛的产物，域名都是.ai，稍微大一点的支持多个平台，很多都是只在slack上使用，有一种bot成海的感觉，什么样的服务都可以用bot来做，强行改变交互方式。有的slack bot服务于team，有的是将slack与其他服务，比如google analytics，以bot的形式进行桥接。</p>
<p>3、有挺多的startups都在做app store的事情，聚合了大量不同类别的bot，统一进行管理，开发者开发好的bot都放在store中进行展示和销售。这类企业也是平台的性质，但没有自己独立的平台，所以做各大平台的聚合。</p>
<p>4、有的startups做的是降低开发bot门槛的事情，和平台提供接入服务不同，这类企业更具有技术性，将bot开发封装成简单的接口或者界面，供“开发者”甚至是小白来开发属于自己的bot，不管是新闻app还是天气、还是旅游都是几分钟配置的事情，完全没有难度。这类公司相比于平台上的简单bot来说，更加底层一些，也更有技术门槛，但结果却是让bot变得没有技术门槛了。</p>
<p>5、有的startups是独立于几大平台的，提供一种私人助理服务，包括会议、日程、旅行、金融各种服务，为了保证服务质量，常常采用AI+人工的模式。这类公司通常都有核心的技术和垂直领域的经验，对该领域地理解比较深，而且跟得上时代的潮流，用chat作为交互是一个大趋势，索性就早一点进入，确立市场地位。</p>
<p>6、有的startups专门做B2B的技术支持服务，提供NLP、知识抽取方面的服务，为上述的各类企业提供技术支撑，没有直接参与bot，但保证了bot的质量。</p>
<p>7、从各个startups成立时间和融资情况来看，平台上的bot都是2015年底或者2016年初开始热起来的，而2013、2014年就开始朝着这个方向做的企业，基本都是做技术平台、企业客服bot或者私人助理app的，相对来说技术壁垒大一些，门槛高，不容易被模仿和抄袭，所以融资情况较好，当然这个只是现在还存活的企业，死掉地可能也有很多。整体来看，slack之类的平台上做个好玩的bot难度不大，数量如雨后春笋般、井喷式地增长，质量良莠不齐，核心技术少，门槛低，从目前的融资情况看不是很好。而开始早并且技术壁垒大的startups有着更好的市场前景，融资情况也比较乐观。</p>
<p>8、可能是因为考察的startups还比较少，并没有发现像国内有那么多家bot企业都挤在客服这个领域，其他领域的bot企业相对较少，（也有可能是关注的比较少）。国内的微信并没有开放这么彻底，或者说没有一个类似的平台可以做类似的事情，所以各种小bot还没有井喷式地出现，但这是一个趋势，今后一定会有类似的平台出来。</p>
<p>9、bot在全球都很火，国内和国外的侧重点感觉不是很一样，国外的形式比较丰富，各个level的蛋糕都有人在吃，简直无孔不入，反观国内，大家都忙于抢客服这块大蛋糕，其他的蛋糕没有太多的人来吃，这样看来可能也是国内的一个机会，只要不做客服bot，做一些别的业务可能都会有几乎吧。</p>
<p>10、不是什么场景都适合用chatbot来解决的，很多时候我们简单操作下软件比和一个不怎么聪明的bot聊半天效率要高很多的，做bot的话，应该首先分析用哪个场景chat会比操作更加简单，而不是盲目地什么都搞成bot。这一点很重要，媒体的炒作，以及大公司的PR都容易蒙蔽双眼，失去理性判断，清醒地分析一下哪些方向是适合做bot的，而不是一味地去为了bot而bot。</p>
<p>注：所有的数据都是来自于<a href="https://www.crunchbase.com/" target="_blank" rel="external">CrouchBase</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;科技媒体的文章有一个明显的好处，就是会报道很多不易被人发现、但却非常有意思的startups，帮助大家拓宽视野；同时也有一个明显的坏处，文章容易标题党，不够专业的编辑容易写出一些极端的结论，比如xxx一定会取代yyy，炒作概念。所以，这里借助了科技类媒体的优势，考察了下国外
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>bot startups</title>
    <link href="http://rsarxiv.github.io/2016/07/25/bot-startups/"/>
    <id>http://rsarxiv.github.io/2016/07/25/bot-startups/</id>
    <published>2016-07-25T18:39:04.000Z</published>
    <updated>2016-07-25T21:18:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>罗列下各种媒体上提到的bot startups，包括：业务范围和融资情况。</p>
<h1 id="motion-ai"><a href="#motion-ai" class="headerlink" title="motion.ai"></a><a href="motion.ai">motion.ai</a></h1><p>用可视化地手段进行构建、训练和发布一个bot。喊出的口号是，只要你会画流程图，你就可以构建一个bot，可以在各种平台上搭建属于自己的bot，比如：sms、web、email、Fb Messenger、Slack等平台。</p>
<p>成立时间：2015.11.05<br>融资情况：$700k 种子轮<br>公司主页：<a href="http://motion.ai" target="_blank" rel="external">http://motion.ai</a></p>
<h1 id="CareerLark"><a href="#CareerLark" class="headerlink" title="CareerLark"></a><a href="http://www.careerlark.com/" target="_blank" rel="external">CareerLark</a></h1><p>构建于Slack平台的一家bot企业，旨在通过micro-feedback来提高生产力。</p>
<p>成立时间：未知<br>融资情况：$50k 种子轮<br>公司主页：<a href="http://www.careerlark.com/" target="_blank" rel="external">http://www.careerlark.com/</a></p>
<h1 id="Carla"><a href="#Carla" class="headerlink" title="Carla"></a><a href="http://carla.io/" target="_blank" rel="external">Carla</a></h1><p>一款虚拟助手，用于提醒自己、朋友和家人，通过自然语言添加日程和追踪自己一天的生活。</p>
<p>成立时间：未知<br>融资情况：未知<br>公司主页：<a href="http://carla.io/" target="_blank" rel="external">http://carla.io/</a></p>
<h1 id="Dexter"><a href="#Dexter" class="headerlink" title="Dexter"></a><a href="https://rundexter.com/" target="_blank" rel="external">Dexter</a></h1><p>帮助企业用户快速构建bot引擎，打造属于自己的bot。</p>
<p>成立时间：未知<br>融资情况：未知<br>公司主页：<a href="https://rundexter.com/" target="_blank" rel="external">https://rundexter.com/</a></p>
<h1 id="kip"><a href="#kip" class="headerlink" title="kip"></a><a href="http://kipthis.com/" target="_blank" rel="external">kip</a></h1><p>办公室团购助手，将B2C搬进bot中，方便大家购物，支持多种平台。</p>
<p>成立时间：2014.05.13<br>融资情况：$317k 两轮<br>公司主页：<a href="http://kipthis.com/" target="_blank" rel="external">http://kipthis.com/</a></p>
<h1 id="Rollio"><a href="#Rollio" class="headerlink" title="Rollio"></a><a href="https://www.rollioforce.com/" target="_blank" rel="external">Rollio</a></h1><p>CRM智能助手，将你的销售变得更加简单，用NLP技术来挖掘客户反馈来文本和声音信息，简化CRM。</p>
<p>成立时间：2014<br>融资情况：$670k 种子轮<br>公司主页：<a href="https://www.rollioforce.com/" target="_blank" rel="external">https://www.rollioforce.com/</a></p>
<h1 id="Assist"><a href="#Assist" class="headerlink" title="Assist"></a><a href="http://www.assi.st/" target="_blank" rel="external">Assist</a></h1><p>将企业现有的业务搬进文本消息平台中，用bot来帮企业做生意。</p>
<p>成立时间：未知<br>融资情况：未知<br>公司主页：<a href="http://www.assi.st/" target="_blank" rel="external">http://www.assi.st/</a></p>
<h1 id="magic"><a href="#magic" class="headerlink" title="magic"></a><a href="https://www.getmagicnow.com/" target="_blank" rel="external">magic</a></h1><p>一个基于文本信息平台的通用bot助理，涵盖的面比较广。</p>
<p>成立时间：2015<br>融资情况：$12M 两轮<br>公司主页：<a href="https://www.getmagicnow.com/" target="_blank" rel="external">https://www.getmagicnow.com/</a></p>
<h1 id="Polly"><a href="#Polly" class="headerlink" title="Polly"></a><a href="https://www.polly.ai/" target="_blank" rel="external">Polly</a></h1><p>基于slack平台的bot服务，收集和分析team的数据，提供一些服务，可定制化。</p>
<p>成立时间：2015<br>融资情况：未知<br>公司主页：<a href="https://www.polly.ai/" target="_blank" rel="external">https://www.polly.ai/</a></p>
<h1 id="StatsBot"><a href="#StatsBot" class="headerlink" title="StatsBot"></a><a href="https://statsbot.co/" target="_blank" rel="external">StatsBot</a></h1><p>基于slack平台的bot服务，提供google analytics、mixpanel、salesforce服务。</p>
<p>成立时间：2015<br>融资情况：未知<br>公司主页：<a href="https://statsbot.co/" target="_blank" rel="external">https://statsbot.co/</a></p>
<h1 id="Birdly"><a href="#Birdly" class="headerlink" title="Birdly"></a><a href="https://www.getbirdly.com/" target="_blank" rel="external">Birdly</a></h1><p>基于slack平台的bot服务，沟通team和salesforce的桥梁。</p>
<p>成立时间：2014<br>融资情况：$120k 种子轮<br>公司主页：<a href="https://www.getbirdly.com/" target="_blank" rel="external">https://www.getbirdly.com/</a></p>
<h1 id="zoom-ai"><a href="#zoom-ai" class="headerlink" title="zoom.ai"></a><a href="http://www.zoom.ai/" target="_blank" rel="external">zoom.ai</a></h1><p>企业级的智能助手，支持多个平台和多项服务。</p>
<p>成立时间：2016.02.22<br>融资情况：未知<br>公司主页：<a href="http://www.zoom.ai/" target="_blank" rel="external">http://www.zoom.ai/</a></p>
<h1 id="HeyTaco"><a href="#HeyTaco" class="headerlink" title="HeyTaco!"></a><a href="https://www.heytaco.chat/" target="_blank" rel="external">HeyTaco!</a></h1><p>基于slack平台的bot服务，当你觉得team中一个人做了一件awesome的事情，可以@username + taco emoji，然后该服务会记录下team中每个成员的taco数，攒齐N个可以换一些gift。</p>
<p>成立时间：2016.02.06<br>融资情况：未知<br>公司主页：<a href="https://www.heytaco.chat/" target="_blank" rel="external">https://www.heytaco.chat/</a></p>
<h1 id="skylar"><a href="#skylar" class="headerlink" title="skylar"></a><a href="https://skylar.ai/" target="_blank" rel="external">skylar</a></h1><p>为团队提供多种服务的bot，整合了一些在线工具API，基于slack和messenger平台。</p>
<p>成立时间：2015.11.17<br>融资情况：未知<br>公司主页：<a href="https://skylar.ai/" target="_blank" rel="external">https://skylar.ai/</a></p>
<h1 id="DigitalGenius"><a href="#DigitalGenius" class="headerlink" title="DigitalGenius"></a><a href="http://digitalgenius.com/" target="_blank" rel="external">DigitalGenius</a></h1><p>bot+人工客服服务，多平台多渠道客服。</p>
<p>成立时间：2013.12.01<br>融资情况：$8.35M 三轮<br>公司主页：<a href="http://digitalgenius.com/" target="_blank" rel="external">http://digitalgenius.com/</a></p>
<h1 id="workbot"><a href="#workbot" class="headerlink" title="workbot"></a><a href="https://www.workato.com/workbot-slack" target="_blank" rel="external">workbot</a></h1><p>基于slack平台的bot服务，为团队提供一系列数据服务。</p>
<p>成立时间：2016.01<br>融资情况：未知<br>公司主页：<a href="https://www.workato.com/workbot-slack" target="_blank" rel="external">https://www.workato.com/workbot-slack</a></p>
<h1 id="poncho"><a href="#poncho" class="headerlink" title="poncho"></a><a href="http://poncho.is/" target="_blank" rel="external">poncho</a></h1><p>量身定做的天气和旅行助手。</p>
<p>成立时间：2013.04.01<br>融资情况：$2M 种子轮<br>公司主页：<a href="http://poncho.is/" target="_blank" rel="external">http://poncho.is/</a></p>
<h1 id="Pana"><a href="#Pana" class="headerlink" title="Pana"></a><a href="https://www.pana.com/" target="_blank" rel="external">Pana</a></h1><p>bot+AI旅行安排服务。</p>
<p>成立时间：2015<br>融资情况：$1.45M 两轮<br>公司主页：<a href="https://www.pana.com/" target="_blank" rel="external">https://www.pana.com/</a></p>
<h1 id="Penny"><a href="#Penny" class="headerlink" title="Penny"></a><a href="https://www.pennyapp.io/" target="_blank" rel="external">Penny</a></h1><p>私人财产顾问型bot。</p>
<p>成立时间：2015.07<br>融资情况：$1.2M 种子轮<br>公司主页：<a href="https://www.pennyapp.io/" target="_blank" rel="external">https://www.pennyapp.io/</a></p>
<h1 id="x-ai"><a href="#x-ai" class="headerlink" title="x.ai"></a><a href="https://x.ai" target="_blank" rel="external">x.ai</a></h1><p>帮你安排会议的私人助手。</p>
<p>成立时间：2014.04.14<br>融资情况：$34.3M 三轮<br>公司主页：<a href="https://x.ai" target="_blank" rel="external">https://x.ai</a></p>
<h1 id="viv-ai"><a href="#viv-ai" class="headerlink" title="viv.ai"></a><a href="http://viv.ai/" target="_blank" rel="external">viv.ai</a></h1><p>一个帮助开发者快速开发bot的技术平台，涵盖的面比较广。</p>
<p>成立时间：未知<br>融资情况：30M 三轮<br>公司主页：<a href="http://viv.ai/" target="_blank" rel="external">http://viv.ai/</a></p>
<h1 id="Kasisto"><a href="#Kasisto" class="headerlink" title="Kasisto"></a><a href="http://kasisto.com/kai/" target="_blank" rel="external">Kasisto</a></h1><p>bot技术平台，帮助开发者轻松搭建一个bot。</p>
<p>成立时间：2013<br>融资情况：$2.25M<br>公司主页：<a href="http://kasisto.com/kai/" target="_blank" rel="external">http://kasisto.com/kai/</a></p>
<p>startups信息来自<a href="crunchbase.com">CrunchBase</a>。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;罗列下各种媒体上提到的bot startups，包括：业务范围和融资情况。&lt;/p&gt;
&lt;h1 id=&quot;motion-ai&quot;&gt;&lt;a href=&quot;#motion-ai&quot; class=&quot;headerlink&quot; title=&quot;motion.ai&quot;&gt;&lt;/a&gt;&lt;a href=&quot;motio
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>再谈bot</title>
    <link href="http://rsarxiv.github.io/2016/07/24/%E5%86%8D%E8%B0%88bot/"/>
    <id>http://rsarxiv.github.io/2016/07/24/再谈bot/</id>
    <published>2016-07-24T20:20:12.000Z</published>
    <updated>2016-07-25T04:32:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文是一个TechCrunch最近一年有关bot新闻报道的survey，从原文中提炼了些核心观点，来研究下国外bot的发展。</p>
<h1 id="Forget-Apps-Now-The-Bots-Take-Over"><a href="#Forget-Apps-Now-The-Bots-Take-Over" class="headerlink" title="Forget Apps, Now The Bots Take Over"></a><a href="https://techcrunch.com/2015/09/29/forget-apps-now-the-bots-take-over/" target="_blank" rel="external">Forget Apps, Now The Bots Take Over</a></h1><p>Sep 29, 2015 TechCrunch</p>
<p>正如浏览器取代了操作系统的地位作为新的平台，网站取代了应用程序的地位，bots将会取代移动app的地位，今后将会是bot store，各种各样的bot，而不再是app store。</p>
<p>类似于微信、Line、Facebook、Slack这样的message平台，将会成为一个新的入口。在message平台上有各种各样的bot，用户通过message与各种bot进行交互，来体会之前在手机各种app上的服务。</p>
<p><img src="media/1.png" alt="1"></p>
<blockquote>
<p>It’s a brave new bot-filled world, with new possibilities and new risks.</p>
</blockquote>
<h1 id="Check-out-the-new-AI-powered-TechCrunch-news-bot-on-Telegram-messenger"><a href="#Check-out-the-new-AI-powered-TechCrunch-news-bot-on-Telegram-messenger" class="headerlink" title="Check out the new AI-powered TechCrunch news bot on Telegram messenger"></a><a href="https://techcrunch.com/2016/03/15/check-out-the-new-ai-powered-techcrunch-news-bot-on-telegram-messenger/" target="_blank" rel="external">Check out the new AI-powered TechCrunch news bot on Telegram messenger</a></h1><p>Mar 15, 2016 TechCrunch</p>
<p>Techcrunch在Telegram上用<a href="https://chatfuel.com/" target="_blank" rel="external">Chatfuel</a>构建了一个news bot，用户可以通过订阅不同的topic，authors和sections，bot根据订阅内容每天会推送两次trending stories digest给用户，另外也可以进行一些问答、聊天。</p>
<p><img src="media/2.gif" alt="2"></p>
<h1 id="Microsoft-is-bringing-bots-to-Skype-—-and-everywhere-else"><a href="#Microsoft-is-bringing-bots-to-Skype-—-and-everywhere-else" class="headerlink" title="Microsoft is bringing bots to Skype — and everywhere else"></a><a href="https://techcrunch.com/2016/03/30/microsoft-is-bringing-bots-to-skype-and-everywhere-else/" target="_blank" rel="external">Microsoft is bringing bots to Skype — and everywhere else</a></h1><p>Mar 30, 2016 TechCrunch</p>
<p>微软CEO Nadella说,bots是下一代应用，只需要用自然语言与bot进行talk就可以完成之前大量手机app和网站做的工作。微软在bot的研究上投入很大，成果也颇多，小冰、Tay、Cortana，和开源的bot framework，并且将很多好玩的deep learning应用与bot做了整合，比如image caption bot，bing music bot，bing news bot。</p>
<p><img src="media/3.jpg" alt="3"></p>
<h1 id="Chat-app-Kik-launches-a-bot-store-and-anyone-can-make-bots-for-it"><a href="#Chat-app-Kik-launches-a-bot-store-and-anyone-can-make-bots-for-it" class="headerlink" title="Chat app Kik launches a bot store and anyone can make bots for it"></a><a href="https://techcrunch.com/2016/04/05/chat-app-kik-launches-a-bot-store-and-anyone-can-make-bots-for-it/" target="_blank" rel="external">Chat app Kik launches a bot store and anyone can make bots for it</a></h1><p>Apr 5, 2016 TechCrunch</p>
<p>Kik是一个聊天app，构建了自己的bot store，chat被认为是下一代操作系统，而聊天app则是新型的浏览器，bots是新型的网站。bot和聊天的环境类似，增加了一些特殊的trigger，用来激发一些特殊的动作。</p>
<p><img src="media/4.png" alt="4"></p>
<h1 id="Botlist-is-an-app-store-for-bots"><a href="#Botlist-is-an-app-store-for-bots" class="headerlink" title="Botlist is an app store for bots"></a><a href="https://techcrunch.com/2016/04/11/botlist-is-an-app-store-for-bots/" target="_blank" rel="external">Botlist is an app store for bots</a></h1><p>Apr 11, 2016 TechCrunch</p>
<p>Botlist是一家做bot聚合的平台，和豌豆荚是类似的概念，聚合了各种message平台上的各种bot应用。</p>
<p><img src="media/5.png" alt="5"></p>
<h1 id="TechCrunch-launches-a-personalized-news-recommendations-bot-on-Facebook-Messenger"><a href="#TechCrunch-launches-a-personalized-news-recommendations-bot-on-Facebook-Messenger" class="headerlink" title="TechCrunch launches a personalized news recommendations bot on Facebook Messenger"></a><a href="https://techcrunch.com/2016/04/19/all-your-bots-are-belong-to-us/" target="_blank" rel="external">TechCrunch launches a personalized news recommendations bot on Facebook Messenger</a></h1><p>Apr 19, 2016 TechCrunch</p>
<p>TechCrunch在Fb平台上的bot具备一个简单的个性化推荐的功能，根据用户的喜欢来推荐可能感兴趣的文章。</p>
<h1 id="ToyTalk-renames-to-PullString-repositions-as-authoring-tool-for-bots"><a href="#ToyTalk-renames-to-PullString-repositions-as-authoring-tool-for-bots" class="headerlink" title="ToyTalk renames to PullString, repositions as authoring tool for bots"></a><a href="https://techcrunch.com/2016/04/26/pullstring-bot-authoring/" target="_blank" rel="external">ToyTalk renames to PullString, repositions as authoring tool for bots</a></h1><p>Apr 26, 2016 TechCrunch</p>
<p>PullString做儿童市场，因为孩子的词汇量非常有限，而且都很容易理解，关键是孩子对那些nonsense的回答并不介意。</p>
<p><img src="media/6.gif" alt="6"></p>
<h1 id="Bots-Messenger-and-the-future-of-customer-service"><a href="#Bots-Messenger-and-the-future-of-customer-service" class="headerlink" title="Bots, Messenger and the future of customer service"></a><a href="https://techcrunch.com/2016/05/07/bots-messenger-and-the-future-of-customer-service/" target="_blank" rel="external">Bots, Messenger and the future of customer service</a></h1><p>May 7, 2016 TechCrunch</p>
<p><img src="media/7.png" alt="7"></p>
<p> 传统的客服总是给人留下低效的印象，而随着AI研究水平地不断提高，用bot来替代或者辅助人工客服将是一种趋势和潮流。</p>
<h1 id="Penny-raises-1-2M-in-seed-funding-for-its-personal-finance-bot"><a href="#Penny-raises-1-2M-in-seed-funding-for-its-personal-finance-bot" class="headerlink" title="Penny raises $1.2M in seed funding for its personal finance bot"></a><a href="https://techcrunch.com/2016/05/23/penny-raises-1-2m-in-seed-funding-for-its-personal-finance-bot/" target="_blank" rel="external">Penny raises $1.2M in seed funding for its personal finance bot</a></h1><p> May 23, 2016 TechCrunch</p>
<p> Penny是一个personal finance bot，通过chat来帮助用户管理finance。不过chat只能通过pre-populated messages，而不是自然语言。尽管进入了一个bot时代，但chat的方式并不是解决所有问题的最好方法，在shopping领域，传统的电商网站比bot更好用。</p>
<p><img src="media/8.jpg" alt="8"></p>
<h1 id="Microsoft-tries-its-hand-at-a-news-bot-with-Rowe"><a href="#Microsoft-tries-its-hand-at-a-news-bot-with-Rowe" class="headerlink" title="Microsoft tries its hand at a news bot with Rowe"></a><a href="https://techcrunch.com/2016/05/24/microsoft-tries-its-hand-at-a-news-bot-with-rowe/" target="_blank" rel="external">Microsoft tries its hand at a news bot with Rowe</a></h1><p>May 24, 2016 TechCrunch</p>
<p>微软太钟爱bot了，在新闻领域开发了一款bot，整合了自家一个新闻App News Pro的功能，通过topic来获取相关news，获取今日头条，获取系统推荐的news。</p>
<p> <img src="media/9.png" alt="9"></p>
<h1 id="Workato-unveils-Personal-Workbot-to-silence-some-of-the-Slack-bot-noise"><a href="#Workato-unveils-Personal-Workbot-to-silence-some-of-the-Slack-bot-noise" class="headerlink" title="Workato unveils Personal Workbot to silence some of the Slack bot noise"></a><a href="https://techcrunch.com/2016/06/23/workato-unveils-personal-workbot-to-silence-some-of-the-slack-bot-noise/" target="_blank" rel="external">Workato unveils Personal Workbot to silence some of the Slack bot noise</a></h1><p>Jun 23, 2016 TechCrunch</p>
<p>Workato提供一个bot服务Personal Workbot，为slack用户过滤掉channel中无关的信息，提高效率。</p>
<p><img src="media/10.png" alt="10"></p>
<h1 id="Zoom-ai-believes-an-automated-assistant-is-the-fix-for-a-weighty-workload"><a href="#Zoom-ai-believes-an-automated-assistant-is-the-fix-for-a-weighty-workload" class="headerlink" title="Zoom.ai believes an automated assistant is the fix for a weighty workload"></a><a href="https://techcrunch.com/2016/07/14/zoom-ai/" target="_blank" rel="external">Zoom.ai believes an automated assistant is the fix for a weighty workload</a></h1><p>Jul 14, 2016 TechCrunch</p>
<p>Zoom.ai与之前的chat bot startups不同，目的客户是企业。创始人说，bot更像是一种UI，bot背后的技术才是真正需要解决的问题，NLP技术才是最关键的东西。</p>
<h1 id="Legion-Analytics-is-building-bots-to-automate-your-sales-pitch"><a href="#Legion-Analytics-is-building-bots-to-automate-your-sales-pitch" class="headerlink" title="Legion Analytics is building bots to automate your sales pitch"></a><a href="https://techcrunch.com/2016/07/15/legion-analytics-kylie/" target="_blank" rel="external">Legion Analytics is building bots to automate your sales pitch</a></h1><p>Jul 15, 2016 TechCrunch</p>
<p>Legion Analytics这家公司借助人工智能技术，帮助销售团队更加高效地工作。并不是说用bot来替代人工销售团队，而是帮助他们处理更加耗时的邮件咨询和demo演示。</p>
<h1 id="Bot-influencers-are-the-programmatic-future-of-conversational-advertising"><a href="#Bot-influencers-are-the-programmatic-future-of-conversational-advertising" class="headerlink" title="Bot influencers are the programmatic future of conversational advertising"></a><a href="https://techcrunch.com/2016/07/21/bot-influencers-the-programmatic-future-of-conversational-advertising/" target="_blank" rel="external">Bot influencers are the programmatic future of conversational advertising</a></h1><p>Jul 21, 2016 TechCrunch</p>
<p>conversational广告有望改善目前digital ads的缺陷，可以做的更加relevant、contextual和unobtrusive。</p>
<h1 id="Why-do-chatbots-suck"><a href="#Why-do-chatbots-suck" class="headerlink" title="Why do chatbots suck?"></a><a href="https://techcrunch.com/2016/05/29/why-do-chatbots-suck/" target="_blank" rel="external">Why do chatbots suck?</a></h1><p>May 29, 2016 TechCrunch</p>
<p>文中的观点基本同意，chatbot领域太广容易失败，不如做好特定领域内的服务。bot有智能的，比如微软的Tay，也有不智能的，比如Facebook平台上的CNN chatbot，设定一些button，绑定一些特定的事件。市面上没有一个真正好用的bot，很多领域为了bot而bot，用传统的app通过几个步骤就可以完成的事情，在bot中需要通过打很多的字才能完成，其实用户并不在意你的东西是不是智能，也不关心你产品背后的技术多牛，只在乎你的产品是不是简单好用效率高。一切以贴牌炒概念的bot产品都是耍流氓。现阶段，很多相关技术并不成熟，作者建议说在企业客服这个领域多做一些工作，比如把企业的产品FAQ bot做好，节约一些人力成本。（国内很多家做FAQ bot的公司）</p>
<h1 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h1><p>本文是考察国外bot文章系列的第一篇，全都来自TechCrunch。看了一天的新闻文章，从国外科技记者的角度看了下bot这个领域的发展和未来。</p>
<p>1、整体来说，比较乐观，从大公司、投资人、记者、用户多个角色来看，大家都比较看好bot的发展，相信bot是下一个app的形式，就像website取代了传统桌面程序一样，bot也会取代现在的手机app。</p>
<p>2、chat的形式就是大家来聊天，自然而然大的message平台，比如Facebook的Messenger，微信，Line，Slack，Telegram等等，就是成为bot的平台，就像现在的操作系统平台一样。</p>
<p>3、国外的bot公司很多很多，后缀带.ai多的数不清，从这些新闻中分享的bot应用，看得出大家现在还停留在一个比较初始的bot状态，有一点像arxiv上占坑的感觉，没有太多所谓的智能，只是有一个chatbot交互的UI，基本上实现具体的功能都靠事先定制好的button来trigger，更像是交互方式的革新，而非真的人工智能。</p>
<p>4、很多bot都在炒概念，往hot topic上靠，为了bot而bot，手机app用基本简单的点击操作就可以完成的任务，用bot却非要花费大量的时间来输入order或者人类语言，有点多此一举了。说白了，语义理解技术还不够成熟，大家将本该高度智能化的bot做成了step by step的引导，让用户使用了更加复杂的操作。当然，如果你的bot可以准确理解一句或几句简单的人话，然后完成复杂的业务处理，并反馈给用户结果，这样的bot才会让用户真的信服。</p>
<p>5、大伙儿基本上都把bot当成下一代app了，于是出现了很多家做bot聚合和分发的平台，类似app store，豌豆荚这种角色。一个市场雏形出来了之后，大家各自定位，各吃一块蛋糕。</p>
<p>6、客服bot是目前国内市场bot最活跃的一类，提供的功能基本上是企业产品或者业务的faq，差异化在于理解用户的query上，可能技术上略有差异。另外还有一种助手式的bot，提供了一些日常服务，比如查天气，订机票，订饭，打车等功能，基本上纯粹理解自然语言的很少，都是预先设定好套路，根据前一个context来trigger出后一个question，step by step地带着用户完成一个指定任务，因为涉及到多轮对话，context的理解和处理就显得非常重要，理解不好就显得bot非常弱智。这里，我觉得根据context做response的生成是个可以应用的点，虽然说可用的dataset规模很小，但可以考虑将已有的dataset做template化，通过template后的dataset来训练response generator。</p>
<p>今天是系列文章的第一篇，后续会读更多的news或者discussion，以及研究国外bot的产品形式和所用技术，做更多的分享，欢迎讨论。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是一个TechCrunch最近一年有关bot新闻报道的survey，从原文中提炼了些核心观点，来研究下国外bot的发展。&lt;/p&gt;
&lt;h1 id=&quot;Forget-Apps-Now-The-Bots-Take-Over&quot;&gt;&lt;a href=&quot;#Forget-Apps-Now-
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>国内bot产品试用总结</title>
    <link href="http://rsarxiv.github.io/2016/07/22/%E5%9B%BD%E5%86%85bot%E4%BA%A7%E5%93%81%E8%AF%95%E7%94%A8%E6%80%BB%E7%BB%93/"/>
    <id>http://rsarxiv.github.io/2016/07/22/国内bot产品试用总结/</id>
    <published>2016-07-22T20:14:05.000Z</published>
    <updated>2016-07-22T21:18:57.000Z</updated>
    
    <content type="html"><![CDATA[<p>理想很丰满，现实却很骨感。用这句话来形容当前国内的bot客服机器人最合适不过。本文考察了国内规模较大的6家做bot企业客服业务的公司，从功能描述、客户范围到实际案例进行一下对比和总结。</p>
<h1 id="功能描述"><a href="#功能描述" class="headerlink" title="功能描述"></a>功能描述</h1><p>在各自的网站上都会介绍公司的优势，基本都会包括下面的字眼：</p>
<p>1、海量的知识库储备</p>
<p>2、精准的语义理解能力</p>
<p>3、快速部署能力</p>
<p>4、减轻人工客服压力，节约人力成本</p>
<p>5、无缝衔接人工客服</p>
<p>6、回答准确高极高</p>
<p>7、多渠道</p>
<p>看起来都是非常厉害，都是很牛的技术，理解语义没有任何难度，仿佛真正的bot已经实现了一样，但现实是这样的吗？可能还并不是，可能还需要多年的学术研究来推动这个行业的进步。</p>
<h1 id="客户范围"><a href="#客户范围" class="headerlink" title="客户范围"></a>客户范围</h1><p>客服是一个很大的市场，在各行各业都需要大量的客服人员来做售前和售后咨询，传统的客服面临着一个很尴尬的问题是，总是在回答大量重复的问题，效率很低。很多问题的答案其实可以在企业网站上的FAQ找到，但是消费者仍是喜欢去问客服。在这个背景下，客服bot应运而生，覆盖的行业领域包括：电子商务、游戏网站、政府网站、一般企业等等各行各业。</p>
<h1 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h1><p>使用了他们6家的案例，简单总结一下：</p>
<p>1、大家规模不同，但有一个共同的特点是，宣传中提到为多少多少客户提供服务，但是很多客户的网站中并不能找到相应的bot服务，而且bot公司的网站上并没有给出直接的链接过去，只是说这家客户在用他们的服务。这一点来说，我觉得水分比较大，不够透明。</p>
<p>2、采用的解决方案基本上都是example-based，即bot公司自己的通用知识库+客户的业务知识库。一个用户在使用企业的客服时，很少有无聊的人去调戏人家bot，都是来咨询相关问题的，所以一般来说，bot公司自己的知识库作用非常小，当企业的知识库回答不了现有的问题，bot公司的这种所谓“海量知识库”可以派上用场，和客户逗趣一会，但本质上没有意义。</p>
<p>example-based方案本质上就是信息检索，根据用户的query来找到最合适的example，然后将example中的response返回给用户。用这种方法做一个企业客服bot的话，核心就在构建业务知识库，主要的技术点也在这个地方，最简单的方法是将客户给的历史聊天记录和faq经过一定预处理，生成一个高可用的知识库，扯太多的新概念就有点过分了。明明“快速建知识库”才是核心技术，非要说自己拥有超强的“语义理解”能力。What a shame！</p>
<p>这种方案做出来的效果基本上是一个自动版的faq，可以回到非常有限的问题，如果是企业新遇到的问题，则需要添加知识库，编辑知识库就是个简单的数据库操作，并无高大上，在faq这个层面上，bot确实减少了人力成本。</p>
<p>大多数对用户提出的在知识库范围内的问题都是可以不错地回答，其他的都是在呵呵呵了。但如果在query的理解上有更加深入地研究，比如在语义层面上对query和example进行对比，而不是简单的keyword匹配，在某种程度上会更好地提高服务质量。</p>
<p>大多数的bot将faq写在右侧，鼓励大家选择这样的问法，这其实是一种trick，回避了自身理解query能力的欠缺。有一个网站做的不错，你每次提一个query，他会给你返回四个similar query，这四个都是example中的，让你从中选一个，4选1，正确的几率还是很大的，尤其是他的知识库做的不错的情况下。</p>
<p>3、完全依靠bot是不现实的，毕竟知识库有限，很容易遇到新的问题，每个公司bot都会和人工服务无缝衔接，用户发现bot不靠谱了，可以直接点击人工服务与人沟通。很多企业的bot客服基本上还是主要依靠人工服务，bot的作用太有限了。</p>
<p>4、大家的模式都差不多，可能有的公司技术稍微领先一点，资源多，拿到了一些大单子，行业的名气大，但实际效果来看，媒体的报道和其他一些场合的PR，只是在鼓吹，实际的体验还是很差的。虽然大家的单子很多，利润也可能不少，但能做的事情实在太有限了，一单接一单地做，都说自己是技术公司，但真正的前沿技术很难看到被应用上，用的技术和10年前的研究成果并无太大不同。比如，context的处理，是一个非常有必要但却没有一家做的很好的公司，用户和bot聊了几轮话了，什么信息量都保存和学习不到，只是做了个小型的搜索引擎就敢说是bot了？智能如何体现呢？有点讽刺啊！大家都说学术界太虚，出的paper难用，只能用10年前的技术来做，旧汤换新药而已，但学术界很多的研究都是前瞻性，也很有启发性，不能直接套用并不代表不能借鉴啊，一概而论地说paper无意义有一点短视，有一点为自己技术不过硬找借口了。如果只是这么简单、浮躁的bot解决方案，我觉得在市场上不会有太强的生命力和长远的发展，因为这点技术，大公司稍微做一下都会比这个强，SaaS的特点就是容易接入，技术但凡领先于现在的专业做bot的企业，自然就会取而代之。当然，如果只是为了赚点快钱，这样做是合理的。</p>
<p>5、关于机会，我觉得bot是一个很大的机会，很多人不看好bot的原因是目前做bot采用的技术太过陈旧，效果太差导致。这么说来，机会其实也是从这里来的，正是因为大家的技术都不是太先进，所以才有机会，专注地做好新技术的研发，改善现有bot存在的问题，带给企业客户更优质的服务。先赢都不算赢，最后赢的才是真的赢。</p>
<p>大家都很急着占一个又一个的客户，好像真的占领了这个市场一样。用了这几家的服务之后，感觉有点失望，欲速则不达。 </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;理想很丰满，现实却很骨感。用这句话来形容当前国内的bot客服机器人最合适不过。本文考察了国内规模较大的6家做bot企业客服业务的公司，从功能描述、客户范围到实际案例进行一下对比和总结。&lt;/p&gt;
&lt;h1 id=&quot;功能描述&quot;&gt;&lt;a href=&quot;#功能描述&quot; class=&quot;hea
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>Attention with Intention for a Neural Network Conversation Model #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/21/Attention-with-Intention-for-a-Neural-Network-Conversation-Model-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/21/Attention-with-Intention-for-a-Neural-Network-Conversation-Model-PaperWeekly/</id>
    <published>2016-07-22T00:27:46.000Z</published>
    <updated>2016-07-22T00:27:46.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Neural Contextual Conversation Learning with Labeled Question-Answering Pairs #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/21/Neural-Contextual-Conversation-Learning-with-Labeled-Question-Answering-Pairs-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/21/Neural-Contextual-Conversation-Learning-with-Labeled-Question-Answering-Pairs-PaperWeekly/</id>
    <published>2016-07-21T18:35:27.000Z</published>
    <updated>2016-07-21T18:35:27.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Attention-over-Attention Neural Networks for Reading Comprehension #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/18/Attention-over-Attention-Neural-Networks-for-Reading-Comprehension-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/18/Attention-over-Attention-Neural-Networks-for-Reading-Comprehension-PaperWeekly/</id>
    <published>2016-07-19T00:21:22.000Z</published>
    <updated>2016-07-19T01:03:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文分享的文章是arxiv今天刚刚新鲜出炉的paper，来自哈工大讯飞联合实验室。前不久，他们构建了一个大型阅读理解语料，今天也发布出来了。(<a href="http://hfl.iflytek.com/chinese-rc/" target="_blank" rel="external">下载地址</a>)</p>
<p>Cloze-style Reading Comprehension这个领域竞争太过激烈了，半年时间把benchmark刷了一遍又一遍，今天的这篇paper又一次刷新了记录。如果对这个领域不太熟悉的话，可以读这篇<a href="http://rsarxiv.github.io/2016/06/18/%E6%95%99%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%98%85%E8%AF%BB/">教机器学习阅读</a>。</p>
<p>本文的模型被称作Attention over Attention(AoA)，和之前的工作不同，不仅仅考虑query-to-document attention，而且考虑了document-to-query attention。模型架构示意图如下：</p>
<p><img src="media/1.png" alt="1"></p>
<p><b>Contextual Embedding</b> 将query和document都embedding化，用Bi-GRU将query和document分别encode，将两个方向的hidden state拼接起来作为该词的state，此时document和query可以分别用一个Dxd和Qxd的矩阵来表示，这里D是document的词数，Q是query的词数，d是embedding的维度。</p>
<p><b>Pair-wise Matching Score</b> </p>
<p><img src="media/2.png" alt="2"></p>
<p>这一步是本质上就是对两个矩阵做矩阵乘法，得到所谓的Matching Score矩阵M，这里的M矩阵的维度是DxQ，矩阵中的每个元素表示对应document和query中的词之间的matching score。</p>
<p><b>Individual Attentions</b> 对M矩阵中的每一列做softmax归一化，得到所谓的query-to-document attention，即给定一个query词，对document中每个词的attention，本文用下式进行表示：</p>
<p><img src="media/3.png" alt="3"></p>
<p><b>Attention-over-Attention</b> 前三个步骤都是很多模型采用的通用做法，这一步是本文的亮点。首先，第三步是对M矩阵的每一列做了softmax归一化，这里对M矩阵的每一行做softmax归一化，即得到所谓的document-to-query attention，用下式来表示：</p>
<p><img src="media/4.png" alt="4"></p>
<p>然后，将document-to-query attention作平均得到最终的query-level attention，如下式：</p>
<p><img src="media/5.png" alt="5"></p>
<p>最后，用每个query-to-document attention和刚刚得到的query-level attention做点乘，得到document中每个词的score。</p>
<p><b>Final Predictions</b> 将相同词的score合并，得到每个词的score，如下式：</p>
<p><img src="media/6.png" alt="6"></p>
<p>从而得到最终的答案。</p>
<p>实验部分用了英文语料CNN和CBT，在没用pre-trained embedding情况下，单模型得到了state-of-the-art结果。</p>
<p><img src="media/7.png" alt="7"></p>
<p>本文模型最大的特点就是不仅仅考虑query到document的attention，而且考虑了document到query的attention，即所谓的attention over attention，在Cloze-style阅读理解任务中取得了更好的结果。同时，作者在未来的工作中，准备将该模型拓展到其他任务中。</p>
<p>attention是一个非常好的机制，将很多任务的benchmark都提高到了很高的水平，是一个革命性的模型。围绕attention的变种做工作，提出各种各样的attention，虽然可以刷新各种任务，但终究不再能够将研究水平提升一个level，需要一个新的机制、新的思想来推动nlp的发展。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文分享的文章是arxiv今天刚刚新鲜出炉的paper，来自哈工大讯飞联合实验室。前不久，他们构建了一个大型阅读理解语料，今天也发布出来了。(&lt;a href=&quot;http://hfl.iflytek.com/chinese-rc/&quot; target=&quot;_blank&quot; rel=&quot;
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="Reading Comprehension" scheme="http://rsarxiv.github.io/tags/Reading-Comprehension/"/>
    
  </entry>
  
  <entry>
    <title>End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/17/End-to-end-LSTM-based-dialog-control-optimized-with-supervised-and-reinforcement-learning-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/17/End-to-end-LSTM-based-dialog-control-optimized-with-supervised-and-reinforcement-learning-PaperWeekly/</id>
    <published>2016-07-17T16:57:22.000Z</published>
    <updated>2016-07-17T17:36:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文介绍的paper一个实用性非常强的解决方案，作者来自于微软研究院，毕业于剑桥大学Spoken Dialogue Group，研究bot很多很多年了。paper的题目是<a href="http://arxiv.org/pdf/1606.01269v1.pdf" target="_blank" rel="external">End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning</a>，最早发表于今年的6月3日。</p>
<p>文章的开头很有意思，先是从一个大家熟知的场景开始介绍，一个经验丰富的客服是如何带一个新入职的客服。四个阶段：</p>
<p>1、告诉新客服哪些”controls”是可用的，比如：如何查找客户的信息，如何确定客户身份等等。<br>2、新客服从老客服做出的good examples中模仿学习。<br>3、新客服开始试着服务客户，老客服及时纠正他的错误。<br>4、老客服放手不管，新客服独自服务客户，不断学习，不断积累经验。</p>
<p>本文的框架就是依照上面的过程进行设计的：</p>
<p>1、开发者提供一系列备选的actions，包括response模板和一些API函数，用来被bot调用。<br>2、由专家提供一系列example dialogues，用RNN来学习。<br>3、用一个模拟user随机产生query，bot进行response，专家进行纠正。<br>4、bot上线服务，与真实客户进行对话，通过反馈来提高bot服务质量。</p>
<p><img src="media/1.png" alt="1"></p>
<p>一个完整的工作流程由上图描述:</p>
<p><img src="media/2.png" alt="2"></p>
<p>本文在训练的时候是用一部分高质量的数据进行监督学习SL，用增强学习RL来优化模型，得到质量更高的结果。并且文中以打电话给指定联系人为应用场景，举了一个实际的例子，来帮助理解本文的思路。</p>
<p>一般来说，很多文章提到end-to-end的模型，都是基于大量训练数据用seq2seq来做response的生成，本文并不是这样，本文的神经网络模型是用来训练action selection的，包括后面用RL policy gradient来提升效果也都是为了选择action。虽然本文不是一个纯粹的end-to-end解决方案，但确实一个非常实用的解决方案，尤其是对于task-oriented bot的业务来说，这样的解决方案更加高效，值得复现，值得在一些细节的地方进行改善，从而真正地减少人工features和人工成本。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文介绍的paper一个实用性非常强的解决方案，作者来自于微软研究院，毕业于剑桥大学Spoken Dialogue Group，研究bot很多很多年了。paper的题目是&lt;a href=&quot;http://arxiv.org/pdf/1606.01269v1.pdf&quot; targ
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>也说bot</title>
    <link href="http://rsarxiv.github.io/2016/07/16/%E4%B9%9F%E8%AF%B4bot/"/>
    <id>http://rsarxiv.github.io/2016/07/16/也说bot/</id>
    <published>2016-07-17T05:02:39.000Z</published>
    <updated>2016-07-17T17:40:33.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>chatbot是最近一段时间非常火的一个词或者一个应用，不仅仅各大新闻媒体在热炒bot的概念，各大巨头也投入巨大的资源进行研发，arxiv上刷出bot相关的paper也更是家常便饭。炒作归炒作，PR归PR，不得不说一个尴尬的事实是市面上确实难以找到一个真正好用的bot。bot按照涉及的领域，分为开放域(open-domain)和面向具体任务(task-oriented)的bot。开放域要做的事情很大，更像是一个什么都能搞的平台，不管你提什么样的需求，它都能够解决，有点true AI的意思，而面向任务的bot则专注做好一件事情，订机票，订餐，办护照等等。</p>
<p>说到开放域bot，大家接触最多的也就是一些回答非常无厘头的娱乐用bot，比如很多年前活跃在各大社交网站上的小黄鸡，现在市面上活跃着很多号称掌握了bot技术，在用深度学习解决bot技术的bot公司，都是这种，解决不了什么实际问题，就是能和大家聊上两句，而且很多时候回答都是牛头不对马嘴的，十分可笑。</p>
<p>再说task-oriented bot，市面上最多的就是客服机器人，银行也好，电商也罢，不想重复性地回答用户的问题，就用一个客服机器人来应对，且不说效果如何，开发一个具体task的bot需要费不少工夫，而且后期还要大量的维护，因为太多的hand crafted features被用到，整个bot的框架横向扩展性相对来说较差，换一个场景基本上就需要重新开发一套，人力成本太高了。</p>
<p>bot的理想非常丰满，大公司描绘的场景也确实很美，但现实的bot却狠狠地浇了一盆冷水下来。期望越高，失望越大。如果媒体一味地吹捧bot，仿佛整个世界明天就会是bot的了，对bot的发展并无益处，捧杀只会带来气泡，破裂之后，一切如初。</p>
<p>功能强大的、开放域的bot在短期内是比较难实现的，但是如果降低期望，将bot不应当做是一种技术层面的革命，而应当做交互层面的革新才是理性的态度，bot作为一种入口，可能大家都不再需要一个随身携带的终端，只需要找到一个可以识别身份，可以联网的硬件，比如一面镜子，就可以执行很多的task，订机票、买东西等等等等。bot这个时候起到的是一个操作的入口和背后执行各种不同task的黑箱，我们不需要看到整个执行过程，也不需要知道原理是什么，通过一些简单的语言交互，就能完成一些复杂的task，终端要做的事情就是反馈结果和接收输入，执行的过程都在云端，各种bot云。</p>
<p>而这一切的关键是解决好task-oriented bot，用更多data driven的解决方案来代替传统的人工features和templates。</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>bot是一个综合性的问题，涉及到下面三个主要问题：</p>
<p>1、response generation(selection)</p>
<p>对话生成是最后一个步骤，是输出的部分。简单总结下，有四种solutions：</p>
<p><b>solution 1</b> 直接根据context来生成对话，这方面最近的paper非常地多，尤其是seq2seq+attention框架席卷了NLP的很多任务之后，对话生成的benchmark也一次又一次地被各种model刷新着。对话生成的问题，被定义为基于某个条件下的生成模型，典型的根据context来predict words，涉及到句子生成的问题，评价问题就会是一个比较难的问题。</p>
<p><b>solution 2</b> 当然有的paper并不是将对话生成定义为语言模型问题，而是一个next utterance selection的问题，一个多选一的问题，给定一个context，给定一个utterance candidate list，从list中选择一个作为response，当然这类问题的难度会小很多，评价起来也非常容易，但是数据集准备起来要多花一些功夫，而且在实际应用中不好被借鉴。</p>
<p><b>solution 3</b> rule-based或者说template-based，response的最终形式其实是填充了一个模板而成的，大多数的东西是给定的，只有一些具体的value需要来填充。这一类解决方案很适合做task-oriented bot，但过多的人工features和templates导致了其难以移植到其他task上。</p>
<p><b>solution 4</b> query-based或者说example-based，response是来自于一个叫做知识库的数据库，里面包含了大量的、丰富的example，根据用户的query，找到最接近的example，将对应的response返回出来作为输出。这一类解决方案非常适合做娱乐、搞笑用的bot，核心技术在于找更多的数据来丰富知识库，来清洗知识库。但毕竟respnose是从别人那里拿出来的，可能会很搞笑，但大多数会牛头不对马嘴。</p>
<p>2、dialog state tracking(DST)</p>
<p>有的paper称DST为belief trackers，这个部件其实是bot的核心，它的作用在于理解或者捕捉user intention或者goal，只有当你真的知道用户需要什么，你才能做出正确的action或者response。关于这个部分，会有Dialog State Tracking Challenge比赛。一般来说都会给定一个state的范围，通过context来predict用户属于哪个state，有什么样的需求，是需要查询天气还是要查询火车票。</p>
<p>3、user modeling</p>
<p>bot面向具体的业务，都是和真实的user来打交道的，如果只是简单的FAQ bot，回答几个常见的问题可能不需要这块，但如果是其他更加复杂、细致的业务，都需要给用户建模，相同的问题，bot给每个人的response一定是不同的，这个道理非常简单。user modeling，需要涉及的不仅仅是简单的用户基本信息和用户的一些显式反馈信息，而更重要的是用户的history conversations，这些隐式的反馈信息。就像是推荐系统火起来之前，大家都是中规中矩地卖东西，但是有一些聪明人开始分析用户的行为，不仅是那些点赞行为，更多的是那些用户不经意间留下的“蛛丝马迹”，从而知道了用户对哪些东西潜在地感兴趣，也就是后来推荐系统在做的事情。对user进行建模，就是做一个个性化的bot，生成的每一个response都有这个user鲜明的特点。</p>
<h1 id="语料"><a href="#语料" class="headerlink" title="语料"></a>语料</h1><p>大型的语料都是用来训练开放域bot对话生成模型的，数据源一般都是来自社交网站。而对于task-oriented bot来说，客户的数据一般规模都非常地小，这也正是难以将data driven的方案直接套用到task-oriented bot上的一个主要原因。</p>
<p>[1]中给出了bot训练语料的survey，感兴趣的同学可以读一下这篇survey。</p>
<p><img src="media/1.png" alt="1"></p>
<p>图来自文章[13]，英文的语料确实比较多，Sina Weibo那个语料是华为诺亚方舟实验室release的[12]。从twitter或者微博上产生bot数据的话，“conversational in nature”效果不如从ubuntu chat logs这种聊天室产生的数据更加适合训练response生成模型，因为更加天然无公害。文章[5]也用了一个大型中文语料，数据来自百度贴吧。</p>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p> 研究bot的paper是在太多了，这是一个非常活跃的研究领域，细分的方向也非常的多，接下来按照所针对的研究问题来分别介绍一些模型。</p>
<h2 id="seq2seq生成模型"><a href="#seq2seq生成模型" class="headerlink" title="seq2seq生成模型"></a>seq2seq生成模型</h2><p> 现在最流行的解决方案是seq2seq+attention，encoder将user query feed进来，输出一个vector representation来表示整个query，然后作为decoder的condition，而decoder本质上就是一个语言模型，一步一步地生成response，[2]采用就是这种方案，google用了海量的参数训练出这么一个模型，得到了一个不错的bot。</p>
<p><img src="media/8.png" alt="8"></p>
<p> 而典型的seq2seq存在一个问题，就是说容易生成一些“呵呵”的response，即一些非常safe，grammatical但没有实际意义的response，比如”I don’t know!”之类的。原因在于传统的seq2seq在decoding过程中都是以MLE(Maximum Likelihood Estimate)为目标函数，即生成最grammatical的话，而不是最有用的话，这些safe句子大量地出现在训练语料中，模型学习了之后，无可避免地总是生成这样的response，而文章[3]借鉴了语音识别的一些经验，在decoding的时候用MMI（Maximum Mutual Information）作为目标函数，提高了response的diversity。</p>
<p> 文章[4]认为类似于RNNLM这样的语言模型在生成人话质量不高的根本原因在于，没有处理好隐藏在utterance中的随机feature或者说noise，从而在生成next token（short term goal）和future tokens（long term goal）效果一般。</p>
<p><img src="media/3.png" alt="3"></p>
<p> 在生成每一个utterance时，需要用到四个部分，encoder RNN、context RNN、latent variable、decoder RNN，按顺序依次输入和输出。这里的latent variable和IR中的LSI有一点异曲同工，latent表明我们说不清他们到底具体是什么，但可能是代表一种topic或者sentiment，是一种降维的表示。</p>
<p> 文章[5]提出了一种叫做content introducing的方法来生成短文本response。</p>
<p><img src="media/4.png" alt="4"></p>
<p><b>step 1</b> 给定query之后，预测一个keyword作为response的topic，这个topic词性是名词，这里的keyword并不能捕捉复杂的语义和语法，而只是根据query的每个词来预估出一个PMI（Pointwise Mutual Information）最高的名词作为keyword.</p>
<p><b>step 2</b> [5]的模型叫做Sequence To Backward and Forward Sequences，首先进行backward step，给定一个query，用encoder表示出来得到一个context，decoder的部分首先给定keyword作为第一个词，然后进行decoding，生成的这部分相当于keyword词前面的部分；接下来进行的是forward step，也是一个典型的seq2seq，用encoder将query表示成context，然后给定backward生成的话和keyword作为decoder的前半部分，继续decoding生成后半部分。整个的流程这样简单描述下：</p>
<p><b>step 1</b> query + keyword =&gt; backward sequence</p>
<p><b>step 2</b> query + keyword + backward sequence(reverse) =&gt; forward sequence</p>
<p><b>step 3</b> response = backward (reverse) sequence + keyword + forward sequence</p>
<h2 id="user-modeling模型"><a href="#user-modeling模型" class="headerlink" title="user modeling模型"></a>user modeling模型</h2><p>文章[6]针对的问题是多轮对话中response不一致的问题，将user identity（比如背景信息、用户画像，年龄等信息）考虑到model中，构建出一个个性化的seq2seq模型，为不同的user，以及同一个user对不同的请将中生成不同风格的response。</p>
<p><img src="media/2.png" alt="2"></p>
<p>[6]的模型叫Speaker Model，是一个典型的seq2seq模型，不同的地方在于在decoding部分增加了一个speaker embedding，类似于word embedding，只是说这里对用户进行建模。因为无法对用户的信息显式地进行建模，所以用了一种embedding的方法，通过训练来得到speaker向量，下面左边的图是speaker向量在二维平面上的表示，具有相似背景信息的user就会很接近，与word向量一个道理。</p>
<h2 id="reinforcement-learning模型"><a href="#reinforcement-learning模型" class="headerlink" title="reinforcement learning模型"></a>reinforcement learning模型</h2><p>用增强学习来解决人机对话问题具有很悠久的历史，只不过随着AlphaGo的炒作，deepmind公司将增强学习重新带回了舞台上面，结合着深度学习来解决一些更难的问题。</p>
<p>增强学习用long term reward作为目标函数，会使得模型通过训练之后可以predict出质量更高的response，文章[7]提出了一个模型框架，具有下面的能力：</p>
<p>1、整合开发者自定义的reward函数，来达到目标。</p>
<p>2、生成一个response之后，可以定量地描述这个response对后续阶段的影响。</p>
<p><img src="media/5.png" alt="5"></p>
<p>两个bot在对话，初始的时候给定一个input message，然后bot1根据input生成5个候选response，依次往下进行，因为每一个input都会产生5个response，随着turn的增加，response会指数增长，这里在每轮对话中，通过sample来选择出5个作为本轮的response。</p>
<p>在一个大型数据集上训练一个效果不错的seq2seq作为初始值，用增强学习来提升模型实现自定义reward函数的能力，以达到期待的效果。</p>
<p>文章[7]的模型可以生成更多轮数的对话，而不至于过早地陷入死循环中，而且生成的对话diversity非常好。</p>
<h2 id="task-oriented-seq2seq模型"><a href="#task-oriented-seq2seq模型" class="headerlink" title="task-oriented seq2seq模型"></a>task-oriented seq2seq模型</h2><p>现有的task-oriented bot多是采用rule-based、template-based或者example-based或者是综合起来用，用data driven的解决方案十分稀有。文章[8]和[9]就是尝试在bot的个别部件上采用深度学习的技术来做，并且给出了切实可行的方案。</p>
<p>文章[8]先是从一个大家熟知的场景开始介绍，一个经验丰富的客服是如何带一个新入职的客服，分为四个阶段：</p>
<p>1、告诉新客服哪些”controls”是可用的，比如：如何查找客户的信息，如何确定客户身份等等。</p>
<p>2、新客服从老客服做出的good examples中模仿学习。</p>
<p>3、新客服开始试着服务客户，老客服及时纠正他的错误。</p>
<p>4、老客服放手不管，新客服独自服务客户，不断学习，不断积累经验。</p>
<p>[8]的模型框架就是依照上面的过程进行设计的：</p>
<p>1、开发者提供一系列备选的actions，包括response模板和一些API函数，用来被bot调用。</p>
<p>2、由专家提供一系列example dialogues，用RNN来学习。</p>
<p>3、用一个模拟user随机产生query，bot进行response，专家进行纠正。</p>
<p>4、bot上线服务，与真实客户进行对话，通过反馈来提高bot服务质量。</p>
<p><img src="media/6.png" alt="6"></p>
<p>一个完整的工作流程由上图描述，具体步骤看下图：</p>
<p><img src="media/12.png" alt="12"></p>
<p>训练的时候是用一部分高质量的数据进行监督学习SL，用增强学习RL来优化模型，得到质量更高的结果。</p>
<p>文章[9]平衡了两种流行方案的优缺点，提出了一套有参考价值的、具有实际意义的seq2seq解决方案。</p>
<p><img src="media/10.png" alt="10"></p>
<p>一共五个组件：</p>
<p>1、 Intent Network</p>
<p>这个部分可以理解为seq2seq的encoder部分，将用户的输入encode成一个vector。</p>
<p>2、 Belief Trackers</p>
<p>又被称为Dialogue State Tracking(DST)，是task-oriented bot的核心部件。本文的Belief Trackers具有以下的作用：</p>
<ul>
<li>支持各种形式的自然语言被映射成一个有限slot-value对集合中的元素，用于在数据库中进行query。</li>
<li>追踪bot的state，避免去学习那些没有信息量的数据。</li>
<li>使用了一种weight tying strategy，可以极大地减少训练数据的需求。</li>
<li>易扩展新的组件。</li>
</ul>
<p>3、 Database Operator</p>
<p>数据库查询的输入来自于Belief Trackers的输出，即各种slot的概率分布，取最大的那个作为DB的输入，进行查询，获取到相应的值。</p>
<p>4、 Policy Network</p>
<p>这个组件是像一个胶水，起到粘合其他上面三个组件的作用。输入是上面三个组件的输出，输出是一个向量。</p>
<p>5、 Generation Network</p>
<p>最后一个组件是生成模型，本质上是一个语言模型，输入是Policy Network的输出，输出是生成的response，再经过一些处理之后可以返回给用户了。这里的处理主要是将response中的slot，比如s.food还原成真实的值。这一步和文章[8]的step 10一样，将具体的值还原到entity上。</p>
<p>完全用end-to-end来解决task-oriented是不可能的事情，一定是在一个框架或者体系内用这种seq2seq的解决方案来做这件事情，文章[8]和[9]给出了很大的启发。</p>
<h2 id="Knowledge-Sources-based模型"><a href="#Knowledge-Sources-based模型" class="headerlink" title="Knowledge Sources based模型"></a>Knowledge Sources based模型</h2><p>纯粹的seq2seq可以解决很多问题，但如果针对具体的任务，在seq2seq的基础上增加一个相关的knowledge sources会让效果好很多。这里的knowledge可以是非结构化的文本源，比如文章[10]中的ubuntu manpages，也可以是结构化的业务数据，比如文章[9]中的database，也可以是一个从源数据和业务数据中提取出的knowledge graph。</p>
<p>文章[10]作者将bot任务定义为next utterance classification，有一点像question answering任务，给定一个context和一个response candidate list作为备选答案，通过context来从candidate list中选择正确的response。本文的贡献在于在context的基础上，引入了task相关的外部专业知识库，并且这个知识库是非结构化的。</p>
<p><img src="media/11.png" alt="11"></p>
<p>模型是三个rnn encoder组成，一个rnn来encode context，一个rnn来encode response，还有一个rnn来encode knowledge，然后综合起来做预测，选出最合适的response。模型被称作knowledge encoder。因为数据集采用的是ubuntu technical support相关的数据集，外部资源就选用了ubuntu manpages。</p>
<h2 id="context-sensitive模型"><a href="#context-sensitive模型" class="headerlink" title="context sensitive模型"></a>context sensitive模型</h2><p>文章[11]的模型比较简单，但考虑的问题意义很大，history information的建模对于bot在解决实际工程应用的帮助很大，也直接决定了你的bot是否能够work。作者将history context用词袋模型表示，而不是我们经常采用的rnn，然后将context和用户query经过一个简单的FNN，得到一个输出。</p>
<p><img src="media/9.png" alt="9"> </p>
<h1 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h1><p>bot response评价很难，虽然说可以借鉴机器翻译的自动评价方法BLEU来做，但效果不会太好。几乎每篇paper都是会花钱雇人来做人工评价，设计一套评价机制来打分，人工的评价更具有说服力。对于实际工程应用更是如此，用户说好才是真的好。而不是简单地拿着自己提的、有偏的指标，和几个方法或者其他公司的bot进行对比，来说明自己好。</p>
<h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><p>读了一些paper，也和一线在做bot应用的工程师交流之后，有了一点思考，总结如下：</p>
<p>1、要不要做bot？流行一种说法是市面上没有好用的bot，要解决bot的问题需要很多技术同时进步，可能还需要非常长的一段时间，现在用这个东西来做business，简直荒谬。我个人的看法是，解决具体task的bot，结合当前先进的技术，做一些框架性的工具，并不是那么遥远的事情，虽然不容易，但却非常有意义，解决了垂直领域的bot问题，才有可能解决open domain的bot问题。也正是因为不容易，提高了门槛，才会出现真正的机会，诞生一些很牛的技术公司。</p>
<p>2、open domain还是task-oriented？如果是我，我会选后者，因为前者只是一个梦想，一个遥不可及的梦想，需要更多的技术层面上的大突破。task-oriented更加具体，更加实用，针对具体的业务，提供一些解决方案，已经有很多企业在做了，虽然一个通用性或者扩展性强的解决方案还没有出现，但一定是一个趋势，也是新一代做bot的公司的机会。</p>
<p>3、task-oriented bot为什么难，该朝哪个方向来发力？end-to-end是一种理想化的模型，用深度学习模型从大量训练数据中来“捕捉”一些features，“拟合”一些函数，虽然可以得到很不错的效果，而且使用起来确实很方便，但尴尬就尴尬在具体的task中是拿不到海量数据的，数据规模小了之后，纯粹的end-to-end就变得非常鸡肋了。然而真实的场景中，很多企业又有一定的数据，也有bot的需求，所以现在成熟的解决方案就是针对你的具体业务，来设计一些features，templates和rules，当客户的业务发生更改时，需要不断地维护现有的bot系统，十分费时费力。真实的场景中往往涉及到很多结构化的业务数据，纯粹地、暴力地直接根据context生成response是不可能做到的，文章[8][9]都给出了非常有启发性的解决方案，将end-to-end应用在局部，而非整体上，配合上Information Extraction和Knowledge Graph等技术，实现一个高可用的框架体系，这个应该是task-oriented bot的发展方向。</p>
<p>4、response的生成应该与哪些因素有关呢？response质量的好坏，需要联系到这几个features：（1）user query，用户的提问，用户在这轮对话中到底在问什么，准确地理解用户的意图，这是至关重要的。（2）user modeling，对用户进行建模，包括用户的基本信息，还有更重要的是用户history conversation logs的mining，这个工作很难，但同时也很见水平，也是一家技术公司证明自己技术牛逼的一种途径。logs的挖掘现在很常见，不见得大家都做的很好，而这里的logs不是一般的设定好的、结构化的指标，而是非结构化的文本logs，挖掘起来难度更大。另外一点，也是paper种看到的，user emotion，情感分析是nlp中研究比较多的task，用户的情绪直接关系到销售的成败，如果技术足够牛，可以考虑的因素就可以足够多，对user的分析也就足够清晰。将history生挂在模型中不是一个好办法，因为history是不断增长，会导致模型在捕捉信息时出现问题，更好的办法可能是build user profile之类的东西，将history沉淀出来，作为一个vector representation，或者一种knowledge graph来表征一个user。有了这种能力的bot，说的冠冕堂皇一点就是个性化的bot。（3）knowledge，外部知识源，涉及到具体业务的时候，业务数据也是一种knowledge，如何将knowledge建模到模型中，在生成对话的时候可以更加专业和准确也是一个非常重要的问题。bot是一个综合性的难题，不仅仅是系统框架上的难，而且是建模上的难。</p>
<p>5、我一直觉得做人和看问题都不可以极端，世界并非非黑即白，而是介于两者之间的连续值。不可能说要么做成一个open-domain巨无霸的bot，要么就是一个什么具体功能都没有的bot，不能只看到现有的bot不成熟，以及幻想中的bot遥不可及，就开始黑这个领域，还嘲笑人家能够居然拿到投资。争吵这些毫无意义，真正有意义的是深挖这个领域，找到痛点和难点，逐个击破，不断地推进这个领域的发展，而不是像一些街边看热闹的人一样，简直无趣！在很多领域突破之前，仿佛都看不到曙光，但几年之后很多当时难以解决的问题不都是红海一片，满大街都是了么？做一个通用的bot可能很长一段时间内都是一件比较困难的事情，但做一个高可用、扩展性不错的bot解决方案还是有盼头的，不必过度自信，也不必妄自菲薄，踏踏实实地做就是了。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://arxiv.org/pdf/1512.05742.pdf" target="_blank" rel="external">A Survey of Available Corpora for Building Data-Driven Dialogue Systems</a></p>
<p>[2] <a href="http://cn.arxiv.org/pdf/1506.05869.pdf" target="_blank" rel="external">A Neural Conversational Model</a></p>
<p>[3] <a href="http://arxiv.org/pdf/1510.03055v1.pdf" target="_blank" rel="external">A Diversity-Promoting Objective Function for Neural Conversation Models</a></p>
<p>[4] <a href="https://arxiv.org/pdf/1605.06069v3.pdf" target="_blank" rel="external">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</a></p>
<p>[5] <a href="http://cn.arxiv.org/pdf/1607.00970" target="_blank" rel="external">Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation</a></p>
<p>[6] <a href="https://arxiv.org/pdf/1603.06155.pdf" target="_blank" rel="external">A Persona-Based Neural Conversation Model</a></p>
<p>[7] <a href="http://arxiv.org/pdf/1606.01541v3.pdf" target="_blank" rel="external">Deep Reinforcement Learning for Dialogue Generation</a></p>
<p>[8] <a href="http://arxiv.org/pdf/1606.01269v1.pdf" target="_blank" rel="external">End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning</a></p>
<p>[9] <a href="http://arxiv.org/pdf/1604.04562v2.pdf" target="_blank" rel="external">A Network-based End-to-End Trainable Task-oriented Dialogue System</a></p>
<p>[10] <a href="http://media.wix.com/ugd/b6d786_137894b7b3a341a09ed0c0b45b46dbb6.pdf" target="_blank" rel="external">Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue Systems</a></p>
<p>[11] <a href="https://michaelauli.github.io/papers/chitchat.pdf" target="_blank" rel="external">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</a></p>
<p>[12] <a href="http://staff.ustc.edu.cn/~cheneh/paper_pdf/2013/HaoWang.pdf" target="_blank" rel="external">A Dataset for Research on Short-Text Conversation</a></p>
<p>[13] <a href="http://arxiv.org/pdf/1506.08909v3.pdf" target="_blank" rel="external">The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems</a></p>
<h1 id="研究组和研究人员"><a href="#研究组和研究人员" class="headerlink" title="研究组和研究人员"></a>研究组和研究人员</h1><p>bot是一个非常活跃的研究领域，全世界有很多的人都在做相关的研究。下面列的是最近所读paper的作者或者所在的group：</p>
<p>[1] <a href="http://mi.eng.cam.ac.uk/research/dialogue/" target="_blank" rel="external">Cambridge Dialogue Systems Group</a></p>
<p>[2] <a href="http://www.noahlab.com.hk/topics/ShortTextConversation" target="_blank" rel="external">Huawei NOAH’S ARK LAB</a></p>
<p>[3] <a href="http://web.stanford.edu/~jiweil/" target="_blank" rel="external">Jiwei Li</a></p>
<p>[4] <a href="http://cs.mcgill.ca/~rlowe1/" target="_blank" rel="external">Ryan Lowe</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引&quot;&gt;&lt;a href=&quot;#引&quot; class=&quot;headerlink&quot; title=&quot;引&quot;&gt;&lt;/a&gt;引&lt;/h1&gt;&lt;p&gt;chatbot是最近一段时间非常火的一个词或者一个应用，不仅仅各大新闻媒体在热炒bot的概念，各大巨头也投入巨大的资源进行研发，arxiv上刷出bo
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>A Neural Network Approach to Context-Sensitive Generation of Conversational Responses #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/15/A-Neural-Network-Approach-to-Context-Sensitive-Generation-of-Conversational-Responses-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/15/A-Neural-Network-Approach-to-Context-Sensitive-Generation-of-Conversational-Responses-PaperWeekly/</id>
    <published>2016-07-15T22:56:35.000Z</published>
    <updated>2016-07-17T06:49:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文分享的这篇paper是旨在训练一个data driven open-domain的bot，在生成response的时候不仅仅考虑user message（query），而且考虑past history作为context。paper的题目是<a href="https://michaelauli.github.io/papers/chitchat.pdf" target="_blank" rel="external">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</a>，作者来自蒙特利尔大学、乔治亚理工、facebook和微软研究院，本文最早发于2015年6月。</p>
<p>开放域的端到端response生成在今年已经不是什么新鲜事了，各种复杂的网络，考虑各种各样的信息，然而在去年的这个时候，本文就提出了一种data driven的解决方案，是一篇有开创性的paper。</p>
<p>bot的几大核心问题，包括：</p>
<p>1、response generation（或者selection）</p>
<p>2、dialogue state tracking</p>
<p>3、user modeling</p>
<p>不管是开域的还是闭域的bot都需要解决好以上三个问题才能做出一个高质量的bot。本文针对的问题是第一个，用的思路也是现在看来比较自然的一种，用语言模型来生成response。</p>
<p>考虑history utterances的responses生成问题，先定义一些参数，m表示message（query），c表示context，r表示response。本文要解决的其实是下面这个问题：</p>
<p><img src="media/1.png" alt="1"></p>
<p>1、Tripled Language Model </p>
<p>将c，m，r作为一句话来理解，给定c和m之后，不断地生成r的内容。<br>这个模型存在一个比较严重的问题是c如果过长的话，用BPTT训练不了RNNLM。（其实换作LSTM或者GRU单元就会好很多。）</p>
<p>2、Dynamic-Context Generative Model I </p>
<p><img src="media/2-1.png" alt="2"></p>
<p>将c和m用词袋模型表示，然后拼接起来，作为输入，通过一个简单的FNN，得到输出，即c和m vector representation。</p>
<p>3、Dynamic-Context Generative Model II</p>
<p><img src="media/3-1.png" alt="3"></p>
<p>与2不同的地方在于，将c和m单独作为输入，通过一个简单的FNN，得到c和m的vector representation。</p>
<p>这篇paper针对的问题很有意义，history information的建模对于bot在解决实际工程应用的时候意义重大，会让你的bot看起来更加的智能，和分析了用户日志的web应用会带来更好的服务是一个道理。本文的将具体的context包含到了模型中，在真正应用的时候，离线系统根据user conversation logs build一个user profile会更加实用，因为确实不可能把所有的history都丢到模型中一起来算。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文分享的这篇paper是旨在训练一个data driven open-domain的bot，在生成response的时候不仅仅考虑user message（query），而且考虑past history作为context。paper的题目是&lt;a href=&quot;https:/
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue Systems #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/15/Incorporating-Unstructured-Textual-Knowledge-Sources-into-Neural-Dialogue-Systems-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/15/Incorporating-Unstructured-Textual-Knowledge-Sources-into-Neural-Dialogue-Systems-PaperWeekly/</id>
    <published>2016-07-15T19:44:07.000Z</published>
    <updated>2016-07-15T20:07:21.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文是Ubuntu Dialogue Corpus贡献者的一篇文章，是接着Ubuntu数据集benchmark的model继续改进了一下。本文的题目是<a href="http://media.wix.com/ugd/b6d786_137894b7b3a341a09ed0c0b45b46dbb6.pdf" target="_blank" rel="external">Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue</a>。作者是来自麦吉尔大学的博士生<a href="http://cs.mcgill.ca/~rlowe1/" target="_blank" rel="external">Ryan Lowe</a>。</p>
<p>作者将bot任务定义为next utterance classification，有一点像question answering任务，给定一个context和一个response candidate list作为备选答案，通过context来从candidate list中选择正确的response。本文的贡献在于在context的基础上，引入了task相关的外部专业知识库，并且这个知识库是非结构化的。</p>
<p><img src="media/2.png" alt="2"></p>
<p>这个模型是ubuntu corpus中的baseline模型，称为dual encoder，一个rnn来encode context，一个rnn来encode response，然后综合起来做预测。</p>
<p><img src="media/1.png" alt="1"></p>
<p>本文模型相当于在dual encoder基础上增加了一个knowledge部分。模型是三个rnn encoder组成，一个rnn来encode context，一个rnn来encode response，还有一个rnn来encode knowledge，然后综合起来做预测，选出最合适的response。模型被称作knowledge encoder。</p>
<p>因为是ubuntu technical support相关的数据集，外部资源就选用了Ubuntu Manpages，各种命令的手册，通过从context中提取entity来匹配最相关的command manpage，为了快速定位manpage，用了hash的方法，先做了一个command entity hashtable和relation hashtable，一个是为了完全匹配，一个是为了相关匹配。得到相关的manpage之后，所包括的文本就是knowledge。效果如下图：</p>
<p><img src="media/3.png" alt="3"></p>
<p>本文定义的问题太过简单，与实际应用相去甚远。但本文用非结构化的外部知识来解决task-oriented bot问题的思路值得借鉴，不仅仅是bot问题，在问答系统中，外部知识如何应用，如何与神经网络模型结合起来使用都是一个非常重要的topic，也是真正可以用来解决实际问题的一种重要手段。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是Ubuntu Dialogue Corpus贡献者的一篇文章，是接着Ubuntu数据集benchmark的model继续改进了一下。本文的题目是&lt;a href=&quot;http://media.wix.com/ugd/b6d786_137894b7b3a341a09ed0c
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/14/The-Ubuntu-Dialogue-Corpus-A-Large-Dataset-for-Research-in-Unstructured-Multi-Turn-Dialogue-Systems-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/14/The-Ubuntu-Dialogue-Corpus-A-Large-Dataset-for-Research-in-Unstructured-Multi-Turn-Dialogue-Systems-PaperWeekly/</id>
    <published>2016-07-15T04:00:30.000Z</published>
    <updated>2016-07-15T18:01:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文分享的paper构建了一组大型非结构化的、多轮的对话系统语料，使用的原始数据来自<a href="https://irclogs.ubuntu.com/" target="_blank" rel="external">Ubuntu IRC Logs</a>，是一些关于Ubuntu的讨论组聊天数据。paper的题目是<a href="http://arxiv.org/pdf/1506.08909v3.pdf" target="_blank" rel="external">The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems</a>，作者是来自蒙特利尔大学的博士生<a href="http://cs.mcgill.ca/~rlowe1/" target="_blank" rel="external">Ryan Lowe</a>。</p>
<p>数据规模在100万左右，平均每组数据有8轮对话，最少包括3轮对话。之前的bot语料包括：Dialogue State Tracking Challenge(DSTC)、SwitchBoard这类结构化的数据和Twitter、Sina Weibo这种非结构化的数据，前者专注于预测用户的需求和状态，而后者数据中包括了一定数量的非“conversational in nature”，做bot的训练数据并不那么合适。本文构建的数据集是一个特定领域内的数据，ubuntu technical conversations，规模很大，对话轮数很多，质量很高，也是后续很多paper在研究bot response问题时常常采用的corpus。</p>
<p><img src="media/1.png" alt="1"></p>
<p>语料的构建非常有意义，大型的语料可以训练更加复杂的、偏向open domain的bot model，小型的语料可以解决具体的工程应用问题，如何从杂乱无章的unstructured data中提取出有用的信息，构造出一个适合训练、测试的数据集是一个很难却十分有意义的工作。</p>
<p>本文需要的数据是多轮的、两人的对话数据，但原始的数据是多人无序的对话数据，作者采用了一些小的技巧，并且忽略了一些不合适的数据，将原始数据处理成一个四元组：</p>
<p>(time,sender,recipient,utterance)</p>
<p>在构造模型的训练和测试集时，作者将上面的四元组处理成下面的三元组：</p>
<p>(context,response,flag)</p>
<p>context类似于用户输入，flag表示response是否是context相关联的，关联则为1，否则为0。</p>
<p>给定了数据集，下面就是作者提供的benchmark model，三个非常简单的model，tf-idf，rnn和lstm，目的是为了从response candidates中选择k个最适合context的response作为答案，然后计算相应的准确率。paper中给的方法是selection的方法，而不是generation，后面的很多研究都是generation，真正地从user query生成response。</p>
<p>本文提供的ubuntu dialogue corpus对于task-oriented、response generation的研究有着非常重要的意义，相比于华为给的微博数据，有更强的conversational in nature特征，更加适合对话生成的研究。本文作者的另外一篇survey文章<a href="http://arxiv.org/pdf/1512.05742.pdf" target="_blank" rel="external">A Survey of Available Corpora for Building Data-Driven Dialogue Systems</a>,系统地介绍了各大数据集。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文分享的paper构建了一组大型非结构化的、多轮的对话系统语料，使用的原始数据来自&lt;a href=&quot;https://irclogs.ubuntu.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Ubuntu IRC Logs&lt;/a&gt;，是一些关于U
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>随笔</title>
    <link href="http://rsarxiv.github.io/2016/07/14/%E9%9A%8F%E7%AC%94/"/>
    <id>http://rsarxiv.github.io/2016/07/14/随笔/</id>
    <published>2016-07-14T17:28:16.000Z</published>
    <updated>2016-07-14T18:29:27.000Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章的题目有些难产，一直想不出叫一个什么名字好。想写写最近看的东西的一点思考，也想写写一些别的东西，很纠结。以前写文章都喜欢用豆瓣fm推荐的第一首歌作为题目，然后开始写，虽然写的内容可能与题目毫无关系，但却不纠结。听着豆瓣fm，写着blog，是一种很多年的习惯了，习惯是一种可怕的东西，养成了之后就会一直这么做，一点都不能变，不然就会不舒服。</p>
<p>人之所以开心地活在这个世界上是因为大家有很多有意思的事情要做，人之所以害怕离开这个世界是因为很多有意思的事情还没做就结束了。不管现在的状况是怎样，心中充满希望就会不一样。有的人说生活不重要，家庭不重要，只有事业最重要，顾及儿女情长没有什么出息，实在不敢苟同，没有了坚实的地基，空中楼阁再漂亮又有何用？生活的目的就是生活本身，而不是虚伪地活给谁看，和谁比较，与谁相争，向谁证明。</p>
<p>我想用一个比喻来形容我遇到我的爱人可能会比较恰当。从前，有一只在一个无形的笼子里飞来飞去的鸟，他看着地上的人们心中总是有一种优越感，以为自己看得到整个世界，浑然不知自己身在牢笼中。后来来了另外一只鸟，一只特别好看的鸟，帮他打开了笼子，带着他飞向了一个真正广阔的天空，带着他到处飞翔，他才恍然大悟，原来世界可以这么大，于是他们开始了属于他们的旅途。世界很大，而我们很小，我们的格局很小，我们的心胸很小，我们看到的世界很小。世界很有趣，生活也不只是油盐酱醋，也不只是眼前的苟且，还有诗和远方。她用心准备婚礼的每一个细节，请帖用了一种古代西方信件的方式，用融化的蜡块来粘合信封，并且盖上我们俩专属的印章；回礼是一个精美的多肉植物，一盆一盆地种下、包好；喜糖是精心挑选的几种糖果，用一个手工纸袋包装好，过程很麻烦，但是她很享受，你要知道，可不是只做一份、十份，是要只做150份左右，她很享受这样的过程，因为她在用她的双手实现她感兴趣的事情，乐在其中。</p>
<p>世界可以灰暗，也可以很美好，决定于你是一个怎样的人，遇见一个怎样的人。很多人的生活每天都是在钱钱钱的争吵中度过的，永远没一个够，多少钱算多呢？人的欲望又能用多少钱来满足呢？生活可以很糟糕，也可以很美好，取决于你的追求，你所追求的是一种怎样的状态。欲望简单但不乏丰富多彩的生活才是真正高质量的生活，你内心保留地纯粹和纯真越多，生活质量就会越高，相反都会生活地很累，觉得生活都是负担。生活的目的就是生活本身，享受生活就是享受生活中的每一个细节，做一顿大餐，开一个小型音乐party，到录音棚录一首歌曲，看一场演唱会，听一场相声，看一场话剧，拍一些照片，吃一些好吃的垃圾食品，带着hare到处走走，吐槽一些烂剧，开始一场说走就走的旅行。生活中如果只有一个目的，只有工作这一件事情重要的话，那么生活本身就失去了意义，你赚钱也就失去了意义，有的人会说我不努力工作，不赚更多的钱怎么生活，完全可以40或50岁之后再开始享受生活。</p>
<p>最近看bot方面的paper，简单说一下对bot的一点naive的理解。bot火是不争的事实，也是一个必然的趋势，可能做成一个true ai的bot是一件遥不可及的事情，但做出一个能够解决实际问题，提升大家效率的bot是指日可待的事情。我觉得大家对bot的期许不应该是一个什么都能解决的通用工具或者通用技术，如果媒体地热炒加上民众过高的期待会造成新一轮的人工智能寒潮，对这个领域并不是好事。大家可以认为bot是一种新的交互方式，是一种新的操作入口，就像互联网，就像操作系统一样，是一种新的模式，在这种模式背后有大量先进的人工智能技术在做支撑。用户在任何一个地方都不再需要一个特定的终端来做一些常规的事情（不是所有的事情），只需要找一个联网的bot（可能是一个手机，可能是一面镜子，可能是一个电话亭，只要能联网并识别用户身份）就可以完成了，bot执行的过程不需要透明，只需要给出一个结果反馈就可以了，大家的生活围绕着各种各样垂直的bot来展开，只需要最简单的交互就可以完成之前需要复杂操作的事情，比如办个护照，买个机票。如果一个事情很难做的话，我们通常会将其分解成多个容易的事情，逐个攻破，不用期许过高，但相信bot一定会给大家的生活带来一次革命。</p>
<p>bot是一个很大的市场，如果真的能做成一个入口式的平台，相当于重新开辟了一个新的市场，重新定义了这个世界，任何的软件和应用都需要换一种形式，来为用户提供服务。bot确实是一个很美好的梦想，也不是那么遥不可及，但也不是那么容易，那么触手可及。还是需要大量的研究人员不断地努力，攻克难题。现在很多公司都在做bot领域的技术积累和市场占坑，以方便在日后新的一轮机会到来之时，分一杯羹。当前bot的平台有几家大企业在做，但整体来说还是将bot作为一种交互方式，将命令菜单化，并不是真正的对话，有一点iffft的感觉，但确实很多企业也在用这样的平台，大家都是在占坑。bot虽热，但并不是媒体热炒的那样，还是有很多的坑在里面，只有对其进行深入地思考和理解，保持一种冷静和独立地思考，才能真正地抓到痛点和需求，而不是一味地盲目跟随。技术的积累非常重要，因为真正要瓜分市场还是要很高门槛的，不是说你做一个简单的陪聊、逗乐用的机器人就掌握了bot核心技术，真的没有这么简单。周末的时候，准备对最近读bot paper的一些思考，写一篇survey。</p>
<p>美好的生活就是做喜欢的事情，比如亲手构建一个美好的世界，一个bot化的世界，一个更加简便、纯粹的世界。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章的题目有些难产，一直想不出叫一个什么名字好。想写写最近看的东西的一点思考，也想写写一些别的东西，很纠结。以前写文章都喜欢用豆瓣fm推荐的第一首歌作为题目，然后开始写，虽然写的内容可能与题目毫无关系，但却不纠结。听着豆瓣fm，写着blog，是一种很多年的习惯了，习惯是
    
    </summary>
    
    
      <category term="随笔" scheme="http://rsarxiv.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
</feed>
