<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>RSarXiv</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://rsarxiv.github.io/"/>
  <updated>2016-08-02T20:33:40.000Z</updated>
  <id>http://rsarxiv.github.io/</id>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>旧幕落下，新幕升起</title>
    <link href="http://rsarxiv.github.io/2016/08/02/%E6%97%A7%E5%B9%95%E8%90%BD%E4%B8%8B%EF%BC%8C%E6%96%B0%E5%B9%95%E5%8D%87%E8%B5%B7/"/>
    <id>http://rsarxiv.github.io/2016/08/02/旧幕落下，新幕升起/</id>
    <published>2016-08-02T18:54:22.000Z</published>
    <updated>2016-08-02T20:33:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>从过年那会筹划一些婚礼的想法开始，到拍婚纱照、找婚庆、跟拍、摄像、化妆、服装、场地、喜宴、安排接送车辆、亲朋住宿以及最近一个月疯狂地在淘宝上购买各种所需的东西，花费的所有时间和精力随着2016.07.31这一天这一场婚礼一起完美谢幕了，整个婚礼结束之后，我带着我的新娘子坐着地铁回家，想想大概也没有谁了。</p>
<p><img src="media/1.pic.jpg" alt="1.pi"></p>
<p>两天过去了，仍然没有从7.31的那场梦里醒来。感谢各位来宾，感谢各位工作人员，感谢保障小组的几位童鞋，感谢烁哥的乐队，感谢祝福我们的每一位！</p>
<p>当时家里不建议7.31结婚，因为他们很迷信地说8.1或者7.29更加适合结婚，而且我妈提前半个月就看天气预报说31号那天有大雨（我早就断定天气预报不准，而且提前那么早看根本没用），但我们仍然坚持就是7.31，不管那天什么天气，都一定是这一天，因为2015.7.31这一天我们正式在法律层面上成为了夫妻，当时离七夕很近，但我们觉得非节日的一天更加适合作为我们的纪念日，于是就在那天领了证，当时我就对韵韵说，明年的今天就是我们大婚的日子，我们要办最有意思、最不一样的婚礼，她点头答应。我们的坚持、我们的固执证明了7.31这一天就是属于我们的，非常棒的天气让整个婚礼进行的非常顺利，非常完美。</p>
<p><img src="media/3.pic.jpg" alt="3.pi"></p>
<p>回礼的准备花费了我们太多的时间和精力，直到婚礼前三天才准备好所有的回礼。长沙这边的一般做法都是准备一盒烟、一袋槟榔和一盒喜糖，当时我们就说要做的不一样，于是韵韵开始了每天长达两小时的淘宝生涯，并且乐此不疲，一盆多肉、一盒果酱和一盒手工喜糖。150份回礼，需要种150盆花，手工装150个喜糖盒子，装150个果酱盒，多亏了几位小同学的帮忙，才能顺利地准备好这些东西，韵韵喜欢兔子，所以袋子也是兔子，多肉的包装上贴着一张兔子贴纸，是我们这次婚礼的logo，是婚庆专门设计的。其实完全可以没必要这么累，直接买现成的就好，但是韵韵坚持要手工做每一个细节，希望每一个细节都做到完美，给宾客们带来不一样的感觉。她做到了！大家都非常喜欢这份回礼。</p>
<p><img src="media/2.pic.jpg" alt="2.pi"></p>
<p>婚礼主持人希望我们两个在婚礼现场可以真情告白一下，于是婚礼前的一周就没有踏实地睡好过，有一天夜里想着我们在一起的这一年多时间，点点滴滴都历历在目，又失眠了！那一晚想了很多很多，每一件事情的每一个细节都记忆犹新，想了很多想要对她说的话，平时也不会说什么深情的话，因为我也不是一个懂浪漫的人。她一直在忙着买各种各样必须的东西，所以直到婚礼前一天晚上在酒店里等我睡着了才开始准备告白的话，2点钟才睡觉，5点就起来准备化妆了。婚礼正式开始了，我之前准备好的词基本上都忘记了，确实有些紧张，但当我看到美丽的新娘站在我的面前时，我就一点都不紧张了，很自然地说出了我内心最真实的感动，以致于第一位伴娘哭的稀里哗啦的，韵韵的台风比我好，一句一句地讲出了我们在一起的美好！</p>
<p><img src="media/4.pic.jpg" alt="4.pi"></p>
<p>我和韵韵正式在一起是在马頔的演唱会上，是在2015.03.18，是我们认识后的第十天，一切看起来都很自然而然，没有任何刻意的安排。我一直有一个心愿就是能够办一场live concert，为我心爱的人献上她最爱的歌曲。于是，我决定在婚礼结束后，安排一场民谣风live concert，邀请喜欢唱歌的同学们一起来嗨。concert很成功，氛围非常好，烁哥的现场没的说，在座的每一位都沉浸在了当时的氛围中，我唱了马頔的《南山南》，韵韵唱了hebe的《小幸运》，一切都是那么地棒！</p>
<p><img src="media/6.pic_hd.jpg" alt="6.pic_hd"></p>
<p>韵韵说她最幸福的时刻就是每天早上醒来，看到身边的我和hare正在酣睡。hare是我们家的小狗，但全家都没有把他当做狗狗来养，我和韵韵是他的爸爸和妈妈，他还有外婆、爷爷和奶奶，每个人都特别爱他，他也是全家的开心果。如果说婚礼有遗憾的话，那就是hare没能来到现场见证他爸爸妈妈最幸福的一刻了。hare之所叫这个名字，是因为他刚刚来家里那会，我正对Air Jordan的Hare球鞋痴迷，Hare本是兔八哥的名字，所以就给他取了这个名字，后来不断地有了很多的名字，张甜心、张甜甜、小黑、心心等等好多的名字，他有一阵子有一些凌乱，突然不知道自己叫什么了。</p>
<p><img src="media/6.pic.jpg" alt="6.pi"></p>
<p>伴郎和伴娘都非常地帅气和美丽，他们给了我们很多的帮助和支持。伴娘都是韵韵的好闺蜜，有陪她一起长大的，有陪她一起工作的，有一个是这个世界上的另外一个她，她们相似的经历，让她们无话不谈，婚礼现场也就是她哭的最厉害了。伴郎都是我的小兄弟，他们替我扛了很多抢亲时的折磨，替我挡了很多的酒，三位伴郎在敬酒时毫无保留，最后通通倒下，有一点遗憾，没有能够参加最后的concert。感谢你们，因为你们，我和韵韵才会更加幸福！</p>
<p><img src="media/7.pic.jpg" alt="7.pi"></p>
<p>婚礼结束了，新的生活开始了！今年27岁，也该有一份自己的事业了，不管现在困难有多少，阻碍有多大，我和韵韵都要开始为我们的事业奋斗了！我一直觉得韵韵不仅仅是生活上的伴侣，更是心灵的伴侣，她最懂我的心，也不顾一切地支持我想做的事业，也愿意和我一起来奋斗这份事业。她细心、聪明、好学、热爱生活、眼光独到，所有美好的标签贴在她身上都不为过，她让我看到了更大的世界，让我明白了生活的意义，走进了我的内心深处让我不再孤独，她的勇敢、知性、独立都让我钦佩，给了我莫大的勇气，让我可以更加自信地活在这个世界上，去勇敢地挑战一些更难的事情。人生就是一场奇遇，感谢上帝让我遇见你！谢谢你，韵韵，我爱你！</p>
<p>旧的一幕已经落下，新的一幕正在升起。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从过年那会筹划一些婚礼的想法开始，到拍婚纱照、找婚庆、跟拍、摄像、化妆、服装、场地、喜宴、安排接送车辆、亲朋住宿以及最近一个月疯狂地在淘宝上购买各种所需的东西，花费的所有时间和精力随着2016.07.31这一天这一场婚礼一起完美谢幕了，整个婚礼结束之后，我带着我的新娘子坐着
    
    </summary>
    
    
      <category term="随笔" scheme="http://rsarxiv.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>如果我也做bot</title>
    <link href="http://rsarxiv.github.io/2016/07/25/%E5%A6%82%E6%9E%9C%E6%88%91%E4%B9%9F%E5%81%9Abot/"/>
    <id>http://rsarxiv.github.io/2016/07/25/如果我也做bot/</id>
    <published>2016-07-26T00:06:49.000Z</published>
    <updated>2016-07-26T00:55:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近初步地研究了下bot这个领域，有了一点浅薄的理解，于是开始想，如果我也做bot的话，解决好哪些问题才会做好这件事情？</p>
<p>1、创业是一件严肃的事情，不是儿戏，需要做好充足的准备，调研和积累都是非常重要的，只有做好100分的准备，才可能在面对各种未知的困难时不慌乱。所以，第一步就是调研，研究bot，从方方面面，比如：</p>
<p>（1）bot为什么会火？<br>（2）国内哪些企业在做bot？他们的产品有哪些优缺点？<br>（3）国外哪些企业在做bot？有哪些优缺点？<br>（4）投资情况如何？投资人怎么看待这个方向？<br>（5）bot需要哪些技术积累？</p>
<p>2、从媒体、投资人的观点来看，bot整个大方向没有错，那么到底应该做哪个子领域呢？是客服？还是技术支持？技术平台？垂直私人助理？平台上应用？可做的事情其实很多，16年开始才井喷式地炒作bot这个概念，所以今年可以当做是bot元年，既然是刚刚起步的一个领域，就有一个天然的好处，蛋糕足够大，品类足够多，看你想吃哪一块？当然也有一个天然的坏处，就是无章可循，大家都是摸着石头过河。</p>
<p>（1）国内的情况是，客服已经有很多家企业在做了，做的模式大同小异，技术方面各有特色吧，可能起步早的现在规模大一些，晚的小一些，但整体来看差异化不大。如果选择这个方向的话，必须做出差异化，研究现有方案的缺点，之前写过一篇文章，简单剖析了现有方案的缺点和可改进的点，让目前的客服bot更进一步，要么就是做一家客服bot，产品更完美、技术更好，和大家分一杯羹；要么就是提供技术支持，帮现有的bot企业更进一步，赚他们的钱。</p>
<p>（2）如果是做技术支持，典型的SaaS+B2B，用自己的技术服务来为别的企业提供支持，response generation、user modeling、context modeling、information extraction都是不错的方向，每一个做好了都有广阔的前景，以为技术支持不直接面对业务，而是帮助改进现有企业提升算法和建模能力，应用的面比较广，可以用在各种类型的bot上以及其他应用背景上。</p>
<p>（3）平台上的应用，比如slack上的bot，做一个有趣的小功能，提高team的工作效率。这个在国外非常地火，平台也很多，就像是现在ios上开发app一样，每个app都有自己的功能。我觉得这块要是做的话，很容易做出差异化，现在已经有各式各样的startups做着各式各样的bot。但整体来说，技术门槛比较低，有一点API整合的意思，但如果你将自己的技术封装成API，在上面做一个bot提供服务也是一种不错的尝试，而且产品周期特别短，但终究卖点应该还是你的技术支持，而不是这个bot。</p>
<p>（4）技术平台的话，类似的有很多帮助企业或个人构建bot在各种平台上跑，假如微信现在开放了这一块，技术平台一定大有用处，这个属于基础的工具类产品，将很复杂的技术做成人人可以轻松使用的工具是一件很有意义的事情，像是IDE的感觉，不管什么背景，只要是有想法，就可以通过这个工具来实现一个bot，如果复杂的，可能需要定制。</p>
<p>（5）特定任务的私人助理，比如帮忙管理日程、制定旅行计划之类的，术业有专攻嘛，这个最好是之前在其他平台上做类似功能的企业转型到bot这里来，有着足够的积淀，融入一些新的交互和技术来提升产品体验。</p>
<p>上面的每个子领域在国外都有模板可以参考，国内的话还比较少，所以是很大的机会，关键在于判断，在于具体情况具体分析。因为有些东西并不适合做成bot这种聊天式的交互方式，简单的几个按钮操作就可以轻松完成的事情，为什么非要打很多的字来做呢？</p>
<p>3、壁垒。你的核心竞争力是什么？什么是你会别人不会的？如果腾讯也做这个事情，你们该怎么办？你的企业增长点在哪里？如何做大？</p>
<p>这些问题是投资人最关注的问题，其实也是创业前最应该想明白的问题，如果自己都想不明白，或者很多问题难以回答的话，说明现在的情况还不适合创业或者拿投资。我认为，无论什么时候人都是最核心的竞争力，技术和交互形式日新月异，更迭很快，团队只要具有很强的学习能力，永远都不会落于下风。没有什么技术一定是只有你一人才会的，工程上的技术壁垒不应是你提出了一个举世无双、天下无敌的算法，而是你在这个领域内实践各种各样算法的经验积累。为什么说一定要专注地做好一个事情，只做这一件事情，将这件事情做到精，因为对这么细小的领域理解地如此之深的人没有几个，这是你的技术壁垒，也是企业的生存之道，也是其他大公司难以抄袭的重要原因。这个问题一定要想清楚，最重要的是人，在技术层面上，不要想着找到一个独门秘籍来打天下，而是对你所研究的问题有非常深入地理解和见解，这是最基本的也是最核心的；接下来才是如何发展和壮大的问题，这个问题需要讲故事的能力，描绘出一幅美好画面的能力。</p>
<p>我觉得人的能力是最根本的壁垒，当然会有不同看法。有的企业快速扩张，积累客户，可能觉得积累的数据和客户资源是壁垒，但我觉得如果一个新的更好用的技术出来了，而你的企业技术却没跟上的话，很容易就会被取代的，不管你是5w+，还是10w+的客户。</p>
<p>一点思考，欢迎交流。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近初步地研究了下bot这个领域，有了一点浅薄的理解，于是开始想，如果我也做bot的话，解决好哪些问题才会做好这件事情？&lt;/p&gt;
&lt;p&gt;1、创业是一件严肃的事情，不是儿戏，需要做好充足的准备，调研和积累都是非常重要的，只有做好100分的准备，才可能在面对各种未知的困难时不慌
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>bot,bot</title>
    <link href="http://rsarxiv.github.io/2016/07/25/bot-bot/"/>
    <id>http://rsarxiv.github.io/2016/07/25/bot-bot/</id>
    <published>2016-07-25T23:12:32.000Z</published>
    <updated>2016-07-26T00:05:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>科技媒体的文章有一个明显的好处，就是会报道很多不易被人发现、但却非常有意思的startups，帮助大家拓宽视野；同时也有一个明显的坏处，文章容易标题党，不够专业的编辑容易写出一些极端的结论，比如xxx一定会取代yyy，炒作概念。所以，这里借助了科技类媒体的优势，考察了下国外的bot startups所覆盖的业务和现状，总结如下：</p>
<p>1、外国的月亮比较圆。有一种常见的误区，也是由来很久的一种偏见，那就是国外的东西一定优质于国内的东西，单纯地从startups的主页来看，国外的风格整体更加清爽和小清新一点，而国内的主页整体来说，充满了一种网站模板没用心选的既视感，有些startups充满了乡土气息。但并不意味着，背后的技术一定比国内好，只是门脸做的不错，slogan喊得不错，每一个startup都有一个改变人类现有生活的理想，仔细看有可能只是一个驻扎在slack或者messenger平台上的小bot。</p>
<p>2、国外的bot startups种类比较多，各个level的企业都有，从最上面的应用层来说，slack、messenger、telegram、kik等各个message平台上都有大量的bot，包括各种各样的服务。这类bot门槛较低，缺乏核心技术，通常是一个idea来支撑整个企业，容易同质化，来源可能是各种bot比赛的产物，域名都是.ai，稍微大一点的支持多个平台，很多都是只在slack上使用，有一种bot成海的感觉，什么样的服务都可以用bot来做，强行改变交互方式。有的slack bot服务于team，有的是将slack与其他服务，比如google analytics，以bot的形式进行桥接。</p>
<p>3、有挺多的startups都在做app store的事情，聚合了大量不同类别的bot，统一进行管理，开发者开发好的bot都放在store中进行展示和销售。这类企业也是平台的性质，但没有自己独立的平台，所以做各大平台的聚合。</p>
<p>4、有的startups做的是降低开发bot门槛的事情，和平台提供接入服务不同，这类企业更具有技术性，将bot开发封装成简单的接口或者界面，供“开发者”甚至是小白来开发属于自己的bot，不管是新闻app还是天气、还是旅游都是几分钟配置的事情，完全没有难度。这类公司相比于平台上的简单bot来说，更加底层一些，也更有技术门槛，但结果却是让bot变得没有技术门槛了。</p>
<p>5、有的startups是独立于几大平台的，提供一种私人助理服务，包括会议、日程、旅行、金融各种服务，为了保证服务质量，常常采用AI+人工的模式。这类公司通常都有核心的技术和垂直领域的经验，对该领域地理解比较深，而且跟得上时代的潮流，用chat作为交互是一个大趋势，索性就早一点进入，确立市场地位。</p>
<p>6、有的startups专门做B2B的技术支持服务，提供NLP、知识抽取方面的服务，为上述的各类企业提供技术支撑，没有直接参与bot，但保证了bot的质量。</p>
<p>7、从各个startups成立时间和融资情况来看，平台上的bot都是2015年底或者2016年初开始热起来的，而2013、2014年就开始朝着这个方向做的企业，基本都是做技术平台、企业客服bot或者私人助理app的，相对来说技术壁垒大一些，门槛高，不容易被模仿和抄袭，所以融资情况较好，当然这个只是现在还存活的企业，死掉地可能也有很多。整体来看，slack之类的平台上做个好玩的bot难度不大，数量如雨后春笋般、井喷式地增长，质量良莠不齐，核心技术少，门槛低，从目前的融资情况看不是很好。而开始早并且技术壁垒大的startups有着更好的市场前景，融资情况也比较乐观。</p>
<p>8、可能是因为考察的startups还比较少，并没有发现像国内有那么多家bot企业都挤在客服这个领域，其他领域的bot企业相对较少，（也有可能是关注的比较少）。国内的微信并没有开放这么彻底，或者说没有一个类似的平台可以做类似的事情，所以各种小bot还没有井喷式地出现，但这是一个趋势，今后一定会有类似的平台出来。</p>
<p>9、bot在全球都很火，国内和国外的侧重点感觉不是很一样，国外的形式比较丰富，各个level的蛋糕都有人在吃，简直无孔不入，反观国内，大家都忙于抢客服这块大蛋糕，其他的蛋糕没有太多的人来吃，这样看来可能也是国内的一个机会，只要不做客服bot，做一些别的业务可能都会有几乎吧。</p>
<p>10、不是什么场景都适合用chatbot来解决的，很多时候我们简单操作下软件比和一个不怎么聪明的bot聊半天效率要高很多的，做bot的话，应该首先分析用哪个场景chat会比操作更加简单，而不是盲目地什么都搞成bot。这一点很重要，媒体的炒作，以及大公司的PR都容易蒙蔽双眼，失去理性判断，清醒地分析一下哪些方向是适合做bot的，而不是一味地去为了bot而bot。</p>
<p>注：所有的数据都是来自于<a href="https://www.crunchbase.com/" target="_blank" rel="external">CrouchBase</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;科技媒体的文章有一个明显的好处，就是会报道很多不易被人发现、但却非常有意思的startups，帮助大家拓宽视野；同时也有一个明显的坏处，文章容易标题党，不够专业的编辑容易写出一些极端的结论，比如xxx一定会取代yyy，炒作概念。所以，这里借助了科技类媒体的优势，考察了下国外
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>bot startups</title>
    <link href="http://rsarxiv.github.io/2016/07/25/bot-startups/"/>
    <id>http://rsarxiv.github.io/2016/07/25/bot-startups/</id>
    <published>2016-07-25T18:39:04.000Z</published>
    <updated>2016-07-25T21:18:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>罗列下各种媒体上提到的bot startups，包括：业务范围和融资情况。</p>
<h1 id="motion-ai"><a href="#motion-ai" class="headerlink" title="motion.ai"></a><a href="motion.ai">motion.ai</a></h1><p>用可视化地手段进行构建、训练和发布一个bot。喊出的口号是，只要你会画流程图，你就可以构建一个bot，可以在各种平台上搭建属于自己的bot，比如：sms、web、email、Fb Messenger、Slack等平台。</p>
<p>成立时间：2015.11.05<br>融资情况：$700k 种子轮<br>公司主页：<a href="http://motion.ai" target="_blank" rel="external">http://motion.ai</a></p>
<h1 id="CareerLark"><a href="#CareerLark" class="headerlink" title="CareerLark"></a><a href="http://www.careerlark.com/" target="_blank" rel="external">CareerLark</a></h1><p>构建于Slack平台的一家bot企业，旨在通过micro-feedback来提高生产力。</p>
<p>成立时间：未知<br>融资情况：$50k 种子轮<br>公司主页：<a href="http://www.careerlark.com/" target="_blank" rel="external">http://www.careerlark.com/</a></p>
<h1 id="Carla"><a href="#Carla" class="headerlink" title="Carla"></a><a href="http://carla.io/" target="_blank" rel="external">Carla</a></h1><p>一款虚拟助手，用于提醒自己、朋友和家人，通过自然语言添加日程和追踪自己一天的生活。</p>
<p>成立时间：未知<br>融资情况：未知<br>公司主页：<a href="http://carla.io/" target="_blank" rel="external">http://carla.io/</a></p>
<h1 id="Dexter"><a href="#Dexter" class="headerlink" title="Dexter"></a><a href="https://rundexter.com/" target="_blank" rel="external">Dexter</a></h1><p>帮助企业用户快速构建bot引擎，打造属于自己的bot。</p>
<p>成立时间：未知<br>融资情况：未知<br>公司主页：<a href="https://rundexter.com/" target="_blank" rel="external">https://rundexter.com/</a></p>
<h1 id="kip"><a href="#kip" class="headerlink" title="kip"></a><a href="http://kipthis.com/" target="_blank" rel="external">kip</a></h1><p>办公室团购助手，将B2C搬进bot中，方便大家购物，支持多种平台。</p>
<p>成立时间：2014.05.13<br>融资情况：$317k 两轮<br>公司主页：<a href="http://kipthis.com/" target="_blank" rel="external">http://kipthis.com/</a></p>
<h1 id="Rollio"><a href="#Rollio" class="headerlink" title="Rollio"></a><a href="https://www.rollioforce.com/" target="_blank" rel="external">Rollio</a></h1><p>CRM智能助手，将你的销售变得更加简单，用NLP技术来挖掘客户反馈来文本和声音信息，简化CRM。</p>
<p>成立时间：2014<br>融资情况：$670k 种子轮<br>公司主页：<a href="https://www.rollioforce.com/" target="_blank" rel="external">https://www.rollioforce.com/</a></p>
<h1 id="Assist"><a href="#Assist" class="headerlink" title="Assist"></a><a href="http://www.assi.st/" target="_blank" rel="external">Assist</a></h1><p>将企业现有的业务搬进文本消息平台中，用bot来帮企业做生意。</p>
<p>成立时间：未知<br>融资情况：未知<br>公司主页：<a href="http://www.assi.st/" target="_blank" rel="external">http://www.assi.st/</a></p>
<h1 id="magic"><a href="#magic" class="headerlink" title="magic"></a><a href="https://www.getmagicnow.com/" target="_blank" rel="external">magic</a></h1><p>一个基于文本信息平台的通用bot助理，涵盖的面比较广。</p>
<p>成立时间：2015<br>融资情况：$12M 两轮<br>公司主页：<a href="https://www.getmagicnow.com/" target="_blank" rel="external">https://www.getmagicnow.com/</a></p>
<h1 id="Polly"><a href="#Polly" class="headerlink" title="Polly"></a><a href="https://www.polly.ai/" target="_blank" rel="external">Polly</a></h1><p>基于slack平台的bot服务，收集和分析team的数据，提供一些服务，可定制化。</p>
<p>成立时间：2015<br>融资情况：未知<br>公司主页：<a href="https://www.polly.ai/" target="_blank" rel="external">https://www.polly.ai/</a></p>
<h1 id="StatsBot"><a href="#StatsBot" class="headerlink" title="StatsBot"></a><a href="https://statsbot.co/" target="_blank" rel="external">StatsBot</a></h1><p>基于slack平台的bot服务，提供google analytics、mixpanel、salesforce服务。</p>
<p>成立时间：2015<br>融资情况：未知<br>公司主页：<a href="https://statsbot.co/" target="_blank" rel="external">https://statsbot.co/</a></p>
<h1 id="Birdly"><a href="#Birdly" class="headerlink" title="Birdly"></a><a href="https://www.getbirdly.com/" target="_blank" rel="external">Birdly</a></h1><p>基于slack平台的bot服务，沟通team和salesforce的桥梁。</p>
<p>成立时间：2014<br>融资情况：$120k 种子轮<br>公司主页：<a href="https://www.getbirdly.com/" target="_blank" rel="external">https://www.getbirdly.com/</a></p>
<h1 id="zoom-ai"><a href="#zoom-ai" class="headerlink" title="zoom.ai"></a><a href="http://www.zoom.ai/" target="_blank" rel="external">zoom.ai</a></h1><p>企业级的智能助手，支持多个平台和多项服务。</p>
<p>成立时间：2016.02.22<br>融资情况：未知<br>公司主页：<a href="http://www.zoom.ai/" target="_blank" rel="external">http://www.zoom.ai/</a></p>
<h1 id="HeyTaco"><a href="#HeyTaco" class="headerlink" title="HeyTaco!"></a><a href="https://www.heytaco.chat/" target="_blank" rel="external">HeyTaco!</a></h1><p>基于slack平台的bot服务，当你觉得team中一个人做了一件awesome的事情，可以@username + taco emoji，然后该服务会记录下team中每个成员的taco数，攒齐N个可以换一些gift。</p>
<p>成立时间：2016.02.06<br>融资情况：未知<br>公司主页：<a href="https://www.heytaco.chat/" target="_blank" rel="external">https://www.heytaco.chat/</a></p>
<h1 id="skylar"><a href="#skylar" class="headerlink" title="skylar"></a><a href="https://skylar.ai/" target="_blank" rel="external">skylar</a></h1><p>为团队提供多种服务的bot，整合了一些在线工具API，基于slack和messenger平台。</p>
<p>成立时间：2015.11.17<br>融资情况：未知<br>公司主页：<a href="https://skylar.ai/" target="_blank" rel="external">https://skylar.ai/</a></p>
<h1 id="DigitalGenius"><a href="#DigitalGenius" class="headerlink" title="DigitalGenius"></a><a href="http://digitalgenius.com/" target="_blank" rel="external">DigitalGenius</a></h1><p>bot+人工客服服务，多平台多渠道客服。</p>
<p>成立时间：2013.12.01<br>融资情况：$8.35M 三轮<br>公司主页：<a href="http://digitalgenius.com/" target="_blank" rel="external">http://digitalgenius.com/</a></p>
<h1 id="workbot"><a href="#workbot" class="headerlink" title="workbot"></a><a href="https://www.workato.com/workbot-slack" target="_blank" rel="external">workbot</a></h1><p>基于slack平台的bot服务，为团队提供一系列数据服务。</p>
<p>成立时间：2016.01<br>融资情况：未知<br>公司主页：<a href="https://www.workato.com/workbot-slack" target="_blank" rel="external">https://www.workato.com/workbot-slack</a></p>
<h1 id="poncho"><a href="#poncho" class="headerlink" title="poncho"></a><a href="http://poncho.is/" target="_blank" rel="external">poncho</a></h1><p>量身定做的天气和旅行助手。</p>
<p>成立时间：2013.04.01<br>融资情况：$2M 种子轮<br>公司主页：<a href="http://poncho.is/" target="_blank" rel="external">http://poncho.is/</a></p>
<h1 id="Pana"><a href="#Pana" class="headerlink" title="Pana"></a><a href="https://www.pana.com/" target="_blank" rel="external">Pana</a></h1><p>bot+AI旅行安排服务。</p>
<p>成立时间：2015<br>融资情况：$1.45M 两轮<br>公司主页：<a href="https://www.pana.com/" target="_blank" rel="external">https://www.pana.com/</a></p>
<h1 id="Penny"><a href="#Penny" class="headerlink" title="Penny"></a><a href="https://www.pennyapp.io/" target="_blank" rel="external">Penny</a></h1><p>私人财产顾问型bot。</p>
<p>成立时间：2015.07<br>融资情况：$1.2M 种子轮<br>公司主页：<a href="https://www.pennyapp.io/" target="_blank" rel="external">https://www.pennyapp.io/</a></p>
<h1 id="x-ai"><a href="#x-ai" class="headerlink" title="x.ai"></a><a href="https://x.ai" target="_blank" rel="external">x.ai</a></h1><p>帮你安排会议的私人助手。</p>
<p>成立时间：2014.04.14<br>融资情况：$34.3M 三轮<br>公司主页：<a href="https://x.ai" target="_blank" rel="external">https://x.ai</a></p>
<h1 id="viv-ai"><a href="#viv-ai" class="headerlink" title="viv.ai"></a><a href="http://viv.ai/" target="_blank" rel="external">viv.ai</a></h1><p>一个帮助开发者快速开发bot的技术平台，涵盖的面比较广。</p>
<p>成立时间：未知<br>融资情况：30M 三轮<br>公司主页：<a href="http://viv.ai/" target="_blank" rel="external">http://viv.ai/</a></p>
<h1 id="Kasisto"><a href="#Kasisto" class="headerlink" title="Kasisto"></a><a href="http://kasisto.com/kai/" target="_blank" rel="external">Kasisto</a></h1><p>bot技术平台，帮助开发者轻松搭建一个bot。</p>
<p>成立时间：2013<br>融资情况：$2.25M<br>公司主页：<a href="http://kasisto.com/kai/" target="_blank" rel="external">http://kasisto.com/kai/</a></p>
<p>startups信息来自<a href="crunchbase.com">CrunchBase</a>。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;罗列下各种媒体上提到的bot startups，包括：业务范围和融资情况。&lt;/p&gt;
&lt;h1 id=&quot;motion-ai&quot;&gt;&lt;a href=&quot;#motion-ai&quot; class=&quot;headerlink&quot; title=&quot;motion.ai&quot;&gt;&lt;/a&gt;&lt;a href=&quot;motio
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>再谈bot</title>
    <link href="http://rsarxiv.github.io/2016/07/24/%E5%86%8D%E8%B0%88bot/"/>
    <id>http://rsarxiv.github.io/2016/07/24/再谈bot/</id>
    <published>2016-07-24T20:20:12.000Z</published>
    <updated>2016-07-25T04:32:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文是一个TechCrunch最近一年有关bot新闻报道的survey，从原文中提炼了些核心观点，来研究下国外bot的发展。</p>
<h1 id="Forget-Apps-Now-The-Bots-Take-Over"><a href="#Forget-Apps-Now-The-Bots-Take-Over" class="headerlink" title="Forget Apps, Now The Bots Take Over"></a><a href="https://techcrunch.com/2015/09/29/forget-apps-now-the-bots-take-over/" target="_blank" rel="external">Forget Apps, Now The Bots Take Over</a></h1><p>Sep 29, 2015 TechCrunch</p>
<p>正如浏览器取代了操作系统的地位作为新的平台，网站取代了应用程序的地位，bots将会取代移动app的地位，今后将会是bot store，各种各样的bot，而不再是app store。</p>
<p>类似于微信、Line、Facebook、Slack这样的message平台，将会成为一个新的入口。在message平台上有各种各样的bot，用户通过message与各种bot进行交互，来体会之前在手机各种app上的服务。</p>
<p><img src="media/1.png" alt="1"></p>
<blockquote>
<p>It’s a brave new bot-filled world, with new possibilities and new risks.</p>
</blockquote>
<h1 id="Check-out-the-new-AI-powered-TechCrunch-news-bot-on-Telegram-messenger"><a href="#Check-out-the-new-AI-powered-TechCrunch-news-bot-on-Telegram-messenger" class="headerlink" title="Check out the new AI-powered TechCrunch news bot on Telegram messenger"></a><a href="https://techcrunch.com/2016/03/15/check-out-the-new-ai-powered-techcrunch-news-bot-on-telegram-messenger/" target="_blank" rel="external">Check out the new AI-powered TechCrunch news bot on Telegram messenger</a></h1><p>Mar 15, 2016 TechCrunch</p>
<p>Techcrunch在Telegram上用<a href="https://chatfuel.com/" target="_blank" rel="external">Chatfuel</a>构建了一个news bot，用户可以通过订阅不同的topic，authors和sections，bot根据订阅内容每天会推送两次trending stories digest给用户，另外也可以进行一些问答、聊天。</p>
<p><img src="media/2.gif" alt="2"></p>
<h1 id="Microsoft-is-bringing-bots-to-Skype-—-and-everywhere-else"><a href="#Microsoft-is-bringing-bots-to-Skype-—-and-everywhere-else" class="headerlink" title="Microsoft is bringing bots to Skype — and everywhere else"></a><a href="https://techcrunch.com/2016/03/30/microsoft-is-bringing-bots-to-skype-and-everywhere-else/" target="_blank" rel="external">Microsoft is bringing bots to Skype — and everywhere else</a></h1><p>Mar 30, 2016 TechCrunch</p>
<p>微软CEO Nadella说,bots是下一代应用，只需要用自然语言与bot进行talk就可以完成之前大量手机app和网站做的工作。微软在bot的研究上投入很大，成果也颇多，小冰、Tay、Cortana，和开源的bot framework，并且将很多好玩的deep learning应用与bot做了整合，比如image caption bot，bing music bot，bing news bot。</p>
<p><img src="media/3.jpg" alt="3"></p>
<h1 id="Chat-app-Kik-launches-a-bot-store-and-anyone-can-make-bots-for-it"><a href="#Chat-app-Kik-launches-a-bot-store-and-anyone-can-make-bots-for-it" class="headerlink" title="Chat app Kik launches a bot store and anyone can make bots for it"></a><a href="https://techcrunch.com/2016/04/05/chat-app-kik-launches-a-bot-store-and-anyone-can-make-bots-for-it/" target="_blank" rel="external">Chat app Kik launches a bot store and anyone can make bots for it</a></h1><p>Apr 5, 2016 TechCrunch</p>
<p>Kik是一个聊天app，构建了自己的bot store，chat被认为是下一代操作系统，而聊天app则是新型的浏览器，bots是新型的网站。bot和聊天的环境类似，增加了一些特殊的trigger，用来激发一些特殊的动作。</p>
<p><img src="media/4.png" alt="4"></p>
<h1 id="Botlist-is-an-app-store-for-bots"><a href="#Botlist-is-an-app-store-for-bots" class="headerlink" title="Botlist is an app store for bots"></a><a href="https://techcrunch.com/2016/04/11/botlist-is-an-app-store-for-bots/" target="_blank" rel="external">Botlist is an app store for bots</a></h1><p>Apr 11, 2016 TechCrunch</p>
<p>Botlist是一家做bot聚合的平台，和豌豆荚是类似的概念，聚合了各种message平台上的各种bot应用。</p>
<p><img src="media/5.png" alt="5"></p>
<h1 id="TechCrunch-launches-a-personalized-news-recommendations-bot-on-Facebook-Messenger"><a href="#TechCrunch-launches-a-personalized-news-recommendations-bot-on-Facebook-Messenger" class="headerlink" title="TechCrunch launches a personalized news recommendations bot on Facebook Messenger"></a><a href="https://techcrunch.com/2016/04/19/all-your-bots-are-belong-to-us/" target="_blank" rel="external">TechCrunch launches a personalized news recommendations bot on Facebook Messenger</a></h1><p>Apr 19, 2016 TechCrunch</p>
<p>TechCrunch在Fb平台上的bot具备一个简单的个性化推荐的功能，根据用户的喜欢来推荐可能感兴趣的文章。</p>
<h1 id="ToyTalk-renames-to-PullString-repositions-as-authoring-tool-for-bots"><a href="#ToyTalk-renames-to-PullString-repositions-as-authoring-tool-for-bots" class="headerlink" title="ToyTalk renames to PullString, repositions as authoring tool for bots"></a><a href="https://techcrunch.com/2016/04/26/pullstring-bot-authoring/" target="_blank" rel="external">ToyTalk renames to PullString, repositions as authoring tool for bots</a></h1><p>Apr 26, 2016 TechCrunch</p>
<p>PullString做儿童市场，因为孩子的词汇量非常有限，而且都很容易理解，关键是孩子对那些nonsense的回答并不介意。</p>
<p><img src="media/6.gif" alt="6"></p>
<h1 id="Bots-Messenger-and-the-future-of-customer-service"><a href="#Bots-Messenger-and-the-future-of-customer-service" class="headerlink" title="Bots, Messenger and the future of customer service"></a><a href="https://techcrunch.com/2016/05/07/bots-messenger-and-the-future-of-customer-service/" target="_blank" rel="external">Bots, Messenger and the future of customer service</a></h1><p>May 7, 2016 TechCrunch</p>
<p><img src="media/7.png" alt="7"></p>
<p> 传统的客服总是给人留下低效的印象，而随着AI研究水平地不断提高，用bot来替代或者辅助人工客服将是一种趋势和潮流。</p>
<h1 id="Penny-raises-1-2M-in-seed-funding-for-its-personal-finance-bot"><a href="#Penny-raises-1-2M-in-seed-funding-for-its-personal-finance-bot" class="headerlink" title="Penny raises $1.2M in seed funding for its personal finance bot"></a><a href="https://techcrunch.com/2016/05/23/penny-raises-1-2m-in-seed-funding-for-its-personal-finance-bot/" target="_blank" rel="external">Penny raises $1.2M in seed funding for its personal finance bot</a></h1><p> May 23, 2016 TechCrunch</p>
<p> Penny是一个personal finance bot，通过chat来帮助用户管理finance。不过chat只能通过pre-populated messages，而不是自然语言。尽管进入了一个bot时代，但chat的方式并不是解决所有问题的最好方法，在shopping领域，传统的电商网站比bot更好用。</p>
<p><img src="media/8.jpg" alt="8"></p>
<h1 id="Microsoft-tries-its-hand-at-a-news-bot-with-Rowe"><a href="#Microsoft-tries-its-hand-at-a-news-bot-with-Rowe" class="headerlink" title="Microsoft tries its hand at a news bot with Rowe"></a><a href="https://techcrunch.com/2016/05/24/microsoft-tries-its-hand-at-a-news-bot-with-rowe/" target="_blank" rel="external">Microsoft tries its hand at a news bot with Rowe</a></h1><p>May 24, 2016 TechCrunch</p>
<p>微软太钟爱bot了，在新闻领域开发了一款bot，整合了自家一个新闻App News Pro的功能，通过topic来获取相关news，获取今日头条，获取系统推荐的news。</p>
<p> <img src="media/9.png" alt="9"></p>
<h1 id="Workato-unveils-Personal-Workbot-to-silence-some-of-the-Slack-bot-noise"><a href="#Workato-unveils-Personal-Workbot-to-silence-some-of-the-Slack-bot-noise" class="headerlink" title="Workato unveils Personal Workbot to silence some of the Slack bot noise"></a><a href="https://techcrunch.com/2016/06/23/workato-unveils-personal-workbot-to-silence-some-of-the-slack-bot-noise/" target="_blank" rel="external">Workato unveils Personal Workbot to silence some of the Slack bot noise</a></h1><p>Jun 23, 2016 TechCrunch</p>
<p>Workato提供一个bot服务Personal Workbot，为slack用户过滤掉channel中无关的信息，提高效率。</p>
<p><img src="media/10.png" alt="10"></p>
<h1 id="Zoom-ai-believes-an-automated-assistant-is-the-fix-for-a-weighty-workload"><a href="#Zoom-ai-believes-an-automated-assistant-is-the-fix-for-a-weighty-workload" class="headerlink" title="Zoom.ai believes an automated assistant is the fix for a weighty workload"></a><a href="https://techcrunch.com/2016/07/14/zoom-ai/" target="_blank" rel="external">Zoom.ai believes an automated assistant is the fix for a weighty workload</a></h1><p>Jul 14, 2016 TechCrunch</p>
<p>Zoom.ai与之前的chat bot startups不同，目的客户是企业。创始人说，bot更像是一种UI，bot背后的技术才是真正需要解决的问题，NLP技术才是最关键的东西。</p>
<h1 id="Legion-Analytics-is-building-bots-to-automate-your-sales-pitch"><a href="#Legion-Analytics-is-building-bots-to-automate-your-sales-pitch" class="headerlink" title="Legion Analytics is building bots to automate your sales pitch"></a><a href="https://techcrunch.com/2016/07/15/legion-analytics-kylie/" target="_blank" rel="external">Legion Analytics is building bots to automate your sales pitch</a></h1><p>Jul 15, 2016 TechCrunch</p>
<p>Legion Analytics这家公司借助人工智能技术，帮助销售团队更加高效地工作。并不是说用bot来替代人工销售团队，而是帮助他们处理更加耗时的邮件咨询和demo演示。</p>
<h1 id="Bot-influencers-are-the-programmatic-future-of-conversational-advertising"><a href="#Bot-influencers-are-the-programmatic-future-of-conversational-advertising" class="headerlink" title="Bot influencers are the programmatic future of conversational advertising"></a><a href="https://techcrunch.com/2016/07/21/bot-influencers-the-programmatic-future-of-conversational-advertising/" target="_blank" rel="external">Bot influencers are the programmatic future of conversational advertising</a></h1><p>Jul 21, 2016 TechCrunch</p>
<p>conversational广告有望改善目前digital ads的缺陷，可以做的更加relevant、contextual和unobtrusive。</p>
<h1 id="Why-do-chatbots-suck"><a href="#Why-do-chatbots-suck" class="headerlink" title="Why do chatbots suck?"></a><a href="https://techcrunch.com/2016/05/29/why-do-chatbots-suck/" target="_blank" rel="external">Why do chatbots suck?</a></h1><p>May 29, 2016 TechCrunch</p>
<p>文中的观点基本同意，chatbot领域太广容易失败，不如做好特定领域内的服务。bot有智能的，比如微软的Tay，也有不智能的，比如Facebook平台上的CNN chatbot，设定一些button，绑定一些特定的事件。市面上没有一个真正好用的bot，很多领域为了bot而bot，用传统的app通过几个步骤就可以完成的事情，在bot中需要通过打很多的字才能完成，其实用户并不在意你的东西是不是智能，也不关心你产品背后的技术多牛，只在乎你的产品是不是简单好用效率高。一切以贴牌炒概念的bot产品都是耍流氓。现阶段，很多相关技术并不成熟，作者建议说在企业客服这个领域多做一些工作，比如把企业的产品FAQ bot做好，节约一些人力成本。（国内很多家做FAQ bot的公司）</p>
<h1 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h1><p>本文是考察国外bot文章系列的第一篇，全都来自TechCrunch。看了一天的新闻文章，从国外科技记者的角度看了下bot这个领域的发展和未来。</p>
<p>1、整体来说，比较乐观，从大公司、投资人、记者、用户多个角色来看，大家都比较看好bot的发展，相信bot是下一个app的形式，就像website取代了传统桌面程序一样，bot也会取代现在的手机app。</p>
<p>2、chat的形式就是大家来聊天，自然而然大的message平台，比如Facebook的Messenger，微信，Line，Slack，Telegram等等，就是成为bot的平台，就像现在的操作系统平台一样。</p>
<p>3、国外的bot公司很多很多，后缀带.ai多的数不清，从这些新闻中分享的bot应用，看得出大家现在还停留在一个比较初始的bot状态，有一点像arxiv上占坑的感觉，没有太多所谓的智能，只是有一个chatbot交互的UI，基本上实现具体的功能都靠事先定制好的button来trigger，更像是交互方式的革新，而非真的人工智能。</p>
<p>4、很多bot都在炒概念，往hot topic上靠，为了bot而bot，手机app用基本简单的点击操作就可以完成的任务，用bot却非要花费大量的时间来输入order或者人类语言，有点多此一举了。说白了，语义理解技术还不够成熟，大家将本该高度智能化的bot做成了step by step的引导，让用户使用了更加复杂的操作。当然，如果你的bot可以准确理解一句或几句简单的人话，然后完成复杂的业务处理，并反馈给用户结果，这样的bot才会让用户真的信服。</p>
<p>5、大伙儿基本上都把bot当成下一代app了，于是出现了很多家做bot聚合和分发的平台，类似app store，豌豆荚这种角色。一个市场雏形出来了之后，大家各自定位，各吃一块蛋糕。</p>
<p>6、客服bot是目前国内市场bot最活跃的一类，提供的功能基本上是企业产品或者业务的faq，差异化在于理解用户的query上，可能技术上略有差异。另外还有一种助手式的bot，提供了一些日常服务，比如查天气，订机票，订饭，打车等功能，基本上纯粹理解自然语言的很少，都是预先设定好套路，根据前一个context来trigger出后一个question，step by step地带着用户完成一个指定任务，因为涉及到多轮对话，context的理解和处理就显得非常重要，理解不好就显得bot非常弱智。这里，我觉得根据context做response的生成是个可以应用的点，虽然说可用的dataset规模很小，但可以考虑将已有的dataset做template化，通过template后的dataset来训练response generator。</p>
<p>今天是系列文章的第一篇，后续会读更多的news或者discussion，以及研究国外bot的产品形式和所用技术，做更多的分享，欢迎讨论。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是一个TechCrunch最近一年有关bot新闻报道的survey，从原文中提炼了些核心观点，来研究下国外bot的发展。&lt;/p&gt;
&lt;h1 id=&quot;Forget-Apps-Now-The-Bots-Take-Over&quot;&gt;&lt;a href=&quot;#Forget-Apps-Now-
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>国内bot产品试用总结</title>
    <link href="http://rsarxiv.github.io/2016/07/22/%E5%9B%BD%E5%86%85bot%E4%BA%A7%E5%93%81%E8%AF%95%E7%94%A8%E6%80%BB%E7%BB%93/"/>
    <id>http://rsarxiv.github.io/2016/07/22/国内bot产品试用总结/</id>
    <published>2016-07-22T20:14:05.000Z</published>
    <updated>2016-07-22T21:18:57.000Z</updated>
    
    <content type="html"><![CDATA[<p>理想很丰满，现实却很骨感。用这句话来形容当前国内的bot客服机器人最合适不过。本文考察了国内规模较大的6家做bot企业客服业务的公司，从功能描述、客户范围到实际案例进行一下对比和总结。</p>
<h1 id="功能描述"><a href="#功能描述" class="headerlink" title="功能描述"></a>功能描述</h1><p>在各自的网站上都会介绍公司的优势，基本都会包括下面的字眼：</p>
<p>1、海量的知识库储备</p>
<p>2、精准的语义理解能力</p>
<p>3、快速部署能力</p>
<p>4、减轻人工客服压力，节约人力成本</p>
<p>5、无缝衔接人工客服</p>
<p>6、回答准确高极高</p>
<p>7、多渠道</p>
<p>看起来都是非常厉害，都是很牛的技术，理解语义没有任何难度，仿佛真正的bot已经实现了一样，但现实是这样的吗？可能还并不是，可能还需要多年的学术研究来推动这个行业的进步。</p>
<h1 id="客户范围"><a href="#客户范围" class="headerlink" title="客户范围"></a>客户范围</h1><p>客服是一个很大的市场，在各行各业都需要大量的客服人员来做售前和售后咨询，传统的客服面临着一个很尴尬的问题是，总是在回答大量重复的问题，效率很低。很多问题的答案其实可以在企业网站上的FAQ找到，但是消费者仍是喜欢去问客服。在这个背景下，客服bot应运而生，覆盖的行业领域包括：电子商务、游戏网站、政府网站、一般企业等等各行各业。</p>
<h1 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h1><p>使用了他们6家的案例，简单总结一下：</p>
<p>1、大家规模不同，但有一个共同的特点是，宣传中提到为多少多少客户提供服务，但是很多客户的网站中并不能找到相应的bot服务，而且bot公司的网站上并没有给出直接的链接过去，只是说这家客户在用他们的服务。这一点来说，我觉得水分比较大，不够透明。</p>
<p>2、采用的解决方案基本上都是example-based，即bot公司自己的通用知识库+客户的业务知识库。一个用户在使用企业的客服时，很少有无聊的人去调戏人家bot，都是来咨询相关问题的，所以一般来说，bot公司自己的知识库作用非常小，当企业的知识库回答不了现有的问题，bot公司的这种所谓“海量知识库”可以派上用场，和客户逗趣一会，但本质上没有意义。</p>
<p>example-based方案本质上就是信息检索，根据用户的query来找到最合适的example，然后将example中的response返回给用户。用这种方法做一个企业客服bot的话，核心就在构建业务知识库，主要的技术点也在这个地方，最简单的方法是将客户给的历史聊天记录和faq经过一定预处理，生成一个高可用的知识库，扯太多的新概念就有点过分了。明明“快速建知识库”才是核心技术，非要说自己拥有超强的“语义理解”能力。What a shame！</p>
<p>这种方案做出来的效果基本上是一个自动版的faq，可以回到非常有限的问题，如果是企业新遇到的问题，则需要添加知识库，编辑知识库就是个简单的数据库操作，并无高大上，在faq这个层面上，bot确实减少了人力成本。</p>
<p>大多数对用户提出的在知识库范围内的问题都是可以不错地回答，其他的都是在呵呵呵了。但如果在query的理解上有更加深入地研究，比如在语义层面上对query和example进行对比，而不是简单的keyword匹配，在某种程度上会更好地提高服务质量。</p>
<p>大多数的bot将faq写在右侧，鼓励大家选择这样的问法，这其实是一种trick，回避了自身理解query能力的欠缺。有一个网站做的不错，你每次提一个query，他会给你返回四个similar query，这四个都是example中的，让你从中选一个，4选1，正确的几率还是很大的，尤其是他的知识库做的不错的情况下。</p>
<p>3、完全依靠bot是不现实的，毕竟知识库有限，很容易遇到新的问题，每个公司bot都会和人工服务无缝衔接，用户发现bot不靠谱了，可以直接点击人工服务与人沟通。很多企业的bot客服基本上还是主要依靠人工服务，bot的作用太有限了。</p>
<p>4、大家的模式都差不多，可能有的公司技术稍微领先一点，资源多，拿到了一些大单子，行业的名气大，但实际效果来看，媒体的报道和其他一些场合的PR，只是在鼓吹，实际的体验还是很差的。虽然大家的单子很多，利润也可能不少，但能做的事情实在太有限了，一单接一单地做，都说自己是技术公司，但真正的前沿技术很难看到被应用上，用的技术和10年前的研究成果并无太大不同。比如，context的处理，是一个非常有必要但却没有一家做的很好的公司，用户和bot聊了几轮话了，什么信息量都保存和学习不到，只是做了个小型的搜索引擎就敢说是bot了？智能如何体现呢？有点讽刺啊！大家都说学术界太虚，出的paper难用，只能用10年前的技术来做，旧汤换新药而已，但学术界很多的研究都是前瞻性，也很有启发性，不能直接套用并不代表不能借鉴啊，一概而论地说paper无意义有一点短视，有一点为自己技术不过硬找借口了。如果只是这么简单、浮躁的bot解决方案，我觉得在市场上不会有太强的生命力和长远的发展，因为这点技术，大公司稍微做一下都会比这个强，SaaS的特点就是容易接入，技术但凡领先于现在的专业做bot的企业，自然就会取而代之。当然，如果只是为了赚点快钱，这样做是合理的。</p>
<p>5、关于机会，我觉得bot是一个很大的机会，很多人不看好bot的原因是目前做bot采用的技术太过陈旧，效果太差导致。这么说来，机会其实也是从这里来的，正是因为大家的技术都不是太先进，所以才有机会，专注地做好新技术的研发，改善现有bot存在的问题，带给企业客户更优质的服务。先赢都不算赢，最后赢的才是真的赢。</p>
<p>大家都很急着占一个又一个的客户，好像真的占领了这个市场一样。用了这几家的服务之后，感觉有点失望，欲速则不达。 </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;理想很丰满，现实却很骨感。用这句话来形容当前国内的bot客服机器人最合适不过。本文考察了国内规模较大的6家做bot企业客服业务的公司，从功能描述、客户范围到实际案例进行一下对比和总结。&lt;/p&gt;
&lt;h1 id=&quot;功能描述&quot;&gt;&lt;a href=&quot;#功能描述&quot; class=&quot;hea
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>Attention with Intention for a Neural Network Conversation Model #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/21/Attention-with-Intention-for-a-Neural-Network-Conversation-Model-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/21/Attention-with-Intention-for-a-Neural-Network-Conversation-Model-PaperWeekly/</id>
    <published>2016-07-22T00:27:46.000Z</published>
    <updated>2016-07-22T00:27:46.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Neural Contextual Conversation Learning with Labeled Question-Answering Pairs #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/21/Neural-Contextual-Conversation-Learning-with-Labeled-Question-Answering-Pairs-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/21/Neural-Contextual-Conversation-Learning-with-Labeled-Question-Answering-Pairs-PaperWeekly/</id>
    <published>2016-07-21T18:35:27.000Z</published>
    <updated>2016-07-21T18:35:27.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Attention-over-Attention Neural Networks for Reading Comprehension #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/18/Attention-over-Attention-Neural-Networks-for-Reading-Comprehension-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/18/Attention-over-Attention-Neural-Networks-for-Reading-Comprehension-PaperWeekly/</id>
    <published>2016-07-19T00:21:22.000Z</published>
    <updated>2016-07-19T01:03:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文分享的文章是arxiv今天刚刚新鲜出炉的paper，来自哈工大讯飞联合实验室。前不久，他们构建了一个大型阅读理解语料，今天也发布出来了。(<a href="http://hfl.iflytek.com/chinese-rc/" target="_blank" rel="external">下载地址</a>)</p>
<p>Cloze-style Reading Comprehension这个领域竞争太过激烈了，半年时间把benchmark刷了一遍又一遍，今天的这篇paper又一次刷新了记录。如果对这个领域不太熟悉的话，可以读这篇<a href="http://rsarxiv.github.io/2016/06/18/%E6%95%99%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%98%85%E8%AF%BB/">教机器学习阅读</a>。</p>
<p>本文的模型被称作Attention over Attention(AoA)，和之前的工作不同，不仅仅考虑query-to-document attention，而且考虑了document-to-query attention。模型架构示意图如下：</p>
<p><img src="media/1.png" alt="1"></p>
<p><b>Contextual Embedding</b> 将query和document都embedding化，用Bi-GRU将query和document分别encode，将两个方向的hidden state拼接起来作为该词的state，此时document和query可以分别用一个Dxd和Qxd的矩阵来表示，这里D是document的词数，Q是query的词数，d是embedding的维度。</p>
<p><b>Pair-wise Matching Score</b> </p>
<p><img src="media/2.png" alt="2"></p>
<p>这一步是本质上就是对两个矩阵做矩阵乘法，得到所谓的Matching Score矩阵M，这里的M矩阵的维度是DxQ，矩阵中的每个元素表示对应document和query中的词之间的matching score。</p>
<p><b>Individual Attentions</b> 对M矩阵中的每一列做softmax归一化，得到所谓的query-to-document attention，即给定一个query词，对document中每个词的attention，本文用下式进行表示：</p>
<p><img src="media/3.png" alt="3"></p>
<p><b>Attention-over-Attention</b> 前三个步骤都是很多模型采用的通用做法，这一步是本文的亮点。首先，第三步是对M矩阵的每一列做了softmax归一化，这里对M矩阵的每一行做softmax归一化，即得到所谓的document-to-query attention，用下式来表示：</p>
<p><img src="media/4.png" alt="4"></p>
<p>然后，将document-to-query attention作平均得到最终的query-level attention，如下式：</p>
<p><img src="media/5.png" alt="5"></p>
<p>最后，用每个query-to-document attention和刚刚得到的query-level attention做点乘，得到document中每个词的score。</p>
<p><b>Final Predictions</b> 将相同词的score合并，得到每个词的score，如下式：</p>
<p><img src="media/6.png" alt="6"></p>
<p>从而得到最终的答案。</p>
<p>实验部分用了英文语料CNN和CBT，在没用pre-trained embedding情况下，单模型得到了state-of-the-art结果。</p>
<p><img src="media/7.png" alt="7"></p>
<p>本文模型最大的特点就是不仅仅考虑query到document的attention，而且考虑了document到query的attention，即所谓的attention over attention，在Cloze-style阅读理解任务中取得了更好的结果。同时，作者在未来的工作中，准备将该模型拓展到其他任务中。</p>
<p>attention是一个非常好的机制，将很多任务的benchmark都提高到了很高的水平，是一个革命性的模型。围绕attention的变种做工作，提出各种各样的attention，虽然可以刷新各种任务，但终究不再能够将研究水平提升一个level，需要一个新的机制、新的思想来推动nlp的发展。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文分享的文章是arxiv今天刚刚新鲜出炉的paper，来自哈工大讯飞联合实验室。前不久，他们构建了一个大型阅读理解语料，今天也发布出来了。(&lt;a href=&quot;http://hfl.iflytek.com/chinese-rc/&quot; target=&quot;_blank&quot; rel=&quot;
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="Reading Comprehension" scheme="http://rsarxiv.github.io/tags/Reading-Comprehension/"/>
    
  </entry>
  
  <entry>
    <title>End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/17/End-to-end-LSTM-based-dialog-control-optimized-with-supervised-and-reinforcement-learning-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/17/End-to-end-LSTM-based-dialog-control-optimized-with-supervised-and-reinforcement-learning-PaperWeekly/</id>
    <published>2016-07-17T16:57:22.000Z</published>
    <updated>2016-07-17T17:36:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文介绍的paper一个实用性非常强的解决方案，作者来自于微软研究院，毕业于剑桥大学Spoken Dialogue Group，研究bot很多很多年了。paper的题目是<a href="http://arxiv.org/pdf/1606.01269v1.pdf" target="_blank" rel="external">End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning</a>，最早发表于今年的6月3日。</p>
<p>文章的开头很有意思，先是从一个大家熟知的场景开始介绍，一个经验丰富的客服是如何带一个新入职的客服。四个阶段：</p>
<p>1、告诉新客服哪些”controls”是可用的，比如：如何查找客户的信息，如何确定客户身份等等。<br>2、新客服从老客服做出的good examples中模仿学习。<br>3、新客服开始试着服务客户，老客服及时纠正他的错误。<br>4、老客服放手不管，新客服独自服务客户，不断学习，不断积累经验。</p>
<p>本文的框架就是依照上面的过程进行设计的：</p>
<p>1、开发者提供一系列备选的actions，包括response模板和一些API函数，用来被bot调用。<br>2、由专家提供一系列example dialogues，用RNN来学习。<br>3、用一个模拟user随机产生query，bot进行response，专家进行纠正。<br>4、bot上线服务，与真实客户进行对话，通过反馈来提高bot服务质量。</p>
<p><img src="media/1.png" alt="1"></p>
<p>一个完整的工作流程由上图描述:</p>
<p><img src="media/2.png" alt="2"></p>
<p>本文在训练的时候是用一部分高质量的数据进行监督学习SL，用增强学习RL来优化模型，得到质量更高的结果。并且文中以打电话给指定联系人为应用场景，举了一个实际的例子，来帮助理解本文的思路。</p>
<p>一般来说，很多文章提到end-to-end的模型，都是基于大量训练数据用seq2seq来做response的生成，本文并不是这样，本文的神经网络模型是用来训练action selection的，包括后面用RL policy gradient来提升效果也都是为了选择action。虽然本文不是一个纯粹的end-to-end解决方案，但确实一个非常实用的解决方案，尤其是对于task-oriented bot的业务来说，这样的解决方案更加高效，值得复现，值得在一些细节的地方进行改善，从而真正地减少人工features和人工成本。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文介绍的paper一个实用性非常强的解决方案，作者来自于微软研究院，毕业于剑桥大学Spoken Dialogue Group，研究bot很多很多年了。paper的题目是&lt;a href=&quot;http://arxiv.org/pdf/1606.01269v1.pdf&quot; targ
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>也说bot</title>
    <link href="http://rsarxiv.github.io/2016/07/16/%E4%B9%9F%E8%AF%B4bot/"/>
    <id>http://rsarxiv.github.io/2016/07/16/也说bot/</id>
    <published>2016-07-17T05:02:39.000Z</published>
    <updated>2016-07-17T17:40:33.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>chatbot是最近一段时间非常火的一个词或者一个应用，不仅仅各大新闻媒体在热炒bot的概念，各大巨头也投入巨大的资源进行研发，arxiv上刷出bot相关的paper也更是家常便饭。炒作归炒作，PR归PR，不得不说一个尴尬的事实是市面上确实难以找到一个真正好用的bot。bot按照涉及的领域，分为开放域(open-domain)和面向具体任务(task-oriented)的bot。开放域要做的事情很大，更像是一个什么都能搞的平台，不管你提什么样的需求，它都能够解决，有点true AI的意思，而面向任务的bot则专注做好一件事情，订机票，订餐，办护照等等。</p>
<p>说到开放域bot，大家接触最多的也就是一些回答非常无厘头的娱乐用bot，比如很多年前活跃在各大社交网站上的小黄鸡，现在市面上活跃着很多号称掌握了bot技术，在用深度学习解决bot技术的bot公司，都是这种，解决不了什么实际问题，就是能和大家聊上两句，而且很多时候回答都是牛头不对马嘴的，十分可笑。</p>
<p>再说task-oriented bot，市面上最多的就是客服机器人，银行也好，电商也罢，不想重复性地回答用户的问题，就用一个客服机器人来应对，且不说效果如何，开发一个具体task的bot需要费不少工夫，而且后期还要大量的维护，因为太多的hand crafted features被用到，整个bot的框架横向扩展性相对来说较差，换一个场景基本上就需要重新开发一套，人力成本太高了。</p>
<p>bot的理想非常丰满，大公司描绘的场景也确实很美，但现实的bot却狠狠地浇了一盆冷水下来。期望越高，失望越大。如果媒体一味地吹捧bot，仿佛整个世界明天就会是bot的了，对bot的发展并无益处，捧杀只会带来气泡，破裂之后，一切如初。</p>
<p>功能强大的、开放域的bot在短期内是比较难实现的，但是如果降低期望，将bot不应当做是一种技术层面的革命，而应当做交互层面的革新才是理性的态度，bot作为一种入口，可能大家都不再需要一个随身携带的终端，只需要找到一个可以识别身份，可以联网的硬件，比如一面镜子，就可以执行很多的task，订机票、买东西等等等等。bot这个时候起到的是一个操作的入口和背后执行各种不同task的黑箱，我们不需要看到整个执行过程，也不需要知道原理是什么，通过一些简单的语言交互，就能完成一些复杂的task，终端要做的事情就是反馈结果和接收输入，执行的过程都在云端，各种bot云。</p>
<p>而这一切的关键是解决好task-oriented bot，用更多data driven的解决方案来代替传统的人工features和templates。</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>bot是一个综合性的问题，涉及到下面三个主要问题：</p>
<p>1、response generation(selection)</p>
<p>对话生成是最后一个步骤，是输出的部分。简单总结下，有四种solutions：</p>
<p><b>solution 1</b> 直接根据context来生成对话，这方面最近的paper非常地多，尤其是seq2seq+attention框架席卷了NLP的很多任务之后，对话生成的benchmark也一次又一次地被各种model刷新着。对话生成的问题，被定义为基于某个条件下的生成模型，典型的根据context来predict words，涉及到句子生成的问题，评价问题就会是一个比较难的问题。</p>
<p><b>solution 2</b> 当然有的paper并不是将对话生成定义为语言模型问题，而是一个next utterance selection的问题，一个多选一的问题，给定一个context，给定一个utterance candidate list，从list中选择一个作为response，当然这类问题的难度会小很多，评价起来也非常容易，但是数据集准备起来要多花一些功夫，而且在实际应用中不好被借鉴。</p>
<p><b>solution 3</b> rule-based或者说template-based，response的最终形式其实是填充了一个模板而成的，大多数的东西是给定的，只有一些具体的value需要来填充。这一类解决方案很适合做task-oriented bot，但过多的人工features和templates导致了其难以移植到其他task上。</p>
<p><b>solution 4</b> query-based或者说example-based，response是来自于一个叫做知识库的数据库，里面包含了大量的、丰富的example，根据用户的query，找到最接近的example，将对应的response返回出来作为输出。这一类解决方案非常适合做娱乐、搞笑用的bot，核心技术在于找更多的数据来丰富知识库，来清洗知识库。但毕竟respnose是从别人那里拿出来的，可能会很搞笑，但大多数会牛头不对马嘴。</p>
<p>2、dialog state tracking(DST)</p>
<p>有的paper称DST为belief trackers，这个部件其实是bot的核心，它的作用在于理解或者捕捉user intention或者goal，只有当你真的知道用户需要什么，你才能做出正确的action或者response。关于这个部分，会有Dialog State Tracking Challenge比赛。一般来说都会给定一个state的范围，通过context来predict用户属于哪个state，有什么样的需求，是需要查询天气还是要查询火车票。</p>
<p>3、user modeling</p>
<p>bot面向具体的业务，都是和真实的user来打交道的，如果只是简单的FAQ bot，回答几个常见的问题可能不需要这块，但如果是其他更加复杂、细致的业务，都需要给用户建模，相同的问题，bot给每个人的response一定是不同的，这个道理非常简单。user modeling，需要涉及的不仅仅是简单的用户基本信息和用户的一些显式反馈信息，而更重要的是用户的history conversations，这些隐式的反馈信息。就像是推荐系统火起来之前，大家都是中规中矩地卖东西，但是有一些聪明人开始分析用户的行为，不仅是那些点赞行为，更多的是那些用户不经意间留下的“蛛丝马迹”，从而知道了用户对哪些东西潜在地感兴趣，也就是后来推荐系统在做的事情。对user进行建模，就是做一个个性化的bot，生成的每一个response都有这个user鲜明的特点。</p>
<h1 id="语料"><a href="#语料" class="headerlink" title="语料"></a>语料</h1><p>大型的语料都是用来训练开放域bot对话生成模型的，数据源一般都是来自社交网站。而对于task-oriented bot来说，客户的数据一般规模都非常地小，这也正是难以将data driven的方案直接套用到task-oriented bot上的一个主要原因。</p>
<p>[1]中给出了bot训练语料的survey，感兴趣的同学可以读一下这篇survey。</p>
<p><img src="media/1.png" alt="1"></p>
<p>图来自文章[13]，英文的语料确实比较多，Sina Weibo那个语料是华为诺亚方舟实验室release的[12]。从twitter或者微博上产生bot数据的话，“conversational in nature”效果不如从ubuntu chat logs这种聊天室产生的数据更加适合训练response生成模型，因为更加天然无公害。文章[5]也用了一个大型中文语料，数据来自百度贴吧。</p>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p> 研究bot的paper是在太多了，这是一个非常活跃的研究领域，细分的方向也非常的多，接下来按照所针对的研究问题来分别介绍一些模型。</p>
<h2 id="seq2seq生成模型"><a href="#seq2seq生成模型" class="headerlink" title="seq2seq生成模型"></a>seq2seq生成模型</h2><p> 现在最流行的解决方案是seq2seq+attention，encoder将user query feed进来，输出一个vector representation来表示整个query，然后作为decoder的condition，而decoder本质上就是一个语言模型，一步一步地生成response，[2]采用就是这种方案，google用了海量的参数训练出这么一个模型，得到了一个不错的bot。</p>
<p><img src="media/8.png" alt="8"></p>
<p> 而典型的seq2seq存在一个问题，就是说容易生成一些“呵呵”的response，即一些非常safe，grammatical但没有实际意义的response，比如”I don’t know!”之类的。原因在于传统的seq2seq在decoding过程中都是以MLE(Maximum Likelihood Estimate)为目标函数，即生成最grammatical的话，而不是最有用的话，这些safe句子大量地出现在训练语料中，模型学习了之后，无可避免地总是生成这样的response，而文章[3]借鉴了语音识别的一些经验，在decoding的时候用MMI（Maximum Mutual Information）作为目标函数，提高了response的diversity。</p>
<p> 文章[4]认为类似于RNNLM这样的语言模型在生成人话质量不高的根本原因在于，没有处理好隐藏在utterance中的随机feature或者说noise，从而在生成next token（short term goal）和future tokens（long term goal）效果一般。</p>
<p><img src="media/3.png" alt="3"></p>
<p> 在生成每一个utterance时，需要用到四个部分，encoder RNN、context RNN、latent variable、decoder RNN，按顺序依次输入和输出。这里的latent variable和IR中的LSI有一点异曲同工，latent表明我们说不清他们到底具体是什么，但可能是代表一种topic或者sentiment，是一种降维的表示。</p>
<p> 文章[5]提出了一种叫做content introducing的方法来生成短文本response。</p>
<p><img src="media/4.png" alt="4"></p>
<p><b>step 1</b> 给定query之后，预测一个keyword作为response的topic，这个topic词性是名词，这里的keyword并不能捕捉复杂的语义和语法，而只是根据query的每个词来预估出一个PMI（Pointwise Mutual Information）最高的名词作为keyword.</p>
<p><b>step 2</b> [5]的模型叫做Sequence To Backward and Forward Sequences，首先进行backward step，给定一个query，用encoder表示出来得到一个context，decoder的部分首先给定keyword作为第一个词，然后进行decoding，生成的这部分相当于keyword词前面的部分；接下来进行的是forward step，也是一个典型的seq2seq，用encoder将query表示成context，然后给定backward生成的话和keyword作为decoder的前半部分，继续decoding生成后半部分。整个的流程这样简单描述下：</p>
<p><b>step 1</b> query + keyword =&gt; backward sequence</p>
<p><b>step 2</b> query + keyword + backward sequence(reverse) =&gt; forward sequence</p>
<p><b>step 3</b> response = backward (reverse) sequence + keyword + forward sequence</p>
<h2 id="user-modeling模型"><a href="#user-modeling模型" class="headerlink" title="user modeling模型"></a>user modeling模型</h2><p>文章[6]针对的问题是多轮对话中response不一致的问题，将user identity（比如背景信息、用户画像，年龄等信息）考虑到model中，构建出一个个性化的seq2seq模型，为不同的user，以及同一个user对不同的请将中生成不同风格的response。</p>
<p><img src="media/2.png" alt="2"></p>
<p>[6]的模型叫Speaker Model，是一个典型的seq2seq模型，不同的地方在于在decoding部分增加了一个speaker embedding，类似于word embedding，只是说这里对用户进行建模。因为无法对用户的信息显式地进行建模，所以用了一种embedding的方法，通过训练来得到speaker向量，下面左边的图是speaker向量在二维平面上的表示，具有相似背景信息的user就会很接近，与word向量一个道理。</p>
<h2 id="reinforcement-learning模型"><a href="#reinforcement-learning模型" class="headerlink" title="reinforcement learning模型"></a>reinforcement learning模型</h2><p>用增强学习来解决人机对话问题具有很悠久的历史，只不过随着AlphaGo的炒作，deepmind公司将增强学习重新带回了舞台上面，结合着深度学习来解决一些更难的问题。</p>
<p>增强学习用long term reward作为目标函数，会使得模型通过训练之后可以predict出质量更高的response，文章[7]提出了一个模型框架，具有下面的能力：</p>
<p>1、整合开发者自定义的reward函数，来达到目标。</p>
<p>2、生成一个response之后，可以定量地描述这个response对后续阶段的影响。</p>
<p><img src="media/5.png" alt="5"></p>
<p>两个bot在对话，初始的时候给定一个input message，然后bot1根据input生成5个候选response，依次往下进行，因为每一个input都会产生5个response，随着turn的增加，response会指数增长，这里在每轮对话中，通过sample来选择出5个作为本轮的response。</p>
<p>在一个大型数据集上训练一个效果不错的seq2seq作为初始值，用增强学习来提升模型实现自定义reward函数的能力，以达到期待的效果。</p>
<p>文章[7]的模型可以生成更多轮数的对话，而不至于过早地陷入死循环中，而且生成的对话diversity非常好。</p>
<h2 id="task-oriented-seq2seq模型"><a href="#task-oriented-seq2seq模型" class="headerlink" title="task-oriented seq2seq模型"></a>task-oriented seq2seq模型</h2><p>现有的task-oriented bot多是采用rule-based、template-based或者example-based或者是综合起来用，用data driven的解决方案十分稀有。文章[8]和[9]就是尝试在bot的个别部件上采用深度学习的技术来做，并且给出了切实可行的方案。</p>
<p>文章[8]先是从一个大家熟知的场景开始介绍，一个经验丰富的客服是如何带一个新入职的客服，分为四个阶段：</p>
<p>1、告诉新客服哪些”controls”是可用的，比如：如何查找客户的信息，如何确定客户身份等等。</p>
<p>2、新客服从老客服做出的good examples中模仿学习。</p>
<p>3、新客服开始试着服务客户，老客服及时纠正他的错误。</p>
<p>4、老客服放手不管，新客服独自服务客户，不断学习，不断积累经验。</p>
<p>[8]的模型框架就是依照上面的过程进行设计的：</p>
<p>1、开发者提供一系列备选的actions，包括response模板和一些API函数，用来被bot调用。</p>
<p>2、由专家提供一系列example dialogues，用RNN来学习。</p>
<p>3、用一个模拟user随机产生query，bot进行response，专家进行纠正。</p>
<p>4、bot上线服务，与真实客户进行对话，通过反馈来提高bot服务质量。</p>
<p><img src="media/6.png" alt="6"></p>
<p>一个完整的工作流程由上图描述，具体步骤看下图：</p>
<p><img src="media/12.png" alt="12"></p>
<p>训练的时候是用一部分高质量的数据进行监督学习SL，用增强学习RL来优化模型，得到质量更高的结果。</p>
<p>文章[9]平衡了两种流行方案的优缺点，提出了一套有参考价值的、具有实际意义的seq2seq解决方案。</p>
<p><img src="media/10.png" alt="10"></p>
<p>一共五个组件：</p>
<p>1、 Intent Network</p>
<p>这个部分可以理解为seq2seq的encoder部分，将用户的输入encode成一个vector。</p>
<p>2、 Belief Trackers</p>
<p>又被称为Dialogue State Tracking(DST)，是task-oriented bot的核心部件。本文的Belief Trackers具有以下的作用：</p>
<ul>
<li>支持各种形式的自然语言被映射成一个有限slot-value对集合中的元素，用于在数据库中进行query。</li>
<li>追踪bot的state，避免去学习那些没有信息量的数据。</li>
<li>使用了一种weight tying strategy，可以极大地减少训练数据的需求。</li>
<li>易扩展新的组件。</li>
</ul>
<p>3、 Database Operator</p>
<p>数据库查询的输入来自于Belief Trackers的输出，即各种slot的概率分布，取最大的那个作为DB的输入，进行查询，获取到相应的值。</p>
<p>4、 Policy Network</p>
<p>这个组件是像一个胶水，起到粘合其他上面三个组件的作用。输入是上面三个组件的输出，输出是一个向量。</p>
<p>5、 Generation Network</p>
<p>最后一个组件是生成模型，本质上是一个语言模型，输入是Policy Network的输出，输出是生成的response，再经过一些处理之后可以返回给用户了。这里的处理主要是将response中的slot，比如s.food还原成真实的值。这一步和文章[8]的step 10一样，将具体的值还原到entity上。</p>
<p>完全用end-to-end来解决task-oriented是不可能的事情，一定是在一个框架或者体系内用这种seq2seq的解决方案来做这件事情，文章[8]和[9]给出了很大的启发。</p>
<h2 id="Knowledge-Sources-based模型"><a href="#Knowledge-Sources-based模型" class="headerlink" title="Knowledge Sources based模型"></a>Knowledge Sources based模型</h2><p>纯粹的seq2seq可以解决很多问题，但如果针对具体的任务，在seq2seq的基础上增加一个相关的knowledge sources会让效果好很多。这里的knowledge可以是非结构化的文本源，比如文章[10]中的ubuntu manpages，也可以是结构化的业务数据，比如文章[9]中的database，也可以是一个从源数据和业务数据中提取出的knowledge graph。</p>
<p>文章[10]作者将bot任务定义为next utterance classification，有一点像question answering任务，给定一个context和一个response candidate list作为备选答案，通过context来从candidate list中选择正确的response。本文的贡献在于在context的基础上，引入了task相关的外部专业知识库，并且这个知识库是非结构化的。</p>
<p><img src="media/11.png" alt="11"></p>
<p>模型是三个rnn encoder组成，一个rnn来encode context，一个rnn来encode response，还有一个rnn来encode knowledge，然后综合起来做预测，选出最合适的response。模型被称作knowledge encoder。因为数据集采用的是ubuntu technical support相关的数据集，外部资源就选用了ubuntu manpages。</p>
<h2 id="context-sensitive模型"><a href="#context-sensitive模型" class="headerlink" title="context sensitive模型"></a>context sensitive模型</h2><p>文章[11]的模型比较简单，但考虑的问题意义很大，history information的建模对于bot在解决实际工程应用的帮助很大，也直接决定了你的bot是否能够work。作者将history context用词袋模型表示，而不是我们经常采用的rnn，然后将context和用户query经过一个简单的FNN，得到一个输出。</p>
<p><img src="media/9.png" alt="9"> </p>
<h1 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h1><p>bot response评价很难，虽然说可以借鉴机器翻译的自动评价方法BLEU来做，但效果不会太好。几乎每篇paper都是会花钱雇人来做人工评价，设计一套评价机制来打分，人工的评价更具有说服力。对于实际工程应用更是如此，用户说好才是真的好。而不是简单地拿着自己提的、有偏的指标，和几个方法或者其他公司的bot进行对比，来说明自己好。</p>
<h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><p>读了一些paper，也和一线在做bot应用的工程师交流之后，有了一点思考，总结如下：</p>
<p>1、要不要做bot？流行一种说法是市面上没有好用的bot，要解决bot的问题需要很多技术同时进步，可能还需要非常长的一段时间，现在用这个东西来做business，简直荒谬。我个人的看法是，解决具体task的bot，结合当前先进的技术，做一些框架性的工具，并不是那么遥远的事情，虽然不容易，但却非常有意义，解决了垂直领域的bot问题，才有可能解决open domain的bot问题。也正是因为不容易，提高了门槛，才会出现真正的机会，诞生一些很牛的技术公司。</p>
<p>2、open domain还是task-oriented？如果是我，我会选后者，因为前者只是一个梦想，一个遥不可及的梦想，需要更多的技术层面上的大突破。task-oriented更加具体，更加实用，针对具体的业务，提供一些解决方案，已经有很多企业在做了，虽然一个通用性或者扩展性强的解决方案还没有出现，但一定是一个趋势，也是新一代做bot的公司的机会。</p>
<p>3、task-oriented bot为什么难，该朝哪个方向来发力？end-to-end是一种理想化的模型，用深度学习模型从大量训练数据中来“捕捉”一些features，“拟合”一些函数，虽然可以得到很不错的效果，而且使用起来确实很方便，但尴尬就尴尬在具体的task中是拿不到海量数据的，数据规模小了之后，纯粹的end-to-end就变得非常鸡肋了。然而真实的场景中，很多企业又有一定的数据，也有bot的需求，所以现在成熟的解决方案就是针对你的具体业务，来设计一些features，templates和rules，当客户的业务发生更改时，需要不断地维护现有的bot系统，十分费时费力。真实的场景中往往涉及到很多结构化的业务数据，纯粹地、暴力地直接根据context生成response是不可能做到的，文章[8][9]都给出了非常有启发性的解决方案，将end-to-end应用在局部，而非整体上，配合上Information Extraction和Knowledge Graph等技术，实现一个高可用的框架体系，这个应该是task-oriented bot的发展方向。</p>
<p>4、response的生成应该与哪些因素有关呢？response质量的好坏，需要联系到这几个features：（1）user query，用户的提问，用户在这轮对话中到底在问什么，准确地理解用户的意图，这是至关重要的。（2）user modeling，对用户进行建模，包括用户的基本信息，还有更重要的是用户history conversation logs的mining，这个工作很难，但同时也很见水平，也是一家技术公司证明自己技术牛逼的一种途径。logs的挖掘现在很常见，不见得大家都做的很好，而这里的logs不是一般的设定好的、结构化的指标，而是非结构化的文本logs，挖掘起来难度更大。另外一点，也是paper种看到的，user emotion，情感分析是nlp中研究比较多的task，用户的情绪直接关系到销售的成败，如果技术足够牛，可以考虑的因素就可以足够多，对user的分析也就足够清晰。将history生挂在模型中不是一个好办法，因为history是不断增长，会导致模型在捕捉信息时出现问题，更好的办法可能是build user profile之类的东西，将history沉淀出来，作为一个vector representation，或者一种knowledge graph来表征一个user。有了这种能力的bot，说的冠冕堂皇一点就是个性化的bot。（3）knowledge，外部知识源，涉及到具体业务的时候，业务数据也是一种knowledge，如何将knowledge建模到模型中，在生成对话的时候可以更加专业和准确也是一个非常重要的问题。bot是一个综合性的难题，不仅仅是系统框架上的难，而且是建模上的难。</p>
<p>5、我一直觉得做人和看问题都不可以极端，世界并非非黑即白，而是介于两者之间的连续值。不可能说要么做成一个open-domain巨无霸的bot，要么就是一个什么具体功能都没有的bot，不能只看到现有的bot不成熟，以及幻想中的bot遥不可及，就开始黑这个领域，还嘲笑人家能够居然拿到投资。争吵这些毫无意义，真正有意义的是深挖这个领域，找到痛点和难点，逐个击破，不断地推进这个领域的发展，而不是像一些街边看热闹的人一样，简直无趣！在很多领域突破之前，仿佛都看不到曙光，但几年之后很多当时难以解决的问题不都是红海一片，满大街都是了么？做一个通用的bot可能很长一段时间内都是一件比较困难的事情，但做一个高可用、扩展性不错的bot解决方案还是有盼头的，不必过度自信，也不必妄自菲薄，踏踏实实地做就是了。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://arxiv.org/pdf/1512.05742.pdf" target="_blank" rel="external">A Survey of Available Corpora for Building Data-Driven Dialogue Systems</a></p>
<p>[2] <a href="http://cn.arxiv.org/pdf/1506.05869.pdf" target="_blank" rel="external">A Neural Conversational Model</a></p>
<p>[3] <a href="http://arxiv.org/pdf/1510.03055v1.pdf" target="_blank" rel="external">A Diversity-Promoting Objective Function for Neural Conversation Models</a></p>
<p>[4] <a href="https://arxiv.org/pdf/1605.06069v3.pdf" target="_blank" rel="external">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</a></p>
<p>[5] <a href="http://cn.arxiv.org/pdf/1607.00970" target="_blank" rel="external">Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation</a></p>
<p>[6] <a href="https://arxiv.org/pdf/1603.06155.pdf" target="_blank" rel="external">A Persona-Based Neural Conversation Model</a></p>
<p>[7] <a href="http://arxiv.org/pdf/1606.01541v3.pdf" target="_blank" rel="external">Deep Reinforcement Learning for Dialogue Generation</a></p>
<p>[8] <a href="http://arxiv.org/pdf/1606.01269v1.pdf" target="_blank" rel="external">End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning</a></p>
<p>[9] <a href="http://arxiv.org/pdf/1604.04562v2.pdf" target="_blank" rel="external">A Network-based End-to-End Trainable Task-oriented Dialogue System</a></p>
<p>[10] <a href="http://media.wix.com/ugd/b6d786_137894b7b3a341a09ed0c0b45b46dbb6.pdf" target="_blank" rel="external">Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue Systems</a></p>
<p>[11] <a href="https://michaelauli.github.io/papers/chitchat.pdf" target="_blank" rel="external">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</a></p>
<p>[12] <a href="http://staff.ustc.edu.cn/~cheneh/paper_pdf/2013/HaoWang.pdf" target="_blank" rel="external">A Dataset for Research on Short-Text Conversation</a></p>
<p>[13] <a href="http://arxiv.org/pdf/1506.08909v3.pdf" target="_blank" rel="external">The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems</a></p>
<h1 id="研究组和研究人员"><a href="#研究组和研究人员" class="headerlink" title="研究组和研究人员"></a>研究组和研究人员</h1><p>bot是一个非常活跃的研究领域，全世界有很多的人都在做相关的研究。下面列的是最近所读paper的作者或者所在的group：</p>
<p>[1] <a href="http://mi.eng.cam.ac.uk/research/dialogue/" target="_blank" rel="external">Cambridge Dialogue Systems Group</a></p>
<p>[2] <a href="http://www.noahlab.com.hk/topics/ShortTextConversation" target="_blank" rel="external">Huawei NOAH’S ARK LAB</a></p>
<p>[3] <a href="http://web.stanford.edu/~jiweil/" target="_blank" rel="external">Jiwei Li</a></p>
<p>[4] <a href="http://cs.mcgill.ca/~rlowe1/" target="_blank" rel="external">Ryan Lowe</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引&quot;&gt;&lt;a href=&quot;#引&quot; class=&quot;headerlink&quot; title=&quot;引&quot;&gt;&lt;/a&gt;引&lt;/h1&gt;&lt;p&gt;chatbot是最近一段时间非常火的一个词或者一个应用，不仅仅各大新闻媒体在热炒bot的概念，各大巨头也投入巨大的资源进行研发，arxiv上刷出bo
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>A Neural Network Approach to Context-Sensitive Generation of Conversational Responses #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/15/A-Neural-Network-Approach-to-Context-Sensitive-Generation-of-Conversational-Responses-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/15/A-Neural-Network-Approach-to-Context-Sensitive-Generation-of-Conversational-Responses-PaperWeekly/</id>
    <published>2016-07-15T22:56:35.000Z</published>
    <updated>2016-07-17T06:49:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文分享的这篇paper是旨在训练一个data driven open-domain的bot，在生成response的时候不仅仅考虑user message（query），而且考虑past history作为context。paper的题目是<a href="https://michaelauli.github.io/papers/chitchat.pdf" target="_blank" rel="external">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</a>，作者来自蒙特利尔大学、乔治亚理工、facebook和微软研究院，本文最早发于2015年6月。</p>
<p>开放域的端到端response生成在今年已经不是什么新鲜事了，各种复杂的网络，考虑各种各样的信息，然而在去年的这个时候，本文就提出了一种data driven的解决方案，是一篇有开创性的paper。</p>
<p>bot的几大核心问题，包括：</p>
<p>1、response generation（或者selection）</p>
<p>2、dialogue state tracking</p>
<p>3、user modeling</p>
<p>不管是开域的还是闭域的bot都需要解决好以上三个问题才能做出一个高质量的bot。本文针对的问题是第一个，用的思路也是现在看来比较自然的一种，用语言模型来生成response。</p>
<p>考虑history utterances的responses生成问题，先定义一些参数，m表示message（query），c表示context，r表示response。本文要解决的其实是下面这个问题：</p>
<p><img src="media/1.png" alt="1"></p>
<p>1、Tripled Language Model </p>
<p>将c，m，r作为一句话来理解，给定c和m之后，不断地生成r的内容。<br>这个模型存在一个比较严重的问题是c如果过长的话，用BPTT训练不了RNNLM。（其实换作LSTM或者GRU单元就会好很多。）</p>
<p>2、Dynamic-Context Generative Model I </p>
<p><img src="media/2-1.png" alt="2"></p>
<p>将c和m用词袋模型表示，然后拼接起来，作为输入，通过一个简单的FNN，得到输出，即c和m vector representation。</p>
<p>3、Dynamic-Context Generative Model II</p>
<p><img src="media/3-1.png" alt="3"></p>
<p>与2不同的地方在于，将c和m单独作为输入，通过一个简单的FNN，得到c和m的vector representation。</p>
<p>这篇paper针对的问题很有意义，history information的建模对于bot在解决实际工程应用的时候意义重大，会让你的bot看起来更加的智能，和分析了用户日志的web应用会带来更好的服务是一个道理。本文的将具体的context包含到了模型中，在真正应用的时候，离线系统根据user conversation logs build一个user profile会更加实用，因为确实不可能把所有的history都丢到模型中一起来算。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文分享的这篇paper是旨在训练一个data driven open-domain的bot，在生成response的时候不仅仅考虑user message（query），而且考虑past history作为context。paper的题目是&lt;a href=&quot;https:/
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue Systems #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/15/Incorporating-Unstructured-Textual-Knowledge-Sources-into-Neural-Dialogue-Systems-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/15/Incorporating-Unstructured-Textual-Knowledge-Sources-into-Neural-Dialogue-Systems-PaperWeekly/</id>
    <published>2016-07-15T19:44:07.000Z</published>
    <updated>2016-07-15T20:07:21.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文是Ubuntu Dialogue Corpus贡献者的一篇文章，是接着Ubuntu数据集benchmark的model继续改进了一下。本文的题目是<a href="http://media.wix.com/ugd/b6d786_137894b7b3a341a09ed0c0b45b46dbb6.pdf" target="_blank" rel="external">Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue</a>。作者是来自麦吉尔大学的博士生<a href="http://cs.mcgill.ca/~rlowe1/" target="_blank" rel="external">Ryan Lowe</a>。</p>
<p>作者将bot任务定义为next utterance classification，有一点像question answering任务，给定一个context和一个response candidate list作为备选答案，通过context来从candidate list中选择正确的response。本文的贡献在于在context的基础上，引入了task相关的外部专业知识库，并且这个知识库是非结构化的。</p>
<p><img src="media/2.png" alt="2"></p>
<p>这个模型是ubuntu corpus中的baseline模型，称为dual encoder，一个rnn来encode context，一个rnn来encode response，然后综合起来做预测。</p>
<p><img src="media/1.png" alt="1"></p>
<p>本文模型相当于在dual encoder基础上增加了一个knowledge部分。模型是三个rnn encoder组成，一个rnn来encode context，一个rnn来encode response，还有一个rnn来encode knowledge，然后综合起来做预测，选出最合适的response。模型被称作knowledge encoder。</p>
<p>因为是ubuntu technical support相关的数据集，外部资源就选用了Ubuntu Manpages，各种命令的手册，通过从context中提取entity来匹配最相关的command manpage，为了快速定位manpage，用了hash的方法，先做了一个command entity hashtable和relation hashtable，一个是为了完全匹配，一个是为了相关匹配。得到相关的manpage之后，所包括的文本就是knowledge。效果如下图：</p>
<p><img src="media/3.png" alt="3"></p>
<p>本文定义的问题太过简单，与实际应用相去甚远。但本文用非结构化的外部知识来解决task-oriented bot问题的思路值得借鉴，不仅仅是bot问题，在问答系统中，外部知识如何应用，如何与神经网络模型结合起来使用都是一个非常重要的topic，也是真正可以用来解决实际问题的一种重要手段。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是Ubuntu Dialogue Corpus贡献者的一篇文章，是接着Ubuntu数据集benchmark的model继续改进了一下。本文的题目是&lt;a href=&quot;http://media.wix.com/ugd/b6d786_137894b7b3a341a09ed0c
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/14/The-Ubuntu-Dialogue-Corpus-A-Large-Dataset-for-Research-in-Unstructured-Multi-Turn-Dialogue-Systems-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/14/The-Ubuntu-Dialogue-Corpus-A-Large-Dataset-for-Research-in-Unstructured-Multi-Turn-Dialogue-Systems-PaperWeekly/</id>
    <published>2016-07-15T04:00:30.000Z</published>
    <updated>2016-07-15T18:01:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文分享的paper构建了一组大型非结构化的、多轮的对话系统语料，使用的原始数据来自<a href="https://irclogs.ubuntu.com/" target="_blank" rel="external">Ubuntu IRC Logs</a>，是一些关于Ubuntu的讨论组聊天数据。paper的题目是<a href="http://arxiv.org/pdf/1506.08909v3.pdf" target="_blank" rel="external">The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems</a>，作者是来自蒙特利尔大学的博士生<a href="http://cs.mcgill.ca/~rlowe1/" target="_blank" rel="external">Ryan Lowe</a>。</p>
<p>数据规模在100万左右，平均每组数据有8轮对话，最少包括3轮对话。之前的bot语料包括：Dialogue State Tracking Challenge(DSTC)、SwitchBoard这类结构化的数据和Twitter、Sina Weibo这种非结构化的数据，前者专注于预测用户的需求和状态，而后者数据中包括了一定数量的非“conversational in nature”，做bot的训练数据并不那么合适。本文构建的数据集是一个特定领域内的数据，ubuntu technical conversations，规模很大，对话轮数很多，质量很高，也是后续很多paper在研究bot response问题时常常采用的corpus。</p>
<p><img src="media/1.png" alt="1"></p>
<p>语料的构建非常有意义，大型的语料可以训练更加复杂的、偏向open domain的bot model，小型的语料可以解决具体的工程应用问题，如何从杂乱无章的unstructured data中提取出有用的信息，构造出一个适合训练、测试的数据集是一个很难却十分有意义的工作。</p>
<p>本文需要的数据是多轮的、两人的对话数据，但原始的数据是多人无序的对话数据，作者采用了一些小的技巧，并且忽略了一些不合适的数据，将原始数据处理成一个四元组：</p>
<p>(time,sender,recipient,utterance)</p>
<p>在构造模型的训练和测试集时，作者将上面的四元组处理成下面的三元组：</p>
<p>(context,response,flag)</p>
<p>context类似于用户输入，flag表示response是否是context相关联的，关联则为1，否则为0。</p>
<p>给定了数据集，下面就是作者提供的benchmark model，三个非常简单的model，tf-idf，rnn和lstm，目的是为了从response candidates中选择k个最适合context的response作为答案，然后计算相应的准确率。paper中给的方法是selection的方法，而不是generation，后面的很多研究都是generation，真正地从user query生成response。</p>
<p>本文提供的ubuntu dialogue corpus对于task-oriented、response generation的研究有着非常重要的意义，相比于华为给的微博数据，有更强的conversational in nature特征，更加适合对话生成的研究。本文作者的另外一篇survey文章<a href="http://arxiv.org/pdf/1512.05742.pdf" target="_blank" rel="external">A Survey of Available Corpora for Building Data-Driven Dialogue Systems</a>,系统地介绍了各大数据集。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文分享的paper构建了一组大型非结构化的、多轮的对话系统语料，使用的原始数据来自&lt;a href=&quot;https://irclogs.ubuntu.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Ubuntu IRC Logs&lt;/a&gt;，是一些关于U
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>随笔</title>
    <link href="http://rsarxiv.github.io/2016/07/14/%E9%9A%8F%E7%AC%94/"/>
    <id>http://rsarxiv.github.io/2016/07/14/随笔/</id>
    <published>2016-07-14T17:28:16.000Z</published>
    <updated>2016-07-14T18:29:27.000Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章的题目有些难产，一直想不出叫一个什么名字好。想写写最近看的东西的一点思考，也想写写一些别的东西，很纠结。以前写文章都喜欢用豆瓣fm推荐的第一首歌作为题目，然后开始写，虽然写的内容可能与题目毫无关系，但却不纠结。听着豆瓣fm，写着blog，是一种很多年的习惯了，习惯是一种可怕的东西，养成了之后就会一直这么做，一点都不能变，不然就会不舒服。</p>
<p>人之所以开心地活在这个世界上是因为大家有很多有意思的事情要做，人之所以害怕离开这个世界是因为很多有意思的事情还没做就结束了。不管现在的状况是怎样，心中充满希望就会不一样。有的人说生活不重要，家庭不重要，只有事业最重要，顾及儿女情长没有什么出息，实在不敢苟同，没有了坚实的地基，空中楼阁再漂亮又有何用？生活的目的就是生活本身，而不是虚伪地活给谁看，和谁比较，与谁相争，向谁证明。</p>
<p>我想用一个比喻来形容我遇到我的爱人可能会比较恰当。从前，有一只在一个无形的笼子里飞来飞去的鸟，他看着地上的人们心中总是有一种优越感，以为自己看得到整个世界，浑然不知自己身在牢笼中。后来来了另外一只鸟，一只特别好看的鸟，帮他打开了笼子，带着他飞向了一个真正广阔的天空，带着他到处飞翔，他才恍然大悟，原来世界可以这么大，于是他们开始了属于他们的旅途。世界很大，而我们很小，我们的格局很小，我们的心胸很小，我们看到的世界很小。世界很有趣，生活也不只是油盐酱醋，也不只是眼前的苟且，还有诗和远方。她用心准备婚礼的每一个细节，请帖用了一种古代西方信件的方式，用融化的蜡块来粘合信封，并且盖上我们俩专属的印章；回礼是一个精美的多肉植物，一盆一盆地种下、包好；喜糖是精心挑选的几种糖果，用一个手工纸袋包装好，过程很麻烦，但是她很享受，你要知道，可不是只做一份、十份，是要只做150份左右，她很享受这样的过程，因为她在用她的双手实现她感兴趣的事情，乐在其中。</p>
<p>世界可以灰暗，也可以很美好，决定于你是一个怎样的人，遇见一个怎样的人。很多人的生活每天都是在钱钱钱的争吵中度过的，永远没一个够，多少钱算多呢？人的欲望又能用多少钱来满足呢？生活可以很糟糕，也可以很美好，取决于你的追求，你所追求的是一种怎样的状态。欲望简单但不乏丰富多彩的生活才是真正高质量的生活，你内心保留地纯粹和纯真越多，生活质量就会越高，相反都会生活地很累，觉得生活都是负担。生活的目的就是生活本身，享受生活就是享受生活中的每一个细节，做一顿大餐，开一个小型音乐party，到录音棚录一首歌曲，看一场演唱会，听一场相声，看一场话剧，拍一些照片，吃一些好吃的垃圾食品，带着hare到处走走，吐槽一些烂剧，开始一场说走就走的旅行。生活中如果只有一个目的，只有工作这一件事情重要的话，那么生活本身就失去了意义，你赚钱也就失去了意义，有的人会说我不努力工作，不赚更多的钱怎么生活，完全可以40或50岁之后再开始享受生活。</p>
<p>最近看bot方面的paper，简单说一下对bot的一点naive的理解。bot火是不争的事实，也是一个必然的趋势，可能做成一个true ai的bot是一件遥不可及的事情，但做出一个能够解决实际问题，提升大家效率的bot是指日可待的事情。我觉得大家对bot的期许不应该是一个什么都能解决的通用工具或者通用技术，如果媒体地热炒加上民众过高的期待会造成新一轮的人工智能寒潮，对这个领域并不是好事。大家可以认为bot是一种新的交互方式，是一种新的操作入口，就像互联网，就像操作系统一样，是一种新的模式，在这种模式背后有大量先进的人工智能技术在做支撑。用户在任何一个地方都不再需要一个特定的终端来做一些常规的事情（不是所有的事情），只需要找一个联网的bot（可能是一个手机，可能是一面镜子，可能是一个电话亭，只要能联网并识别用户身份）就可以完成了，bot执行的过程不需要透明，只需要给出一个结果反馈就可以了，大家的生活围绕着各种各样垂直的bot来展开，只需要最简单的交互就可以完成之前需要复杂操作的事情，比如办个护照，买个机票。如果一个事情很难做的话，我们通常会将其分解成多个容易的事情，逐个攻破，不用期许过高，但相信bot一定会给大家的生活带来一次革命。</p>
<p>bot是一个很大的市场，如果真的能做成一个入口式的平台，相当于重新开辟了一个新的市场，重新定义了这个世界，任何的软件和应用都需要换一种形式，来为用户提供服务。bot确实是一个很美好的梦想，也不是那么遥不可及，但也不是那么容易，那么触手可及。还是需要大量的研究人员不断地努力，攻克难题。现在很多公司都在做bot领域的技术积累和市场占坑，以方便在日后新的一轮机会到来之时，分一杯羹。当前bot的平台有几家大企业在做，但整体来说还是将bot作为一种交互方式，将命令菜单化，并不是真正的对话，有一点iffft的感觉，但确实很多企业也在用这样的平台，大家都是在占坑。bot虽热，但并不是媒体热炒的那样，还是有很多的坑在里面，只有对其进行深入地思考和理解，保持一种冷静和独立地思考，才能真正地抓到痛点和需求，而不是一味地盲目跟随。技术的积累非常重要，因为真正要瓜分市场还是要很高门槛的，不是说你做一个简单的陪聊、逗乐用的机器人就掌握了bot核心技术，真的没有这么简单。周末的时候，准备对最近读bot paper的一些思考，写一篇survey。</p>
<p>美好的生活就是做喜欢的事情，比如亲手构建一个美好的世界，一个bot化的世界，一个更加简便、纯粹的世界。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章的题目有些难产，一直想不出叫一个什么名字好。想写写最近看的东西的一点思考，也想写写一些别的东西，很纠结。以前写文章都喜欢用豆瓣fm推荐的第一首歌作为题目，然后开始写，虽然写的内容可能与题目毫无关系，但却不纠结。听着豆瓣fm，写着blog，是一种很多年的习惯了，习惯是
    
    </summary>
    
    
      <category term="随笔" scheme="http://rsarxiv.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/13/A-Hierarchical-Latent-Variable-Encoder-Decoder-Model-for-Generating-Dialogues-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/13/A-Hierarchical-Latent-Variable-Encoder-Decoder-Model-for-Generating-Dialogues-PaperWeekly/</id>
    <published>2016-07-13T18:19:26.000Z</published>
    <updated>2016-07-13T18:52:05.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文分享的paper旨在解决语言模型生成部分存在的问题，并且以bot为应用背景进行了实验。paper的题目是<a href="https://arxiv.org/pdf/1605.06069v3.pdf" target="_blank" rel="external">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</a>，作者来自蒙特利尔大学和Maluuba公司，这家公司的研究水平非常地高，arxiv上常常可以刷出高质量的paper。</p>
<p>通常来讲，自然语言对话都会包含两个层次的结构，一个是utterance，由语言的局部统计信息来表征其含义，一个是topic，由一些随机的特征来表征。本文的工作就是对这些utterance中存在的随机特征进行建模，从而提高语言模型生成人类语言时的质量。本文认为，类似于RNNLM这样的语言模型在生成人话质量不高的根本原因在于，没有处理好隐藏在utterance中的随机feature或者说noise，从而在生成next token（short term goal）和future tokens（long term goal）效果一般。</p>
<p>本文的模型Latent Variable Hierarchical Recurrent Encoder Decoder(VHRED)，在生成过程中分为两步：</p>
<p>step 1 随机采样latent variables</p>
<p>step 2 生成输出序列</p>
<p>架构示意图见下图：</p>
<p><img src="media/1.png" alt="1"></p>
<p>在生成每一个utterance时，需要用到四个部分，encoder RNN、context RNN、latent variable、decoder RNN，按顺序依次输入和输出。这里的latent variable和IR中的LSI有一点异曲同工，latent表明我们说不清他们到底具体是什么，但可能是代表一种topic或者sentiment，是一种降维的表示。</p>
<p>实验部分，选择了bot作为应用背景，得到了不错的效果。见下图：</p>
<p><img src="media/2.png" alt="2"></p>
<p>本文解决的不仅仅是bot领域对话生成的问题，而是整个seq2seq框架中decoder的问题，只要涉及到decoder生成的部分都可以采用本文的思想来解决问题。latent topic是一个非常有意思的东西，在LSI、推荐系统中都有非常重要的意义，矩阵分解之后得到两个降维之后的矩阵，从一组两个维度映射到了两组两个维度，也就是多了所谓的latent topic，说不清这些topic是什么，但的确可以将相似的东西聚到了一起。本文也是用latent topic来描述隐藏在utterance中那些说不清道不明的随机noise，得到了更好的效果。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文分享的paper旨在解决语言模型生成部分存在的问题，并且以bot为应用背景进行了实验。paper的题目是&lt;a href=&quot;https://arxiv.org/pdf/1605.06069v3.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;A H
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>A Network-based End-to-End Trainable Task-oriented Dialogue System #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/12/A-Network-based-End-to-End-Trainable-Task-oriented-Dialogue-System-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/12/A-Network-based-End-to-End-Trainable-Task-oriented-Dialogue-System-PaperWeekly/</id>
    <published>2016-07-12T22:11:19.000Z</published>
    <updated>2016-07-12T23:53:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>构建一个task-oriented的bot，比如订票，技术支持服务等等，是一件非常难的事情，因为对于特定任务，训练数据会非常非常有限。在学术界，bot领域现在最流行的解决方案之一是seq2seq，在一个非常庞大的open-domain数据集上进行训练，得到一些效果不错的模型，但难以应用到具体task中，因为这类模型无法做到与数据库交互以及整合其他有用的信息，从而生成实用的response。还有一种非常流行的方案是reinforcement learning，上一篇分享的paper<a href="http://rsarxiv.github.io/2016/07/11/Deep-Reinforcement-Learning-for-Dialogue-Generation-PaperWeekly/">Deep Reinforcement Learning for Dialogue Generation</a>将两者有机地结合在了一起，增强学习可以使得response生成时考虑更长远的影响。</p>
<p>本文将分享的这篇paper，针对task-oriented的bot问题，平衡了两种流行方案的优缺点，提出了一套有参考价值的、具有实际意义的seq2seq解决方案。paper的题目是<a href="http://arxiv.org/pdf/1604.04562v2.pdf" target="_blank" rel="external">A Network-based End-to-End Trainable Task-oriented Dialogue System</a>，本文于2016年5月20日发表于arxiv上，作者是来自剑桥大学Dialogue System Group的博士生<a href="http://mi.eng.cam.ac.uk/~thw28/" target="_blank" rel="external">Tsung-Hsien Wen</a>，该组专门研究chatbot相关技术，发表过大量与之相关的paper，后续会更多地关注该组的工作。</p>
<p><img src="media/1.png" alt="1"></p>
<p>上图是本文方案的架构示意图，分为五个部分。下面分别进行介绍：</p>
<p>1、Intent Network</p>
<p>这个部分可以理解为seq2seq的encoder部分，将用户的输入encode成一个vector z(t)。encoder部分分别用了lstm和cnn两种模型对该输入进行建模。这两种句子表示的方法在之前的文章中都有介绍。</p>
<p>2、Belief Trackers</p>
<p>这个部分又被称作是Dialogue State Tracking(DST)，是task-oriented bot的核心部件。本文的Belief Trackers具有以下的作用：</p>
<ul>
<li><p>支持各种形式的自然语言被映射成一个有限slot-value对集合中的元素，用于在数据库中进行query。</p>
</li>
<li><p>追踪bot的state，避免去学习那些没有信息量的数据。</p>
</li>
<li><p>使用了一种weight tying strategy，可以极大地减少训练数据的需求。</p>
</li>
<li><p>易扩展新的组件。</p>
</li>
</ul>
<p><img src="media/2.png" alt="2"></p>
<p>这个组件的输入时用户的input，输出是一个informable slot和requestable slot的概率分布，这里的informable slot是指food，price range和area（以订餐为例），用来约束数据库中的查询，requestable slot是指address，phone，postcode等一些可以被询问的值。这里会定义一个针对具体task的知识图谱，来表示这些slot之间的关系，每个slot都会定义一个tracker，tracker的模型如上图所示，包括一个CNN特征提取模块和一个Jordan型的RNN模块，CNN不仅仅对当前的input进行处理，还对上一轮的user input进行处理，综合起来作为RNN的输入。</p>
<p>这个组件的意义在于获取到预先定好的知识图谱中每个slot的分布，就是说弄清楚用户在这轮对话中的需求是哪个词或者词组。</p>
<p>3、Database Operator</p>
<p>数据库查询的输入来自于Belief Trackers的输出，即各种slot的概率分布，取最大的那个作为DB的输入，进行查询，获取到相应的值。</p>
<p>4、Policy Network</p>
<p>这个组件是像一个胶水，起到粘合其他上面三个组件的作用。输入是上面三个组件的输出，输出是一个向量。</p>
<p>5、Generation Network </p>
<p>最后一个组件是生成模型，本质上是一个语言模型，输入是Policy Network的输出，输出是生成的response，再经过一些处理之后可以返回给用户了。这里的处理主要是将response中的slot，比如s.food还原成真实的值。生成部分用简单的LSTM-LM可以做，用Attention Model也可以做，效果会更好。</p>
<p>数据的准备这部分，利用了众包进行收集，一共采用了680轮对话作为训练数据，数据库中保存了99个饭馆，3个informable slots和7个requestable slots。</p>
<p>训练分为两个阶段，第一阶段是训练belief trackers，得到模型之后，更新参数，对生成网络中的语言模型进行训练，得到full model，batch size取1。</p>
<p>bot模型自动评价这块是一个非常难的事情，本文选择了BLEU score、entity matching rate和objective task success rate，本文模型均取得了不错的结果。另外，通过人工评价对本文模型和rule-based进行了对比，结果看下图：</p>
<p><img src="media/3.png" alt="3"></p>
<p>最后paper给出了一种生成的句子向量的二维图，如下图：</p>
<p><img src="media/4.png" alt="4"></p>
<p>几乎同一类话都被聚集到了相似的位置上，验证了模型的有效性。</p>
<p>开放域的bot只是根据query生成一句response，虽然质量可以做到很高，但实用价值不大。面向具体业务的闭域bot一直难以应用seq2seq的解决方案在于，无法将大量的专业信息建模到模型中来，包括：历史信息，用户身份信息，业务信息等等，本文打开了一扇窗，就是将具体的业务信息和历史信息加到了模型中，并且通过将对话中的slot词转换为一些slot表示，就好比构建了很多的模板，降低了对训练数据的需求，避免了seq2seq在应用时存在的问题。如果再考虑上Jiwei Li的那篇<a href="http://rsarxiv.github.io/2016/07/10/A-Persona-Based-Neural-Conversation-Model-PaperWeekly/">A Persona-Based Neural Conversation Model</a>中对用户信息的建模，bot的实用价值就会更大，用data来解决真正的业务问题就会更进一步。</p>
<p>一点思考，欢迎交流。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;构建一个task-oriented的bot，比如订票，技术支持服务等等，是一件非常难的事情，因为对于特定任务，训练数据会非常非常有限。在学术界，bot领域现在最流行的解决方案之一是seq2seq，在一个非常庞大的open-domain数据集上进行训练，得到一些效果不错的模型
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
  </entry>
  
  <entry>
    <title>Deep Reinforcement Learning for Dialogue Generation #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/11/Deep-Reinforcement-Learning-for-Dialogue-Generation-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/11/Deep-Reinforcement-Learning-for-Dialogue-Generation-PaperWeekly/</id>
    <published>2016-07-11T23:47:50.000Z</published>
    <updated>2016-07-12T16:58:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文将会分享一篇深度增强学习在bot中应用的文章，增强学习在很早的时候就应用于bot中来解决一些实际问题，最近几年开始流行深度增强学习，本文作者将其引入到最新的bot问题中。paper的题目是<a href="http://arxiv.org/pdf/1606.01541v3.pdf" target="_blank" rel="external">Deep Reinforcement Learning for Dialogue Generation</a>，作者是Jiwei Li，最早于2016年6月10日发在arxiv上。</p>
<p>现在学术界中bot领域流行的解决方案是seq2seq，本文针对这种方案抛出两个问题：</p>
<p>1、用MLE作为目标函数会导致容易生成类似于“呵呵呵”的reply，grammatical、safe但是没有营养，没有实际意义的话。</p>
<p>2、用MLE作为目标函数容易引起对话的死循环，如下图：</p>
<p><img src="media/1.png" alt="1"></p>
<p>解决这样的问题需要bot框架具备以下的能力：</p>
<p>1、整合开发者自定义的回报函数，来达到目标。</p>
<p>2、生成一个reply之后，可以定量地描述这个reply对后续阶段的影响。</p>
<p>所以，本文提出用seq2seq+增强学习的思路来解决这个问题。</p>
<p>说到增强学习，就不得不提增强学习的四元素：</p>
<ul>
<li>Action</li>
</ul>
<p>这里的action是指生成的reply，action空间是无限大的，因为可以reply可以是任意长度的文本序列。</p>
<ul>
<li>State</li>
</ul>
<p>这里的state是指[pi,qi]，即上一轮两个人的对话表示。</p>
<ul>
<li>Policy</li>
</ul>
<p>policy是指给定state之后各个action的概率分布。可以表示为：pRL(pi+1|pi, qi)</p>
<ul>
<li>Reward</li>
</ul>
<p>reward表示每个action获得的回报，本文自定义了三种reward。 </p>
<p>1、Ease of Answering</p>
<p>这个reward指标主要是说生成的reply一定是容易被回答的。本文用下面的公式来计算容易的程度：</p>
<p><img src="media/2.png" alt="2"></p>
<p>其实就是给定这个reply之后，生成的下一个reply是dull的概率大小。这里所谓的dull就是指一些“呵呵呵”的reply，比如“I don’t know what you are talking about”等没有什么营养的话，作者手动给出了这样的一个dull列表。</p>
<p>2、Information Flow</p>
<p>生成的reply尽量和之前的不要重复。</p>
<p><img src="media/3.png" alt="3"></p>
<p>这里的h是bot的reply表示，i和i+1表示该bot的前后两轮。这个式子表示同一个bot两轮的对话越像reward越小。</p>
<p>3、Semantic Coherence</p>
<p>这个指标是用来衡量生成reply是否grammatical和coherent。如果只有前两个指标，很有可能会得到更高的reward，但是生成的句子并不连贯或者说不成一个自然句子。</p>
<p><img src="media/4.png" alt="4"></p>
<p>这里采用互信息来确保生成的reply具有连贯性。</p>
<p>最终的reward由这三部分加权求和计算得到。</p>
<p>增强学习的几个要素介绍完之后，接下来就是如何仿真的问题，本文采用两个bot相互对话的方式进行。</p>
<p><b>step 1</b> 监督学习。将数据中的每轮对话当做target，将之前的两句对话当做source进行seq2seq训练得到模型，这一步的结果作为第二步的初值。</p>
<p><b>step 2</b> 增强学习。因为seq2seq会容易生成dull reply，如果直接用seq2seq的结果将会导致增强学习这部分产生的reply也不是非常的diversity，从而无法产生高质量的reply。所以，这里用MMI(Maximum Mutual Information，这里与之前Jiwei Li的两篇paper做法一致)来生成更加diversity的reply，然后将生成最大互信息reply的问题转换为一个增强学习问题，这里的互信息score作为reward的一部分（r3）。用第一步训练好的模型来初始化policy模型，给定输入[pi,qi]，生成一个候选列表作为action集合，集合中的每个reply都计算出其MMI score，这个score作为reward反向传播回seq2seq模型中，进行训练。整个仿真过程如下图：</p>
<p><img src="media/5.png" alt="5"></p>
<p>两个bot在对话，初始的时候给定一个input message，然后bot1根据input生成5个候选reply，依次往下进行，因为每一个input都会产生5个reply，随着turn的增加，reply会指数增长，这里在每轮对话中，通过sample来选择出5个作为本轮的reply。</p>
<p>接下来就是评价的部分，自动评价指标一共两个：</p>
<p>1、对话轮数。<br><img src="media/6.png" alt="6"></p>
<p>很明显，增强学习生成的对话轮数更多。</p>
<p>2、diversity。<br><img src="media/7.png" alt="7"><br>增强学习生成的词、词组更加丰富和多样。</p>
<p>下图给出了一个MMI seq2seq与RL方法的对比结果：</p>
<p><img src="media/8.png" alt="8"><br>RL不仅仅在回答上一个提问，而且常常能够提出一个新的问题，让对话继续下去，所以对话轮数就会增多。原因是，RL在选择最优action的时候回考虑长远的reward，而不仅仅是当前的reward。</p>
<p>本文是一篇探索性的文章，将seq2seq与RL整合在一起解决bot的问题是一个不错的思路，很有启发性，尤其是用RL可以将问题考虑地更加长远，获得更大的reward。用两个bot相互对话来产生大量的训练数据也非常有用，在实际工程应用背景下数据的缺乏是一个很严重的问题，如果有一定质量的bot可以不断地模拟真实用户来产生数据，将deep learning真正用在bot中解决实际问题就指日可待了。</p>
<p>RL解决bot问题的文章在之前出现过一些，但都是人工给出一些feature来进行增强学习，随着deepmind用seq2seq+RL的思路成功地解决video games的问题，这种seq2seq的思想与RL的结合就成为了一种趋势，朝着data driven的方向更进一步。</p>
<p>一点思考，欢迎交流。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将会分享一篇深度增强学习在bot中应用的文章，增强学习在很早的时候就应用于bot中来解决一些实际问题，最近几年开始流行深度增强学习，本文作者将其引入到最新的bot问题中。paper的题目是&lt;a href=&quot;http://arxiv.org/pdf/1606.01541v
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
      <category term="DQN" scheme="http://rsarxiv.github.io/tags/DQN/"/>
    
  </entry>
  
  <entry>
    <title>Consensus Attention-based Neural Networks for Chinese Reading Comprehension #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/11/Consensus-Attention-based-Neural-Networks-for-Chinese-Reading-Comprehension-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/11/Consensus-Attention-based-Neural-Networks-for-Chinese-Reading-Comprehension-PaperWeekly/</id>
    <published>2016-07-11T20:03:05.000Z</published>
    <updated>2016-07-11T20:26:12.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文分享的是今天刚刚刷出的一篇paper，是研究阅读理解的同学们的福音，因为要放出新的而且是中文的数据集。本文的题目是<a href="http://cn.arxiv.org/pdf/1607.02250" target="_blank" rel="external">Consensus Attention-based Neural Networks for Chinese Reading Comprehension</a>，作者均来自哈工大讯飞联合实验室。</p>
<p>对于机器阅读理解的基本内容就不作介绍了，感兴趣的同学可以参考之前写的一篇摘要<a href="http://rsarxiv.github.io/2016/06/18/%E6%95%99%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%98%85%E8%AF%BB/">教机器学习阅读</a>。本文最大的亮点在于构建了中文机器阅读语料，语料分为两个部分，一个是训练集和自测试集，一个是领域外的测试集，包括人工的提问和自动获取的提问两种。（<a href="http://hfl.iflytek.com/chinese-rc/" target="_blank" rel="external">语料地址</a>，可能过段时间会publish出来）</p>
<p>第一个部分是从人民日报获取的新闻语料，构建方法比较简单，先用POS工具对每篇新闻的词性进行标注，选择出现过两次以上的名词作为候选答案词。从候选词总随机选择一个词作为答案词，用包含答案词的句子作为问题query，剩下的部分作为document，从而构造出一个<document,query,answer>对。这种做法的好处是基于一个不太多的语料都可以构建出大量的<document,query,answer>对用来训练，这样也迎合了deep learning的需求。</document,query,answer></document,query,answer></p>
<p>第二个部分也是非常有意思的部分，就是提出了用一个训练数据领域外的数据集作为测试集，构造的方法分为两种，一种是自动的方法和第一部分相同，第二种是基于人工的提问，而且是对于机器来说难度较大的问题。之所以采用领域外的数据进行测试，是为了防止新闻数据中很多问题可以通过外部知识库来进行回答，导致问题变得简单，如果用一个儿童读物的数据作为测试集，就会将这个问题变得更加纯粹和有挑战性。</p>
<p>既然提出了新数据，baseline模型也省不了，本文提出的模型叫Consensus Attention Sum Reader，没有太多的新东西，效果也没有之前文章中Gate Attention Reader和Iterative Alternating Attention那么好，所以就不再介绍了。</p>
<p>训练数据的自动标注和生成是deep learning应用的关键，很多领域发展缓慢或者在工程中应用不好都是因为data的量不够多，且没有太多好的方法来生成或者标注。机器阅读这个领域，相对来说，dataset的自动构建还是很容易做的，操作也比较简单，抠掉一个核心词就可以。而bot，自动文摘，在实际的工程应用中都难以用流行的data driven方案来解决，因为代价太大了。</p>
<p>一点思考，欢迎交流。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文分享的是今天刚刚刷出的一篇paper，是研究阅读理解的同学们的福音，因为要放出新的而且是中文的数据集。本文的题目是&lt;a href=&quot;http://cn.arxiv.org/pdf/1607.02250&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Co
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="reading comprehension" scheme="http://rsarxiv.github.io/tags/reading-comprehension/"/>
    
  </entry>
  
  <entry>
    <title>A Diversity-Promoting Objective Function for Neural Conversation Models #PaperWeekly#</title>
    <link href="http://rsarxiv.github.io/2016/07/11/A-Diversity-Promoting-Objective-Function-for-Neural-Conversation-Models-PaperWeekly/"/>
    <id>http://rsarxiv.github.io/2016/07/11/A-Diversity-Promoting-Objective-Function-for-Neural-Conversation-Models-PaperWeekly/</id>
    <published>2016-07-11T18:06:42.000Z</published>
    <updated>2016-07-11T18:59:57.000Z</updated>
    
    <content type="html"><![CDATA[<p>本篇分享的文章是前一篇分享<a href="http://rsarxiv.github.io/2016/07/10/A-Persona-Based-Neural-Conversation-Model-PaperWeekly/">A Persona-Based Neural Conversation Model</a>的pre-paper，题目是<a href="http://arxiv.org/pdf/1510.03055v1.pdf" target="_blank" rel="external">A Diversity-Promoting Objective Function for Neural Conversation Models</a>，作者是Jiwei Li，最早于2015年10月11日发在arxiv上。</p>
<p>本文针对的问题是seq2seq方案在解决bot问题上容易生成一些“呵呵”的reply，比如“I don’t know”之类的非常safe，grammatical的reply，但是营养太少，没有太多实际的意义。造成这种情况的原因是目标函数不合适，在最近流行的自然语言生成任务中一般都采用MLE作为目标函数，这个目标函数可以保证生成出最自然的语言，但diversity太差，当然如果在decoding部分生成大量的N-best list的话，也是有很多不错的reply但都排名很靠后。</p>
<p>本文就是针对这样的一个问题，提出了用Maximum Mutual Information（MMI）作为目标函数来提高reply的diversity和实用性。MMI这个目标函数在Jiwei Li的多篇文章中都出现过，他很喜欢用这个来代替MLE作为目标函数来解决问题。互信息的方程如下：</p>
<p><img src="media/1.png" alt="1"></p>
<p>经过简单的推导，可得出下式作为目标函数：</p>
<p><img src="media/2.png" alt="2"></p>
<p>而，一般的seq2seq采用MLE，如下式：</p>
<p><img src="media/4.png" alt="4"></p>
<p>本文方法比传统seq2seq多了后面的一项。</p>
<p>p(T)其实是一个语言模型，为了在目标中控制reply的多样性，添加一个惩罚系数，如下式：</p>
<p><img src="media/3-1.png" alt="3"></p>
<p>这个式子记作(4)，经过简单的推导得到下式：</p>
<p><img src="media/5.png" alt="5"></p>
<p>记作(5)</p>
<p>作者根据式子(4)和(5)提出了两种MMI，分别是MMI-antiLM和MMI-bidi。</p>
<p>首先是antiLM，单看-log p(T)这一项，其实就是一个语言模型，anti表示反着的，因为有个负号。这一项不仅仅可以影响到你生成reply的diversity，同时也可以影响到你生成的reply是否是grammatical的，其实是一把双刃剑，需要做好控制，一般来说lambda小于1之后，后一项的影响相对较小了。</p>
<p>本文用一个带权重的语言模型U(T)来替换当前的p(T)，如下式：</p>
<p><img src="media/6.png" alt="6"></p>
<p>这里g(k)是权重，k是index，g(k)的特点是随着k的增加单调递减。这样做有两个目的：</p>
<p>1、decoding时对先生成的词的惩罚比后生成的词的惩罚对diversity的影响更大。</p>
<p>2、随着decoding部分的输入对后续生成影响的减弱，语言模型U(T)将会占主导地位，reply后面的部分也会非常grammatical。</p>
<p>bidi这个目标函数的思路是，先从第一项来生成N-Best List，然后用第二项对其进行排序，将diversity更好的reply放在前面。</p>
<p>在训练过程中，仍旧是采用MLE，但在测试的时候，用本文提到的MMI来做测试。</p>
<p>这个结果是由MMI-antiLM产生的：</p>
<p><img src="media/7.png" alt="7"></p>
<p>这个结果是MMI-bidi产生的：</p>
<p><img src="media/8.png" alt="8"></p>
<p>生成的reply确实seq2seq更加有营养。</p>
<p>本文解决问题的一个思路是很有借鉴意义的，正如abstractive summarization中有一篇paper用MRT来替换传统的MLE作为目标函数，将评价指标考虑进了目标函数中进行优化，起码在benchmark上得到非常好的结果。这其实是一条不错的路，就是将你当前的评价指标融入到你的优化目标中进行优化学习，自然会得到比单纯地用MLE来优化要好的多，也有很多的paper在用这样的思路解决问题。我们不仅仅满足于可以生成一个grammatical的reply，我们更需要的是有意义的、有实际使用价值的bot。另外就是具体到目标函数的建模，如果你希望目标中减小哪些因素对目标的影响，就增加一项惩罚项，这也是做优化时候的一般方案，但在解决具体问题时会非常有效。本文虽然针对的是bot reply的生成问题，其实可以推广到一般的自然语言生成问题上来，只是要涉及到MLE做生成都可以换成本文的方法来提升相应的指标。</p>
<p>一点思考，欢迎交流。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇分享的文章是前一篇分享&lt;a href=&quot;http://rsarxiv.github.io/2016/07/10/A-Persona-Based-Neural-Conversation-Model-PaperWeekly/&quot;&gt;A Persona-Based Neural 
    
    </summary>
    
    
      <category term="nlp" scheme="http://rsarxiv.github.io/tags/nlp/"/>
    
      <category term="PaperWeekly" scheme="http://rsarxiv.github.io/tags/PaperWeekly/"/>
    
      <category term="bot" scheme="http://rsarxiv.github.io/tags/bot/"/>
    
      <category term="seq2seq" scheme="http://rsarxiv.github.io/tags/seq2seq/"/>
    
  </entry>
  
</feed>
