<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>PaperWeekly</title>
  
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="PaperWeekly"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="PaperWeekly" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-77933764-1', 'auto');
	ga('send', 'pageview');

</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">PaperWeekly</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/atom.xml">Rss</a></li>
    
      <li><a href="/about/index.html">About</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-01-11T20:00:23.000Z"><a href="/2017/01/11/PaperWeekly-ç¬¬äºŒåä¸€æœŸ/">2017-01-11</a></time>
      
      
  
    <h1 class="title"><a href="/2017/01/11/PaperWeekly-ç¬¬äºŒåä¸€æœŸ/">PaperWeekly ç¬¬äºŒåä¸€æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•"><a href="#å¼•" class="headerlink" title="å¼•"></a>å¼•</h1><p>å¤šä¿¡æ¯èåˆæ˜¯ä¸€ä¸ªé‡è¦çš„ç ”ç©¶è¶‹åŠ¿ï¼Œå°¤å…¶æ˜¯å¯¹äºè®­ç»ƒæ•°æ®ç¼ºä¹çš„ä»»åŠ¡æ¥è¯´ï¼Œå¦‚ä½•èå…¥å…¶ä»–ç›¸å…³ä¿¡æ¯æ¥æé«˜æœ¬ä»»åŠ¡çš„å‡†ç¡®ç‡æ˜¯ä¸€ä¸ªéå¸¸å€¼å¾—ç ”ç©¶çš„é—®é¢˜ã€‚æœºå™¨ç¿»è¯‘æ˜¯ä¸€ä¸ªçƒ­é—¨çš„ç ”ç©¶é¢†åŸŸï¼Œéšç€è®­ç»ƒæ•°æ®è§„æ¨¡åœ°å¢åŠ ï¼Œå„ç§NNæ¨¡å‹çš„æ•ˆæœä¹Ÿå–å¾—äº†çªç ´çš„è¿›å±•ï¼Œgoogleå’Œç™¾åº¦å‡å·²éƒ¨ç½²ä¸Šçº¿NMTç³»ç»Ÿï¼›èåˆå›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ã€æ–‡æœ¬ç­‰å„ç§æ¨¡æ€æ•°æ®çš„å¤šæ¨¡æ€ç ”ç©¶ä¹Ÿæ˜¯ä¸€ä¸ªéå¸¸çƒ­é—¨çš„ç ”ç©¶æ–¹å‘ï¼Œæœ¬æœŸPaperWeeklyå°†ä¸ºå¤§å®¶å¸¦æ¥NMTå’Œå¤šæ¨¡æ€äº¤å‰ç ”ç©¶çš„paperè§£è¯»ï¼Œå…±3ç¯‡paperï¼š</p>
<p>1ã€Attention-based Multimodal Neural Machine Translation, 2016<br>2ã€Multimodal Attention for Neural Machine Translation, 2016<br>3ã€Zero-resource Machine Translation by Multimodal Encoder-decoder Network with Multimedia Pivot, 2016</p>
<h1 id="Attention-based-Multimodal-Neural-Machine-Translation"><a href="#Attention-based-Multimodal-Neural-Machine-Translation" class="headerlink" title="Attention-based Multimodal Neural Machine Translation"></a><a href="https://www.aclweb.org/anthology/W/W16/W16-2360.pdf" target="_blank" rel="external">Attention-based Multimodal Neural Machine Translation</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Po-Yao Huang, Frederick Liu, Sz-Rung Shiang, Jean Oh, Chris Dyer</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>CMU</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Visual Features, Attention, Multimodal NMT</p>
<h2 id="æ–‡ç« æ¥æº"><a href="#æ–‡ç« æ¥æº" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ACL 2016</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¤šæ¨¡æ€ç¥ç»æœºå™¨ç¿»è¯‘ï¼Œåœ¨ä¼ ç»Ÿçš„seq2seqç¿»è¯‘æ¨¡å‹ä¸Šï¼Œåˆ©ç”¨å›¾åƒç‰¹å¾ä¿¡æ¯å¸®åŠ©æé«˜æœºå™¨ç¿»è¯‘çš„ç»“æœ</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>åœ¨WMT16çš„å¤šæ¨¡æ€ç¥ç»ç½‘ç»œæœºå™¨ç¿»è¯‘æ–°ä»»åŠ¡ä¸Šçš„å·¥ä½œã€‚<br>æå‡ºäº†3ç§å¦‚ä½•å°†visual featureåŠ å…¥åˆ°seq2seqç½‘ç»œä¸­çš„encoderï¼Œä»è€Œä½¿å¾—decoderæ›´å¥½çš„attentionåˆ°ä¸å›¾åƒï¼Œè¯­ä¹‰ç›¸å…³éƒ¨åˆ†çš„æ¨¡å‹ï¼š global visual featureï¼Œ regional visual featureï¼Œparalle threads.</p>
<p><img src="media/global_visual.png" alt="global_visua"></p>
<p>global visualï¼š ç›´æ¥å°†VGGä¸­çš„fc7æŠ½å‡ºçš„featureåŠ å…¥åˆ°encoderçš„first step(head)æˆ–è€…æ˜¯last step(tail)</p>
<p><img src="media/region_visual.png" alt="region_visua"></p>
<p>regional visualï¼š å…ˆç”¨R-CNNæŠ½å‡ºregion boxçš„ä¿¡æ¯ï¼Œå†ç”¨VGGå¾—åˆ°fc7çš„ç‰¹å¾ï¼Œå°†top4å¯¹åº”çš„region featureï¼Œä»¥åŠglobal visual featureåˆ†åˆ«ä½œä¸ºæ¯ä¸€ä¸ªstepè¾“å…¥åˆ°encoderä¸­</p>
<p><img src="media/parallel_threads.png" alt="parallel_threads"></p>
<p>parallel threads: ä¸regional visualç›¸å¯¹åº”çš„æ˜¯ï¼Œæ¯ä¸ªthreadåªåˆ©ç”¨ä¸€ä¸ªregion boxçš„featureï¼Œå’Œglobal visualä¸€æ ·çš„ç½‘ç»œï¼Œå°†top 4å¯¹åº”çš„4 threadså’Œgloabl threadä¸€èµ·åšaverage poolingï¼Œæ¯ä¸ªtheradçš„å‚æ•°å…±äº«; attentionåˆ™å¯¹åº”æ‰€æœ‰threadsä¸­çš„æ‰€æœ‰hidden states</p>
<p>åŒæ—¶æœ¬æ–‡è¿˜æå‡ºäº†ä¸‰ç§rescoring translationçš„ç»“æœçš„æ–¹æ³•ï¼Œ ç”¨ 1ï¼‰language model 2ï¼‰bilingual autoencoder 3ï¼‰bilingual dictionaryåˆ†åˆ«æ¥æŒ‘é€‰translationçš„å¥å­ï¼Œå‘ç°bilingual dictionaryæ¥åˆ é€‰ç¿»è¯‘çš„å¥å­æ•ˆæœæœ€å¥½</p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æ•°æ®é›†ï¼š WMT2016 (En-Ge)<br>å›¾åƒç‰¹å¾æå–ï¼š VGGï¼Œ R-CNN</p>
<h2 id="å®éªŒç»“æœ"><a href="#å®éªŒç»“æœ" class="headerlink" title="å®éªŒç»“æœ"></a>å®éªŒç»“æœ</h2><p>åœ¨En-Geçš„ç»“æœå¦‚å›¾ï¼š<br><img src="media/en-ge.png" alt="en-ge"></p>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>NMTï¼š Kalchbrenner and Blunsom 2013<br>Attention NMTï¼š Bahdanau 2014<br>Joint Space Learningï¼š Zhang 2014ï¼ŒSu 2015ï¼ŒKiros 2014<br>å¤šæ¨¡æ€ä¸Šç›¸å…³å·¥ä½œç›®å‰å¹¶æ²¡æœ‰å¾ˆå¤šï¼Œå€¼å¾—å¿«é€Ÿå…¥æ‰‹</p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹å›¾åƒå’Œæ–‡æœ¬ç»“åˆçš„ç¥ç»ç½‘ç»œç¿»è¯‘æ¨¡å‹ï¼Œéå¸¸è‡ªç„¶çš„å°†å›¾åƒç‰¹å¾åŠ å…¥åˆ°seq2seqæ¨¡å‹çš„encoderéƒ¨åˆ†ï¼Œä½¿decoderä¸ä»…èƒ½å¤Ÿattentionåœ¨æ–‡æœ¬ä¸Šï¼ŒåŒæ—¶ä¹Ÿèƒ½å¤Ÿfocusåˆ°å›¾åƒä¸Š(globalæˆ–è€…region)ï¼›å¹¶ä¸”æ¨¡å‹çš„è®¾è®¡æ¯”è¾ƒç®€å•ï¼Œæ²¡æœ‰åŠ å…¥å¤ªå¤šå¤æ‚çš„æ¨¡å—ã€‚<br>ä¸è¿‡åªæ˜¯ç®€å•çš„å°†å›¾åƒçš„ç‰¹å¾ä½œä¸ºseqä¸­çš„ä¸€ä¸ªstepï¼Œå¹¶æ²¡æœ‰è€ƒè™‘æ–‡æœ¬å’Œå›¾åƒä¹‹é—´çš„ç›¸å…³å…³ç³»ï¼Œå¦‚joint spaceï¼Œç›¸ä¿¡åŠ å…¥joint learingä¼šæœ‰æå‡ã€‚</p>
<h2 id="å®Œæˆäººä¿¡æ¯"><a href="#å®Œæˆäººä¿¡æ¯" class="headerlink" title="å®Œæˆäººä¿¡æ¯"></a>å®Œæˆäººä¿¡æ¯</h2><p>Lijun Wu from SYSU.</p>
<h1 id="Multimodal-Attention-for-Neural-Machine-Translation"><a href="#Multimodal-Attention-for-Neural-Machine-Translation" class="headerlink" title="Multimodal Attention for Neural Machine Translation"></a><a href="https://arxiv.org/abs/1609.03976" target="_blank" rel="external">Multimodal Attention for Neural Machine Translation</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Ozan Caglayan, LoÃ¯c Barrault, Fethi Bougares</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>University of Le Mans, Galatasaray University</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>NMT, Attention</p>
<h2 id="æ–‡ç« æ¥æº-1"><a href="#æ–‡ç« æ¥æº-1" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv 2016.09</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>ç»™å®šå›¾ç‰‡å’Œæºè¯­è¨€æè¿°çš„æƒ…å†µä¸‹ï¼ŒåŸºäºattentionæœºåˆ¶,ç”Ÿæˆç›®æ ‡è¯­è¨€çš„å›¾ç‰‡æè¿°ã€‚</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æ¨¡å‹æœ‰ä¸¤ä¸ªencoderï¼Œä¸€ä¸ªæ˜¯textual encoder,æ˜¯ä¸€ä¸ªåŒå‘GRUï¼Œç”¨äºè·å–æºè¯­è¨€æ–‡æœ¬çš„å‘é‡è¡¨ç¤º$A^{txt} = {a^{txt}_1,a^{txt}_2,â€¦}$ï¼Œå¦å¤–ä¸€ä¸ªæ˜¯visual encoder,ä½¿ç”¨çš„æ˜¯ç°æˆç”±ImageNetæ•°æ®é›†è®­å¥½çš„ResNet-50ç½‘ç»œï¼Œç”¨äºè·å–å›¾ç‰‡çš„å‘é‡è¡¨ç¤ºã€‚$A^{im} = {a^{im}_1,a^{im}_2,â€¦}$. Decoderéƒ¨åˆ†ï¼Œæ˜¯ä¸¤å±‚çš„stakced GRU,å…ˆç”¨attentionæ–¹å¼ï¼Œåˆ†åˆ«è·å–æ–‡æœ¬éƒ¨åˆ†å’Œå›¾åƒéƒ¨åˆ†çš„contextå‘é‡$c^{txt}$å’Œ$c^{im}$,ç„¶åå°†ä¸¤ä¸ªå‘é‡concatåœ¨ä¸€èµ·ï¼Œä½œä¸ºæ–°çš„context å‘é‡$c$ã€‚<br>å¦‚å›¾ï¼š</p>
<p><img src="media/mul_attention.jpg" alt="mul_attention"></p>
<p>è¿™æ ·decoderéƒ¨åˆ†çš„è§£ç ç¿»è¯‘çš„æ—¶å€™ï¼Œä¸ä»…å¯ä»¥è€ƒè™‘åˆ°æºè¯­è¨€çš„æ–‡æœ¬ä¿¡æ¯ï¼Œä¹Ÿå¯ä»¥è€ƒè™‘åˆ°åŸå§‹å›¾ç‰‡çš„ä¿¡æ¯ã€‚</p>
<h2 id="èµ„æº-1"><a href="#èµ„æº-1" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p><a href="https://github.com/elliottd/GroundedTranslation" target="_blank" rel="external">IAPRTC-12 dataset for English and German</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-1"><a href="#ç›¸å…³å·¥ä½œ-1" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>2014å¹´Bahdanauçš„Neural Machine Translation by Jointly Learning to Align and Translateï¼Œä½¿NMTè¶…è¿‡äº†ä¼ ç»Ÿçš„PBMTï¼Œåæ¥çš„NMTè®ºæ–‡åŸºæœ¬éƒ½æ˜¯åœ¨è¿™ä¸ªæ–‡ç« åŸºç¡€ä¸Šè¿›è¡Œçš„æ”¹è¿›ã€‚<br>2015å¹´Elliottçš„å·¥ä½œMulti-language image description with neural sequence models. ä¹Ÿæ˜¯åœ¨ç»™å®šæºè¯­è¨€å’Œå›¾ç‰‡çš„æƒ…å†µä¸‹ï¼Œç”Ÿæˆç›®æ ‡è¯­è¨€ã€‚ä¸è¿‡å¹¶æ²¡æœ‰ä½¿ç”¨attentionæœºåˆ¶ã€‚</p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¯¥æ–‡ç« çš„åˆ›æ–°ä¹‹å¤„ï¼Œåœ¨äºå¯¹å›¾ç‰‡æè¿°æ–‡å­—è¿›è¡Œç¿»è¯‘çš„æ—¶å€™ï¼Œè€ƒè™‘åˆ°äº†å›¾ç‰‡æœ¬èº«çš„ç‰¹å¾ä¿¡æ¯å¹¶å¼•å…¥attentionæœºåˆ¶ã€‚åœ¨æºè¯­è¨€æ–‡æœ¬ç”Ÿæˆå‡ºé”™çš„æƒ…å†µä¸‹ï¼Œå› ä¸ºæœ‰å›¾ç‰‡ä¿¡æ¯å‚è€ƒï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šï¼Œå¯ä»¥å‡è½»è¿™ç§é”™è¯¯å¸¦æ¥çš„å½±å“ã€‚ä¸è¿‡æ–‡ç« å¹¶æ²¡æœ‰åˆ©ç”¨å¤–éƒ¨è‹±å¾·å¹³è¡Œè¯­æ–™ï¼Œè¿™å¯ä»¥è€ƒè™‘ä½œä¸ºåé¢çš„æ”¹è¿›æ–¹å‘ã€‚</p>
<h2 id="å®Œæˆäººä¿¡æ¯-1"><a href="#å®Œæˆäººä¿¡æ¯-1" class="headerlink" title="å®Œæˆäººä¿¡æ¯"></a>å®Œæˆäººä¿¡æ¯</h2><p>xiaose@mail.ustc.edu.cn<br>ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦</p>
<h1 id="Zero-resource-Machine-Translation-by-Multimodal-Encoder-decoder-Network-with-Multimedia-Pivot"><a href="#Zero-resource-Machine-Translation-by-Multimodal-Encoder-decoder-Network-with-Multimedia-Pivot" class="headerlink" title="Zero-resource Machine Translation by Multimodal Encoder-decoder Network with Multimedia Pivot"></a><a href="https://arxiv.org/pdf/1611.04503.pdf" target="_blank" rel="external">Zero-resource Machine Translation by Multimodal Encoder-decoder Network with Multimedia Pivot</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Hideki Nakayamaï¼ŒNoriki Nishida</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>The University of Tokyo</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>pivot, multimodal, NMT</p>
<h2 id="æ–‡ç« æ¥æº-2"><a href="#æ–‡ç« æ¥æº-2" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv, 2016.11</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>åœ¨æ²¡æœ‰å¹³è¡Œè¯­æ–™çš„æƒ…å†µä¸‹ï¼Œç”¨imageå½“ä½œpivotæ¥å®ç°æœºå™¨ç¿»è¯‘</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æ•´ä½“ä¸Šè®²ï¼Œæ¨¡å‹åˆ†æˆä¸¤éƒ¨åˆ†ã€‚ç¬¬ä¸€éƒ¨åˆ†æ˜¯å¤šæ¨¡æ€embeddingï¼Œé‡‡ç”¨pairwise ranking lossæ¥å®šä¹‰æŸå¤±å‡½æ•°ï¼›ç¬¬äºŒéƒ¨åˆ†æ˜¯ç”¨RNNæ¥å®ç°çš„decoder,è·Ÿimage captioné‡Œé¢çš„decoderç±»ä¼¼ã€‚å¯¹è¿™ä¸ªé—®é¢˜æ¥è¯´ï¼Œæˆ‘ä»¬çš„è®­ç»ƒæ•°æ®åŒ…æ‹¬$i^{s}$ï¼šæºç«¯çš„å›¾ç‰‡ï¼Œ$d^{s}$ï¼šæºç«¯å›¾ç‰‡å¯¹åº”çš„å¥å­æè¿°ï¼›$i^{t}$ï¼šç›®æ ‡ç«¯çš„å›¾ç‰‡ï¼Œ$d^{t<br>}$ï¼šç›®æ ‡ç«¯å›¾ç‰‡å¯¹åº”çš„å¥å­æè¿°ï¼Œå’Œæºç«¯ç”¨çš„ä¸ä¸€æ ·çš„è¯­è¨€ã€‚æ–‡ä¸­æå‡ºäº†2ä¸ªæ¨¡å‹æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼š&lt;div<br><img src="media/21-1-1.png" alt="21-1"></p>
<p>æ¨¡å‹1çš„å¤šæ¨¡æ€ç«¯åŒ…æ‹¬äº†å›¾ç‰‡çš„encoderå’Œæºå¥å­çš„encoderã€‚å›¾ç‰‡encoderå¯ä»¥å¯¹æºå›¾ç‰‡å’Œç›®æ ‡å›¾ç‰‡é€šç”¨ã€‚å¤šæ¨¡æ€ç«¯ç”¨$i^{s}$,$d^{s}$è¿›è¡Œè®­ç»ƒï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š</p>
<p><img src="media/21-2.png" alt="21-2"></p>
<p>$E^{v}$è¡¨ç¤ºå›¾ç‰‡çš„encoder(æ¯”å¦‚ç”¨VGG-16æå–å›¾ç‰‡çš„feature), $E^{s}$è¡¨ç¤ºæºå¥å­çš„encoder(æ¯”å¦‚ç”¨RNN)ï¼Œ$d^{s}_{ng}$è¡¨ç¤ºå’Œæºç«¯å›¾ç‰‡ä¸ç›¸å…³çš„æè¿°ã€‚Decoderç«¯ç”¨$i^{t}$,$d^{t}$è¿›è¡Œè®­ç»ƒï¼ŒæŸå¤±å‡½æ•°ä¸ºæ ‡å‡†çš„ cross-entropy lossï¼ˆç§°ä½œå›¾ç‰‡æŸå¤±):</p>
<p><img src="media/21-3.png" alt="21-3"></p>
<p>æ¨¡å‹2æ¯”æ¨¡å‹1æ›´å¤æ‚ä¸€ç‚¹ã€‚åœ¨æºç«¯å¢åŠ äº†ä¸€ä¸ªç›®æ ‡å¥å­æè¿°çš„encoderã€‚å› æ­¤ï¼Œåœ¨å¤šæ¨¡æ€embeddingçš„å­¦ä¹ ä¸­ï¼ŒæŸå¤±å‡½æ•°å¢åŠ äº†ç›®æ ‡å›¾ç‰‡å’Œç›®æ ‡å›¾ç‰‡æè¿°çš„pairwise ranking loss.</p>
<p><img src="media/21-4.png" alt="21-4"></p>
<p>åœ¨decoderçš„å­¦ä¹ ä¸­ï¼Œæ¨¡å‹2é™¤äº†å‰é¢çš„å…¬å¼2å®šä¹‰çš„å›¾ç‰‡æŸå¤±å¤–ï¼Œè¿˜å¢åŠ äº†ç›®æ ‡æè¿°çš„reconstruction lossï¼Œå³ä»å¤šæ¨¡æ€ç«¯è¾“å…¥ç›®æ ‡æè¿°ï¼Œå¸Œæœ›é€šè¿‡embeddingå’Œdecoderé‡å»ºè¿™ä¸ªç›®æ ‡æè¿°ã€‚<br><img src="media/21-5.png" alt="21-5"></p>
<h2 id="èµ„æº-2"><a href="#èµ„æº-2" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>ä¸¤ä¸ªMultilingual image-descriptionçš„æ•°æ®é›†ï¼šIAPR-TC12ï¼ˆåŒ…å«2ä¸‡å›¾ç‰‡ä»¥åŠè‹±è¯­å’Œå¾·è¯­çš„æè¿°ï¼‰å’Œ Multi30Kï¼ˆåŒ…å«3ä¸‡å›¾ç‰‡ä»¥åŠè‹±è¯­å’Œå¾·è¯­çš„æè¿°)</p>
<h2 id="ç›¸å…³å·¥ä½œ-2"><a href="#ç›¸å…³å·¥ä½œ-2" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>å¯¹äºæ²¡æœ‰å¹³è¡Œè¯­æ–™çš„æœºå™¨ç¿»è¯‘ï¼Œå¤šæ•°æ–‡ç« æ˜¯ç”¨æŸç§å¸¸è§è¯­è¨€ä½œä¸ºpivotï¼Œæ¯”å¦‚â€œNeural Machine Translation with Pivot Languagesâ€, ç”¨è‹±è¯­ä½œä¸ºè¥¿ç­ç‰™è¯­æ³•è¯­ä»¥åŠå¾·è¯­æ³•è¯­ä¹‹é—´çš„pivotã€‚ç¼ºç‚¹æ˜¯ç¿»è¯‘çš„æ—¶å€™è¿˜æ˜¯è¦ç»è¿‡pivoté‚£ä¸€æ­¥ã€‚ å¦å¤–ï¼Œè¿˜è¦ä¸€äº›å·¥ä½œæ˜¯ç”¨ä¸€ä¸ªæ¨¡å‹å®ç°many to manyçš„ç¿»è¯‘ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ²¡æœ‰å¹³è¡Œè¯­æ–™çš„è¯­è¨€å¯¹ä¹Ÿèƒ½ç”¨è¿™ä¸ªæ¨¡å‹è¿›è¡Œç¿»è¯‘ã€‚ä¸éœ€è¦ç»è¿‡pivoté‚£ä¸ªä¸­é—´å±‚ï¼Œä½†æ˜¯æ•ˆæœä¸€èˆ¬ä¼šå·®ä¸€ç‚¹ã€‚æ¯”å¦‚â€œGoogleâ€™s Multilingual Neural Machine Translation Systemâ€è¿™ç¯‡æ–‡ç« ã€‚</p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¿™ç¯‡æ–‡ç« çš„æ€è·¯å¾ˆæ–°é¢–ï¼Œè€ƒè™‘ç”¨å›¾ç‰‡æ¥ä½œä¸ºpivotï¼Œå®ç°æ²¡æœ‰å¹³è¡Œè¯­æ–™çš„è¯­è¨€å¯¹ä¹‹é—´çš„ç¿»è¯‘ã€‚è®­ç»ƒå®Œæˆåå¯ä»¥ç›´æ¥ä»æºè¯­è¨€åˆ°ç›®æ ‡è¯­è¨€è¿›è¡Œç¿»è¯‘ï¼Œä¸éœ€è¦ç»è¿‡å›¾ç‰‡ã€‚ä½†æ˜¯æ­£å¦‚æ–‡ä¸­æåˆ°çš„ï¼Œè¿™ç§æ–¹æ³•è·Ÿæœ‰è¯­æ–™è®­ç»ƒå‡ºæ¥çš„ç¿»è¯‘æ•ˆæœæ¯”èµ·æ¥è¿˜æ˜¯å·®å¾ˆå¤šï¼Œå¹¶ä¸”ç¿»è¯‘çš„å¥å­éƒ½æ¯”è¾ƒçŸ­ã€‚å¦å¤–ï¼Œå¯¹ä¸€äº›å›¾ç‰‡éš¾ä»¥è¡¨è¾¾çš„ä¿¡æ¯å¾ˆéš¾é€šè¿‡è¿™ç§æ–¹å¼å­¦åˆ°ã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>äº¤å‰é¢†åŸŸçš„ç ”ç©¶æ€»æ˜¯ä¼šå¸¦ç»™å¤§å®¶æƒŠå–œï¼Œäº¤å‰é¢†åŸŸçš„äº¤å‰é¢†åŸŸæ›´æ˜¯å¦‚æ­¤ï¼Œè¿™ä¸ªé¢†åŸŸåˆšåˆšå¼€å‘ï¼Œæ¬¢è¿å„ä½æœ‰å¿—ä¹‹å£«è·³å‘ã€‚å¹¶ä¸”åœ¨2016å¹´ä¸¾åŠäº†ç¬¬ä¸€å±Šå¤šæ¨¡æ€æœºå™¨ç¿»è¯‘ï¼ˆMultimodal Machine Translationï¼‰å’Œå¤šè¯­çœ‹å›¾è¯´è¯ï¼ˆCrosslingual Image Descriptionï¼‰æ¯”èµ›ï¼Œæ¯”èµ›ä¸»é¡µ<a href="http://www.statmt.org/wmt16/multimodal-task.html" target="_blank" rel="external">http://www.statmt.org/wmt16/multimodal-task.html</a>, æ€»ç»“æ€§çš„paper <a href="http://anthology.aclweb.org/W/W16/W16-2346.pdf" target="_blank" rel="external">http://anthology.aclweb.org/W/W16/W16-2346.pdf</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-01-07T06:06:34.000Z"><a href="/2017/01/06/æœ¬å‘¨å€¼å¾—è¯»-2016-12-26-2017-01-06/">2017-01-06</a></time>
      
      
  
    <h1 class="title"><a href="/2017/01/06/æœ¬å‘¨å€¼å¾—è¯»-2016-12-26-2017-01-06/">æœ¬å‘¨å€¼å¾—è¯»(2016.12.26-2017.01.06)</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="The-Neural-Hawkes-Process-A-Neurally-Self-Modulating-Multivariate-Point-Process"><a href="#The-Neural-Hawkes-Process-A-Neurally-Self-Modulating-Multivariate-Point-Process" class="headerlink" title="The Neural Hawkes Process: A Neurally Self-Modulating Multivariate Point Process"></a><a href="http://t.cn/RMwnQmN" target="_blank" rel="external">The Neural Hawkes Process: A Neurally Self-Modulating Multivariate Point Process</a></h1><p>ã€æ—¶é—´åºåˆ—æ¨¡å‹ã€‘ æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªé€šç”¨çš„è¿ç»­æ—¶é—´åºåˆ—æ¨¡å‹â€”Neural Hawkes processï¼Œç”¨æ¥å­¦ä¹ äº‹ä»¶æµä¸­ä¸åŒäº‹ä»¶ä¹‹é—´çš„å½±å“å…³ç³»ï¼Œè¿›è€Œå¯¹æœªæ¥äº‹ä»¶çš„å‘ç”Ÿæ—¶é—´å’Œç±»å‹è¿›è¡Œé¢„æµ‹ã€‚è¯¥æ¨¡å‹åœ¨ä¼ ç»ŸHawkes processçš„åŸºç¡€ä¸Šï¼Œç”¨ Recurrent Neural Network æ¥æ€»ç»“äº‹ä»¶æµçš„å†å²ä¿¡æ¯ï¼Œå¹¶åŠ¨æ€åœ°ä¼°è®¡ä¸åŒæ—¶åˆ»ä¸åŒäº‹ä»¶ä¹‹é—´å¤æ‚çš„ç›¸äº’å½±å“å…³ç³»ï¼Œè¿›è€Œå¾—å‡ºæœªæ¥äº‹ä»¶çš„å‘ç”Ÿæ—¶é—´å’Œç±»å‹çš„æ¦‚ç‡åˆ†å¸ƒã€‚æ­¤æ¨¡å‹å¯ä»¥ç”¨äºå¤šç§äº‹ä»¶æµçš„åˆ†æï¼ŒåŒ…æ‹¬åŒ»å­¦è¯Šæ–­ï¼Œæ¶ˆè´¹è€…è¡Œä¸ºï¼Œå’Œç¤¾äº¤ç½‘ç»œæ´»åŠ¨çš„é¢„æµ‹ç­‰ï¼Œå¹¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°å‡ºäº†æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚ä½œè€…æ¥è‡ªçº¦ç¿°éœæ™®é‡‘æ–¯å¤§å­¦NLPç»„ï¼Œä¸»é¡µåœ°å€<a href="http://www.cs.jhu.edu/~hmei/" target="_blank" rel="external">http://www.cs.jhu.edu/~hmei/</a>  æœ‰éœ€è¦è®¨è®ºçš„å¯ä»¥ç›´æ¥è”ç³»ä½œè€…æœ¬æ–‡  hmei@cs.jhu.edu</p>
<h1 id="Understanding-Image-and-Text-Simultaneously-a-Dual-Vision-Language-Machine-Comprehension-Task"><a href="#Understanding-Image-and-Text-Simultaneously-a-Dual-Vision-Language-Machine-Comprehension-Task" class="headerlink" title="Understanding Image and Text Simultaneously: a Dual Vision-Language Machine Comprehension Task"></a><a href="http://t.cn/RIYdnYx" target="_blank" rel="external">Understanding Image and Text Simultaneously: a Dual Vision-Language Machine Comprehension Task</a></h1><p>ã€å¤šæ¨¡æ€ã€‘image captionä»»åŠ¡çš„è‡ªåŠ¨è¯„ä»·å­˜åœ¨ä¸€å®šçš„å¼Šç«¯ï¼Œæœ¬æ–‡æå‡ºäº†æ–°çš„ä»»åŠ¡ï¼Œå³ç»™å®šä¸€å¹…å›¾ï¼Œç»™å‡ºnä¸ªcaptioné€‰é¡¹ï¼Œåªæœ‰ä¸€ä¸ªæ˜¯æ­£ç¡®ç­”æ¡ˆï¼Œé€šè¿‡å‡†ç¡®ç‡æ¥è¯„ä»·ç®—æ³•çš„æ•ˆæœã€‚æ„å»ºè¿™æ ·ä¸€ä¸ªä»»åŠ¡éœ€è¦å…ˆé’ˆå¯¹æ¯ä¸€å¼ å›¾ç”Ÿæˆå¤šä¸ªéš¾åº¦è¾ƒé«˜çš„å¹²æ‰°é€‰é¡¹ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€äº›æ„é€ æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨cocoæ•°æ®é›†ä¸Šç”Ÿæˆäº†æœ¬æ–‡çš„æ•°æ®é›†ï¼Œé€šè¿‡äººå·¥é€‰æ‹©è·å¾—è¯¥ä»»åŠ¡çš„å‡†ç¡®ç‡ä¸Šé™ã€‚æ•°æ®é›†å·²å¼€æ”¾ï¼Œåœ°å€ <a href="https://github.com/google/mcic-coco" target="_blank" rel="external">https://github.com/google/mcic-coco</a></p>
<h1 id="A-Joint-Speaker-Listener-Reinforcer-Model-for-Referring-Expressions"><a href="#A-Joint-Speaker-Listener-Reinforcer-Model-for-Referring-Expressions" class="headerlink" title="A Joint Speaker-Listener-Reinforcer Model for Referring Expressions"></a><a href="http://t.cn/RMhX58u" target="_blank" rel="external">A Joint Speaker-Listener-Reinforcer Model for Referring Expressions</a></h1><p>ã€å¤šæ¨¡æ€ã€‘æœ¬æ–‡ç ”ç©¶çš„é—®é¢˜éå¸¸æœ‰è¶£ï¼Œæ˜¯Referring Expressionsï¼Œç®€å•ç‚¹è¯´å°±æ˜¯ç»™ä¸€å¼ å›¾å’Œä¸€ä¸ªæè¿°ï¼Œè¦æ±‚æ‰¾åˆ°æè¿°ä¸­å¯¹åº”çš„objectï¼Œé€šå¸¸åŒ…æ‹¬ä¸¤ä¸ªä»»åŠ¡ï¼š1ã€æ ¹æ®å›¾ç‰‡å’ŒæŒ‡å®šobjectç”Ÿæˆä¸€ä¸ªæè¿°ï¼›2ã€æ ¹æ®å›¾ç‰‡å’Œæè¿°æ¥æ‰¾objectã€‚æœ¬æ–‡æ„å»ºäº†ä¸€ä¸ªè”åˆè®­ç»ƒæ¨¡å‹ï¼Œå°†ä¸¤ä¸ªä»»åŠ¡ä¸€èµ·è®­ç»ƒï¼ŒåŠ ä¸Šä¸€å±‚å¢å¼ºå­¦ä¹ æ¥æé«˜æ‰€ç”Ÿæˆæè¿°çš„å¤šæ ·æ€§ï¼Œå¾—åˆ°äº†ä¸é”™çš„ç»“æœã€‚demoå’Œdatasetåœ°å€ï¼š<a href="https://vision.cs.unc.edu/refer/" target="_blank" rel="external">https://vision.cs.unc.edu/refer/</a></p>
<h1 id="Supervised-Opinion-Aspect-Extraction-by-Exploiting-Past-Extraction-Results"><a href="#Supervised-Opinion-Aspect-Extraction-by-Exploiting-Past-Extraction-Results" class="headerlink" title="Supervised Opinion Aspect Extraction by Exploiting Past Extraction Results"></a><a href="http://t.cn/RIYgOoK" target="_blank" rel="external">Supervised Opinion Aspect Extraction by Exploiting Past Extraction Results</a></h1><p>ã€è§‚ç‚¹æŒ–æ˜ã€‘ã€è¿ç§»å­¦ä¹ ã€‘æœ¬æ–‡åšçš„å·¥ä½œæ˜¯å°†æŸä¸€äº›é¢†åŸŸä¸­å·²ç»æŠ½å–çš„éå¸¸å¥½çš„aspectè¿ç§»è‡³æ–°çš„é¢†åŸŸï¼Œæ¯”å¦‚screenåœ¨è‹¹æœæ‰‹æœºä¸­å­˜åœ¨è¿™ä¹ˆä¸€ä¸ªaspectï¼Œå…¶ä»–å“ç‰Œçš„æ‰‹æœºä¹Ÿå­˜åœ¨ï¼Œå…¶ä»–çš„ç”µå­è®¾å¤‡å¯èƒ½ä¹Ÿå­˜åœ¨ï¼Œåˆ©ç”¨å·²æœ‰çš„â€œçŸ¥è¯†â€æ¥æé«˜å‡†ç¡®ç‡ã€‚</p>
<h1 id="Language-Modeling-with-Gated-Convolutional-Networks"><a href="#Language-Modeling-with-Gated-Convolutional-Networks" class="headerlink" title="Language Modeling with Gated Convolutional Networks"></a><a href="http://t.cn/RIYkG0b" target="_blank" rel="external">Language Modeling with Gated Convolutional Networks</a></h1><p>ã€CNNè¯­è¨€æ¨¡å‹ã€‘æœ¬æ–‡çš„å·¥ä½œæ˜¯å°†CNNæ¨¡å‹å’Œä¸€ç§gateæœºåˆ¶ç»“åˆèµ·æ¥åšè¯­è¨€æ¨¡å‹ï¼ŒæŒ‘æˆ˜äº†RNNåœ¨è¿™ä¸ªé¢†åŸŸçš„éœ¸ä¸»åœ°ä½ã€‚å·¥ä½œæ¥è‡ªFacebookï¼Œä»–ä»¬å¯¹CNNæœ‰éå¸¸çš„åå¥½ã€‚ </p>
<h1 id="Understanding-Neural-Networks-through-Representation-Erasure"><a href="#Understanding-Neural-Networks-through-Representation-Erasure" class="headerlink" title="Understanding Neural Networks through Representation Erasure"></a><a href="http://t.cn/RIRFnkr" target="_blank" rel="external">Understanding Neural Networks through Representation Erasure</a></h1><p>ã€è§£é‡Šç¥ç»ç½‘ç»œã€‘å¤§å®¶éƒ½çŸ¥é“æ·±åº¦å­¦ä¹ æ•ˆæœå¥½ï¼Œä½†åŸå› ç¡®å®è§£é‡Šä¸æ¸…æ¥šã€‚æœ¬æ–‡å°è¯•ç€åšäº†ä¸€äº›è§£é‡Šæ–¹é¢çš„å·¥ä½œï¼Œé€šè¿‡â€œeraseâ€æ‰ä¸€äº›representationæ¥ç ”ç©¶ç»“æœçš„å˜åŒ–ï¼Œç”šè‡³é€šè¿‡å¢å¼ºå­¦ä¹ æ¥ç ”ç©¶æœ€å¤šâ€œeraseâ€æ‰å“ªäº›representationä»ä¸å½±å“æœ€ç»ˆçš„ç»“æœã€‚æ·±åº¦å­¦ä¹ å¦‚æœæœ‰äº†å¯è§£é‡Šæ€§ï¼Œç›¸ä¿¡åˆå°†ä¼šæ˜¯ä¸€ä¸ªæ–°çš„ç ”ç©¶æ°´å¹³äº†ã€‚ </p>
<h1 id="Shortcut-Sequence-Tagging"><a href="#Shortcut-Sequence-Tagging" class="headerlink" title="Shortcut Sequence Tagging"></a><a href="http://t.cn/RMw38iV" target="_blank" rel="external">Shortcut Sequence Tagging</a></h1><p>ã€æ–°ç½‘ç»œç»“æ„ã€‘æœ¬æ–‡é’ˆå¯¹å¤šå±‚RNNéš¾è®­ç»ƒçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§gateæœºåˆ¶å’Œshortcutsæœºåˆ¶æ··åˆçš„æ–¹æ³•ï¼Œå¹¶ç ”ç©¶äº†ä¸åŒçš„ç»„åˆæ•ˆæœã€‚æ–¹æ³•åœ¨åºåˆ—æ ‡æ³¨é—®é¢˜ä¸Šè¿›è¡ŒéªŒè¯ï¼Œä»ç»“æœä¸Šæ¥çœ‹ï¼Œæé«˜çš„ä¸å¤šï¼Œä¹Ÿä»ä¾§é¢åæ˜ å‡ºä¸€ä¸ªé—®é¢˜ï¼Œç°æœ‰çš„ç½‘ç»œç»“æ„åŠ ä¸€äº›æ’åˆ—ç»„åˆæˆ–è€…å°æ”¹åŠ¨å¾ˆéš¾è§£å†³æ ¹æœ¬æ€§çš„é—®é¢˜ã€‚</p>
<h1 id="Unsupervised-neural-and-Bayesian-models-for-zero-resource-speech-processing"><a href="#Unsupervised-neural-and-Bayesian-models-for-zero-resource-speech-processing" class="headerlink" title="Unsupervised neural and Bayesian models for zero-resource speech processing"></a><a href="http://t.cn/RMLugMZ" target="_blank" rel="external">Unsupervised neural and Bayesian models for zero-resource speech processing</a></h1><p>ã€æ— ç›‘ç£ã€‘ã€è´å¶æ–¯ã€‘æœ¬æ–‡æ˜¯ä¸€ç¯‡æ¥è‡ªçˆ±ä¸å ¡å¤§å­¦çš„åšå£«è®ºæ–‡ã€‚</p>
<h1 id="Textual-Entailment-with-Structured-Attentions-and-Composition"><a href="#Textual-Entailment-with-Structured-Attentions-and-Composition" class="headerlink" title="Textual Entailment with Structured Attentions and Composition"></a><a href="http://t.cn/RM4seBe" target="_blank" rel="external">Textual Entailment with Structured Attentions and Composition</a></h1><p>ã€æ–‡æœ¬è•´å«ã€‘æœ¬æ–‡çš„è´¡çŒ®åœ¨äºå°†attentionåº”ç”¨åˆ°äº†å¥æ³•æ ‘ä¸Šï¼Œè€Œä¸æ˜¯åªå¯¹å¥å­åšattentionã€‚ </p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-01-06T18:31:23.000Z"><a href="/2017/01/06/PaperWeekly-ç¬¬äºŒåæœŸ/">2017-01-06</a></time>
      
      
  
    <h1 class="title"><a href="/2017/01/06/PaperWeekly-ç¬¬äºŒåæœŸ/">PaperWeekly ç¬¬äºŒåæœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="GANï¼ˆGenerative-Adversarial-Netsï¼‰ç ”ç©¶è¿›å±•"><a href="#GANï¼ˆGenerative-Adversarial-Netsï¼‰ç ”ç©¶è¿›å±•" class="headerlink" title="GANï¼ˆGenerative Adversarial Netsï¼‰ç ”ç©¶è¿›å±•"></a>GANï¼ˆGenerative Adversarial Netsï¼‰ç ”ç©¶è¿›å±•</h1><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>1ã€Unsupervised learning</p>
<p>é¦–å…ˆæˆ‘ä»¬ä»generative modelè¯´èµ·ã€‚generattive modelçš„ç›®çš„æ˜¯æ‰¾åˆ°ä¸€ä¸ªå‡½æ•°å¯ä»¥æœ€å¤§çš„è¿‘ä¼¼æ•°æ®çš„çœŸå®åˆ†å¸ƒã€‚å¦‚æœæˆ‘ä»¬ç”¨ f(X; ğœƒ) æ¥è¡¨ç¤ºè¿™æ ·ä¸€ä¸ªå‡½æ•°ï¼Œé‚£ä¹ˆæ‰¾åˆ°ä¸€ä¸ªä½¿ç”Ÿæˆçš„æ•°æ®æœ€åƒçœŸå®æ•°æ®çš„ ğœƒ å°±æ˜¯ä¸€ä¸ªmaximum likelihood estimationçš„è¿‡ç¨‹ã€‚é—®é¢˜åœ¨äºï¼Œå½“æ•°æ®çš„åˆ†å¸ƒæ¯”è¾ƒå¤æ‚æ—¶ï¼Œæˆ‘ä»¬éœ€è¦çš„ f ä¹Ÿä¼šå˜å¤æ‚ã€‚ç°åœ¨æˆ‘ä»¬æœ‰æ·±åº¦ç½‘ç»œç»“æ„å¯ä»¥è¡¨è¾¾è¿™æ ·ä¸€ä¸ªå¤æ‚çš„å‡½æ•°ï¼ˆdeep generative modelï¼‰ï¼Œä½†æ˜¯è®­ç»ƒè¿‡ç¨‹æˆä¸ºäº†å…³é”®ã€‚åŸºäºsamplingçš„è®­ç»ƒè¿‡ç¨‹æ˜¾ç„¶ä¸æ˜¯å¾ˆé«˜æ•ˆçš„ã€‚å› æ­¤ï¼Œå¦‚ä½•è®¾è®¡æ¨¡å‹ä»¥ä¾¿åˆ©ç”¨backpropagationæ¥è®­ç»ƒç½‘ç»œæˆä¸ºäº†ä¸€ä¸ªé‡è¦çš„ç›®æ ‡ã€‚å½“å‰ä¸¤ä¸ªæ¯”è¾ƒçªå‡ºçš„æ¨¡å‹å®ç°çš„å°±æ˜¯è¿™ä¸ªç›®çš„ï¼Œä¸€ä¸ªæ˜¯variational autoencoder(VAE)ï¼Œå¦ä¸€ä¸ªå°±æ˜¯è¿™ç¯‡æ–‡ç« çš„ä¸»é¢˜generative adversarial netsã€‚</p>
<p>è¿™ç¯‡æ–‡ç« ä¼šä»åŸºæœ¬çš„GANæ¨¡å‹è®²èµ·ï¼Œé‡ç‚¹è®¨è®ºæ¨¡å‹å…¬å¼èƒŒåçš„åŸç†ã€‚ä¹‹åä¼šè®¨è®ºå‡ ç¯‡GANçš„æ‰©å±•å·¥ä½œï¼Œå¸Œæœ›èƒ½å¤Ÿæ‰©å±•ä¸€ä¸‹å¤§å®¶çš„æ€è·¯ï¼Œä¹Ÿå¯ä»¥åŠ æ·±å¯¹GANæ¨¡å‹çš„ç†è§£ã€‚ä¸‹é¢çš„å…³ç³»å›¾å¤§è‡´æè¿°äº†è¿™äº›æ¨¡å‹ä¹‹é—´çš„ç»§æ‰¿å…³ç³»ã€‚æˆ‘ä»¬ä¼šæŒ‰ç…§å›¾ä¸­çš„å…³ç³»ä¸€ä¸ªä¸€ä¸ªå±•å¼€ã€‚</p>
<p><img src="media/gan-kg.png" alt="gan-kg"></p>
<p>2ã€GAN</p>
<p>é¦–å…ˆæ˜¯æœ€ç»å…¸çš„GANæ¨¡å‹ã€‚ç”±Ian Goodfellowå’ŒBengioç­‰åœ¨2014å¹´æå‡ºã€‚ä¸ºäº†ç®€æ˜æ‰¼è¦ï¼Œæˆ‘ä»¬ç›´æ¥çœ‹å›¾è¯´è¯ã€‚</p>
<p><img src="media/gan-formula.png" alt="gan-formula"></p>
<p>å›¾ä¸­ä¸ŠåŠéƒ¨åˆ†æ˜¯GANæ¨¡å‹çš„åŸºæœ¬æ¶æ„ã€‚æˆ‘ä»¬å…ˆä»ä¸€ä¸ªç®€å•çš„åˆ†å¸ƒä¸­é‡‡æ ·ä¸€ä¸ªå™ªå£°ä¿¡å· zï¼ˆå®é™…ä¸­å¯ä»¥é‡‡ç”¨[0, 1]çš„å‡åŒ€åˆ†å¸ƒæˆ–è€…æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼‰ï¼Œç„¶åç»è¿‡ä¸€ä¸ªç”Ÿæˆå‡½æ•°åæ˜ å°„ä¸ºæˆ‘ä»¬æƒ³è¦çš„æ•°æ®åˆ†å¸ƒ Xg ï¼ˆz å’Œ X éƒ½æ˜¯å‘é‡ï¼‰ã€‚ç”Ÿæˆçš„æ•°æ®å’ŒçœŸå®æ•°æ®éƒ½ä¼šè¾“å…¥ä¸€ä¸ªè¯†åˆ«ç½‘ç»œ Dã€‚è¯†åˆ«ç½‘ç»œé€šè¿‡åˆ¤åˆ«è¾“å‡ºä¸€ä¸ªæ ‡é‡ï¼Œè¡¨ç¤ºæ•°æ®æ¥è‡ªçœŸå®æ•°æ®çš„<strong>æ¦‚ç‡</strong>ã€‚åœ¨å®ç°ä¸Šï¼ŒG å’Œ D éƒ½æ˜¯å¯å¾®åˆ†å‡½æ•°ï¼Œéƒ½å¯ä»¥ç”¨å¤šå±‚ç¥ç»ç½‘ç»œå®ç°ã€‚å› æ­¤ä¸Šé¢çš„æ•´ä¸ªæ¨¡å‹çš„å‚æ•°å°±å¯ä»¥åˆ©ç”¨backpropagationæ¥è®­ç»ƒå¾—åˆ°ã€‚</p>
<p>å›¾ä¸­çš„ä¸‹åŠéƒ¨åˆ†æ˜¯æ¨¡å‹è®­ç»ƒä¸­çš„ç›®æ ‡å‡½æ•°ã€‚ä»”ç»†çœ‹å¯ä»¥å‘ç°è¿™ä¸ªå…¬å¼å¾ˆåƒcross entropyï¼Œæ³¨æ„Dæ˜¯ P(Xdata) çš„è¿‘ä¼¼ã€‚å¯¹äº D è€Œè¨€è¦å°½é‡ä½¿å…¬å¼æœ€å¤§åŒ–ï¼ˆè¯†åˆ«èƒ½åŠ›å¼ºï¼‰ï¼Œè€Œå¯¹äº G åˆæƒ³ä½¿ä¹‹æœ€å°ï¼ˆç”Ÿæˆçš„æ•°æ®æ¥è¿‘å®é™…æ•°æ®ï¼‰ã€‚æ•´ä¸ªè®­ç»ƒæ˜¯ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ï¼Œä½†æ˜¯åœ¨è¿­ä»£ä¸­ï¼Œå¯¹ D çš„ä¼˜åŒ–åˆæ˜¯å†…å¾ªç¯ã€‚æ‰€ä»¥æ¯æ¬¡è¿­ä»£ï¼ŒD å…ˆè®­ç»ƒ kæ¬¡ï¼ŒG è®­ç»ƒä¸€æ¬¡ã€‚</p>
<p>GANæ¨¡å‹æœ€å¤§çš„ä¼˜åŠ¿å°±æ˜¯è®­ç»ƒç®€å•ï¼Œä½†æ˜¯ä¹Ÿæœ‰ç¼ºç‚¹æ¯”å¦‚è®­ç»ƒçš„ç¨³å®šæ€§ã€‚æœ‰è¶£çš„æ˜¯ï¼Œåœ¨è¿™ç¯‡æ–‡ç« future workéƒ¨åˆ†ï¼Œä½œè€…æå‡ºäº†5ä¸ªå¯èƒ½æ‰©å±•çš„æ–¹å‘ï¼Œè€Œç°åœ¨å›è¿‡å¤´æ¥çœ‹ï¼Œåç»­çš„å¾ˆå¤šå·¥ä½œçœŸçš„å°±æ˜¯åœ¨ç…§ç€è¿™å‡ ä¸ªæ€è·¯å¡«å‘ã€‚æ¯”å¦‚ç¬¬ä¸€ä¸ªconditional generative modelå°±æ˜¯åé¢è¦è®²çš„conditional GANçš„æ€è·¯ï¼Œè€Œæœ€åä¸€ä¸ªdeterming better distribution to sample z from during trainingåˆ™æ˜¯åé¢InfoGANçš„æ€è·¯ã€‚</p>
<p>ä¸‹é¢æ˜¯æ¥è‡ªtwitter[9] çš„ä¸€å¹…å›¾ï¼Œå¾ˆå¥½çš„æ€»ç»“äº†å„ç§è¡ç”Ÿæ¨¡å‹çš„ç»“æ„ã€‚</p>
<p><img src="media/gan.jpeg" alt="gan"></p>
<p>2.1 DCGAN </p>
<p>ä¸Šé¢Ian J. Goodfellowç­‰äººçš„æ–‡ç« æå‡ºäº†GANçš„æ¨¡å‹å’Œè®­ç»ƒæ¡†æ¶ï¼Œä½†æ˜¯æ²¡æœ‰æè¿°å…·ä½“çš„å®ç°ï¼Œè€ŒDCGAN[2] è¿™ç¯‡æ–‡ç« è®²çš„å°±æ˜¯ç”¨deep convolutional networkå®ç°ä¸€ä¸ªç”Ÿæˆå›¾ç‰‡çš„GANæ¨¡å‹ã€‚è¿™ç¯‡æ–‡ç« æ²¡æœ‰åœ¨åŸºæœ¬æ¨¡å‹ä¸Šæœ‰æ‰€æ‰©å±•ï¼Œä½†æ˜¯ä»–æè¿°äº†å¾ˆå¤šå®ç°ä¸Šç»†èŠ‚ï¼Œå°¤å…¶æ˜¯è®©GANæ¨¡å‹stableçš„æ–¹æ³•ã€‚æ‰€ä»¥å¦‚æœå¯¹äºGANçš„å®ç°æœ‰å…´è¶£ï¼Œè¿™ç¯‡æ–‡ç« ä¹Ÿæ˜¯å¿…è¯»ã€‚æ­¤å¤–ï¼Œæœ€æ–°NIPS2016ä¹Ÿæœ‰æœ€æ–°çš„å…³äºè®­ç»ƒGANæ¨¡å‹çš„æ€»ç»“ [How to Train a GAN? Tips and tricks to make GANs work] (<a href="https://github.com/soumith/ganhacks" target="_blank" rel="external">https://github.com/soumith/ganhacks</a> â€œGAN tricksâ€)ã€‚</p>
<p>3ã€InfoGAN</p>
<p>åœ¨GANæ¨¡å‹ä¸­ï¼Œç”Ÿæˆæ¨¡å‹çš„è¾“å…¥æ˜¯ä¸€ä¸ªè¿ç»­çš„å™ªå£°ä¿¡å·ï¼Œç”±äºæ²¡æœ‰ä»»ä½•çº¦æŸï¼Œå³ä¾¿æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªæœ‰æ•ˆçš„ç”Ÿæˆæ¨¡å‹ï¼Œzä¹Ÿä¸èƒ½è¢«å¾ˆå¥½çš„è§£é‡Šã€‚ä¸ºäº†ä½¿è¾“å…¥åŒ…å«å¯ä»¥è§£é‡Šï¼Œæ›´æœ‰ä¿¡æ¯çš„æ„ä¹‰ï¼ŒInfoGAN[7]çš„æ¨¡å‹åœ¨zä¹‹å¤–ï¼Œåˆå¢åŠ äº†ä¸€ä¸ªè¾“å…¥cï¼Œç§°ä¹‹ä¸ºéšå«è¾“å…¥(latent code)ï¼Œç„¶åé€šè¿‡çº¦æŸcä¸ç”Ÿæˆæ•°æ®ä¹‹é—´çš„å…³ç³»ï¼Œä½¿å¾—cé‡Œé¢å¯ä»¥åŒ…å«æŸäº›è¯­ä¹‰ç‰¹å¾(semantic feature)ï¼Œæ¯”å¦‚å¯¹MNISTæ•°æ®ï¼Œcå¯ä»¥æ˜¯digit(0-9)ï¼Œå€¾æ–œåº¦ï¼Œç¬”ç”»åšåº¦ç­‰ã€‚å…·ä½“åšæ³•æ˜¯ï¼šé¦–å…ˆæˆ‘ä»¬ç¡®å®šéœ€è¦è¡¨è¾¾å‡ ä¸ªç‰¹å¾ä»¥åŠè¿™äº›ç‰¹å¾çš„æ•°æ®ç±»å‹ï¼Œæ¯”å¦‚æ˜¯ç±»åˆ«(categorical)è¿˜æ˜¯è¿ç»­æ•°å€¼ï¼Œå¯¹æ¯ä¸ªç‰¹å¾æˆ‘ä»¬ç”¨ä¸€ä¸ªç»´åº¦è¡¨ç¤ºci  ã€‚</p>
<p>æ¥ä¸‹æ¥ï¼Œåˆ©ç”¨äº’ä¿¡æ¯é‡æ¥çº¦æŸcã€‚åŸç†åœ¨äºï¼Œå¦‚æœ c å’Œç”Ÿæˆçš„å›¾åƒä¹‹é—´å­˜åœ¨æŸç§ç‰¹å®šçš„å¯¹åº”ï¼ˆå¦‚æœcæ˜¯å›¾åƒçš„æŸäº›ç‰¹å¾ï¼Œåˆ™æœ‰è¿™æ ·çš„å‡½æ•°å­˜åœ¨ï¼‰ï¼Œé‚£ä¹ˆcå’ŒG(z,c)ä¹‹é—´å°±åº”è¯¥æœ‰äº’ä¿¡æ¯é‡ã€‚å¦‚æœæ˜¯æ— çº¦æŸçš„æƒ…å†µï¼Œæ¯”å¦‚zå•ç‹¬çš„æ¯ä¸€ä¸ªç»´åº¦éƒ½è·Ÿå’ŒG(z)æ²¡æœ‰ç‰¹å®šçš„å…³ç³»ï¼Œé‚£ä¹ˆå®ƒä»¬ä¹‹é—´çš„äº’ä¿¡æ¯é‡åº”è¯¥æ¥è¿‘0ã€‚æ‰€ä»¥åŠ ä¸Šè¿™ä¸ªçº¦æŸä¹‹åï¼Œè¦ä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°å°±å˜æˆäº†</p>
<pre><code>min max V(D,G) = V(D,G) - ğœ† I(c;G(z,c))
</code></pre><p>æ¥ä¸‹æ¥å°±æ˜¯å¦‚ä½•å¤„ç† I(c; G)â€‹ã€‚ç”±äº I(c;G(z,c))â€‹ çš„è®¡ç®—éœ€è¦ p(c|x)â€‹ï¼Œè€Œæˆ‘ä»¬å¹¶ä¸çŸ¥é“çœŸå®çš„åˆ†å¸ƒã€‚è¿™æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦ç”¨ä¸€ä¸ª Q(c|x)â€‹ æ¥è¿‘ä¼¼ï¼Œå¾ˆæ˜¾ç„¶ï¼ŒQå¯ä»¥ç”¨ç¥ç»ç½‘ç»œæ¥å®ç°ã€‚æ­¤å¤–ï¼Œ å¯ä»¥åˆ©ç”¨reparametrizationï¼ˆè§é™„å½•ï¼‰çš„æŠ€å·§æ¥ç®€åŒ–ç½‘ç»œã€‚</p>
<p>åœ¨å®é™…ä¸­ï¼Œç”±äºQå’ŒDéƒ½æ˜¯è¾“å…¥ xï¼Œè€Œä¸”è¯†åˆ«ç½‘ç»œDé™¤äº†å¯ä»¥è¾“å‡ºæ¦‚ç‡ï¼Œä¹Ÿå¯ä»¥åšç‰¹å¾æå–ï¼Œå› æ­¤Qå¯ä»¥å’ŒDå…±äº«å‚æ•°ã€‚åœ¨æ­£å¸¸çš„Dä¹‹åï¼Œé¢å¤–åŠ ä¸€å±‚full connected layerï¼Œåˆ©ç”¨softmaxç­‰å¯ä»¥è¾“å‡ºcã€‚è¿™ä¹Ÿæ˜¯å›¾3ä¸­çš„ç»“æ„ã€‚</p>
<p>4ã€ Conditional GAN</p>
<p>Conditional GANçš„åŸºæœ¬æ¨¡å‹è§å›¾3ã€‚æ‰€è°“conditionalçš„æ„æ€å°±æ˜¯ï¼Œç”Ÿæˆå›¾ç‰‡çš„æ¨¡å‹å˜æˆäº† P(X|z, c)ï¼Œè€Œcæ˜¯æˆ‘ä»¬é¢å¤–æä¾›çš„ä¿¡æ¯ã€‚è¿™é‡Œè¦æ³¨æ„conditional GANå’ŒInfo GANçš„ç»“æ„åŒºåˆ«</p>
<ul>
<li>Infoä¸­cä¿¡æ¯æ˜¯éœ€è¦ç½‘ç»œå»å­¦ä¹ æå–çš„ç‰¹å¾ï¼Œè€Œè¿™é‡Œæ˜¯éœ€è¦æˆ‘ä»¬è¾“å…¥ç½‘ç»œçš„ä¿¡æ¯ã€‚</li>
<li>Infoä¸­cåªè¾“å…¥ç”Ÿæˆç½‘ç»œï¼Œè€Œè¿™é‡Œéœ€è¦åŒæ—¶è¾“å…¥ç”Ÿæˆå’Œè¯†åˆ«ç½‘ç»œï¼Œä»¥ä¾¿è®©ç½‘ç»œå­¦ä¹ åˆ°å®ƒä»¬ä¹‹é—´çš„å…³è”ã€‚</li>
</ul>
<p>åœ¨Conditional GANä¸­ï¼Œéšç€cçš„å˜æ¢å¯ä»¥è¡ç”Ÿå‡ºå¾ˆå¤šåº”ç”¨ï¼Œæ¯”å¦‚è¾“å…¥å¯ä»¥æ˜¯labelï¼Œå¯ä»¥æ˜¯åˆ†ç±»ã€‚ç”šè‡³æ˜¯å¦å¤–ä¸€ä¸ªå›¾ç‰‡ï¼Œæ¯”å¦‚å¯ä»¥åšimage to imageçš„é£æ ¼è½¬æ¢ï¼Œä¹Ÿå¯ä»¥åšåˆ†è¾¨ç‡æå‡super-resolutionã€‚è¿™é‡Œæˆ‘ä»¬ä»¥Text-to-Image[5] ä¸ºä¾‹ï¼Œè®²ä¸€ä¸‹conditional GANçš„ä¸€ç§å»ºæ¨¡æ–¹æ³•ã€‚</p>
<p>åŒæ ·ï¼Œå…ˆä¸Šå›¾ï¼š</p>
<p><img src="media/text2img.png" alt="text2img"></p>
<p>æ¨¡å‹çš„ä»»åŠ¡æ˜¯ç»™å®šä¸€å¥æ–‡å­—æè¿°ï¼Œç„¶åå¯ä»¥ç”Ÿæˆç¬¦åˆæè¿°çš„å›¾åƒã€‚å¯ä»¥çœ‹åˆ°ï¼Œç½‘ç»œçš„è¾“å…¥é™¤äº†é‡‡æ ·å™ªå£°zä»¥å¤–è¿˜æœ‰æ–‡å­—ä¿¡æ¯ã€‚æ•´ä¸ªä»»åŠ¡åˆ†ä¸ºä¸¤å¤§éƒ¨åˆ†ï¼šç¬¬ä¸€éƒ¨åˆ†æ˜¯è¦å¯¹æ–‡å­—è¿›è¡Œç¼–ç (text encoding)ï¼Œè¿™éƒ¨åˆ†å¹¶ä¸æ˜¯Conditonal GANæ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼Œå¯ä»¥ä½¿ç”¨RNNæˆ–è€…char-CNNç­‰ã€‚æ–‡ä¸­ç”¨çš„æ˜¯deep convolutional and recurrent text encoder[4] ï¼Œæ„Ÿå…´è¶£å¯ä»¥å»çœ‹è¿™ç¯‡æ–‡ç« [4]ã€‚</p>
<p>åœ¨æ¨¡å‹ä¸­ï¼Œæ–‡å­—ä¿¡æ¯åŒæ—¶è¾“å…¥ G å’Œ D æ˜¯å…³é”®æ‰€åœ¨ï¼Œè¿™æ ·ç½‘ç»œæ‰èƒ½å¤Ÿå°†æ–‡å­—å’Œå›¾ç‰‡å…³è”èµ·æ¥ã€‚å…¶æ¬¡ï¼Œåœ¨è®­ç»ƒä¸­ï¼ŒåŸGANä¸­ D åªéœ€è¦åˆ¤æ–­ä¸¤ç§æ•°æ®ï¼šreal/fakeçš„å›¾ç‰‡ã€‚è€Œè¿™é‡Œï¼ŒD éœ€è¦åˆ¤æ–­ï¼ˆè¾“å…¥ï¼‰ä¸‰ç§æ•°æ®{real image, right text}ï¼Œ{real image, wrong text}ä»¥åŠ{fake image, right text}ã€‚</p>
<p>5ã€ StackGAN</p>
<p>StackGAN[8] æ¨¡å‹æœ¬è´¨å°±æ˜¯æ˜¯Conditional GANï¼Œåªä¸è¿‡å®ƒä½¿ç”¨äº†ä¸¤å±‚conditional GANæ¨¡å‹ï¼Œç¬¬ä¸€å±‚æ¨¡å‹ P(X1|z, c) åˆ©ç”¨è¾“å…¥çš„æ–‡å­—ä¿¡æ¯cç”Ÿæˆä¸€ä¸ªè¾ƒä½åˆ†è¾¨ç‡çš„å›¾ç‰‡ã€‚ä¹‹åç¬¬äºŒå±‚æ¨¡å‹ P(X|c,,X1) åŸºäºç¬¬ä¸€å±‚ç”Ÿæˆçš„å›¾ç‰‡ä»¥åŠæ–‡å­—ä¿¡æ¯ç”Ÿæˆæ›´åŠ ä¼˜åŒ–çš„å›¾ç‰‡ã€‚æ–‡ä¸­ç»™å‡ºçš„å®éªŒæ•ˆæœéå¸¸çš„æƒŠäººï¼Œå¯ä»¥ç”Ÿæˆ256x256çš„éå¸¸çœŸå®çš„å›¾ç‰‡ã€‚è¿™é‡Œä¸å†é‡å¤ç»†èŠ‚ã€‚ä¸‹å›¾ä¸ºç®€åŒ–çš„StackGANæ¨¡å‹ã€‚</p>
<p><img src="media/stackGAN.png" alt="stackGAN"></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Goodfellow, Ian, et al. â€œGenerative adversarial nets.â€ <em>Advances in Neural Information Processing Systems</em>. 2014.</li>
<li>Radford, Alec, Luke Metz, and Soumith Chintala. â€œUnsupervised representation learning with deep convolutional generative adversarial networks.â€ <em>arXiv preprint arXiv:1511.06434</em> (2015).</li>
<li>Reed, Scott, et al. â€œGenerative adversarial text to image synthesis.â€ <em>arXiv preprint arXiv:1605.05396</em> (2016).</li>
<li>Reed, Scott, et al. â€œLearning Deep Representations of Fine-Grained Visual Descriptions.â€ <em>arXiv preprint arXiv:1605.05395</em> (2016).</li>
<li>Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network</li>
<li>Image-to-Image Translation with Conditional Adversarial Networks</li>
<li>Chen, Xi, et al. â€œInfogan: Interpretable representation learning by information maximizing generative adversarial nets.â€ <em>Advances in Neural Information Processing Systems</em>. 2016.</li>
<li>Zhang, Han, et al. â€œStackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks.â€ <em>arXiv preprint arXiv:1612.03242</em> (2016).</li>
<li><a href="https://twitter.com/ch402/status/793535193835417601" target="_blank" rel="external">https://twitter.com/ch402/status/793535193835417601</a></li>
</ol>
<h2 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h2><p>çœ‹äº†å‡ ç¯‡å…³äºGANçš„æ–‡ç« ï¼Œå‘ç°æœ‰å‡ ä¸ªå»ºæ¨¡çš„å°trick</p>
<ul>
<li>åœ¨ç”Ÿæˆæ¨¡å‹ä¸­ï¼Œä¹‹æ‰€ä»¥å¯ä»¥ä»ä¸€ä¸ªç®€å•çš„åˆ†å¸ƒé‡‡æ ·ï¼Œç„¶åé€šè¿‡ä¸€ä¸ªç½‘ç»œï¼ˆå‚æ•°éœ€è¦å­¦ä¹ ï¼‰å»è¿‘ä¼¼æ•°æ®çš„åˆ†å¸ƒ èƒŒåçš„åŸç†æ˜¯</li>
</ul>
<blockquote>
<p>Any distribution in d dim can be generated by taking a set of d normal distribution variables. mapping through a sufficiently complicated function. So provided powerful function approximators, we can simply learn a function mapping independent norm distribution z to whatever X.</p>
</blockquote>
<ul>
<li><p>åœ¨æ¨¡å‹ä¸­ï¼Œå¦‚æœç›®æ ‡å‡½æ•°ä¸­æŸä¸ªæ¡ä»¶æ¦‚ç‡æ— æ³•ç›´æ¥å¾—åˆ°ï¼Œé‚£ä¹ˆå¯ä»¥å­¦ä¹ ä¸€ä¸ªç½‘ç»œQå»è¿‘ä¼¼ã€‚åˆ©ç”¨KL divergence D{KL}[P||Q] = H(P,Q) - H(P) ä»¥åŠ<br>D{KL} &gt;= 0 å¯ä»¥æ¨å‡ºä¸€ä¸ªæ›´æ˜“ä¼˜åŒ–çš„ä¸Š/ä¸‹ç•Œã€‚</p>
</li>
<li><p><strong>reparametrization trick</strong> ä¸¾ä¸ªä¾‹å­ï¼Œæ¯”å¦‚æ¨¡å‹ä¸­ç”¨ä¸€ä¸ªç½‘ç»œ Q(z|x) æ¥è¿‘ä¼¼çœŸå®çš„ P(z|x)ï¼Œæˆ‘ä»¬å¸¸ç”¨æ­£æ€åˆ†å¸ƒæ¥å»ºæ¨¡Qï¼Œå³<br>N(Î¼, ğ›´)ï¼ˆè¿™é‡Œ Î¼ å’Œ ğ›´ éƒ½æ˜¯å¸¦å‚æ•°çš„ç½‘ç»œï¼Œé€šè¿‡å­¦ä¹ å¾—åˆ°ï¼‰ã€‚å½“é‡‡æ ·çš„ x é€šè¿‡ Q åå°±å¯ä»¥å¾—åˆ°zã€‚ä½†æ˜¯ç”±äºè¿™ä¸€æ­¥æ˜¯éšæœºè¿‡ç¨‹ï¼Œbackpropagationå°±ä¼šä¸­æ–­ã€‚è¿™ä¸ªæ—¶å€™æˆ‘ä»¬å°±å¯ä»¥åˆ©ç”¨ N(Î¼, ğ›´) = N(0, I) â¨‰ ğœ® + Î¼ å°†éšæœºè¿‡ç¨‹è½¬ç§»åˆ°è¾“å…¥ç«¯ã€‚å…ˆä»æ ‡å‡†æ­£æ€åˆ†å¸ƒé‡‡æ · z0ï¼Œæ­¤æ—¶ç½‘ç»œ Q å¹¶ä¸ç›´æ¥è¾“å‡ºzï¼Œè€Œæ˜¯è¾“å‡ºä¸¤ä¸ªå‚æ•°Î¼ å’Œ ğ›´ï¼Œä¹‹ååœ¨é€šè¿‡ z=z0 â¨‰ ğ›´ + Î¼ å¾—åˆ°zã€‚ç”±äºä¸­é—´èŠ‚ç‚¹å˜æˆäº†å¸¸è§„è¿ç®—ï¼Œå› æ­¤backpropagationå¯ä»¥æ­£å¸¸ä¼ å›è¾“å…¥ç«¯ã€‚</p>
<p>  â€‹</p>
</li>
</ul>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-12-30T04:10:12.000Z"><a href="/2016/12/29/2016å¹´è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸ10ç¯‡å€¼å¾—è¯»çš„Paper/">2016-12-29</a></time>
      
      
  
    <h1 class="title"><a href="/2016/12/29/2016å¹´è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸ10ç¯‡å€¼å¾—è¯»çš„Paper/">2016å¹´è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸ15ç¯‡å€¼å¾—è¯»çš„Paper</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="Learning-to-Compose-Neural-Networks-for-Question-Answering"><a href="#Learning-to-Compose-Neural-Networks-for-Question-Answering" class="headerlink" title="Learning to Compose Neural Networks for Question Answering"></a><a href="https://arxiv.org/abs/1601.01705" target="_blank" rel="external">Learning to Compose Neural Networks for Question Answering</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Department of Electrical Engineering and Computer Sciences<br>University of California, Berkeley</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Question Answering</p>
<h1 id="Text-understanding-with-the-attention-sum-reader-network"><a href="#Text-understanding-with-the-attention-sum-reader-network" class="headerlink" title="Text understanding with the attention sum reader network"></a><a href="https://arxiv.org/abs/1603.01547" target="_blank" rel="external">Text understanding with the attention sum reader network</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Rudolf Kadlec, Martin Schmid, Ondrej Bajgar, Jan Kleindienst</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>IBM Watson</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Machine Reading Comprehension </p>
<h1 id="Improving-Information-Extraction-by-Acquiring-External-Evidence-with-Reinforcement-Learning"><a href="#Improving-Information-Extraction-by-Acquiring-External-Evidence-with-Reinforcement-Learning" class="headerlink" title="Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning"></a><a href="https://arxiv.org/abs/1603.07954" target="_blank" rel="external">Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Karthik Narasimhan, Adam Yala, Regina Barzilay</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>CSAIL, MIT</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Information Extraction; Reinforcement Learning</p>
<h1 id="Pointing-the-Unknown-Words"><a href="#Pointing-the-Unknown-Words" class="headerlink" title="Pointing the Unknown Words"></a><a href="https://arxiv.org/abs/1603.08148" target="_blank" rel="external">Pointing the Unknown Words</a></h1><h2 id="ä½œè€…-3"><a href="#ä½œè€…-3" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Caglar Gulcehre, Sungjin Ahn, Ramesh Nallapati, Bowen Zhou, Yoshua Bengio</p>
<h2 id="å•ä½-3"><a href="#å•ä½-3" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Universite de MontrÂ´eal<br>IBM T.J. Watson Research<br>CIFAR Senior Fellow</p>
<h2 id="å…³é”®è¯-3"><a href="#å…³é”®è¯-3" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Unknown Words</p>
<h1 id="Sequence-to-Sequence-Learning-as-Beam-Search-Optimization"><a href="#Sequence-to-Sequence-Learning-as-Beam-Search-Optimization" class="headerlink" title="Sequence-to-Sequence Learning as Beam-Search Optimization"></a><a href="https://arxiv.org/abs/1606.02960" target="_blank" rel="external">Sequence-to-Sequence Learning as Beam-Search Optimization</a></h1><h2 id="ä½œè€…-4"><a href="#ä½œè€…-4" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Sam Wiseman, Alexander M. Rush</p>
<h2 id="å•ä½-4"><a href="#å•ä½-4" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>School of Engineering and Applied Sciences, Harvard University</p>
<h2 id="å…³é”®è¯-4"><a href="#å…³é”®è¯-4" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Seq2Seq; Beam Search</p>
<h1 id="SQuAD-100-000-Questions-for-Machine-Comprehension-of-Text"><a href="#SQuAD-100-000-Questions-for-Machine-Comprehension-of-Text" class="headerlink" title="SQuAD: 100,000+ Questions for Machine Comprehension of Text"></a><a href="https://arxiv.org/abs/1606.05250" target="_blank" rel="external">SQuAD: 100,000+ Questions for Machine Comprehension of Text</a></h1><h2 id="ä½œè€…-5"><a href="#ä½œè€…-5" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang</p>
<h2 id="å•ä½-5"><a href="#å•ä½-5" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Computer Science Department<br>Stanford University</p>
<h2 id="å…³é”®è¯-5"><a href="#å…³é”®è¯-5" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Machine Reading Comprehension; Dataset</p>
<h1 id="End-to-End-Reinforcement-Learning-of-Dialogue-Agents-for-Information-Access"><a href="#End-to-End-Reinforcement-Learning-of-Dialogue-Agents-for-Information-Access" class="headerlink" title="End-to-End Reinforcement Learning of Dialogue Agents for Information Access"></a><a href="https://arxiv.org/abs/1609.00777" target="_blank" rel="external">End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a></h1><h2 id="ä½œè€…-6"><a href="#ä½œè€…-6" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen, Faisal Ahmed, Li Deng</p>
<h2 id="å•ä½-6"><a href="#å•ä½-6" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>School of Computer Science, Carnegie Mellon University<br>Microsoft Research<br>National Taiwan University</p>
<h2 id="å…³é”®è¯-6"><a href="#å…³é”®è¯-6" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Reinforcement Learning; Dialogue System</p>
<h1 id="ReasoNet-Learning-to-Stop-Reading-in-Machine-Comprehension"><a href="#ReasoNet-Learning-to-Stop-Reading-in-Machine-Comprehension" class="headerlink" title="ReasoNet: Learning to Stop Reading in Machine Comprehension"></a><a href="https://arxiv.org/abs/1609.05284" target="_blank" rel="external">ReasoNet: Learning to Stop Reading in Machine Comprehension</a></h1><h2 id="ä½œè€…-7"><a href="#ä½œè€…-7" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Yelong Shen, Po-Sen Huang, Jianfeng Gao, Weizhu Chen</p>
<h2 id="å•ä½-7"><a href="#å•ä½-7" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Microsoft Research Redmond</p>
<h2 id="å…³é”®è¯-7"><a href="#å…³é”®è¯-7" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Machine Reading Comprehension </p>
<h1 id="Personalizing-a-Dialogue-System-with-Transfer-Learning"><a href="#Personalizing-a-Dialogue-System-with-Transfer-Learning" class="headerlink" title="Personalizing a Dialogue System with Transfer Learning"></a><a href="https://arxiv.org/abs/1610.02891" target="_blank" rel="external">Personalizing a Dialogue System with Transfer Learning</a></h1><h2 id="ä½œè€…-8"><a href="#ä½œè€…-8" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Kaixiang Mo, Shuangyin Li, Yu Zhang, Jiajun Li, Qiang Yang</p>
<h2 id="å•ä½-8"><a href="#å•ä½-8" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>The Hong Kong University of Science and Technology</p>
<h2 id="å…³é”®è¯-8"><a href="#å…³é”®è¯-8" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Dialogue System; Transfer Learning</p>
<h1 id="LightRNN-Memory-and-Computation-Efficient-Recurrent-Neural-Network"><a href="#LightRNN-Memory-and-Computation-Efficient-Recurrent-Neural-Network" class="headerlink" title="LightRNN Memory and Computation-Efficient Recurrent Neural Network"></a><a href="https://arxiv.org/abs/1610.09893" target="_blank" rel="external">LightRNN Memory and Computation-Efficient Recurrent Neural Network</a></h1><h2 id="ä½œè€…-9"><a href="#ä½œè€…-9" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Xiang Li, Tao Qin, Jian Yang, Tie-Yan Liu</p>
<h2 id="å•ä½-9"><a href="#å•ä½-9" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Nanjing University of Science and Technology<br>Microsoft Research Asia</p>
<h2 id="å…³é”®è¯-9"><a href="#å…³é”®è¯-9" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>New Recurrent Neural Network</p>
<h1 id="Dual-Learning-for-Machine-Translation"><a href="#Dual-Learning-for-Machine-Translation" class="headerlink" title="Dual Learning for Machine Translation"></a><a href="https://arxiv.org/abs/1611.00179" target="_blank" rel="external">Dual Learning for Machine Translation</a></h1><h2 id="ä½œè€…-10"><a href="#ä½œè€…-10" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Yingce Xia, Di He, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, Wei-Ying Ma</p>
<h2 id="å•ä½-10"><a href="#å•ä½-10" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>University of Science and Technology of China<br>Key Laboratory of Machine Perception (MOE), School of EECS, Peking University<br>Microsoft Research</p>
<h2 id="å…³é”®è¯-10"><a href="#å…³é”®è¯-10" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Dual Learning; Neural Machine Translation</p>
<h1 id="Neural-Machine-Translation-with-Reconstruction"><a href="#Neural-Machine-Translation-with-Reconstruction" class="headerlink" title="Neural Machine Translation with Reconstruction"></a><a href="https://arxiv.org/abs/1611.01874" target="_blank" rel="external">Neural Machine Translation with Reconstruction</a></h1><h2 id="ä½œè€…-11"><a href="#ä½œè€…-11" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Zhaopeng Tu, Yang Liu, Lifeng Shang, Xiaohua Liu, Hang Li</p>
<h2 id="å•ä½-11"><a href="#å•ä½-11" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Noahâ€™s Ark Lab, Huawei Technologies<br>Department of Computer Science and Technology, Tsinghua University</p>
<h2 id="å…³é”®è¯-11"><a href="#å…³é”®è¯-11" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Neural Machine Translation</p>
<h1 id="Linguistically-Regularized-LSTMs-for-Sentiment-Classification"><a href="#Linguistically-Regularized-LSTMs-for-Sentiment-Classification" class="headerlink" title="Linguistically Regularized LSTMs for Sentiment Classification"></a><a href="https://arxiv.org/abs/1611.03949" target="_blank" rel="external">Linguistically Regularized LSTMs for Sentiment Classification</a></h1><h2 id="ä½œè€…-12"><a href="#ä½œè€…-12" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Qiao Qian, Minlie Huang, Xiaoyan Zhu</p>
<h2 id="å•ä½-12"><a href="#å•ä½-12" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>State Key Lab. of Intelligent Technology and Systems, National Lab. for Information Science and Technology<br>Dept. of Computer Science and Technology, Tsinghua University</p>
<h2 id="å…³é”®è¯-12"><a href="#å…³é”®è¯-12" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Sentiment Classification; LSTM</p>
<h1 id="Googleâ€™s-Multilingual-Neural-Machine-Translation-System-Enabling-Zero-Shot-Translation"><a href="#Googleâ€™s-Multilingual-Neural-Machine-Translation-System-Enabling-Zero-Shot-Translation" class="headerlink" title="Googleâ€™s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation"></a><a href="https://arxiv.org/abs/1611.04558" target="_blank" rel="external">Googleâ€™s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation</a></h1><h2 id="ä½œè€…-13"><a href="#ä½œè€…-13" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Melvin Johnson, Mike Schuster, Quoc V. Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda ViÃ©gas, Martin Wattenberg, Greg Corrado, Macduff Hughes, Jeffrey Dean</p>
<h2 id="å•ä½-13"><a href="#å•ä½-13" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Google</p>
<h2 id="å…³é”®è¯-13"><a href="#å…³é”®è¯-13" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Multilingual Neural Machine Translation; Zero-Shot</p>
<h1 id="Language-Modeling-with-Gated-Convolutional-Networks"><a href="#Language-Modeling-with-Gated-Convolutional-Networks" class="headerlink" title="Language Modeling with Gated Convolutional Networks"></a><a href="https://arxiv.org/abs/1612.08083" target="_blank" rel="external">Language Modeling with Gated Convolutional Networks</a></h1><h2 id="ä½œè€…-14"><a href="#ä½œè€…-14" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Yann N. Dauphin, Angela Fan, Michael Auli, David Grangier</p>
<h2 id="å•ä½-14"><a href="#å•ä½-14" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Facebook AI Research</p>
<h2 id="å…³é”®è¯-14"><a href="#å…³é”®è¯-14" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Language Modeling; Gated CNN</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-12-29T19:20:43.000Z"><a href="/2016/12/29/å‘Šåˆ«2016ï¼Œè¿æ¥2017/">2016-12-29</a></time>
      
      
  
    <h1 class="title"><a href="/2016/12/29/å‘Šåˆ«2016ï¼Œè¿æ¥2017/">å‘Šåˆ«2016ï¼Œè¿æ¥2017</a></h1>
  

    </header>
    <div class="entry">
      
        <p>2016å¹´å³å°†ç»“æŸï¼Œé¦–å…ˆå¯¹æ”¯æŒPaperWeeklyçš„å„ä½ç«¥é‹è¡¨ç¤ºè¡·å¿ƒçš„æ„Ÿè°¢ï¼Œæ„Ÿè°¢ä½ ä»¬è®©æˆ‘æœ‰åŠ¨åŠ›å°†è¿™ä¸ªç”¨æ¥ç£ä¿ƒæˆ‘è‡ªå·±å¤šè¯»paperçš„side projectåšæŒä¸€ç›´åšä¸‹æ¥ï¼Œæ„Ÿè°¢å„ä½å¯¹è‡ªç„¶è¯­è¨€å¤„ç†æ„Ÿå…´è¶£å¹¶ä¸”æ„¿æ„ç‰ºç‰²ä¸€äº›ä¸ªäººæ—¶é—´æ¥å†™paper noteçš„å°ä¼™ä¼´ï¼Œä¹Ÿæ„Ÿè°¢æ¯å¤©åšæŒä¸€èµ·åˆ·arXivæ¥ä¿è¯å‘¨æœ«æ¨èâ€œæ¯å‘¨å€¼å¾—è¯»â€è´¨é‡çš„å‡ ä½ç«¥é‹ï¼Œæ„Ÿè°¢åŠ å…¥PaperWeeklyäº¤æµç¾¤æ¯å¤©éƒ½è´¡çŒ®å¾ˆå¤šé«˜è´¨é‡è®¨è®ºå†…å®¹çš„å„ä½æœ‹å‹ï¼Œæ„Ÿè°¢ä¸ºä¸‰ä¸ªäº¤æµç¾¤åšæ¶ˆæ¯åŒæ­¥æœºå™¨äººçš„ç§ç“œåŒå­¦ã€‚</p>
<p>PaperWeeklyä»åˆšå¼€å§‹åªæœ‰æˆ‘ä¸€ä¸ªäººï¼Œåˆ°ç°åœ¨ä¸€å…±æœ‰50å¤šä½ä¸€èµ·æ„¿æ„åˆ†äº«å†…å®¹çš„å°ä¼™ä¼´ï¼Œå¹¶ä¸”è¿™ä¸ªæ•°å­—éšç€å¤§å®¶çš„çƒ­æƒ…å‚ä¸ä¼šé€æ¸å¢åŠ ï¼Œæ­£æ˜¯æœ‰äº†è¿™ä¹ˆå¤šç§¯æå‚ä¸çš„å°ä¼™ä¼´ï¼Œæ‰æœ‰äº†PaperWeeklyä¸€å‘¨æ•¢åšä¸€ä¸ªtopicçš„åº•æ°”ã€‚ä»9æœˆ1å·é‡æ–°ç»„ç»‡PaperWeeklyçš„å†…å®¹å½¢å¼ï¼Œåˆ°ä»Šå¤©ä¸ºæ­¢ï¼Œä¸€å…±å‘å¸ƒäº†17æœŸå†…å®¹ï¼ŒåŠ ä¸Šä¹‹å‰æˆ‘è‡ªå·±å†™çš„2æœŸå†…å®¹ï¼Œä¸€å…±æ˜¯19æœŸå†…å®¹ï¼Œ19æœŸæ„å‘³ç€19å‘¨çš„æ—¶é—´ï¼Œ19å‘¨çš„æ—¶é—´æˆ‘ä»¬å¯ä»¥èµ°è¿‡å¾ˆå¤šåœ°æ–¹ï¼Œåƒè¿‡å¾ˆå¤šç¾é£Ÿï¼Œçœ‹è¿‡å¾ˆå¤šç¾æ™¯ï¼Œè€Œæˆ‘ä»¬é€‰æ‹©äº†è¯»19å‘¨çš„paperï¼Œé€‰æ‹©äº†å†™19å‘¨çš„paper noteï¼Œé€‰æ‹©äº†æ¨èè¿™19å‘¨ä¸­é«˜è´¨é‡çš„paperï¼Œé€‰æ‹©äº†åˆ†äº«è¿™19å‘¨ä»¥æ¥å¤§å®¶çš„æˆé•¿ã€ç§¯ç´¯ä¸æ€è€ƒã€‚</p>
<p>19å‘¨çš„æ—¶é—´ï¼ŒPaperWeeklyä¸€å…±å®Œæˆäº†83ç¯‡paper notesï¼Œè€Œè¿™83ç¯‡paperå¯ä»¥ç”¨19ä¸ªç‹¬ç«‹çš„topicç»„ç»‡èµ·æ¥ï¼Œæ¯”å¦‚ï¼š</p>
<p>1ã€æé«˜seq2seqç”Ÿæˆå¯¹è¯çš„æµç•…æ€§å’Œå¤šæ ·æ€§ï¼›<br>2ã€é€šè¿‡æ— ç›‘ç£/åŠç›‘ç£çš„æ–¹æ³•æ¥åšå‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰ï¼›<br>3ã€å“ªäº›ICLR2017çš„paperå€¼å¾—å…³æ³¨ï¼›<br>4ã€Attentionæ¨¡å‹åœ¨NMTä»»åŠ¡ä¸­çš„åº”ç”¨å’Œè¿›å±•ï¼›<br>5ã€æ–‡æœ¬æ‘˜è¦æŠ€æœ¯çš„è¿›å±•æƒ…å†µï¼›<br>6ã€å¢å¼ºå­¦ä¹ åœ¨å¯¹è¯ç”Ÿæˆä¸­çš„åº”ç”¨ï¼›<br>7ã€GANçš„ç ”ç©¶è¿›å±•ï¼›</p>
<p>æ¯ä¸ªtopicéƒ½æ¶‰åŠåˆ°äº†ä¸€ä¸ªç ”ç©¶æ–¹å‘ï¼Œæœ‰çš„å†…å®¹éå¸¸çƒ­é—¨ï¼Œæ¯”å¦‚GANï¼Œæœ‰çš„å†…å®¹éå¸¸ç»å…¸ï¼Œæ¯”å¦‚NERï¼Œæ¯ä¸ªtopicéƒ½ä¼šæŠ“ä½ä¸€äº›ç‰¹ç‚¹æ¥å½’çº³å‡ ç¯‡paperï¼Œä¸ºå‡†å¤‡å…¥é—¨ã€æ­£åœ¨å…¥é—¨ã€å·²ç»å…¥é—¨çš„åŒå­¦æä¾›äº†æœåŠ¡å’Œæ–¹ä¾¿ã€‚</p>
<p>ä»8.25å¼€å§‹ï¼ŒPaperWeeklyæ¨å‡ºäº†â€œæ¯å‘¨å€¼å¾—è¯»â€æ ç›®ï¼Œæ—¨åœ¨å……å½“arXivä¸Šè‡ªç„¶è¯­è¨€å¤„ç†æ–¹é¢çš„äººå·¥è¿‡æ»¤å™¨ï¼Œæ—¨åœ¨è§£å†³ä¿¡æ¯è¿‡è½½é—®é¢˜ï¼Œæ—¨åœ¨å¸®åŠ©å¤§å®¶æ›´å¿«åœ°äº†è§£åˆ°å“ªäº›paperæ›´å€¼å¾—å…³æ³¨ã€‚</p>
<p>ä»8.25å¼€å§‹ï¼ŒPaperWeeklyä¸€å…±æ¨èäº†153ç¯‡é«˜è´¨é‡çš„paperï¼Œå½“ç„¶æ¯ä¸ªäººå¯¹äºè´¨é‡çš„ç†è§£éƒ½ä¼šæœ‰æ‰€åå·®ï¼Œæœ‰çš„paperç»™æ•´ä¸ªç ”ç©¶å¸¦æ¥äº†å·¨å¤§çš„å½±å“ï¼Œæœ‰çš„paperå¯èƒ½å¯¹æŸä¸ªé¢†åŸŸæœ‰æ‰€æé«˜ï¼Œæœ‰çš„paperæ‰€è•´å«çš„æ€æƒ³ä¼šå¸¦æ¥å¾ˆå¤šçš„å¯å‘ï¼Œè¿™æ˜¯ä¸€ä»¶ä»è€…è§ä»æ™ºè€…è§æ™ºçš„äº‹æƒ…ã€‚</p>
<p>åœ¨åšPaperWeeklyçš„æ—¶å€™ï¼Œæˆ‘è§‚å¯Ÿåˆ°å¤§å®¶æœ‰ä¸€å®šçš„æ‹›è˜éœ€æ±‚ï¼Œå¯èƒ½æ˜¯å…¬å¸ï¼Œä¹Ÿå¯èƒ½æ˜¯é™¢æ ¡æˆ–è€…ç§‘ç ”æœºæ„ï¼Œä½†æ˜¯åœ¨äº¤æµç¾¤ä¸­å‘çš„æ•ˆæœåˆä¸æ˜¯å¾ˆå¥½ï¼Œäºæ˜¯åšäº†ä¸ªå†³å®šï¼Œåœ¨11æœˆä¸­æ—¬å¼€å§‹æ¨å‡ºäº†ä¸€é¡¹æ–°çš„æœåŠ¡â€”å…¬ç›Šå¹¿å‘ŠæœåŠ¡ï¼Œä»ç¬¬ä¸€ä¸ªå¸®åŠ©æ¸…åå¤§å­¦åˆ˜çŸ¥è¿œè€å¸ˆæ‹›åšå£«åå¼€å§‹è‡³ä»Šå·²ç»å‘äº†ä¸€äº›å¹¿å‘Šäº†ï¼Œè™½ç„¶è¿˜æ²¡æœ‰åšæ•ˆæœåé¦ˆå·¥ä½œï¼Œä½†æˆ‘ä»¬ç¡®å®å°½åŠ›åœ¨å¸®è¿™äº›éœ€è¦å¸®åŠ©çš„ä¼ä¸šæˆ–è€…é™¢æ ¡ï¼Œå¦‚æœæ‚¨æœ‰è¿™æ ·çš„æ‹›è˜éœ€æ±‚ï¼Œå¯ä»¥ç§ä¿¡æ¥è”ç³»æˆ‘ï¼Œå¦‚æœå¯ä»¥ä¸PaperWeeklyåˆä½œå†™ä¸€æœŸæ–‡ç« ä¼šæ›´å¥½ï¼</p>
<p>åœ¨åšPaperWeeklyçš„æ—¶å€™ï¼Œæˆ‘ä¹Ÿæœ‰è¿‡ä¸€é˜µè¿·èŒ«ï¼Œå°±æ˜¯å…³äºPaperWeeklyåˆ°åº•æ˜¯ä»€ä¹ˆçš„æ€è€ƒï¼Œè®°å¾—æ˜¯ä¸€ä¸ªå‘¨æ—¥æ™šä¸Šï¼Œæˆ‘åˆ°äº†å¤œé‡Œ3ç‚¹ä»æ²¡æœ‰ç¡ç€ï¼Œå°±çˆ¬èµ·æ¥å†™äº†ä¸€ç¯‡ã€ŠPaperWeeklyåˆ°åº•æ˜¯ä»€ä¹ˆã€‹çš„æ–‡ç« ï¼Œæ¥å¥½å¥½åœ°å®šä¹‰äº†ä¸€ä¸‹æˆ‘ä»¬æ‰€åšçš„äº‹æƒ…ä»¥åŠæ‰€æƒ³è¿½æ±‚çš„ä¸œè¥¿ã€‚æœ€åï¼Œæˆ‘æ˜¯è¿™ä¹ˆå®šä¹‰PaperWeeklyçš„ï¼Œâ€œPaperWeeklyæ˜¯ä¸€ä¸ªç”±50å¤šåå–œæ¬¢åˆ†äº«çŸ¥è¯†çš„ç«¥é‹åˆ©ç”¨å®è´µçš„ä¸šä½™æ—¶é—´æ¥ä¸€èµ·ï¼Œä»¥ä¸€å‘¨ä¸ºå•ä½ã€å¯¹ä¸€ä¸ªtopicè¿›è¡Œå¤šç¯‡paperè§£è¯»å’Œå¯¹æ¯”æ€»ç»“çš„ã€ä¸è¿½æ±‚çƒ­ç‚¹ã€ä¸æäº›å™±å¤´çš„çˆ±å¿ƒå…¬ç›Šç»„ç»‡ï¼Œæ—¨åœ¨åˆ†äº«çŸ¥è¯†ã€‚â€</p>
<p>å¯¹ä¸€ä¸ªä¸œè¥¿çš„å®šä½å¾ˆé‡è¦ï¼Œç›´æ¥å†³å®šäº†å¯¹è¿™ä¸ªä¸œè¥¿çš„æ€åº¦å’Œæ‰€åº”é‡‡å–çš„æ–¹å¼ã€æ–¹æ³•ã€‚æˆ‘åšä¸åˆ°æ‹¿ä¸€äº›å“—ä¼—å–å® çš„åå­—æ¥å‘½åæ–‡ç« æ ‡é¢˜ï¼Œä¹Ÿåšä¸åˆ°è¿‡åˆ†åœ°å¤¸å¤§æˆ–è€…è´¬ä½æŸä¸€ä¸ªä¸œè¥¿ï¼Œæˆ‘åªæƒ³çº¯ç²¹åœ°åšè¿™ä¹ˆä¸€ä»¶äº‹æƒ…ã€‚å„ç§æŒ‡æ ‡å¯¹æˆ‘ä»¬æ¥è¯´æ²¡æœ‰æ„ä¹‰ï¼Œå“ªæ€•æ²¡æœ‰äººæ¥è¯»æ–‡ç« ï¼Œè€Œæˆ‘ä»¬æ¯å¤©æ‰€è¯»çš„è¿™äº›paperï¼Œæ‰€å­¦åˆ°çš„çŸ¥è¯†éƒ½ä¸ä¼šå‡å°‘ï¼Œå½“ç„¶æˆ‘å¸Œæœ›å¤§å®¶å†™çš„ä¸œè¥¿å¯ä»¥åˆ†äº«ç»™æ›´å¤šçš„äººï¼Œè®©æ›´å¤šçš„äººä¸€èµ·æ¥æ„Ÿå—ç§‘æŠ€çš„è¿›æ­¥å’Œå­¦æœ¯çš„å‰æ²¿ï¼Œä½†æˆ‘ä»¬ä¸ä¼šåˆ»æ„åœ°å»è¿½æ±‚ä»€ä¹ˆã€‚æˆ‘ä¸€ç›´è®¤ä¸ºäººèƒ½å¤ŸåšæŒå¹¶ä¸”åŠªåŠ›åšå¥½ä¸€ä»¶äº‹æƒ…çš„æœ€å¤§åŠ¨åŠ›æ˜¯çƒ­çˆ±ï¼Œæ˜¯é‚£ç§æ²¡æœ‰åŠç‚¹è™šä¼ªã€æ²¡æœ‰åŠç‚¹åŠŸåˆ©çš„çƒ­çˆ±ã€‚å› ä¸ºçƒ­çˆ±ï¼Œæ‰€ä»¥çº¯ç²¹ã€‚</p>
<p>PaperWeeklyä¸æ˜¯ä¸€ä¸ªå®Œç¾çš„ä¸œè¥¿ï¼Œä½†æ˜¯ä¸€ä¸ªæˆé•¿çš„ä¸œè¥¿ï¼Œæ˜¯ä¸€ä¸ªä¸€ç›´åœ¨åŠªåŠ›å˜å¥½çš„ä¸œè¥¿ã€‚2016å¿«è¦ç»“æŸäº†ï¼Œåœ¨2017å¹´é‡Œï¼Œæˆ‘ä»¬å°†ä¸æ–­åœ°å®Œå–„æ–‡ç« è´¨é‡ï¼Œä¸°å¯Œæ–‡ç« çš„å½¢å¼ï¼Œå¢åŠ ä¸€äº›ç¾¤å†…çš„ç›´æ’­äº¤æµæ´»åŠ¨ï¼Œæ¯”å¦‚é’ˆå¯¹æŸä¸€ç¯‡ã€æŸå‡ ç¯‡paperçš„è®¨è®ºï¼Œä¸å®šæœŸåœ°é‚€è¯·æ›´å¤šçš„ä¸šç•Œå¤§ç‰›æ¥è®²ä¸€è®²ç†è®ºå’ŒæŠ€æœ¯å¦‚ä½•åœ¨å·¥ä¸šç•Œè½åœ°ç­‰ç­‰ã€‚</p>
<p>PaperWeeklyæ˜¯ä¸€ä¸ªéå¸¸å¼€æ”¾çš„ç»„ç»‡ï¼Œéšæ—¶æ¬¢è¿æƒ³ä¸€èµ·å†™paper notesæˆ–è€…å†™åˆ†äº«çš„ç«¥é‹åŠ å…¥ï¼Œè®©æˆ‘ä»¬ä¸æ–­åœ°åŠªåŠ›ï¼Œä¸æ–­åœ°å£®å¤§åŠ›é‡ï¼Œåœ¨2017å¹´ä¹¦å†™å‡ºæ›´å¤šå€¼å¾—è¯»çš„æ–‡ç« ï¼Œäº§ç”Ÿæ›´å¤šé«˜è´¨é‡çš„è®¨è®ºå†…å®¹ï¼Œä¸€èµ·ä¸ºå›½å†…è‡ªç„¶è¯­è¨€å¤„ç†çš„å‘å±•è´¡çŒ®ä¸€ç‚¹ç‚¹åŠ›é‡ã€‚</p>
<p>æœ€åï¼Œæ„Ÿè°¢å„ä½åˆä½œä¼™ä¼´å¯¹PaperWeeklyçš„å¤§åŠ›æ”¯æŒï¼Œæ„Ÿè°¢æœºå™¨ä¹‹å¿ƒã€ç§‘ç ”åœˆã€IEEEè®¡ç®—ç§‘å­¦è¯„è®ºã€ChatbotChinaã€å°†é—¨åˆ›æŠ•ç­‰åª’ä½“å’Œæœºæ„çš„æ”¯æŒã€‚</p>
<p>2016å¹´æ˜¯ä¸€ä¸ªå¼€å§‹ï¼Œä¹Ÿä»…ä»…æ˜¯ä¸€ä¸ªå¼€å§‹ï¼Œ2017å¹´å³å°†åˆ°æ¥ï¼ŒPaperWeeklyå°†ä¸æ·±åº¦å­¦ä¹ ç¤¾åŒºAI100è¿›è¡Œæ·±åº¦åˆä½œï¼Œä¸ºå¤§å®¶æä¾›æ›´å¥½çš„æœåŠ¡ï¼</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-12-25T18:31:57.000Z"><a href="/2016/12/25/æœ¬å‘¨å€¼å¾—è¯»-2016-12-19-2016-12-23/">2016-12-25</a></time>
      
      
  
    <h1 class="title"><a href="/2016/12/25/æœ¬å‘¨å€¼å¾—è¯»-2016-12-19-2016-12-23/">æœ¬å‘¨å€¼å¾—è¯»(2016.12.19-2016.12.23)</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="Machine-Reading-with-Background-Knowledge"><a href="#Machine-Reading-with-Background-Knowledge" class="headerlink" title="Machine Reading with Background Knowledge"></a><a href="http://t.cn/RIx3EjP" target="_blank" rel="external">Machine Reading with Background Knowledge</a></h2><p>ã€è¯­ä¹‰ç†è§£ã€‘åœ¨ç†è§£ä¸€å¥è¯çš„æ—¶å€™é€šå¸¸æ˜¯ç›´æ¥åˆ†æè¯¥å¥è¯ï¼Œè€Œæ²¡æœ‰å€ŸåŠ©å…¶ä»–å¤–éƒ¨çš„çŸ¥è¯†ï¼Œæ‰€ä»¥å¸¸å¸¸ä¼šäº§ç”Ÿä¸€äº›æ­§ä¹‰æˆ–è€…é”™è¯¯ã€‚æœ¬æ–‡çš„æ€è·¯æ˜¯åœ¨åˆ†æä¸€å¥è¯æ—¶ï¼Œå€ŸåŠ©ä¸€äº›èƒŒæ™¯çŸ¥è¯†æ¥è¿›è¡Œè¾…åŠ©ï¼Œæ–‡ä¸­ç»™å‡ºäº†ä¸¤ä¸ªä»»åŠ¡ï¼Œä¸€ä¸ªæ˜¯å¥æ³•åˆ†æä¸­çš„ä»‹è¯çŸ­è¯­æ¶ˆæ­§ï¼Œä¸€ä¸ªæ˜¯åè¯çŸ­è¯­çš„å…³ç³»æŠ½å–ï¼Œéƒ½å–å¾—äº†æ˜æ˜¾çš„æ•ˆæœã€‚æœ¬æ–‡ä½œè€…åŒ…æ‹¬äº†ã€Šæœºå™¨å­¦ä¹ ã€‹çš„ä½œè€…Tom M. Mitchellæ•™æˆã€‚å•çº¯åœ°åŸºäºç»Ÿè®¡æ–¹æ³•æ¥åšå¥æ³•åˆ†ææˆ–è€…è¯­ä¹‰è§’è‰²æ ‡æ³¨ç¡®å®ä¼šé‡åˆ°ä¸€äº›ç“¶é¢ˆï¼Œå€ŸåŠ©å¤–éƒ¨çš„èƒŒæ™¯çŸ¥è¯†æ˜¯ä¸€ä¸ªä¸é”™çš„æ€è·¯ã€‚éšç€æœ¬æ–‡ä¸€èµ·è¿˜å¼€æ”¾äº†ä¸€ä¸ªæ•°æ®é›† Prepositional Phrase Attachment Ambiguity (PPA) dataset <a href="http://t.cn/RIx1lEm" target="_blank" rel="external">http://t.cn/RIx1lEm</a></p>
<h2 id="A-User-Simulator-for-Task-Completion-Dialogues"><a href="#A-User-Simulator-for-Task-Completion-Dialogues" class="headerlink" title="A User Simulator for Task-Completion Dialogues"></a><a href="http://t.cn/RI9czrW" target="_blank" rel="external">A User Simulator for Task-Completion Dialogues</a></h2><p>ã€å¯¹è¯ç³»ç»Ÿã€‘æœ¬æ–‡ç ”ç©¶çš„é—®é¢˜éå¸¸æœ‰ç”¨ï¼Œäººäººéƒ½åœ¨åšchatbotï¼Œå´è‹¦äºæ²¡æœ‰è®­ç»ƒæ•°æ®ï¼Œç”¨æˆ·æ¨¡æ‹Ÿæ˜¯ä¸€ä¸ªä¸é”™çš„æ€è·¯ã€‚æœ¬æ–‡æ¢ç´¢äº†ä¸€ç§æ¨¡æ‹ŸçœŸå®ç”¨æˆ·æ¥è®­ç»ƒchatbotçš„æ–¹æ³•ï¼Œæ–‡ä¸­ç»™å‡ºäº†æ¨¡æ‹Ÿå™¨çš„è®¾è®¡å’Œéƒ¨åˆ†ä»£ç ï¼Œæ¶‰åŠåˆ°çš„é¢†åŸŸåŒ…æ‹¬æ‰¾ç”µå½±å’Œè®¢ç”µå½±ç¥¨ã€‚è™½ç„¶æ•ˆæœæœ‰å¾ˆå¤§æå‡ç©ºé—´ï¼Œä½†æ˜¯ä¸ªä¸é”™çš„å°è¯•ã€‚æ¨èç»™ç ”ç©¶å’Œå¼€å‘chatbotçš„ç«¥é‹ã€‚æºä»£ç ä¹ŸåŒæ—¶å¼€æ”¾äº†ï¼Œåœ°å€ <a href="http://t.cn/RICfMSB" target="_blank" rel="external">http://t.cn/RICfMSB</a> æ„Ÿå…´è¶£çš„ç«¥é‹å¯ä»¥ç ”ç©¶ä¸‹ã€‚</p>
<h2 id="Reducing-Redundant-Computations-with-Flexible-Attention"><a href="#Reducing-Redundant-Computations-with-Flexible-Attention" class="headerlink" title="Reducing Redundant Computations with Flexible Attention"></a><a href="http://t.cn/RI9f3Bx" target="_blank" rel="external">Reducing Redundant Computations with Flexible Attention</a></h2><p>ã€æ³¨æ„åŠ›æ¨¡å‹ä¼˜åŒ–ã€‘æ³¨æ„åŠ›å·²ç»æ˜¯ä¸€ä¸ªåº”ç”¨æ¯”è¾ƒå¹¿æ³›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œæœ¬æ–‡å¯¹decodingè¿‡ç¨‹ä¸­çš„è®¡ç®—æ•ˆç‡è¿›è¡Œäº†ä¼˜åŒ–ï¼Œæå‡ºäº†ä¸€ç§Flexibleæ³¨æ„åŠ›æ¨¡å‹ï¼Œåœ¨æ¯ä¸€æ­¥è§£ç æ—¶éƒ½ä¼šé€šè¿‡ä¸€ä¸ªæƒ©ç½šå‡½æ•°æ¥è¿‡æ»¤æ‰ä¸€äº›ä¸é‡è¦çš„encoder unitï¼Œä»è€Œé™ä½è®¡ç®—é‡ã€‚ </p>
<h2 id="Improving-Tweet-Representations-using-Temporal-and-User-Context"><a href="#Improving-Tweet-Representations-using-Temporal-and-User-Context" class="headerlink" title="Improving Tweet Representations using Temporal and User Context"></a><a href="http://t.cn/RI9I8LS" target="_blank" rel="external">Improving Tweet Representations using Temporal and User Context</a></h2><p>ã€ç”¨æˆ·ç”»åƒã€‘æœ¬æ–‡åœ¨å¯¹tweetè¿›è¡Œè¡¨ç¤ºå­¦ä¹ æ—¶ï¼Œé€šè¿‡å¼•å…¥ç”¨æˆ·timelineä¸Šç›¸é‚»çš„tweetsæ¥æé«˜å‡†ç¡®åº¦ã€‚</p>
<h2 id="Automatic-Generation-of-Grounded-Visual-Questions"><a href="#Automatic-Generation-of-Grounded-Visual-Questions" class="headerlink" title="Automatic Generation of Grounded Visual Questions"></a><a href="http://t.cn/RIKmwoo" target="_blank" rel="external">Automatic Generation of Grounded Visual Questions</a></h2><p>ã€VQAã€‘ã€é—®é¢˜ç”Ÿæˆã€‘å¯è§†åŒ–é—®ç­”æ˜¯ä¸ªå¾ˆæœ‰æ„æ€çš„ä¸œè¥¿ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ä»»åŠ¡ï¼Œè‡ªåŠ¨ç”Ÿæˆä¸å›¾ç‰‡å†…å®¹ç›¸å…³çš„é—®é¢˜ï¼Œæœ‰ä¸€ç‚¹image captionçš„æ„æ€ï¼Œåªæ˜¯è¯´è¿™é‡Œç”¨æ¥æé—®ã€‚æ„Ÿå…´è¶£çš„ç«¥é‹å¯ä»¥å…³æ³¨ä¸€ä¸‹ã€‚ </p>
<h2 id="CLEVR-A-Diagnostic-Dataset-for-Compositional-Language-and-Elementary-Visual-Reasoning"><a href="#CLEVR-A-Diagnostic-Dataset-for-Compositional-Language-and-Elementary-Visual-Reasoning" class="headerlink" title="CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning"></a><a href="http://t.cn/RICIat8" target="_blank" rel="external">CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning</a></h2><p>ã€VQAã€‘ã€æ•°æ®ç¦åˆ©ã€‘Li Feifeiç»„å‘å¸ƒçš„ä¸€ç»„VQAæ•°æ®é›†ï¼Œ100kè§„æ¨¡çš„å›¾ç‰‡é›†ï¼Œå€¼å¾—å…³æ³¨ï¼æ–‡ä¸­æåˆ°æ•°æ®å’Œç›¸å…³çš„å¤„ç†ä»£ç è¿‘æœŸä¼šå…¬å¼€ã€‚</p>
<h2 id="Fast-Domain-Adaptation-for-Neural-Machine-Translation"><a href="#Fast-Domain-Adaptation-for-Neural-Machine-Translation" class="headerlink" title="Fast Domain Adaptation for Neural Machine Translation"></a><a href="http://t.cn/RICJro8" target="_blank" rel="external">Fast Domain Adaptation for Neural Machine Translation</a></h2><p>ã€æœºå™¨ç¿»è¯‘ã€‘ã€è¿ç§»å­¦ä¹ ã€‘æœ¬æ–‡çš„å·¥ä½œæ˜¯å°†æŸä¸€ä¸ªé¢†åŸŸä¸­è®­ç»ƒå¥½çš„æ¨¡å‹ä»¥æœ€ä½çš„ä»£ä»·è¿ç§»åˆ°é¢†åŸŸå¤–ï¼ŒåŒæ—¶ä¿è¯é¢†åŸŸå†…å’Œé¢†åŸŸå¤–éƒ½æœ‰ä¸é”™çš„æ•ˆæœã€‚å…·ä½“çš„æ€è·¯æ˜¯ï¼šå…ˆè®­ç»ƒå‡ºä¸€ä¸ªä¸é”™çš„baseline modelï¼Œç„¶ååœ¨baselineçš„åŸºç¡€ä¸Šä½¿ç”¨é¢†åŸŸå¤–çš„å°‘é‡æ•°æ®è¿›è¡Œå‡ ä¸ªå›åˆçš„è®­ç»ƒï¼Œå¾—åˆ°ä¸€ä¸ªcontinue modelï¼Œç„¶åå°†baselineå’Œcontinueè¿›è¡Œmixï¼Œå¾—åˆ°æœ€ç»ˆçš„modelã€‚</p>
<h2 id="A-Context-aware-Attention-Network-for-Interactive-Question-Answering"><a href="#A-Context-aware-Attention-Network-for-Interactive-Question-Answering" class="headerlink" title="A Context-aware Attention Network for Interactive Question Answering"></a><a href="http://t.cn/RINpcT9" target="_blank" rel="external">A Context-aware Attention Network for Interactive Question Answering</a></h2><p>ã€äº¤äº’å¼QAã€‘æœ¬æ–‡çš„å·¥ä½œäº®ç‚¹åœ¨äºåšé—®ç­”æ—¶æä¾›äº†ä¸€ç§äº¤äº’æœºåˆ¶ï¼Œå½“answeræ¨¡å—è§‰å¾—ç°æœ‰çš„ä¿¡æ¯æ— æ³•å›ç­”questionçš„è¯ï¼Œä¼šç”Ÿæˆä¸€ä¸ªæ›´åŠ æ·±å…¥çš„é—®é¢˜ç»™ç”¨æˆ·ï¼Œé€šè¿‡å­¦ä¹ ç”¨æˆ·çš„åé¦ˆæ¥ç”Ÿæˆç­”æ¡ˆã€‚</p>
<h2 id="ä¸­æ–‡ä¿¡æ¯å¤„ç†å‘å±•æŠ¥å‘Š"><a href="#ä¸­æ–‡ä¿¡æ¯å¤„ç†å‘å±•æŠ¥å‘Š" class="headerlink" title="ä¸­æ–‡ä¿¡æ¯å¤„ç†å‘å±•æŠ¥å‘Š"></a><a href="http://t.cn/RINHLN8" target="_blank" rel="external">ä¸­æ–‡ä¿¡æ¯å¤„ç†å‘å±•æŠ¥å‘Š</a></h2><p>ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼šå‘å¸ƒ2016å¹´ã€Šä¸­æ–‡ä¿¡æ¯å¤„ç†å‘å±•æŠ¥å‘Šã€‹ï¼Œå€¼å¾—ä¸€è¯»ï¼</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-12-23T18:40:03.000Z"><a href="/2016/12/23/PaperWeekly-ç¬¬åä¹æœŸ/">2016-12-23</a></time>
      
      
  
    <h1 class="title"><a href="/2016/12/23/PaperWeekly-ç¬¬åä¹æœŸ/">PaperWeekly ç¬¬åä¹æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•"><a href="#å¼•" class="headerlink" title="å¼•"></a>å¼•</h1><p>æœ¬æœŸçš„PaperWeeklyä¸€å…±åˆ†äº«å››ç¯‡æœ€è¿‘arXivä¸Šå‘å¸ƒçš„é«˜è´¨é‡paperï¼ŒåŒ…æ‹¬ï¼šæƒ…æ„Ÿåˆ†æã€æœºå™¨é˜…è¯»ç†è§£ã€çŸ¥è¯†å›¾è°±ã€æ–‡æœ¬åˆ†ç±»ã€‚äººå·¥æ™ºèƒ½åŠå…¶ç›¸å…³ç ”ç©¶æ—¥æ–°æœˆå¼‚ï¼Œæœ¬æ–‡å°†å¸¦ç€å¤§å®¶äº†è§£ä¸€ä¸‹ä»¥ä¸Šå››ä¸ªç ”ç©¶æ–¹å‘éƒ½æœ‰å“ªäº›æœ€æ–°è¿›å±•ã€‚å››ç¯‡paperåˆ†åˆ«æ˜¯ï¼š</p>
<p>1ã€Linguistically Regularized LSTMs for Sentiment Classification, 2016.11<br>2ã€End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension, 2016.10<br>3ã€Knowledge will Propel Machine Understanding of Content: Extrapolating from Current Examples, 2016.10<br>4ã€AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text Classification, 2016.11</p>
<h1 id="Linguistically-Regularized-LSTMs-for-Sentiment-Classification"><a href="#Linguistically-Regularized-LSTMs-for-Sentiment-Classification" class="headerlink" title="Linguistically Regularized LSTMs for Sentiment Classification"></a><a href="https://arxiv.org/pdf/1611.03949v1.pdf" target="_blank" rel="external">Linguistically Regularized LSTMs for Sentiment Classification</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Qiao Qian, Minlie Huang, Xiaoyan Zhu</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>State Key Lab. of Intelligent Technology and Systems, National Lab. for Information Science and Technology, Dept. of Computer Science and Technology, Tsinghua University</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>sentiment classification, neural network models, linguistically coherent representations,</p>
<h2 id="æ–‡ç« æ¥æº"><a href="#æ–‡ç« æ¥æº" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv, 2016.11</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>åˆ©ç”¨è¯­è¨€èµ„æºå’Œç¥ç»ç½‘ç»œç›¸ç»“åˆæ¥æå‡æƒ…æ„Ÿåˆ†ç±»é—®é¢˜çš„ç²¾åº¦</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>åœ¨LSTMå’ŒBi-LSTMæ¨¡å‹çš„åŸºç¡€ä¸ŠåŠ å…¥å››ç§è§„åˆ™çº¦æŸï¼Œè¿™å››ç§è§„åˆ™åˆ†åˆ«æ˜¯: Non-Sentiment Regularizer,Sentiment Regularizer, Negation Regularizer, Intensity Regularizer.å› æ­¤ï¼Œæ–°çš„loss functionå˜ä¸º:</p>
<p><img src="media/eqn.png" alt="eqn"></p>
<p>ä¸åŒçš„è§„åˆ™çº¦æŸå¯¹åº”ä¸åŒçš„Lå‡½æ•°</p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>1ã€Movie Review (MR) <a href="https://www.cs.cornell.edu/people/pabo/movie-review-data/" target="_blank" rel="external">https://www.cs.cornell.edu/people/pabo/movie-review-data/</a><br>2ã€Stanford Sentiment Tree- bank (SST) <a href="http://nlp.stanford.edu/sentiment/treebank.html" target="_blank" rel="external">http://nlp.stanford.edu/sentiment/treebank.html</a></p>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>1ã€Neural Networks for Sentiment Classification<br><a href="https://arxiv.org/abs/1412.3555" target="_blank" rel="external">Empirical evaluation of gated recurrent neural networks on sequence modeling</a><br><a href="https://pdfs.semanticscholar.org/5807/664af8e63d5207f59fb263c9e7bd3673be79.pdf" target="_blank" rel="external">Hybrid speech recognition with deep bidirectional lstm</a><br>2ã€Applying Linguistic Knowledge for Sentiment Classification<br><a href="http://www.site.uottawa.ca/~diana/publications/ci.pdf" target="_blank" rel="external">Sentiment classification of movie reviews using contextual valence shifters</a></p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºè¯­è¨€èµ„æºçº¦æŸå’ŒLSTM/Bi-LSTMçš„æ¨¡å‹ç”¨äºæƒ…æ„Ÿåˆ†ç±»ï¼Œå¹¶é€šè¿‡åœ¨MRå’ŒSSTæ•°æ®é›†ä¸Šçš„å®éªŒå’Œå¯¹RNN/RNTN,LSTM,Tree-LSTM,CNNçš„æ•ˆæœå¯¹æ¯”è¯æ˜äº†è¿™ä¸€æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæœ¬æ–‡è¿˜åŸºäºä¸åŒçš„çº¦æŸè¿›è¡Œäº†å®éªŒï¼Œè¯æ˜çš„ä¸åŒçš„çº¦æŸåœ¨æé«˜åˆ†ç±»ç²¾åº¦ä¸Šçš„ä½œç”¨ã€‚æœ¬æ–‡å®éªŒä¸°å¯Œï¼Œæ•ˆæœçš„æå‡è™½ä¸æ˜¾è‘—ï¼Œä½†æ–°çš„æ¨¡å‹ç¡®å®åœ¨ä¸åŒç¨‹åº¦ä¸Šå…‹æœäº†æ—§æ¨¡å‹çš„ä¸€äº›ä¸è¶³ã€‚</p>
<h1 id="End-to-End-Answer-Chunk-Extraction-and-Ranking-for-Reading-Comprehension"><a href="#End-to-End-Answer-Chunk-Extraction-and-Ranking-for-Reading-Comprehension" class="headerlink" title="End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension"></a><a href="https://arxiv.org/pdf/1610.09996v2.pdf" target="_blank" rel="external">End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Yang Yu, Wei Zhang, Kazi Hasan, Mo Yu, Bing Xiang, Bowen Zhou</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>IBM Watson</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Reading Comprehension, Chunk extraction, Ranking</p>
<h2 id="æ–‡ç« æ¥æº-1"><a href="#æ–‡ç« æ¥æº-1" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv, 2016.10</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>é’ˆå¯¹ç­”æ¡ˆéå®šé•¿çš„é˜…è¯»ç†è§£ä»»åŠ¡ï¼Œæœ¬æ–‡æå‡ºäº†DCRï¼ˆdynamic chunk readerï¼‰æ¨¡å‹<br>æ¥ä»ç»™å®šçš„æ–‡æ¡£ä¸­æŠ½å–å¯èƒ½çš„å€™é€‰ç­”æ¡ˆå¹¶è¿›è¡Œæ’åºã€‚</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æœ¬æ–‡æå‡ºçš„æ¨¡å‹ç»“æ„å…±åˆ†ä¸ºå››éƒ¨åˆ†ï¼Œ<br>1ã€Encoder Layer<br>å¦‚å›¾æ‰€ç¤ºï¼Œè¿™éƒ¨åˆ†æ˜¯ç”¨åŒå‘GRUåˆ†åˆ«å¯¹æ–‡æ¡£ï¼ˆPassageï¼‰å’Œé—®é¢˜ï¼ˆQuestionï¼‰è¿›è¡Œç¼–ç ã€‚<br>2ã€Attention Layer<br>è¯¥å±‚é‡‡ç”¨çš„æ–¹æ³•ä¸ç›¸å…³å·¥ä½œä¸­çš„mLSTMç±»ä¼¼ï¼Œæ–‡æ¡£æ¯ä¸ªæ—¶åˆ»çš„çŠ¶æ€h<sub>j</sub><sup>p</sup>éƒ½ä¸é—®é¢˜ä¸­çš„æ¯ä¸ªçŠ¶æ€h<sub>k</sub><sup>q</sup>è¿›è¡ŒåŒ¹é…å¾—åˆ°ä¸€ä¸ªæƒé‡å‘é‡Î±<sub>k</sub>ï¼Œç„¶åå†æ ¹æ®è¯¥æƒé‡å‘é‡å¯¹é—®é¢˜çš„GRUéšå±‚è¾“å‡ºh<sup>p</sup>è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°æ–‡æ¡£ä¸­è¯¥æ—¶åˆ»çŠ¶æ€h<sub>j</sub><sup>p</sup>å¯¹åº”çš„ä¸Šä¸‹æ–‡å‘é‡Î²<sub>j</sub>ï¼Œä¸¤ä¸ªå‘é‡h<sub>j</sub><sup>p</sup>å’ŒÎ²<sub>j</sub>æ‹¼æ¥åœ¨ä¸€èµ·ä½œä¸ºè¯¥æ—¶åˆ»æ–°çš„è¡¨ç¤ºv<sub>j</sub>ã€‚æœ€åå†å°†ä¸Šè¿°ä¸é—®é¢˜ç›¸å…³çš„æ–°æ–‡æ¡£è¡¨ç¤ºvé€šè¿‡åŒå‘GRUï¼Œå¾—åˆ°æ–‡æ¡£æœ€ç»ˆçš„è¡¨ç¤ºÎ³ã€‚<br><img src="media/DCR.png" alt="DC"></p>
<p>3ã€Chunk-Representation Layer<br>ä¸Šä¸€éƒ¨åˆ†è·å¾—äº†ä¸é—®é¢˜ç›¸å…³çš„æ–‡æ¡£è¡¨ç¤ºÎ³ï¼Œé‚£ä¹ˆè¿™éƒ¨åˆ†åˆ™æ˜¯è€ƒè™‘å¦‚ä½•æŠ½å–å€™é€‰ç­”æ¡ˆï¼Œå¹¶è·å¾—å€™é€‰ç­”æ¡ˆçš„è¡¨ç¤ºå‘é‡ã€‚æœ¬æ–‡æå‡ºäº†ä¸¤ç§å€™é€‰ç­”æ¡ˆæŠ½å–æ–¹æ³•ï¼Œç¬¬ä¸€ç§æ–¹æ³•æ˜¯æŠ½å–æ‰€æœ‰æ»¡è¶³è®­ç»ƒæ•°æ®ä¸­ç­”æ¡ˆå¯¹åº”è¯æ€§æ ‡æ³¨æ¨¡å¼çš„å€™é€‰é¡¹ï¼Œç¬¬äºŒç§æ–¹æ³•åˆ™æ˜¯ç®€å•ç²—æš´åœ°ç¡®å®šä¸€ä¸ªå€™é€‰é¡¹æœ€å¤§é•¿åº¦ï¼Œç„¶åéå†æ‰€æœ‰å¯èƒ½çš„å€™é€‰é¡¹ã€‚è‡³äºå€™é€‰ç­”æ¡ˆçš„è¡¨ç¤ºæ–¹å¼ï¼Œæœ¬æ–‡å°†å€™é€‰ç­”æ¡ˆå‰å‘GRUçš„æœ€åä¸€ä¸ªæ—¶åˆ»çŠ¶æ€å’Œåå‘GRUç¬¬ä¸€ä¸ªæ—¶åˆ»çŠ¶æ€æ‹¼æ¥åœ¨ä¸€èµ·ä½œä¸ºæœ€ç»ˆå€™é€‰é¡¹çš„è¡¨ç¤ºã€‚<br>4ã€Ranker Layer<br>å·²ç»è·å¾—äº†æ‰€æœ‰å€™é€‰é¡¹çš„è¡¨ç¤ºï¼Œé‚£ä¹ˆæ¥ç€å°±æ˜¯å¯¹æ‰€æœ‰å€™é€‰é¡¹è¿›è¡Œæ‰“åˆ†æ’åºã€‚æœ¬æ–‡ä¸­æ‰“åˆ†æ˜¯é‡‡ç”¨é—®é¢˜çš„è¡¨ç¤ºå’Œå€™é€‰é¡¹çš„è¡¨ç¤ºè®¡ç®—å†…ç§¯çš„æ–¹å¼å¾—åˆ°çš„ï¼Œæœ¬æ–‡è®­ç»ƒè¿‡ç¨‹ä¸­æ²¡æœ‰é‡‡ç”¨å¸¸è§äºæ’åºä»»åŠ¡çš„Margin ranking lossï¼Œè€Œæ˜¯å…ˆç”¨softmaxå¯¹æ‰€æœ‰å€™é€‰é¡¹è®¡ç®—ä¸€ä¸ªæ¦‚ç‡å€¼ï¼Œç„¶åé‡‡ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒã€‚</p>
<p>æœ¬æ–‡åœ¨SQuADæ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒï¼Œæå‡ºçš„æ–¹æ³•æ•ˆæœæ¯”ä¹‹å‰ä¸¤ç¯‡SQuADç›¸å…³paperçš„æ–¹æ³•æœ‰è¾ƒå¤§çš„æå‡ã€‚</p>
<h2 id="èµ„æº-1"><a href="#èµ„æº-1" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>1ã€SQuAD <a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank" rel="external">https://rajpurkar.github.io/SQuAD-explorer/</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-1"><a href="#ç›¸å…³å·¥ä½œ-1" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>1ã€æ•°æ®é›†ç›¸å…³è®ºæ–‡<br>SQuAD: 100,000+ Questions for Machine Comprehension of Text<br>2ã€æ¨¡å‹ç›¸å…³è®ºæ–‡<br>MACHINE COMPREHENSION USING MATCH-LSTM</p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>åœ¨å¯¹æ–‡æ¡£å’Œé—®é¢˜ç¼–ç é˜¶æ®µï¼Œæœ¬ç¯‡è®ºæ–‡æå‡ºçš„æ¨¡å‹ä¸ä¹‹å‰mLSTMé‚£ç¯‡paperæœ‰äº›ç›¸ä¼¼ã€‚ä¸¤ç¯‡è®ºæ–‡ä¸­æ¨¡å‹çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼šmLSTMé‚£ç¯‡è®ºæ–‡é‡‡ç”¨é¢„æµ‹èµ·å§‹ã€ç»ˆæ­¢ä½ç½®çš„æ–¹æ³•æ¥ç¡®å®šç­”æ¡ˆï¼Œè€Œæœ¬æ–‡åˆ™æ˜¯å…ˆé‡‡ç”¨ä¸€äº›è§„åˆ™æˆ–Patternçš„æ–¹æ³•æ¥æŠ½å–ä¸€äº›å€™é€‰ç­”æ¡ˆï¼Œç„¶åå†å¯¹å€™é€‰ç­”æ¡ˆè¿›è¡Œæ’åºã€‚</p>
<h2 id="è”ç³»æ–¹å¼"><a href="#è”ç³»æ–¹å¼" class="headerlink" title="è”ç³»æ–¹å¼"></a>è”ç³»æ–¹å¼</h2><p>æœ‰DLæˆ–è€…NLPç›¸å…³è¯é¢˜ï¼Œæ¬¢è¿è®¨è®ºã€‚destin.bxwang@gmail.com </p>
<h1 id="Knowledge-will-Propel-Machine-Understanding-of-Content-Extrapolating-from-Current-Examples"><a href="#Knowledge-will-Propel-Machine-Understanding-of-Content-Extrapolating-from-Current-Examples" class="headerlink" title="Knowledge will Propel Machine Understanding of Content: Extrapolating from Current Examples"></a><a href="https://arxiv.org/abs/1610.07708?from=groupmessage&amp;isappinstalled=0" target="_blank" rel="external">Knowledge will Propel Machine Understanding of Content: Extrapolating from Current Examples</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Amit Sheth, Sujan Perera, and Sanjaya Wijeratne</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Kno.e.sis Center, Wright State University Dayton, Ohio, USA</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Semantic analysis of multimodal dataï¼ŒMachine intelligence,Understanding complex textï¼ŒEmojiNet</p>
<h2 id="æ–‡ç« æ¥æº-2"><a href="#æ–‡ç« æ¥æº-2" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv, 2016.10</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>åˆ©ç”¨çŸ¥è¯†å’Œå¤šæ¨¡æ€æ•°æ®æ¥è§£å†³ç‰¹å®šæƒ…å†µä¸‹çš„å¤æ‚æ–‡æœ¬çš„æ·±å±‚ç†è§£é—®é¢˜</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>1ã€ç°çŸ¥è¯†åº“åœ¨å¤„ç†ç‰¹å®šé¢†åŸŸé—®é¢˜ä¸­çš„å±€é™æ€§åŠè§£å†³æ–¹æ³•<br>ï¼ˆ1ï¼‰çŸ¥è¯†åº“çš„æ‚ä¹±<br>è§£å†³æ–¹æ³•ï¼šé‡‡ç”¨è‡ªåŠ¨åˆ¤åˆ«æŠ€æœ¯ï¼Œé¢†åŸŸçŸ¥è¯†åº“ç´¢å¼•æŠ€æœ¯ï¼Œåˆ©ç”¨å®ä½“å’Œå…³ç³»çš„è¯­ä¹‰å»åˆ¤åˆ«æ‰€ç»™å®šçŸ¥è¯†åº“é¢†åŸŸä¸­çš„ç›¸å…³éƒ¨åˆ†ã€‚<br>ï¼ˆ2ï¼‰çŸ¥è¯†åº“æ•°æ®çš„ä¸å®Œå¤‡å’Œä¸å……è¶³<br>è§£å†³æ–¹æ³•ï¼šä½¿ç”¨ human-in-the-loopæ¨¡å‹åœ¨çœŸå®çš„ä¸´åºŠæ•°æ®å’Œå·²æœ‰çš„çŸ¥è¯†åº“ä¸­å»å‘ç°æ›´å¤šçš„å®ä½“ä¸å®ä½“ä¹‹é—´çš„å…³ç³»ã€‚<br>ï¼ˆ3ï¼‰çŸ¥è¯†è¡¨ç¤ºæŠ€æœ¯å’Œæ¨ç†æŠ€æœ¯çš„å±€é™æ€§<br>è§£å†³æ–¹æ³•ï¼šåœ¨å•ä¸ªå±æ€§çš„è¡¨ç¤ºä¸­åŠ å…¥äº†ä¸‰å…ƒç»„å’Œè½¯é€»è¾‘çš„è§£é‡Šèƒ½åŠ›åŠå…¶ç›¸å…³æ¦‚ç‡å€¼å’Œç†ç”±ã€‚</p>
<p>2ã€æ–°çš„ç ”ç©¶åº”ç”¨<br>ï¼ˆ1ï¼‰éšå®ä½“é“¾æ¥<br>ï¼ˆ2ï¼‰è¡¨æƒ…ç¬¦å·è¯­ä¹‰æ¶ˆæ­§<br>ï¼ˆ3ï¼‰ç†è§£å’Œåˆ†æwebè®ºå›ä¸­å…³äºè¯ç‰©æ»¥ç”¨çš„ç›¸å…³è®¨è®º<br>åˆ©ç”¨ç›¸å…³èƒŒæ™¯çŸ¥è¯†åŠ å¼ºä¸åŒç§ç±»ä¿¡æ¯çš„ä¿¡æ¯æŠ½å–æ¨¡å‹<br><img src="media/img1.png" alt="img1"></p>
<p>3ã€åœ¨å¥åº·é¢†åŸŸä¸­çš„æ–‡æœ¬ç†è§£æ¨¡å‹<br><img src="media/img2.png" alt="img2"></p>
<p>4ã€ä½¿ç”¨æ„ŸçŸ¥å™¨å’Œæ–‡æœ¬èµ„æ–™äº†è§£åŸå¸‚äº¤é€šæƒ…å†µ<br>(1)äº¤é€šé¢†åŸŸçš„æ¦‚å¿µå…³ç³»ç½‘æ¨¡å‹<br>(2)æ¦‚ç‡å›¾æ¨¡å‹<br><img src="media/img3.png" alt="img3"></p>
<p>ä½¿ç”¨é¢†åŸŸçŸ¥è¯†å…³è”ä¸åŒæ¨¡æ€ä¸‹çš„ä¸Šä¸‹æ–‡ç›¸å…³æ•°æ®<br><img src="media/img4.png" alt="img4"></p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡ä¸»è¦ä¸¾ä¾‹è¯´æ˜äº†çŸ¥è¯†å°†æ¨åŠ¨æœºå™¨å¯¹å†…å®¹çš„ç†è§£ã€‚æ€»ä½“æ¥çœ‹æœ¬æ–‡åƒä¸€ç¯‡ç»¼è¿°æ€§çš„æ–‡ç« ï¼Œç»™å‡ºäº†åœ¨çŸ¥è¯†åº“åˆ›å»ºè¿‡ç¨‹ä¸­æ‰€é‡åˆ°çš„é—®é¢˜çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒæ—¶ä»¥å®é™…æ¡ˆä¾‹æ¥é˜è¿°çŸ¥è¯†åœ¨æˆ‘ä»¬å®é™…é—®é¢˜ä¸­åº”ç”¨ã€‚</p>
<h1 id="AC-BLSTM-Asymmetric-Convolutional-Bidirectional-LSTM-Networks-for-Text-Classification"><a href="#AC-BLSTM-Asymmetric-Convolutional-Bidirectional-LSTM-Networks-for-Text-Classification" class="headerlink" title="AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text Classification"></a><a href="https://arxiv.org/pdf/1611.01884v2.pdf" target="_blank" rel="external">AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text Classification</a></h1><h2 id="ä½œè€…-3"><a href="#ä½œè€…-3" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Depeng Liang and Yongdong Zhang</p>
<h2 id="å•ä½-3"><a href="#å•ä½-3" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Guangdong Province Key Laboratory of Computational Science, School of Data and<br>Computer Science, Sun Yat-sen University, Guang Zhou, China</p>
<h2 id="å…³é”®è¯-3"><a href="#å…³é”®è¯-3" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>ACNN; BLSTM; Text Classification</p>
<h2 id="æ–‡ç« æ¥æº-3"><a href="#æ–‡ç« æ¥æº-3" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv, 2016.11</p>
<h2 id="é—®é¢˜-3"><a href="#é—®é¢˜-3" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„æ·±åº¦å­¦ä¹ çš„æ¨¡å‹â€“AC-BLSTMçš„æ¨¡å‹ï¼ˆå³ï¼šå°†ACNNå’ŒBLSTMç»„åˆåœ¨ä¸€èµ·ï¼‰ï¼Œç”¨äºå¥å­å’Œæ–‡ç« å±‚é¢çš„åˆ†ç±»ã€‚</p>
<h2 id="æ¨¡å‹-3"><a href="#æ¨¡å‹-3" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>AC-BLSTMæ¨¡å‹å¯ä»¥åˆ†æˆå››ä¸ªéƒ¨åˆ†,å¦‚Figure 1æ‰€ç¤ºï¼š<br>1.è¾“å…¥: è¾“å…¥æ˜¯ä¸€ä¸ªsentenceï¼Œä½¿ç”¨ ( L <em> d )çš„çŸ©é˜µè¡¨ç¤ºï¼Œå…¶ä¸­Lè¡¨ç¤ºå¥å­ä¸­çš„Lä¸ªè¯ï¼Œdè¡¨ç¤ºæ¯ä¸ªè¯çš„è¯å‘é‡çš„ç»´åº¦<br>2.ACNN(Asymmetric CNN): ä¼ ç»Ÿçš„CNNé‡‡ç”¨çš„æ˜¯ ( k </em> d ) å¤§å°çš„filterï¼ŒACNNåˆ™æŠŠfilterçš„è¿‡ç¨‹åˆ†æˆ ( 1 <em> d ) å’Œ ( k </em> 1 ) çš„ä¸¤ä¸ªè¿‡ç¨‹ï¼Œç›¸å½“äºæ˜¯æŠŠ ( k <em> d ) çš„filteråšå› å¼åˆ†è§£ã€‚<br>è¿™ä¸€å±‚çš„è¾“å…¥æ˜¯ä¸€ä¸ª ( L </em> d ) çš„çŸ©é˜µï¼Œå¯¹äºnä¸ªå°ºåº¦ä¸º( 1 <em> d ) å’Œ( ki </em> 1 )çš„å·ç§¯å±‚çš„è¾“å‡ºæ˜¯ä¸€ä¸ª [ (L - ki + 1) <em> n ]çš„çŸ©é˜µï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæœ¬æ–‡é‡‡ç”¨äº†3ç§ä¸åŒçš„å·ç§¯æ ¸ï¼Œæ‰€ä»¥è¾“å‡ºæ˜¯3ç§ä¸åŒçš„[ (L - ki + 1) </em> n ]çš„çŸ©é˜µï¼ˆå›¾ä¸­ä¸€ä¸ªå½©è‰²çš„å°æ–¹å—è¡¨ç¤º (1 * n)çš„å‘é‡ï¼‰<br>3.è¿æ¥å±‚: ä¸ºäº†ç»™BLSTMæ„é€ è¾“å…¥ï¼Œè¿æ¥å±‚å°†3ç§ä¸åŒå·ç§¯å±‚çš„è¾“å‡ºï¼Œä»¥Ct^iè¡¨ç¤ºç¬¬1ç§å·ç§¯å±‚ä¸ºLSTMç¬¬tä¸ªtime stepè´¡çŒ®çš„è¾“å…¥ï¼Œåˆ™LSTMç½‘ç»œçš„ç¬¬tæ­¥è¾“å…¥Ct = [Ct^1, Ct^2, Ct^3]ï¼Œå…¶ä¸­tå±äº{1,2,â€¦,L-K+1}, K = max{ki}<br>4.BLSTM: LSTMèƒ½å¤Ÿå¾ˆå¥½çš„è§£å†³long time delay å’Œlong range contextçš„é—®é¢˜ï¼Œä½†å…¶å¤„ç†æ˜¯å•å‘çš„ï¼Œè€ŒBLSTMèƒ½å¤Ÿè§£å†³given pointçš„åŒè¾¹çš„ä¾èµ–å…³ç³»ï¼Œå› æ­¤ï¼Œæœ¬æ–‡é€‰æ‹©äº†BLSTMç½‘ç»œå±‚æ¥å­¦ä¹ ACNNè¾“å…¥çš„ç‰¹å¾çš„dependencies<br>5.Softmaxå±‚: ä¸ºäº†åº”ç”¨äºåˆ†ç±»é—®é¢˜ï¼Œæœ¬æ–‡åœ¨æœ€åä½¿ç”¨å…¨è¿æ¥å±‚å’Œsoftmaxå‡½æ•°æ¥å®ç°åˆ†ç±»ã€‚<br><img src="media/Figure1.jpg" alt="Figure1"></p>
<h2 id="èµ„æº-2"><a href="#èµ„æº-2" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æ–‡ç« ä¸­ä½¿ç”¨çš„æ•°æ®é›†<br>1ã€SST-1 <a href="http://nlp.stanford.edu/sentiment/index.html" target="_blank" rel="external">http://nlp.stanford.edu/sentiment/index.html</a><br>2ã€SST-2 <a href="http://nlp.stanford.edu/sentiment/index.html" target="_blank" rel="external">http://nlp.stanford.edu/sentiment/index.html</a><br>3ã€Movie Review(MR) <a href="https://www.cs.cornell.edu/people/pabo/movie-review-data/" target="_blank" rel="external">https://www.cs.cornell.edu/people/pabo/movie-review-data/</a><br>4ã€SUBJ <a href="https://www.cs.cornell.edu/people/pabo/movie-review-data/" target="_blank" rel="external">https://www.cs.cornell.edu/people/pabo/movie-review-data/</a><br>5ã€TREC <a href="http://cogcomp.cs.illinois.edu/Data/QA/QC/" target="_blank" rel="external">http://cogcomp.cs.illinois.edu/Data/QA/QC/</a><br>6ã€YELP13 <a href="https://www.yelp.com/dataset_challenge" target="_blank" rel="external">https://www.yelp.com/dataset_challenge</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-2"><a href="#ç›¸å…³å·¥ä½œ-2" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>1ã€Yoon Kimäº2014å¹´åœ¨<a href="http://www.aclweb.org/anthology/D14-1181" target="_blank" rel="external"><strong>Convolutional neural networks for sentence classification</strong></a>ä¸€æ–‡ä¸­æå‡ºå°†è¯å‘é‡å’ŒCNNç»“åˆï¼Œç”¨äºå¥å­åˆ†ç±»çš„æ¨¡å‹ã€‚åœ¨è¯¥æ–‡ä¸­ï¼ŒKimå°†ä¸åŒé•¿åº¦çš„filterçš„ç»„åˆåœ¨ä¸€èµ·ï¼Œä¸”æå‡ºäº†staticæˆ–è€…å¯ä»¥fine-tuningçš„word embeddingæ¨¡å‹<br>2ã€Zhou et al.åˆ™äº2015å¹´åœ¨<a href="https://arxiv.org/abs/1511.08630" target="_blank" rel="external"><strong>A C-LSTM neural network for text classification</strong></a>ä¸€æ–‡ä¸­æå‡ºå°†CNNå’ŒLSTMå åŠ çš„æ¨¡å‹ï¼Œä¸”ä½¿ç”¨å›ºå®šçš„word embedding<br>3ã€Szegedy et al.äº2015å¹´åœ¨<a href="https://arxiv.org/pdf/1512.00567v3.pdf" target="_blank" rel="external"><strong>Rethinking the Inception Architecture for Computer Vision</strong></a>ä¸­æå‡ºäº†ACNNæ¨¡å‹ï¼Œè¿™å‡å°‘äº†å‚æ•°çš„ä¸ªæ•°ä¸”æé«˜äº†æ¨¡å‹çš„è¡¨å¾</p>
<h2 id="ç®€è¯„-3"><a href="#ç®€è¯„-3" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¿™ç¯‡æ–‡ç« ä¸»è¦è´¡çŒ®å°±æ˜¯æå‡ºäº†ä¸€ä¸ªAC-BSLTMçš„æ¨¡å‹ç”¨äºæ–‡æœ¬åˆ†ç±»ï¼Œäº®ç‚¹å°±åœ¨äºï¼šACNNå¯ä»¥åœ¨å‡å°‘å‚æ•°çš„ä¸ªæ•°çš„åŒæ—¶é€šè¿‡å¢åŠ æ›´å¤šçš„éçº¿æ€§æ€§æ¥æé«˜è¡¨è¾¾èƒ½åŠ›ï¼Œè€ŒBLSTMèƒ½å¤Ÿæ•æ‰è¾“å…¥çš„ä¸¤ç«¯çš„ä¿¡æ¯ã€‚ä¸¤è€…çš„ç»“åˆå°±æé«˜äº†åˆ†ç±»çš„ç²¾åº¦ã€‚ä½†äº‹å®ä¸Šï¼Œè¿™ä¸¤ä¸ªç½‘ç»œæ¨¡å‹éƒ½æ˜¯ç°æœ‰çš„ï¼Œæœ¬æ–‡çš„å·¥ä½œæ„Ÿè§‰åªæ˜¯ä¸¤ä¸ªç½‘ç»œçš„è¿æ¥ï¼Œåœ¨æœ¬è´¨ä¸Šæ²¡æœ‰å¤ªå¤§çš„æ”¹è¿›ï¼Œä¸”åœ¨åˆ†ç±»ç²¾åº¦ä¸Šçš„æé«˜ä¹Ÿæ¯”è¾ƒæœ‰é™ã€‚</p>
<h1 id="è‡´è°¢"><a href="#è‡´è°¢" class="headerlink" title="è‡´è°¢"></a>è‡´è°¢</h1><p>æ„Ÿè°¢@æ–¹å˜‰å€© @destin wang å’Œ @min279 ä¸‰ä½ç«¥é‹çš„è¾›å‹¤å·¥ä½œã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-12-18T17:16:11.000Z"><a href="/2016/12/18/æœ¬å‘¨å€¼å¾—è¯»-2016-12-12-2016-12-16/">2016-12-18</a></time>
      
      
  
    <h1 class="title"><a href="/2016/12/18/æœ¬å‘¨å€¼å¾—è¯»-2016-12-12-2016-12-16/">æœ¬å‘¨å€¼å¾—è¯»(2016.12.12-2016.12.16)</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="Building-Large-Machine-Reading-Comprehension-Datasets-using-Paragraph-Vectors"><a href="#Building-Large-Machine-Reading-Comprehension-Datasets-using-Paragraph-Vectors" class="headerlink" title="Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors "></a><a href="http://t.cn/RIbpc9X" target="_blank" rel="external">Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors </a></h2><p>ã€æœºå™¨é˜…è¯»ç†è§£ã€‘ã€æ•°æ®ç¦åˆ©ã€‘<br>æœ¬æ–‡åˆ©ç”¨ä¸€ç§æ— ç›‘ç£çš„æ–¹æ³•æ„å»ºäº†ä¸€ç»„å¤§å‹çš„æœºå™¨é˜…è¯»ç†è§£æ•°æ®é›†ã€‚å…¶ä¸­æœºå™¨é˜…è¯»ç†è§£é—®é¢˜æ˜¯æä¾›ä¸€ç¯‡æ–°é—»ï¼Œä»5ä¸ªå€™é€‰æ ‡é¢˜ä¸­é€‰æ‹©ä¸€ä¸ªæ­£ç¡®çš„ã€‚æ— ç›‘ç£çš„æ–¹æ³•ç”¨äº†Mikolovæå‡ºçš„Paragraph Vectorï¼ˆWord2Vecçš„æ–‡æ¡£ç‰ˆï¼‰ï¼Œç”¨æ¥è®­ç»ƒå’Œè®¡ç®—å„ä¸ªæ–°é—»æ ‡é¢˜ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œäº§ç”Ÿå€™é€‰ç­”æ¡ˆã€‚æœ¬æ–‡æ‰€ç”Ÿæˆçš„æ•°æ®é›†åœ°å€ï¼š<a href="https://github.com/google/mcafp" target="_blank" rel="external">https://github.com/google/mcafp</a></p>
<h2 id="Multi-Perspective-Context-Matching-for-Machine-Comprehension"><a href="#Multi-Perspective-Context-Matching-for-Machine-Comprehension" class="headerlink" title="Multi-Perspective Context Matching for Machine Comprehension "></a><a href="http://t.cn/RIbdvXM" target="_blank" rel="external">Multi-Perspective Context Matching for Machine Comprehension </a></h2><p>ã€æœºå™¨é˜…è¯»ç†è§£ã€‘æœ¬æ–‡çš„ç ”ç©¶åŸºäºSQuADæ•°æ®é›†ï¼Œæå‡ºäº†ä¸€ä¸ªç«¯åˆ°ç«¯è®­ç»ƒæ¨¡å‹ï¼Œä¸»è¦çš„æ€è·¯æ˜¯passageä¸­ä¸é—®é¢˜ç›¸ä¼¼çš„spanæ›´åŠ å€¾å‘äºæ˜¯æ­£ç¡®ç­”æ¡ˆã€‚SQuADæ˜¯è¿™ä¸ªé¢†åŸŸä¸­æœ‰åçš„æ•°æ®é›†ï¼Œç›¸åº”çš„æ¨¡å‹å¾ˆå¤šï¼Œæœ¬æ–‡çš„ç»“æœç›¸å¯¹ä¸€èˆ¬ã€‚</p>
<h2 id="ConceptNet-5-5-An-Open-Multilingual-Graph-of-General-Knowledge"><a href="#ConceptNet-5-5-An-Open-Multilingual-Graph-of-General-Knowledge" class="headerlink" title="ConceptNet 5.5: An Open Multilingual Graph of General Knowledge "></a><a href="http://t.cn/RIbgeA5" target="_blank" rel="external">ConceptNet 5.5: An Open Multilingual Graph of General Knowledge </a></h2><p>ã€çŸ¥è¯†å›¾è°±ã€‘ã€èµ„æºæ¨èã€‘æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªé€šç”¨çŸ¥è¯†å›¾è°±ConceptNet 5.5ï¼Œå›¾è°±ä¸»é¡µçš„åœ°å€ï¼š<a href="http://conceptnet.io/" target="_blank" rel="external">http://conceptnet.io/</a>  ç›¸å…³çš„codeå’Œæ–‡æ¡£åœ°å€ï¼š <a href="https://github.com/commonsense/conceptnet5" target="_blank" rel="external">https://github.com/commonsense/conceptnet5</a></p>
<h2 id="Tracking-the-World-State-with-Recurrent-Entity-Networks"><a href="#Tracking-the-World-State-with-Recurrent-Entity-Networks" class="headerlink" title="Tracking the World State with Recurrent Entity Networks "></a><a href="http://t.cn/RIbsLuo" target="_blank" rel="external">Tracking the World State with Recurrent Entity Networks </a></h2><p>ã€Dynamic Memoryã€‘æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„æ¨¡å‹ï¼ŒRecurrent Entity Network (EntNet)ï¼Œå¼•ç”¨å¤–éƒ¨åŠ¨æ€é•¿ç¨‹è®°å¿†æ¥åšæ¨ç†ï¼Œå¹¶åœ¨ SYNTHETIC WORLD MODELã€bAbIå’ŒCBTä¸‰ä¸ªä»»åŠ¡ä¸Šå¾—åˆ°äº†éªŒè¯ï¼Œå€¼å¾—å…³æ³¨ã€‚æœ¬æ–‡å·¥ä½œæ¥è‡ªFB LeCunç»„ã€‚</p>
<h2 id="Online-Sequence-to-Sequence-Reinforcement-Learning-for-Open-Domain-Conversational-Agents"><a href="#Online-Sequence-to-Sequence-Reinforcement-Learning-for-Open-Domain-Conversational-Agents" class="headerlink" title="Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents "></a><a href="http://t.cn/RIbsrka" target="_blank" rel="external">Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents </a></h2><p>ã€å¯¹è¯ç³»ç»Ÿã€‘ç”¨å‡ ä¸ªå…³é”®è¯æ¥æ¦‚æ‹¬ä¸€ä¸‹æœ¬æ–‡çš„å·¥ä½œï¼š1ã€åœ¨çº¿è®­ç»ƒï¼›2ã€seq2seqï¼›3ã€æ·±åº¦å¢å¼ºå­¦ä¹ ï¼›4ã€å¼€æ”¾åŸŸé—®é¢˜ã€‚å»ºè®®å¯¹å¯¹è¯ç³»ç»Ÿæ„Ÿå…´è¶£çš„ç«¥é‹ç ”è¯»ã€‚</p>
<h2 id="Neural-Emoji-Recommendation-in-Dialogue-Systems"><a href="#Neural-Emoji-Recommendation-in-Dialogue-Systems" class="headerlink" title="Neural Emoji Recommendation in Dialogue Systems "></a><a href="http://t.cn/RIqZTsq" target="_blank" rel="external">Neural Emoji Recommendation in Dialogue Systems </a></h2><p>ã€å¯¹è¯ç³»ç»Ÿã€‘ã€Emojiã€‘Emojiè¡¨æƒ…æ˜¯å¤§å®¶åœ¨å¹³æ—¶èŠå¤©æ—¶ç»å¸¸ä¼šç”¨åˆ°çš„ï¼Œå¾€å¾€ä¸€ä¸ªè¡¨æƒ…èƒœè¿‡ä¸€å¥è¯çš„è¡¨è¾¾ã€‚æœ¬æ–‡ç ”ç©¶äº†åœ¨å¤šè½®å¯¹è¯ä¸­å¦‚ä½•é€šè¿‡ä¸Šä¸‹æ–‡æ¥é¢„æµ‹å’Œæ¨èemojiè¡¨æƒ…ï¼Œæ˜¯ä¸ªå¾ˆå¥½ç©çš„å·¥ä½œã€‚å¦‚æœèƒ½å¤Ÿåˆ†æå’Œé¢„æµ‹æ›´å¹¿æ³›çš„è¡¨æƒ…åŒ…ï¼ˆä¸ä»…é™äºemojiï¼‰çš„è¯ï¼Œå¯èƒ½æ˜¯ä»¶æ›´å¥½ç©çš„äº‹æƒ…ã€‚</p>
<h2 id="Learning-Through-Dialogue-Interactions"><a href="#Learning-Through-Dialogue-Interactions" class="headerlink" title="Learning Through Dialogue Interactions "></a><a href="http://t.cn/RI5dgWk" target="_blank" rel="external">Learning Through Dialogue Interactions </a></h2><p>ã€å¯¹è¯ç³»ç»Ÿã€‘Jiwei Liçš„æ–°æ–‡ç« ï¼Œé€šè¿‡å’ŒTeacherçš„äº¤äº’ï¼ˆåŸºäºçŸ¥è¯†åº“ç›¸äº’é—®å’Œç­”ï¼‰æ¥æé«˜botçš„å­¦ä¹ èƒ½åŠ›ï¼Œæ•´ä½“æ¡†æ¶ä»æ˜¯å¢å¼ºå­¦ä¹ ï¼Œå€¼å¾—ç²¾è¯»ã€‚ä»£ç å’Œæ•°æ®éƒ½å·²å¼€æ”¾ï¼Œåœ°å€ï¼š<a href="https://github.com/facebook/MemNN/tree/master/AskingQuestions" target="_blank" rel="external">https://github.com/facebook/MemNN/tree/master/AskingQuestions</a> torchå®ç°ã€‚</p>
<h2 id="Diverse-Beam-Search-Decoding-Diverse-Solutions-from-Neural-Sequence-Models"><a href="#Diverse-Beam-Search-Decoding-Diverse-Solutions-from-Neural-Sequence-Models" class="headerlink" title="Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models "></a><a href="http://t.cn/RVbp10D" target="_blank" rel="external">Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models </a></h2><p>ã€seq2seqå¤šæ ·æ€§ã€‘ã€æŸ±æœç´¢ã€‘ä¸€ç¯‡è€ƒè™‘äº†ç”Ÿæˆå†…å®¹å¤šæ ·æ€§çš„beam searchæ”¹è¿›ç®—æ³•ï¼Œå¯ä»¥åº”ç”¨åœ¨chatbotã€nmtã€image captionã€vqaç­‰å„ç§åœºæ™¯ä¸­ã€‚å¼€æºä»£ç ç”¨torchå®ç°çš„ï¼ŒåŸºäºneuraltalk2ä»£ç ã€‚åœ°å€ï¼š<a href="https://github.com/ashwinkalyan/dbs" target="_blank" rel="external">https://github.com/ashwinkalyan/dbs</a>  åœ¨çº¿demoåœ°å€ï¼š<a href="http://dbs.cloudcv.org/captioning" target="_blank" rel="external">http://dbs.cloudcv.org/captioning</a></p>
<h2 id="Multilingual-Word-Embeddings-using-Multigraphs"><a href="#Multilingual-Word-Embeddings-using-Multigraphs" class="headerlink" title="Multilingual Word Embeddings using Multigraphs "></a><a href="http://t.cn/RIqqODu" target="_blank" rel="external">Multilingual Word Embeddings using Multigraphs </a></h2><p>ã€è¯å‘é‡ã€‘æœ¬æ–‡ç»™äº†ä¸€ç»„å•è¯­å’Œå¤šè¯­çš„è¯å‘é‡å­¦ä¹ æ–¹æ³•ï¼ŒåŸºäºSkipGramæ¨¡å‹ï¼Œskipgramçš„contextè€ƒè™‘æ¯”è¾ƒç®€å•ï¼Œæœ¬æ–‡ä¸»è¦æ˜¯åœ¨contextä¸Šåšäº†ä¸€äº›æ–‡ç« ï¼Œæ·»åŠ äº†ä¸€äº›ç‰¹å¾ï¼Œæ¯”å¦‚syntactic dependencies and word alignmentsç­‰ã€‚</p>
<h2 id="FastText-zip-Compressing-text-classification-models"><a href="#FastText-zip-Compressing-text-classification-models" class="headerlink" title="FastText.zip: Compressing text classification models "></a><a href="http://t.cn/RI4uuHE" target="_blank" rel="external">FastText.zip: Compressing text classification models </a></h2><p>ã€æ¨¡å‹å‹ç¼©ã€‘æ¨¡å‹è¿‡å¤§æ˜¯DLçš„ä¸€ä¸ªé—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨éƒ¨ç½²æ¨¡å‹æ—¶ï¼Œè¿™ä¸ªé—®é¢˜å°¤å…¶æ˜æ˜¾ã€‚æœ¬æ–‡å·¥ä½œæ¥è‡ªFBï¼Œæ˜¯å¼€æºåˆ†ç±»å·¥å…·fasttextçš„ä¸€ä¸ªæ¨¡å‹å‹ç¼©ç‰ˆã€‚FastTextçš„åœ°å€ï¼š<a href="https://github.com/facebookresearch/fastText" target="_blank" rel="external">https://github.com/facebookresearch/fastText</a></p>
<h2 id="Mining-Compatible-Incompatible-Entities-from-Question-and-Answering-via-Yes-No-Answer-Classification-using-Distant-Label-Expansion"><a href="#Mining-Compatible-Incompatible-Entities-from-Question-and-Answering-via-Yes-No-Answer-Classification-using-Distant-Label-Expansion" class="headerlink" title="Mining Compatible/Incompatible Entities from Question and Answering via Yes/No Answer Classification using Distant Label Expansion "></a><a href="http://t.cn/RIqG4QU" target="_blank" rel="external">Mining Compatible/Incompatible Entities from Question and Answering via Yes/No Answer Classification using Distant Label Expansion </a></h2><p>ã€è¯„è®ºæŒ–æ˜ã€‘æœ¬æ–‡é’ˆå¯¹çš„åº”ç”¨åœºæ™¯æ˜¯ä»å•†å“è¯„è®ºä¸­æŒ–æ˜å„ç§å•†å“çš„å…¼å®¹æ€§ï¼Œæ¯”å¦‚ä¹°äº†ä¸ªé¼ æ ‡ï¼Œæƒ³çŸ¥é“è¿™ä¸ªé¼ æ ‡å’Œipadã€pcçš„å…¼å®¹æ€§å¦‚ä½•ã€‚æ–‡ä¸­çš„Complementary Entity Recognition æ–¹æ³•æ¥è‡ªä¸Šå‘¨åŒä½œè€…çš„ä¸€ç¯‡æ–‡ç« ï¼Œåœ°å€æ˜¯<a href="https://arxiv.org/abs/1612.01039" target="_blank" rel="external">https://arxiv.org/abs/1612.01039</a> è¿™ä¸ªåº”ç”¨åœºæ™¯æ¯”è¾ƒæ¥åœ°æ°”ï¼Œå»ºè®®å¯¹è¯„è®ºæŒ–æ˜æ„Ÿå…´è¶£çš„ç«¥é‹é˜…è¯»ã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-12-17T18:37:27.000Z"><a href="/2016/12/17/PaperWeekly-ç¬¬åå…«æœŸ/">2016-12-17</a></time>
      
      
  
    <h1 class="title"><a href="/2016/12/17/PaperWeekly-ç¬¬åå…«æœŸ/">PaperWeekly ç¬¬åå…«æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•è¨€"><a href="#å¼•è¨€" class="headerlink" title="å¼•è¨€"></a>å¼•è¨€</h1><p>å¯¹è¯ç³»ç»Ÿæ˜¯å½“å‰çš„ç ”ç©¶çƒ­ç‚¹ï¼Œä¹Ÿæ˜¯é£é™©æŠ•èµ„çš„çƒ­ç‚¹ï¼Œä»2016å¹´åˆå¼€å§‹ï¼Œæˆç«‹äº†æ— æ•°å®¶åšchatbotã€è¯­éŸ³åŠ©æ‰‹ç­‰ç±»ä¼¼äº§å“çš„å…¬å¸ï¼Œä¸ç®¡æ˜¯å¯¹ç”¨æˆ·çš„ï¼Œè¿˜æ˜¯å¯¹ä¼ä¸šçš„ï¼Œå°†å¯¹è¯ç³»ç»Ÿè¿™ä¸€åº”ç”¨æ¨åˆ°äº†ä¸€ä¸ªæ–°çš„é«˜åº¦ã€‚seq2seqæ˜¯å½“å‰æµè¡Œçš„ç®—æ³•æ¡†æ¶ï¼Œç»™å®šä¸€ä¸ªè¾“å…¥ï¼Œæ¨¡å‹è‡ªåŠ¨ç»™å‡ºä¸€ä¸ªä¸é”™çš„è¾“å‡ºï¼Œå¬èµ·æ¥éƒ½æ˜¯ä¸€ä»¶ç¾å¥½çš„äº‹æƒ…ã€‚seq2seqåœ¨å¯¹è¯ç³»ç»Ÿä¸­çš„ç ”ç©¶æ¯”è¾ƒå¤šï¼Œæœ¬æœŸPaperWeeklyåˆ†äº«4ç¯‡éå¸¸æ–°çš„paper notesï¼Œæ¶‰åŠåˆ°å¦‚ä½•æé«˜æ‰€ç”Ÿæˆå¯¹è¯çš„æµç•…åº¦å’Œå¤šæ ·æ€§ï¼Œä½¿å¾—å¯¹è¯ç³»ç»Ÿèƒ½å¤Ÿæ›´åŠ æ¥è¿‘äººç±»çš„å¯¹è¯ã€‚4ç¯‡paperå¦‚ä¸‹ï¼š</p>
<p>1ã€Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation, 2016<br>2ã€A Simple, Fast Diverse Decoding Algorithm for Neural Generation, 2016<br>3ã€DIVERSE BEAM SEARCH: DECODING DIVERSE SOLUTIONS FROM NEURAL SEQUENCE MODELS, 2016<br>4ã€A Diversity-Promoting Objective Function for Neural Conversation Models, 2015</p>
<h1 id="Sequence-to-Backward-and-Forward-Sequences-A-Content-Introducing-Approach-to-Generative-Short-Text-Conversation"><a href="#Sequence-to-Backward-and-Forward-Sequences-A-Content-Introducing-Approach-to-Generative-Short-Text-Conversation" class="headerlink" title="Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation"></a><a href="http://cn.arxiv.org/pdf/1607.00970" target="_blank" rel="external">Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Lili Mou, Yiping Song, Rui Yan, Ge Li, Lu Zhang, Zhi Jin</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Key Laboratory of High Confidence Software Technologies (Peking University), MoE, China<br>Institute of Software, Peking University, China<br>Institute of Network Computing and Information Systems, Peking Univerity, China<br>Institute of Computer Science and Technology, Peking University, China</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>content-introducing approach<br>neural network-based<br>generative dialogue systems<br>seq2BF</p>
<h2 id="æ–‡ç« æ¥æº"><a href="#æ–‡ç« æ¥æº" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv, 2016</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>ä½¿ç”¨å¼•å…¥å†…å®¹æ–¹æ³•ï¼Œç”¨äºå¤„ç†åŸºäºç¥ç»ç½‘ç»œçš„ç”Ÿæˆå¼å¯¹è¯ç³»ç»Ÿ</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p><img src="media/model-18.png" alt="mode"></p>
<p>è¯¥æ¨¡å‹ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š<br>1ã€use PMI to predict a keyword for the reply<br>ä½¿ç”¨é€ç‚¹äº’ä¿¡æ¯(PMI)è¿›è¡Œé¢„æµ‹ï¼Œé€‰å–PMIå€¼æœ€å¤§çš„å•è¯ä½œä¸ºå›ç­”ä¸­çš„å…³é”®è¯ï¼Œè¯¥å…³é”®è¯å¯ä»¥å‡ºç°åœ¨å›ç­”è¯­å¥ä¸­çš„ä»»æ„ä½ç½®ã€‚<br><img src="media/%E5%85%AC%E5%BC%8F.png" alt="å…¬å¼"></p>
<p>2ã€generate a reply conditioned on the keyword as well as the query<br>ä½¿ç”¨sequence to backward and forward sequences(seq2BF)æ¨¡å‹æ¥ç”ŸæˆåŒ…å«å…³é”®è¯çš„å›ç­”ã€‚ä»¥è¯¥å…³é”®è¯ä¸ºåŸºç‚¹ï¼Œå°†å›ç­”è¯­å¥åˆ’åˆ†ä¸ºä¸¤ä¸ªåºåˆ—ï¼š<br>(1) åå‘åºåˆ—ï¼šå…³é”®è¯å·¦ä¾§çš„æ‰€æœ‰å•è¯ä»¥é€†åºæ’åˆ—<br>(2) æ­£å‘åºåˆ—ï¼šå…³é”®è¯å³ä¾§çš„æ‰€æœ‰å•è¯ä»¥é¡ºåºæ’åˆ—</p>
<p>seq2BFæ¨¡å‹å…·ä½“å·¥ä½œå¦‚ä¸‹ï¼š<br>(1) ä½¿ç”¨seq2seqç¥ç»ç½‘ç»œå°†é—®é¢˜ç¼–ç ï¼Œä»…å¯¹å…³é”®è¯å·¦ä¾§çš„å•è¯è¿›è¡Œè§£ç ï¼Œé€†åºè¾“å‡ºæ¯ä¸ªå•è¯<br>(2) ä½¿ç”¨å¦ä¸€ä¸ªseq2seqæ¨¡å‹å°†é—®é¢˜å†æ¬¡ç¼–ç ï¼Œåœ¨ç»™å®šä¸Šæ­¥ä¸­è§£ç åçš„é€†åºå•è¯åºåˆ—ä¸‹ï¼Œå¯¹å›ç­”ä¸­çš„å‰©ä½™å•è¯è¿›è¡Œé¡ºåºè§£ç ï¼Œè¾“å‡ºæœ€ç»ˆå•è¯åºåˆ—<br><img src="media/%E5%85%AC%E5%BC%8F3.png" alt="å…¬å¼3"></p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>Datasetï¼š<a href="http://tieba.baidu.com" target="_blank" rel="external">http://tieba.baidu.com</a></p>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>1ã€ Dialogue Systems<br>(1) (Isbell et al., 2000; Wang et al., 2013) retrieval methods<br>(2)  (Ritter et al., 2011) phrase-based machine translation<br>(3)  (Sordoni et al., 2015; Shang et al., 2015) recurrent neural networks </p>
<p>2ã€ Neural Networks for Sentence Generation<br>(1)  (Sordoni et al., 2015) bag-of-words features<br>(2)  (Shang et al., 2015) seq2seq-like neural networks<br>(3)  (Yao et al., 2015; Serban et al., 2016a) design hierarchical neural networks<br>(4)  (Li et al., 2016a) mutual information training objective</p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºï¼Œä¸åŒä¸ç›®å‰æ™®éå­˜åœ¨çš„ä»å¥é¦–åˆ°å¥å°¾é¡ºåºç”Ÿæˆç›®æ ‡å•è¯çš„æ–¹æ³•ï¼Œå¼•å…¥é€ç‚¹äº’ä¿¡æ¯æ–¹æ³•æ¥é¢„æµ‹å›ç­”è¯­å¥ä¸­çš„å…³é”®è¯ï¼Œä½¿ç”¨seq2BFæœºåˆ¶ç¡®ä¿è¯¥å…³é”®è¯å¯ä»¥å‡ºç°åœ¨ç›®æ ‡å›ç­”è¯­å¥çš„ä»»æ„ä½ç½®ä¹‹ä¸­å¹¶ç¡®ä¿è¾“å‡ºçš„æµåˆ©åº¦ï¼Œç›¸æ¯”äºseq2seqçš„ç”Ÿæˆæ–¹æ³•æ˜¾è‘—åœ°æå‡äº†å¯¹è¯ç³»ç»Ÿçš„è´¨é‡ã€‚</p>
<h1 id="A-Simple-Fast-Diverse-Decoding-Algorithm-for-Neural-Generation"><a href="#A-Simple-Fast-Diverse-Decoding-Algorithm-for-Neural-Generation" class="headerlink" title="A Simple, Fast Diverse Decoding Algorithm for Neural Generation"></a><a href="https://arxiv.org/abs/1611.08562" target="_blank" rel="external">A Simple, Fast Diverse Decoding Algorithm for Neural Generation</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Jiwei Li, Will Monroe and Dan Jurafsky</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Stanford</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>seq2seq, diversity, RL</p>
<h2 id="æ–‡ç« æ¥æº-1"><a href="#æ–‡ç« æ¥æº-1" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv, 2016</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>seq2seqæ¨¡å‹decoderæ—¶æ”¹è¿›beam searchï¼Œå¼•å…¥æƒ©ç½šå› å­å½±å“æ’åºç»“æœï¼Œå¹¶åŠ å…¥å¼ºåŒ–å­¦ä¹ æ¨¡å‹æ¥è‡ªåŠ¨å­¦ä¹ diversity rateï¼Œä½¿å¾—è§£ç å‡ºçš„ç»“æœæ›´å…·å¤šæ ·æ€§</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p><img src="media/18-0.png" alt="18-0"></p>
<p>å¯¹æ¯”æ ‡å‡†beam searchï¼Œæœ¬æ¨¡å‹å¼•å…¥æƒ©ç½šå› å­ï¼Œå…¬å¼å¦‚ä¸‹</p>
<p><img src="media/18-1.png" alt="18-1"></p>
<p>å…¶ä¸­$\gamma$ç§°ä¸ºdiversity rateï¼Œkâ€™èŒƒå›´ä¸º[1,k]ï¼ŒKä¸ºbeam size<br>å¼ºåŒ–å­¦ä¹ æ¨¡å‹ä¸­ï¼Œç­–ç•¥ä¸º</p>
<p><img src="media/18-2.png" alt="18-2"></p>
<p>rewardä¸ºè¯„ä»·æŒ‡æ ‡ï¼Œä¾‹å¦‚æœºå™¨ç¿»è¯‘ä¸­çš„BLEUå€¼ç­‰</p>
<h2 id="èµ„æº-1"><a href="#èµ„æº-1" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>1ã€å›å¤ç”Ÿæˆå®éªŒæ•°æ®é›†ï¼šOpenSubtitles <a href="https://github.com/jiweil/mutual-information-for-neural-machine-translation" target="_blank" rel="external">https://github.com/jiweil/mutual-information-for-neural-machine-translation</a><br>ï¼ˆä»£ç æ¨¡å‹å¯ä»ä½œè€…å¦å¤–ä¸€ç¯‡æ–‡ç« çš„æºç ç¨åŠ æ”¹åŠ¨ï¼‰</p>
<p>2ã€æœºå™¨ç¿»è¯‘æ•°æ®é›†ï¼šWMTâ€™14 <a href="http://www.statmt.org/wmt13/translation-task.html" target="_blank" rel="external">http://www.statmt.org/wmt13/translation-task.html</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-1"><a href="#ç›¸å…³å·¥ä½œ-1" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p><img src="media/18-3.png" alt="18-3"></p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ¨¡å‹çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥æƒ©ç½šå› å­ï¼Œä½¿å¾—decoderæ—¶å¯¹standard beam searchç®—æ³•è¿›è¡Œé‡æ’åºï¼Œå¹¶å¼•å…¥å¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼Œè‡ªåŠ¨å­¦ä¹ diversity rateã€‚ä½œè€…åˆ†åˆ«åœ¨ä¸‰ä¸ªå®éªŒä¸Šè¿›è¡ŒéªŒè¯ï¼Œæœºå™¨ç¿»è¯‘ã€æ‘˜è¦æŠ½å–ä¸å¯¹è¯å›å¤ç”Ÿæˆï¼Œå®éªŒè¡¨æ˜åœ¨ä¸åŒçš„å®éªŒä¸Šæœ‰ä¸åŒçš„è¡¨ç°ï¼Œä½†æ˜¯æ€»ä½“è€Œè¨€æœ¬æ–¹æ³•èƒ½å¤Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šè§£ç å‡ºæ›´å…·æœ‰å¤šæ ·æ€§çš„å¥å­ã€‚ï¼ˆæ€è·¯ç®€æ˜æ¸…æ™°ï¼Œå¯¹äºä¼ ç»Ÿçš„beam searchç¨åŠ æ”¹åŠ¨ï¼ŒåŸæ–‡ä¸­ä½œè€…æåˆ°åœ¨Matlabä»£ç ä¸­åªæ”¹åŠ¨ä¸€è¡Œå³å¯ï¼‰</p>
<h1 id="DIVERSE-BEAM-SEARCH-DECODING-DIVERSE-SOLUTIONS-FROM-NEURAL-SEQUENCE-MODELS"><a href="#DIVERSE-BEAM-SEARCH-DECODING-DIVERSE-SOLUTIONS-FROM-NEURAL-SEQUENCE-MODELS" class="headerlink" title="DIVERSE BEAM SEARCH: DECODING DIVERSE SOLUTIONS FROM NEURAL SEQUENCE MODELS"></a><a href="https://arxiv.org/abs/1610.02424" target="_blank" rel="external">DIVERSE BEAM SEARCH: DECODING DIVERSE SOLUTIONS FROM NEURAL SEQUENCE MODELS</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Ashwin K Vijayakumar, Michael Cogswell, Ramprasath R. Selvaraju, Qing Sun1 Stefan Lee, David Crandall &amp; Dhruv Batra</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Virginia Tech, Blacksburg, VA, USA<br>Indiana University, Bloomington, IN, USA</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Beam Search; Diversity; Image Caption; Machine Translation; Visual Question Answer; Chatbot</p>
<h2 id="æ–‡ç« æ¥æº-2"><a href="#æ–‡ç« æ¥æº-2" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv, 2016.10</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•æ”¹è¿›beam searchè§£ç ç®—æ³•ï¼Œä½¿å…¶åœ¨seq2seqæ¨¡å‹ä¸­å¯ä»¥ç”Ÿæˆæ›´åŠ ä¸°å¯Œçš„ç»“æœï¼Ÿ</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>ç»å…¸çš„beam searchç®—æ³•ä»¥æœ€å¤§åéªŒæ¦‚ç‡ä½œä¸ºä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼Œæ¯ä¸€ä¸ªtime stepåªä¿ç•™Bä¸ªæœ€ä¼˜çš„çŠ¶æ€ï¼Œæ˜¯ä¸€ç§å…¸å‹çš„è´ªå¿ƒç®—æ³•ï¼Œè¿™ä¸ªç»å…¸ç®—æ³•å¸¸å¸¸è¢«ç”¨äºè§£ç å¯é€‰çŠ¶æ€æ•°é‡å¤šçš„æƒ…å½¢ï¼Œæ¯”å¦‚ç”Ÿæˆå¯¹è¯ã€ç”Ÿæˆå›¾ç‰‡æè¿°ã€æœºå™¨ç¿»è¯‘ç­‰ï¼Œæ¯ä¸€æ­¥éƒ½æœ‰è¯è¡¨å¤§å°çš„å¯é€‰çŠ¶æ€é›†ã€‚seq2seqæ¨¡å‹çš„æµè¡Œï¼Œè®©è¿™ç§è§£ç ç®—æ³•çš„ç ”ç©¶å˜å¾—çƒ­é—¨ã€‚åœ¨ç”Ÿæˆå¯¹è¯ä»»åŠ¡æ—¶ï¼Œç”¨ç»å…¸çš„beam searchä¼šç”Ÿæˆç±»ä¼¼â€œæˆ‘ä¸çŸ¥é“â€ç­‰è¿™ç§æ²¡æœ‰è¥å…»çš„å¯¹è¯ï¼Œè™½ç„¶æ²¡æœ‰è¯­æ³•ä¸Šçš„é”™è¯¯ï¼Œè€Œä¸”å¯èƒ½åœ¨ä¸€å®šçš„è¯„ä»·ä½“ç³»å†…ä¼šå¾—åˆ°ä¸é”™çš„åˆ†æ•°ï¼Œä½†å®é™…åº”ç”¨æ•ˆæœå¤ªå·®ï¼Œå› æ­¤diversityçš„ç ”ç©¶å˜å¾—çƒ­é—¨ã€‚</p>
<p>æœ¬æ–‡é’ˆå¯¹diversityçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ”¹è¿›ç‰ˆçš„beam searchç®—æ³•ï¼Œæ—¨åœ¨ç”Ÿæˆæ›´åŠ å¤šæ ·æ€§çš„è¯ã€‚</p>
<p><img src="media/18-5.png" alt="18-5"></p>
<p>æ–°ç®—æ³•çš„ä¸»è¦æ€è·¯æ˜¯å°†ç»å…¸ç®—æ³•ä¸­çš„Beamè¿›è¡Œåˆ†ç»„ï¼Œé€šè¿‡å¼•å…¥ä¸€ä¸ªæƒ©ç½šæœºåˆ¶ï¼Œä½¿å¾—æ¯ä¸€ç»„çš„ç›¸ä¼¼åº¦å°½é‡ä½ï¼Œè¿™ä¸€é¡¹ä¿è¯äº†ç”Ÿæˆçš„è¯ç›¸äº’ä¹‹é—´å·®å¼‚æ›´å¤§ä¸€äº›ï¼Œå³æ»¡è¶³äº†å¤šæ ·æ€§çš„éœ€æ±‚ï¼Œåœ¨æ¯ä¸€ç»„Beamä¸­ï¼Œç”¨ç»å…¸çš„ç®—æ³•è¿›è¡Œä¼˜åŒ–æœç´¢ã€‚å…·ä½“çš„ç®—æ³•æµç¨‹å¦‚ä¸‹å›¾ï¼š</p>
<p><img src="media/18-6.png" alt="18-6"></p>
<p>å®éªŒä¸­ï¼Œç”¨äº†Image Captionã€Machine Translationå’ŒVQAä¸‰ä¸ªä»»åŠ¡è¿›è¡Œäº†å¯¹æ¯”ï¼ŒéªŒè¯äº†æœ¬æ–‡ç®—æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸”å¯¹ç®—æ³•ä¸­çš„å‡ ä¸ªå‚æ•°è¿›è¡Œäº†æ•æ„Ÿåº¦åˆ†æï¼Œåˆ†æäº†åˆ†ç»„æ•°å¯¹å¤šæ ·æ€§çš„å½±å“ã€‚</p>
<h2 id="èµ„æº-2"><a href="#èµ„æº-2" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>1ã€æœ¬æ–‡ç®—æ³•torchå®ç° <a href="https://github.com/ashwinkalyan/dbs" target="_blank" rel="external">https://github.com/ashwinkalyan/dbs</a><br>2ã€æœ¬æ–‡åœ¨çº¿demo dbs.cloudcv.org<br>3ã€neuraltalk2å®ç° <a href="https://github.com/karpathy/neuraltalk2" target="_blank" rel="external">https://github.com/karpathy/neuraltalk2</a><br>4ã€æœºå™¨ç¿»è¯‘å¼€æºå®ç°dl4mt <a href="https://github.com/nyu-dl/dl4mt-tutorial" target="_blank" rel="external">https://github.com/nyu-dl/dl4mt-tutorial</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-2"><a href="#ç›¸å…³å·¥ä½œ-2" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>ç›¸å…³çš„å·¥ä½œä¸»è¦åˆ†ç±»ä¸¤ç±»ï¼š<br>1ã€Diverse M-Best Lists<br>2ã€Diverse Decoding for RNNs<br>ä¹‹å‰Jiwei Liå°†è§£ç ç®—æ³•çš„ç›®æ ‡å‡½æ•°æ¢æˆäº†äº’ä¿¡æ¯è¿›è¡Œä¼˜åŒ–è§£ç ï¼Œå¯¹diversityè¿›è¡Œäº†ç ”ç©¶ã€‚</p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡ç ”ç©¶çš„é—®é¢˜æ˜¯ä¸€ç±»åŸºç¡€é—®é¢˜ï¼Œbeam searchç®—æ³•ä½œä¸ºä¸€ç§ç»å…¸çš„è¿‘ä¼¼è§£ç ç®—æ³•ï¼Œåº”ç”¨çš„åœºæ™¯éå¸¸å¤šã€‚ä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå°¤å…¶æ˜¯å…·ä½“åˆ°ç”Ÿæˆå¯¹è¯ã€ç”Ÿæˆç­”æ¡ˆç­‰ä»»åŠ¡ä¸Šï¼Œå­˜åœ¨ä¸€äº›é€‚åº”æ€§çš„é—®é¢˜ï¼Œæ¯”å¦‚diversityã€‚åªæ˜¯ç”Ÿæˆç®€å•è€Œåˆå®‰å…¨çš„è¯å¯¹äºå®é™…åº”ç”¨æ²¡æœ‰å¤ªå¤šçš„æ„ä¹‰ï¼Œæ‰€ä»¥æœ¬æ–‡çš„ç ”ç©¶éå¸¸æœ‰æ„ä¹‰ã€‚æœ¬æ–‡çš„å®éªŒä»ä¸‰ä¸ªä¸åŒçš„ä»»åŠ¡ä¸Šå¯¹æ”¹è¿›åçš„beam searchéƒ½åšäº†å¯¹æ¯”éªŒè¯ï¼Œéå¸¸æ‰å®çš„ç»“æœéªŒè¯äº†ç®—æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸”å¯¹å‡ ä¸ªå…³é”®å‚æ•°è¿›è¡Œäº†æ•æ„Ÿåº¦åˆ†æï¼Œæœ‰ç†æœ‰æ®ã€‚åŒæ—¶åœ¨githubä¸Šå¼€æºäº†ä»£ç ï¼Œå¹¶ä¸”ç»™å‡ºäº†ä¸€ä¸ªåœ¨çº¿demoã€‚åœ¨è¯„ä»·æ–¹é¢ï¼Œä¸ä»…ä»…è®¾è®¡äº†å‡ ä¸ªè‡ªåŠ¨è¯„ä»·æŒ‡æ ‡ï¼Œè€Œä¸”ç”¨äº†äººå·¥è¯„ä»·çš„æ–¹æ³•å¯¹æœ¬æ–‡ç®—æ³•è¿›è¡Œäº†éªŒè¯ï¼Œæ˜¯ä¸€ç¯‡éå¸¸å¥½çš„paperï¼Œå€¼å¾—å­¦ä¹ ã€‚</p>
<h1 id="A-Diversity-Promoting-Objective-Function-for-Neural-Conversation-Models"><a href="#A-Diversity-Promoting-Objective-Function-for-Neural-Conversation-Models" class="headerlink" title="A Diversity-Promoting Objective Function for Neural Conversation Models"></a><a href="https://arxiv.org/pdf/1510.03055.pdf" target="_blank" rel="external">A Diversity-Promoting Objective Function for Neural Conversation Models</a></h1><h2 id="ä½œè€…-3"><a href="#ä½œè€…-3" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, Bill Dolan</p>
<h2 id="å•ä½-3"><a href="#å•ä½-3" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Stanford University, Stanford, CA, USA<br>Microsoft Research, Redmond, WA, USA</p>
<h2 id="å…³é”®è¯-3"><a href="#å…³é”®è¯-3" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Sequence-to-sequence neural network models, conversational responses, Maximum Mutual Information(MMI)</p>
<h2 id="æ–‡ç« æ¥æº-3"><a href="#æ–‡ç« æ¥æº-3" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv, 2015</p>
<h2 id="é—®é¢˜-3"><a href="#é—®é¢˜-3" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>ä½¿ç”¨MMIè®­ç»ƒsequence-to-sequence model for conversational responses generation<br>ä¼ ç»Ÿçš„ML(æœ€å¤§ä¼¼ç„¶ä¼°è®¡)åœ¨è®­ç»ƒsequence-to-sequence modelçš„æ—¶å€™ï¼Œæ˜“äº§ç”Ÿä¸è¾“å…¥æ— å…³çš„â€™safeâ€™ responses(æœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„å¼Šç—…â€”-always try to cover all mode of input data)<br>ä½œè€…é€šè¿‡ä½¿ç”¨MMI, æœ€å¤§åŒ–è¾“å…¥ä¸è¾“å‡ºçš„äº’ä¿¡æ¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé¿å…ä¸è¾“å…¥æ— å…³çš„responsesï¼Œå¾—åˆ°æ›´ä¸ºdiverseçš„responses.</p>
<h2 id="æ¨¡å‹-3"><a href="#æ¨¡å‹-3" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>MMIæœ€æ—©åœ¨speech recognitionä¸­æå‡ºå¹¶åº”ç”¨(discriminative training criteria). è¯­éŸ³è¯†åˆ«ä¸­ï¼Œé€šå¸¸å…ˆç”¨MLè®­ç»ƒå£°å­¦æ¨¡å‹ï¼Œç„¶åå†æ¥MMIå’Œè¯­è¨€æ¨¡å‹ï¼Œå¯¹å£°å­¦æ¨¡å‹è¿›ä¸€æ­¥è°ƒä¼˜ã€‚</p>
<p>åœ¨æœ¬æ–‡ä¸­ï¼Œä½œè€…é€šè¿‡æå‡ºMMIç”¨äºseq-to-seq modelçš„ä¼˜åŒ–ã€‚ä½œè€…æå‡ºäº†MMI-antiLMå’ŒMMI-bidi ä¸¤ä¸ªä¸åŒçš„MMIçš„formulations. MMIåœ¨seq-to-seqçš„åº”ç”¨ä¸­å­˜åœ¨decodingçš„é—®é¢˜ã€‚</p>
<p>MMI-antiLMä¸­ï¼Œä½œè€…é€šè¿‡ä½¿ç”¨å¸¦æœ‰æƒé‡çš„LMä»¥ç”Ÿæˆæ›´ä¸ºdiverseçš„responses by penalizing first wordã€‚</p>
<p>MMI-bidiä¸­ï¼Œæœç´¢ç©ºé—´çš„æ•°ç›®è¿‡å¤§ï¼Œå¯¼è‡´expolringæ‰€æœ‰çš„å¯èƒ½æ€§åœ¨å®é™…ä¸­æ— æ³•å®ç°ã€‚ä½œè€…é¦–å…ˆäº§ç”ŸN-best list, ç„¶åæ ¹æ®ç›¸åº”çš„å‡†åˆ™å‡½æ•° re-rankå¾—åˆ°çš„N-best listã€‚</p>
<p>åœ¨MMIä¸åŒçš„formulationä¸­ï¼Œä½œè€…é€šè¿‡å¯å‘å¼çš„è®¾è®¡ï¼Œä½¿å¾—decodingæ›´ä¸ºå®¹æ˜“ä¸”äº§ç”Ÿçš„responseæ›´ä¸ºdiverseï¼Œåœ¨ç›¸å…³çš„æ•°æ®é›†ä¸Šå–å¾—äº†è¾ƒå¥½çš„BLEUä¸”äº§ç”Ÿçš„responseæ›´ä¸ºdiverseã€‚</p>
<h2 id="ç®€è¯„-3"><a href="#ç®€è¯„-3" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ€å¤§åéªŒæ¦‚ç‡é€šå¸¸ä½œä¸ºä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°ï¼Œä½†å¾ˆå¤šåº”ç”¨åœºæ™¯ä¸­å¾—åˆ°çš„ç»“æœå¹¶ä¸ç†æƒ³ã€‚æœ¬æ–‡é‡‡ç”¨äº†ä¸€ä¸ªæ–°çš„è€Œä¸”ä¹Ÿæ˜¯å…¶ä»–é¢†åŸŸä¸­æ¯”è¾ƒå¸¸è§çš„ç›®æ ‡å‡½æ•°æ¥æ›¿æ¢æœ€å¤§åéªŒæ¦‚ç‡ï¼Œåœ¨ç”Ÿæˆå¯¹è¯æ—¶å¾—åˆ°äº†æ›´åŠ ä¸°å¯Œçš„ç»“æœã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>å¯¹è¯ç³»ç»Ÿæ˜¯ä¸€ä¸ªç›¸å¯¹é«˜çº§çš„ã€ç»¼åˆæ€§å¾ˆå¼ºçš„ä»»åŠ¡ï¼Œæ‰€ä¾èµ–çš„åŸºç¡€ä»»åŠ¡æ¯”è¾ƒå¤šï¼Œæ¯”å¦‚åˆ†è¯ã€å‘½åå®ä½“è¯†åˆ«ã€å¥æ³•åˆ†æã€è¯­ä¹‰è§’è‰²æ ‡æ³¨ç­‰ç­‰ã€‚å¯¹äºè§„èŒƒçš„ä¸­æ–‡è¡¨è¾¾è€Œè¨€ï¼Œå¥æ³•åˆ†æä»æ˜¯ä¸€ä¸ªæ²¡æœ‰è§£å†³å¥½çš„é—®é¢˜ï¼Œæ›´ä½•å†µæ˜¯ä¸é‚£ä¹ˆè§„èŒƒçš„äººè¯ï¼Œå¥æ³•åˆ†æçš„å‡†ç¡®æ€§åˆè¦ä¸‹ä¸€ä¸ªleveläº†ï¼Œéšä¹‹è¯­ä¹‰è§’è‰²æ ‡æ³¨ä¹Ÿå¾—ä¸åˆ°å¥½çš„æ•ˆæœã€‚ç»å…¸çš„ã€åŸºç¡€çš„ä»»åŠ¡è¿˜æœ‰å¾ˆé•¿çš„è·¯è¦èµ°ï¼Œå¯¹è¯ç³»ç»Ÿè¿™ç§æ›´éš¾ã€æ›´å¤æ‚çš„ä»»åŠ¡ç›¸ä¿¡ä¸æ˜¯ä¸€å¹´ã€ä¸¤å¹´å°±å¯ä»¥çªç ´çš„äº‹æƒ…ï¼Œè™½ç„¶ç°åœ¨å¤§çƒ­ï¼Œåšçš„äººå¾ˆå¤šï¼Œä½†å°±ç›®å‰çš„ç ”ç©¶æ°´å¹³æ¥çœ‹ï¼Œåº”è¯¥è¿˜æœ‰å¾ˆé•¿çš„è·¯è¦èµ°ã€‚seq2seqæ˜¯ä¸ªé€ƒé¿è¿™äº›é—®é¢˜çš„å¥½æ–¹æ³•å’Œå¥½æ€è·¯ï¼Œä½†ç›¸å¯¹æ¥è¯´æ›´åŠ ä¸æˆç†Ÿï¼Œè€Œä¸”å­˜åœ¨ç€å¾ˆå¤šçš„é—®é¢˜ï¼Œæƒ³é€šè¿‡å¤§é‡çš„æ•°æ®æ¥è¦†ç›–æ‰€æœ‰çš„é—®é¢˜ï¼Œæ˜¯ä¸€ç§ä¸å¤ªç§‘å­¦çš„æ€è·¯ã€‚æˆ‘æƒ³ï¼Œseq2seqæ˜¯ä¸ªå¥½æ–¹æ³•ï¼Œä½†ä¼ ç»Ÿçš„NLPæ–¹æ³•ä¹Ÿæ˜¯å¿…ä¸å¯å°‘çš„ï¼Œè€Œä¸”ä¸¤è€…åº”è¯¥æ˜¯ç›¸äº’è¡¥å……çš„ã€‚è¶Šå¤šçš„äººå…³æ³¨å¯¹è¯ç³»ç»Ÿï¼Œå°±ä¼šè¶Šå¿«åœ°æ¨åŠ¨è¿™ä¸ªé¢†åŸŸçš„å‘å±•ï¼Œå¸Œæœ›æ—©æ—¥çœ‹åˆ°é è°±çš„ã€æˆç†Ÿçš„è§£å†³æ–¹æ¡ˆã€‚æ„Ÿè°¢@Pennyã€@tonyaã€@zhangjunå’Œ@çš“å¤© å››ä½ç«¥é‹å®Œæˆçš„paper notesã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-12-11T16:51:29.000Z"><a href="/2016/12/11/æœ¬å‘¨å€¼å¾—è¯»-2016-12-05-2016-12-09/">2016-12-11</a></time>
      
      
  
    <h1 class="title"><a href="/2016/12/11/æœ¬å‘¨å€¼å¾—è¯»-2016-12-05-2016-12-09/">æœ¬å‘¨å€¼å¾—è¯»(2016.12.05-2016.12.09)</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="ä¸€å‘¨å€¼å¾—è¯»"><a href="#ä¸€å‘¨å€¼å¾—è¯»" class="headerlink" title="ä¸€å‘¨å€¼å¾—è¯»"></a>ä¸€å‘¨å€¼å¾—è¯»</h1><h2 id="End-to-End-Joint-Learning-of-Natural-Language-Understanding-and-Dialogue-Manager"><a href="#End-to-End-Joint-Learning-of-Natural-Language-Understanding-and-Dialogue-Manager" class="headerlink" title="End-to-End Joint Learning of Natural Language Understanding and Dialogue Manager "></a><a href="http://t.cn/RfDCS5X" target="_blank" rel="external">End-to-End Joint Learning of Natural Language Understanding and Dialogue Manager </a></h2><p>ã€å¯¹è¯ç³»ç»Ÿã€‘è‡ªç„¶è¯­è¨€ç†è§£å’Œå¯¹è¯ç®¡ç†é€šå¸¸æ˜¯ä¸¤ä¸ªç‹¬ç«‹çš„ä»»åŠ¡ï¼ŒNLUçš„è¯¯å·®ä¼šå½±å“åˆ°å¯¹è¯ç®¡ç†çš„æ•ˆæœã€‚æœ¬æ–‡å°†ä¸¤ä¸ªä»»åŠ¡è”åˆèµ·æ¥è¿›è¡Œç«¯åˆ°ç«¯çš„è®­ç»ƒï¼Œå¾—åˆ°äº†ä¸é”™çš„æ•ˆæœã€‚å»ºè®®ç ”ç©¶å¯¹è¯ç³»ç»Ÿçš„ç«¥é‹æ¥è¯»ã€‚</p>
<h2 id="Sequential-Match-Network-A-New-Architecture-for-Multi-turn-Response-Selection-in-Retrieval-based-Chatbots"><a href="#Sequential-Match-Network-A-New-Architecture-for-Multi-turn-Response-Selection-in-Retrieval-based-Chatbots" class="headerlink" title="Sequential Match Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots "></a><a href="http://t.cn/RIhcTFP" target="_blank" rel="external">Sequential Match Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots </a></h2><p>ã€å¯¹è¯ç³»ç»Ÿã€‘æœ¬æ–‡ç ”ç©¶çš„é—®é¢˜æ˜¯åŸºäºæ£€ç´¢çš„å¤šè½®å¯¹è¯æœºå™¨äººï¼Œå•è½®å¯¹è¯å’Œå¤šè½®å¯¹è¯çš„ä¸€å¤§åŒºåˆ«åœ¨äºåè€…éœ€è¦è€ƒè™‘æ›´å¤šçš„ä¸Šä¸‹æ–‡å†…å®¹ï¼Œæœ¬æ–‡åœ¨æ£€ç´¢ç­”æ¡ˆæ—¶é™¤äº†ç›¸å…³æ€§è¿˜è€ƒè™‘äº†ä¸Šä¸‹æ–‡ä¹‹é—´çš„å…³ç³»ï¼Œå»ºè®®ç ”ç©¶æ£€ç´¢å¼èŠå¤©æœºå™¨äººçš„ç«¥é‹æ¥è¯»æœ¬æ–‡ã€‚æœ¬æ–‡è¿˜ç»™å‡ºäº†ä¸€ä¸ªæµ‹è¯•æ•°æ®é›†ï¼Œåœ°å€åœ¨ï¼š<a href="http://t.cn/RIhf4Sh" target="_blank" rel="external">http://t.cn/RIhf4Sh</a></p>
<h2 id="CER-Complementary-Entity-Recognition-via-Knowledge-Expansion-on-Large-Unlabeled-Product-Reviews"><a href="#CER-Complementary-Entity-Recognition-via-Knowledge-Expansion-on-Large-Unlabeled-Product-Reviews" class="headerlink" title="CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews "></a><a href="http://t.cn/RfDpyCm" target="_blank" rel="external">CER: Complementary Entity Recognition via Knowledge Expansion on Large Unlabeled Product Reviews </a></h2><p>ã€ç›¸å…³å®ä½“è¯†åˆ«ã€‘æœ¬æ–‡ç ”ç©¶çš„é—®é¢˜æ˜¯äº§å“è¯„è®ºæ•°æ®ä¸­çš„ç›¸å…³å®ä½“è¯†åˆ«é—®é¢˜ï¼Œè¯„è®ºæ•°æ®æ˜¯ä¸ªå¾ˆæœ‰æ„æ€çš„æ•°æ®ï¼Œç”¨æˆ·åœ¨ä¹°ä¸œè¥¿æ—¶å¸Œæœ›å¯ä»¥é€šè¿‡å¯¹æ¯”ä¹°åˆ°æ›´å¥½çš„äº§å“ã€‚å»ºè®®åšè¯„è®ºæŒ–æ˜çš„ç«¥é‹è¯»ã€‚</p>
<h2 id="The-Evolution-of-Sentiment-Analysis-A-Review-of-Research-Topics-Venues-and-Top-Cited-Papers"><a href="#The-Evolution-of-Sentiment-Analysis-A-Review-of-Research-Topics-Venues-and-Top-Cited-Papers" class="headerlink" title="The Evolution of Sentiment Analysis - A Review of Research Topics, Venues, and Top Cited Papers "></a><a href="http://t.cn/RIvkAop" target="_blank" rel="external">The Evolution of Sentiment Analysis - A Review of Research Topics, Venues, and Top Cited Papers </a></h2><p>ã€æƒ…æ„Ÿåˆ†æã€‘ã€ç»¼è¿°ã€‘ä¸€ç¯‡å¾ˆç»†çš„æƒ…æ„Ÿåˆ†æçš„ç»¼è¿°ï¼Œåˆšåˆšè¿›å…¥è¿™ä¸ªé¢†åŸŸçš„ç«¥é‹å¯ä»¥æ¥è¯»ä¸€è¯»ã€‚</p>
<h2 id="ä¸€å‘¨èµ„æº"><a href="#ä¸€å‘¨èµ„æº" class="headerlink" title="ä¸€å‘¨èµ„æº"></a>ä¸€å‘¨èµ„æº</h2><h2 id="æ–‡æœ¬ä¸Šçš„ç®—æ³•"><a href="#æ–‡æœ¬ä¸Šçš„ç®—æ³•" class="headerlink" title="æ–‡æœ¬ä¸Šçš„ç®—æ³•"></a><a href="http://t.cn/RhtyvzE" target="_blank" rel="external">æ–‡æœ¬ä¸Šçš„ç®—æ³•</a></h2><p>ã€Šæ–‡æœ¬ä¸Šçš„ç®—æ³•ã€‹v4.0ï¼šå¢åŠ è‡ªç„¶è¯­è¨€å¤„ç†å’Œå¯¹è¯ç³»ç»Ÿç« èŠ‚ï¼›ä¸°å¯Œäº†å…¶ä»–å†…å®¹ã€‚</p>
<h2 id="NIPS-2016-Spotlight-Videos"><a href="#NIPS-2016-Spotlight-Videos" class="headerlink" title="NIPS 2016 Spotlight Videos"></a><a href="http://t.cn/RfB5cA2" target="_blank" rel="external">NIPS 2016 Spotlight Videos</a></h2><p>ã€NIPS 2016 Spotlight Videosã€‘NIPS 2016ç„¦ç‚¹è§†é¢‘é›†ã€‚ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿå¤§ä¼š(Conference and Workshop on Neural Information Processing Systems)ï¼Œç®€ç§°NIPSï¼Œæ˜¯ä¸€ä¸ªå…³äºæœºå™¨å­¦ä¹ å’Œè®¡ç®—ç¥ç»ç§‘å­¦çš„å›½é™…ä¼šè®®ã€‚è¯¥ä¼šè®®å›ºå®šåœ¨æ¯å¹´çš„12æœˆä¸¾è¡Œ,ç”±NIPSåŸºé‡‘ä¼šä¸»åŠã€‚NIPSæ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸçš„é¡¶çº§ä¼šè®® ã€‚åœ¨ä¸­å›½è®¡ç®—æœºå­¦ä¼šçš„å›½é™…å­¦æœ¯ä¼šè®®æ’åä¸­ï¼ŒNIPSä¸ºäººå·¥æ™ºèƒ½é¢†åŸŸçš„Aç±»ä¼šè®®ã€‚(via @ç½‘è·¯å†·çœ¼)</p>
<h2 id="2016å¹´æ·±åº¦å­¦ä¹ çš„ä¸»è¦è¿›å±•"><a href="#2016å¹´æ·±åº¦å­¦ä¹ çš„ä¸»è¦è¿›å±•" class="headerlink" title="2016å¹´æ·±åº¦å­¦ä¹ çš„ä¸»è¦è¿›å±•"></a><a href="http://t.cn/RIvuIuV" target="_blank" rel="external">2016å¹´æ·±åº¦å­¦ä¹ çš„ä¸»è¦è¿›å±•</a></h2><p>2016å¹´æ·±åº¦å­¦ä¹ çš„ä¸»è¦è¿›å±•ï¼ŒThe major advancements in Deep Learning in 2016 (via @è§†è§‰æœºå™¨äºº)</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-12-10T18:16:44.000Z"><a href="/2016/12/10/PaperWeekly-ç¬¬åä¸ƒæœŸ/">2016-12-10</a></time>
      
      
  
    <h1 class="title"><a href="/2016/12/10/PaperWeekly-ç¬¬åä¸ƒæœŸ/">PaperWeekly ç¬¬åä¸ƒæœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•è¨€"><a href="#å¼•è¨€" class="headerlink" title="å¼•è¨€"></a>å¼•è¨€</h1><p>å‘½åå®ä½“è¯†åˆ«æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ä¸€ä¸ªéå¸¸åŸºç¡€çš„å·¥ä½œï¼Œæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­å…³é”®çš„ä¸€ä¸ªç¯èŠ‚ã€‚ç›‘ç£å­¦ä¹ æ˜¯è§£å†³å‘½åå®ä½“è¯†åˆ«çš„ä¸€ä¸ªåŸºæœ¬æ‰‹æ®µï¼Œä½†æ ‡æ³¨æ•°æ®çš„è·å–æˆæœ¬å¾€å¾€ä¼šæ¯”è¾ƒé«˜ï¼Œæœ¬æœŸPaperWeeklyå°†å¸¦å¤§å®¶æ¥çœ‹ä¸€ä¸‹å¦‚ä½•é€šè¿‡åŠç›‘ç£æˆ–è€…æ— ç›‘ç£çš„æ–¹æ³•æ¥åšå‘½åå®ä½“è¯†åˆ«ä»»åŠ¡ã€‚æœ¬æœŸåˆ†äº«çš„4ç¯‡Paper Notesåˆ†åˆ«æ˜¯ï¼š</p>
<p>1ã€Building a Fine-Grained Entity Typing System Overnight for a New X (X = Language, Domain, Genre), 2016<br>2ã€ClusType: Effective Entity Recognition and Typing by Relation Phrase-Based Clustering, 2015<br>3ã€Bootstrapped Text-level Named Entity Recognition for Literature, 2016<br>4ã€Recognizing Named Entities in Tweets, 2011</p>
<h1 id="Building-a-Fine-Grained-Entity-Typing-System-Overnight-for-a-New-X-X-Language-Domain-Genre"><a href="#Building-a-Fine-Grained-Entity-Typing-System-Overnight-for-a-New-X-X-Language-Domain-Genre" class="headerlink" title="Building a Fine-Grained Entity Typing System Overnight for a New X (X = Language, Domain, Genre)"></a><a href="https://arxiv.org/pdf/1603.03112v1.pdf" target="_blank" rel="external">Building a Fine-Grained Entity Typing System Overnight for a New X (X = Language, Domain, Genre)</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Lifu Huang, Jonathan May, Xiaoman Pan, Heng Ji</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Rensselaer Polytechnic Institute,<br>Information Sciences Institute,<br>Rensselaer Polytechnic Institute</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Entity Recognition and Typing, Unspuversied</p>
<h2 id="æ–‡ç« æ¥æº"><a href="#æ–‡ç« æ¥æº" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv, 2016</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>ç»†ç²’åº¦çš„å®ä½“è¯†åˆ«æ˜¯è¿™å‡ å¹´æ¯”è¾ƒæµè¡Œçš„å·¥ä½œã€‚ä¼ ç»Ÿçš„æ–¹æ³•æ˜¯éœ€è¦å…ˆé¢„å®šä¹‰ä¸€ç»„å®ä½“æ‰€å±ç±»å‹ï¼Œéšåä½¿ç”¨å¤§é‡çš„æ ‡æ³¨æ•°æ®æ¥è®­ç»ƒå¤šåˆ†ç±»å™¨ã€‚æœ¬æ–‡é’ˆå¯¹éœ€è¦æ ‡æ³¨æ•°æ®çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªä½¿ç”¨éç›‘ç£å­¦ä¹ çš„æ€è·¯æ¥è§£å†³è¿™ä¸ªé—®é¢˜</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æœ¬æ–‡ä¸­æ–¹æ³•çš„æ¶æ„å¦‚ä¸‹å›¾:</p>
<p><img src="media/overview.png" alt="overvie"></p>
<p>1ï¼‰é€šè¿‡entity mentionçš„è¯­æ–™ï¼Œæ„å»ºentity mentionçš„context<br>2ï¼‰éšåæ„å»ºçŸ¥è¯†åº“çš„è¡¨è¾¾<br>3ï¼‰é€šè¿‡çŸ¥è¯†åº“å’Œentity mentionè¿›è¡Œè¿æ¥<br>4ï¼‰å°†è¿æ¥åçš„æ•°æ®å­¦ä¹ ä¸‰ç§è¡¨è¾¾</p>
<ul>
<li>a general entity distributed representation</li>
<li>a specific context representation</li>
<li>a knowledge representation</li>
</ul>
<p>å…¶ä¸­entity distributed representationä¸»è¦æ˜¯é€šè¿‡ä¸Šä¸‹æ–‡æ¥è¡¨è¾¾å®ä½“ã€‚<br>è€Œ a specific context representationä¸»è¦æ˜¯è¡¨è¾¾ä¸€äº›local featureå’Œä¸€äº›è¯­è¨€ç»“æ„çš„ç‰¹å¾ã€‚<br>æœ€åa knowledge representationä¸»è¦æ˜¯ç”¨æ¥æ¨¡æ‹Ÿé¢†åŸŸç›¸å…³çš„çŸ¥è¯†</p>
<p>æœ€åç®—æ³•é€šè¿‡ä¸€ä¸ªå±‚æ¬¡èšç±»ç®—æ³•æ¥è·å–entity mentionå¯èƒ½çš„åˆ†ç±»ä¿¡æ¯</p>
<p>1ã€General Entity Representation<br>entity mentionçš„è¡¨è¾¾ä½œè€…ä¸»è¦æ˜¯ç”¨äº†Skip-gram modelé€šè¿‡å¤§é‡çš„è¯­æ–™æ¥è®­ç»ƒï¼Œæœ€ç»ˆå¯ä»¥å¾—åˆ°æ¯ä¸ªentity mentionçš„è¡¨è¾¾ã€‚è¿™ä¸ªæ€è·¯çš„å¥½å¤„æ˜¯è®©ä¸¤ä¸ªentity mentionå±äºåŒä¸€ç±»å‹æ—¶ï¼Œentity mentionçš„ä¸Šä¸‹æ–‡ä¼šæ¯”è¾ƒç›¸ä¼¼ï¼Œè¿›è€Œå¯ä»¥å¾—åˆ°ç›¸ä¼¼çš„åˆ†å¸ƒå¼è¡¨è¾¾</p>
<p>2ã€a specific context representation<br>ä¸ºäº†å¾—åˆ°a specific context representationï¼Œæœ¬æ–‡ä½¿ç”¨AMRï¼ˆ(Abstract Meaning Representationï¼‰è¯­æ³•æˆ–è€…å¥æ³•ç»“æ„çš„ä¸Šä¸‹æ–‡ã€‚<br>å…¶ç”Ÿæˆçš„ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚æ ¹æ®ç»™å®šçš„entity mentionä»¥åŠå¯¹åº”å…³ç³»ï¼Œé¦–å…ˆé€‰æ‹©entity mentionå¯èƒ½çš„ç±»å‹ï¼Œå¦‚å…³ç³»ä¸ºARG0 capital of ARG1åˆ™ARG0å¯èƒ½çš„ç±»å‹åˆ™ä¸ºå›½å®¶ï¼ŒåŒç†ARG1å¯èƒ½çš„ç±»å‹ä¸ºåŸå¸‚ã€‚éšåå°†æ‰€æœ‰entity mentionå¯èƒ½çš„å€™é€‰ç±»å‹é€šè¿‡ä¸€ä¸ªencoder-decoderæ¨¡å‹å¾—åˆ°ä¸€ä¸ªå•ä¸€çš„è¡¨è¾¾</p>
<p><img src="media/context%20specific.png" alt="context specifi"></p>
<p>3ã€Knowledge Representation</p>
<p>ç”±äºentity mentionçš„ç±»å‹åœ¨å¾ˆå¤šæƒ…å†µæ˜¯éå¸¸ä¾èµ–é¢†åŸŸç›¸å…³çš„çŸ¥è¯†åº“çš„ã€‚å› æ­¤æœ¬æ–‡ä¹Ÿå¯¹çŸ¥è¯†åº“è¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œæ¨æ–­å‡ºåœ¨æŸä¸ªç›¸å…³é¢†åŸŸä¸‹æ›´ç»†ç²’åº¦çš„å®ä½“ã€‚ä¸ºä¾‹è®¡ç®—Knowledge Representationï¼Œé¦–å…ˆå¯¹entity mentionè·ŸçŸ¥è¯†åº“åšè¿æ¥ã€‚éšåæ ¹æ®é“¾æ¥çš„å®ä½“å’Œå®ä½“å¯¹åº”çš„å±æ€§ä»¥åŠç±»å‹ä¿¡æ¯æ„å»ºä¸€ä¸ªåŸºäºæƒé‡çš„äºŒæ­¥å›¾ã€‚æ„å»ºå¥½çš„äºŒæ­¥å›¾æ ¹æ® Large-scale information network embeddingç®—æ³•æ¥å¯¹è¿™ä¸ªäºŒæ­¥å›¾è®­ç»ƒå¹¶å¾—åˆ°å…¶åˆ†å¸ƒå¼è¡¨è¾¾ã€‚</p>
<p>æœ€åå¯¹äºä¸€ä¸ªentity mentionï¼Œå°†è¯¥entity mentionå¯¹åº”çš„ä¸‰ç§è¡¨è¾¾General Entity Representationï¼Œa specific context representationå’ŒKnowledge Representationæ•´åˆï¼Œé€šè¿‡ä¸€ä¸ªhierarchical X-means clusteringç®—æ³•å¾—åˆ°è¿™ä¸ªentity mentionåœ¨ä¸€ä¸ªåˆ†ç±»ä½“ç³»ä¸‹çš„typeä¿¡æ¯ã€‚æœ€ç»ˆå®Œæˆè¯†åˆ«å®ä½“ç±»å‹çš„ä¿¡æ¯ã€‚</p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>ç»†ç²’åº¦çš„å®ä½“è¯†åˆ«æ˜¯è¿™å‡ å¹´æ¯”è¾ƒæµè¡Œçš„å·¥ä½œã€‚ä¼ ç»Ÿçš„æ–¹æ³•æ˜¯éœ€è¦å…ˆé¢„å®šä¹‰ä¸€ç»„å®ä½“æ‰€å±ç±»å‹ï¼Œéšåä½¿ç”¨å¤§é‡çš„æ ‡æ³¨æ•°æ®æ¥è®­ç»ƒå¤šåˆ†ç±»å™¨ã€‚è¿™ç¯‡æ–‡ç« çš„åˆ›æ–°ç‚¹æ˜¯æå‡ºäº†ä¸€ä¸ªéç›‘ç£å­¦ä¹ çš„ç®—æ³•æ¥è¯†åˆ«å®ä½“æ‰€å±çš„typeï¼Œè¿™ç§éç›‘ç£çš„æ–¹æ³•åœ¨ç¼ºå°‘æ ‡æ³¨æ•°æ®çš„å‚ç›´é¢†åŸŸå…·æœ‰ä¸€å®šçš„å®ç”¨æ€§ã€‚æœ¬æ–‡çš„æ€è·¯ä¸»è¦æ˜¯é€šè¿‡æ–‡ç« ä¸­çš„entity mentionè·ŸçŸ¥è¯†åº“è¿›è¡Œè¿æ¥ï¼Œé€šè¿‡æ–‡ç« çš„ä¸Šä¸‹æ–‡å­¦ä¹ entity mentionçš„åˆ†å¸ƒå¼è¡¨è¾¾ï¼ŒåŒæ—¶é€šè¿‡å­¦ä¹ çŸ¥è¯†åº“ä¸­å®ä½“å’Œç±»å‹çš„åˆ†å¸ƒå¼è¡¨è¾¾ã€‚æœ€åå°†è¿™äº›è¡¨è¾¾é€å…¥ä¸€ä¸ªå±‚æ¬¡èšç±»ç®—æ³•ï¼Œentity mentionå¾—åˆ°çš„embeddingå’Œç›¸ä¼¼çš„çŸ¥è¯†åº“ç¬¦å·embeddingä¼šèšåˆ°åŒä¸€ä¸ªèšç±»ä¸‹ã€‚è¿›è€Œé€šè¿‡éç›‘ç£çš„æ–¹æ³•å¯¹entity mentionæ‰“ä¸Štypeçš„æ ‡ç­¾ã€‚å®éªŒè¯æ˜æœ¬æ–‡çš„æ–¹æ³•å¯ä»¥è·Ÿç›‘ç£å­¦ä¹ èµ·åˆ°ç±»ä¼¼çš„æ•ˆæœã€‚</p>
<h1 id="ClusType-Effective-Entity-Recognition-and-Typing-by-Relation-Phrase-Based-Clustering"><a href="#ClusType-Effective-Entity-Recognition-and-Typing-by-Relation-Phrase-Based-Clustering" class="headerlink" title="ClusType: Effective Entity Recognition and Typing by Relation Phrase-Based Clustering"></a><a href="http://nlp.cs.rpi.edu/paper/entitytyping.pdf" target="_blank" rel="external">ClusType: Effective Entity Recognition and Typing by Relation Phrase-Based Clustering</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Xiang Ren, Ahmed El-Kishky, Chi Wang, Fangbo Tao, Clare R. Voss, Heng Ji, Jiawei Han</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>University of Illinois at Urbana-Champaign,<br>Microsoft Research, Redmond,<br>Rensselaer Polytechnic Institute,<br>Army Research Laboratory, Adelphi</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Entity Recognition and Typing,<br>Relation Phrase Clustering</p>
<h2 id="æ–‡ç« æ¥æº-1"><a href="#æ–‡ç« æ¥æº-1" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>KDD, 2015</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>è¿œç¨‹ç›‘ç£æ–¹æ³•åœ¨ç‰¹å®šé¢†åŸŸçš„å®ä½“æŠ½å–æ–¹é¢å­˜åœ¨é¢†åŸŸæ‰©å±•æ€§å·®ã€å®ä½“æ­§ä¹‰é—®é¢˜ä»¥åŠä¸Šä¸‹æ–‡ç¨€ç¼ºä¸‰å¤§é—®é¢˜ï¼Œæœ¬æ–‡ä¸»è¦ç ”ç©¶å¦‚ä½•æ”¹è¿›è¿™ä¸‰ä¸ªé—®é¢˜ã€‚</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>é’ˆå¯¹ä¸Šè¿°çš„ä¸‰ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†å„è‡ªå¯¹åº”çš„è§£å†³æ€è·¯ï¼šåªä½¿ç”¨æµ…å±‚çš„åˆ†ææ–¹æ³•ä¾‹å¦‚POSç­‰è§£å†³é¢†åŸŸç‹¬ç«‹æ€§é—®é¢˜ï¼›å¯¹entity mention(token span in the text document which refers to a real-world entity)åº”ç”¨è¯å½¢å’Œä¸Šä¸‹æ–‡è”åˆå»ºæ¨¡æ¥è§£å†³æ­§ä¹‰é—®é¢˜ï¼›æŒ–æ˜relation phraseå’Œentity mentionçš„å…±ç°æƒ…å†µï¼Œåˆ©ç”¨relation phraseå‰åå®ä½“ï¼ˆä¸»è¯­å’Œå®¾è¯­ï¼‰çš„ç±»åˆ«æ¥æ‰¾åˆ°ç›¸åŒçš„å…³ç³»ï¼Œè¿›è€Œè¾…åŠ©å®ä½“ç±»å‹çš„æ¨æ–­ã€‚åŸºäºä¸Šè¿°çš„æ€è·¯ï¼Œæœ¬æ–‡æå‡ºäº†ClusTypeçš„æ–¹æ³•ã€‚</p>
<p>ClusTypeçš„é—®é¢˜å®šä¹‰å¦‚ä¸‹ï¼šç»™å®šä¸€ä¸ªç‰¹å®šé¢†åŸŸçš„æ–‡æ¡£é›†åˆï¼Œä¸€ä¸ªå®ä½“ç±»å‹é›†åˆä»¥åŠä¸€ä¸ªçŸ¥è¯†åº“ï¼Œä¸»è¦å®Œæˆä¸‰ä¸ªä»»åŠ¡ï¼šç¬¬ä¸€ï¼Œä»æ–‡æ¡£é›†åˆä¸­æŠ½å–å‡ºå€™é€‰çš„entity mentioné›†åˆï¼›ç¬¬äºŒï¼Œå°†ä¸€éƒ¨åˆ†entity mentioné“¾æ¥åˆ°çŸ¥è¯†åº“ï¼Œä½œä¸ºç§å­entity mentioné›†åˆï¼›ç¬¬ä¸‰ï¼Œå¯¹äºå‰©ä½™æœªå®ŒæˆçŸ¥è¯†é“¾æ¥çš„entity mentioné›†åˆï¼Œé¢„æµ‹æ¯ä¸€ä¸ªentity mentionçš„å¯¹åº”å®ä½“ç±»åˆ«ã€‚</p>
<p>æ ¹æ®ä»»åŠ¡çš„å®šä¹‰ï¼Œæ•´ä¸ªæ¡†æ¶ä¹Ÿåˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼Œåˆ†åˆ«è§£å†³è¿™ä¸‰ä¸ªä»»åŠ¡ã€‚</p>
<p>æœ¬æ–‡æ–¹æ¡ˆçš„å…·ä½“æ€è·¯å¦‚ä¸‹ï¼š</p>
<p>1ã€æ„å»ºå…³ç³»å›¾</p>
<p>å…³ç³»å›¾çš„åŸºæœ¬æ ·å¼å¦‚ä¸‹ï¼š  </p>
<p><img src="media/graph.png" alt="graph"></p>
<p>å›¾å½“ä¸­çš„èŠ‚ç‚¹ä¸»è¦åˆ†ä¸ºä¸‰ç§ï¼šentity mention, surface name, relation phrase.<br>å›¾ä¸­çš„è¾¹çš„ç±»å‹ä¹Ÿæœ‰ä¸‰ç§ï¼šentity mentionå’Œsurface nameçš„å…³ç³»ã€surface nameå’Œrelation phraseåœ¨è¯­æ–™ä¸­çš„å…±ç°æƒ…å†µã€entity mentionå’Œentity mentionçš„å…³ç³»ï¼Œè¡¨ç°entity mentionä¹‹é—´çš„ç›¸ä¼¼ç¨‹åº¦ã€‚è¿™ä¸‰ä¸ªå…³ç³»å‡æ˜¯é€šè¿‡é‚»æ¥çŸ©é˜µçš„å½¢å¼è¡¨ç¤ºã€‚<br>å…³äºä¸‰ç§è¦ç´ çš„ç¡®å®šï¼Œrelation phraseçš„ç¡®å®šä¸»è¦å‚è€ƒå¼€æ”¾åŸŸæŠ½å–çš„æ–¹æ³•ï¼Œentity mentionçš„ç¡®å®šæ–¹æ³•ä¹Ÿæ¯”è¾ƒç®€å•ï¼šé¦–å…ˆæ‰¾åˆ°å›ºå®šé•¿åº¦çš„ä¸€ä¸ªé¢‘ç¹è¯ä¸²é›†ï¼›ä¸ºé›†åˆä¸­æ¯ä¸€ä¸ªè¯ä¸²è®¡ç®—ä¸¤ä¸¤ä¹‹é—´çš„å¾—åˆ†ï¼Œå¾—åˆ†è¶Šé«˜è¯æ˜è¶Šéœ€è¦åˆå¹¶ï¼›åœ¨åˆå¹¶çš„è¿‡ç¨‹ä¸­ï¼Œåˆ©ç”¨è´ªå¿ƒç®—æ³•ï¼Œä»å¾—åˆ†æœ€é«˜å¼€å§‹åˆå¹¶ï¼Œç›´åˆ°æ‰€æœ‰å¾—åˆ†å‡ä½äºæŸä¸€é˜ˆå€¼ã€‚</p>
<p>2ã€ç§å­é›†åˆçš„ç”Ÿæˆ</p>
<p>è¿™é‡Œåˆ©ç”¨äº†dbpedia-spotlightå·¥å…·è¿›è¡Œentity mentionåˆ°çŸ¥è¯†åº“çš„æ˜ å°„ï¼Œåªé€‰å–ç½®ä¿¡åº¦å¾—åˆ†é«˜äº0.8çš„ä½œä¸ºæœ‰æ•ˆè¾“å‡ºã€‚</p>
<p>3ã€å®ä½“ç±»å‹æ¨æ–­<br>ç›®æ ‡å‡½æ•°å¦‚ä¸‹ï¼š<br><img src="media/function.png" alt="function"><br>å…¬å¼å…±åˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼š<br>ç¬¬ä¸€éƒ¨åˆ†éµå¾ªå®ä½“å…³ç³»å…±ç°å‡è®¾ï¼šå¦‚æœä¸€ä¸ªsurface nameç»å¸¸åœ¨relation phraseå‰åå‡ºç°ï¼Œé‚£ä¹ˆå®ƒçš„ç±»å‹åº”è¯¥åŒrelation phraseå‰åå®ä½“çš„ç±»å‹ç›¸å…³ã€‚  </p>
<p>ç¬¬äºŒéƒ¨åˆ†éµå¾ªä¸¤ä¸ªå‡è®¾ã€‚<br>å‡è®¾ä¸€ï¼šå¦‚æœä¸¤ä¸ªrelation phraseç›¸ä¼¼ï¼Œé‚£ä¹ˆä»–ä»¬å‰åå®ä½“çš„ç±»å‹ä¹Ÿåº”è¯¥ç›¸ä¼¼ï¼›<br>å‡è®¾äºŒï¼šåˆ¤æ–­ä¸¤ä¸ªrelation phraseç›¸ä¼¼çš„ç‰¹å¾ä¸ºè¯å½¢ã€ä¸Šä¸‹æ–‡å’Œå…¶å‰åå®ä½“çš„ç±»å‹ã€‚<br>å› æ­¤ï¼Œç¬¬äºŒéƒ¨åˆ†çš„ä½œç”¨åœ¨äºæ ¹æ®ä¸¤ä¸ªå‡è®¾å»ºæ¨¡ä¸€ä¸ªåŸºäºjoint non-negative matrix factorizationçš„multi-view clustering.</p>
<p>ç¬¬ä¸‰éƒ¨åˆ†å°±æ˜¯å»ºæ¨¡entity mentionå¯¹åº”å®ä½“ç±»åˆ«ã€entity mentionä¹‹é—´çš„å…³ç³»ä»¥åŠå¼•å…¥ç§å­é›†åˆçš„ç›‘ç£ï¼Œåˆ©ç”¨ä¸€ä¸ªentity mentionçš„surface nameå’Œrelation phraseå¯¹åº”çš„å…³ç³»ç±»åˆ«æ¨æ–­å…³ç³»ç±»å‹ï¼ŒåŒæ—¶è€ƒè™‘åˆ°ç›¸ä¼¼entity mentionçš„ä¸€è‡´æ€§ä»¥åŠå¯¹äºç§å­é›†åˆçš„é¢„æµ‹è¯¯å·®å‡½æ•°ã€‚</p>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>æœ¬æ–‡ä¸»è¦å€Ÿé‰´ä¸¤æ–¹é¢çš„å·¥ä½œï¼Œä¸€éƒ¨åˆ†æ˜¯è¿œè·ç¦»ç›‘ç£çš„æ–¹æ³•ï¼Œå¦ä¸€éƒ¨åˆ†æ˜¯å¼€æ”¾å…³ç³»æŠ½å–ã€‚<br>è¿œè·ç¦»ç›‘ç£çš„å·¥ä½œä¸»è¦æœ‰ï¼š<br>1ã€N. Nakashole, T. Tylenda, and G. Weikum. Fine-grained semantic typing of emerging entities. In ACL, 2013.<br>2ã€T. Lin, O. Etzioni, et al. No noun phrase left behind: de- tecting and typing unlinkable entities. In EMNLP, 2012.<br>3ã€X. Ling and D. S. Weld. Fine-grained entity recognition. In AAAI, 2012.<br>å¼€æ”¾å…³ç³»æŠ½å–çš„å·¥ä½œä¸»è¦æœ‰ï¼š<br>1ã€A. Fader, S. Soderland, and O. Etzioni. Identifying relations for open information extraction. In EMNLP, 2011.</p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡é€šè¿‡å¯¹äºè¿œç¨‹ç›‘ç£æ–¹æ³•çš„ç¼ºé™·åˆ†æï¼Œæå‡ºäº†ä¸€ç§åŸºäºå…³ç³»çŸ­è¯­çš„å®ä½“è¯†åˆ«æ–¹æ³•ã€‚åŒæ—¶ï¼Œè¿˜æå‡ºäº†ä¸€ä¸ªé¢†åŸŸæ— å…³çš„ç”Ÿæˆrelation phraseå’Œentity mentionã€‚é€šè¿‡å°†å…³ç³»çŸ­è¯­çš„èšç±»å’Œå®ä½“ç±»å‹çš„è¯†åˆ«è”åˆå»ºæ¨¡ï¼Œå¯ä»¥åœ¨è§£å†³å®ä½“æ­§ä¹‰å’Œä¸Šä¸‹æ–‡é—®é¢˜ä¸Šå‘æŒ¥å¾ˆå¤§çš„ä½œç”¨ï¼Œè€Œä¸”å¯ä»¥æ ¹æ®entity mentionçš„surface nameå’Œrelation phraseé¢„æµ‹å…³ç³»ç±»å‹ã€‚åŒæ—¶ï¼Œæˆ‘ä¸ªäººè®¤ä¸ºï¼Œå°†å®ä½“è¯†åˆ«å’Œå…³ç³»è¯†åˆ«è¿›è¡Œè”åˆå»ºæ¨¡å¯ä»¥èµ·åˆ°ä¸€ä¸ªç›¸äº’ä¿ƒè¿›çš„ä½œç”¨ï¼Œè€Œä¸”å¯ä»¥å¾ˆå¥½çš„é¿å…åœ¨è¿™ä¸¤ä¸ªä»»åŠ¡å½“ä¸­å¼•å…¥æ·±åº¦è¯­æ³•åˆ†æçš„å·¥å…·å¦‚ä¾å­˜ã€å¥æ³•åˆ†æç­‰ï¼Œå‡å°‘è¯¯å·®ç§¯ç´¯å’Œé¢†åŸŸä¾èµ–æ€§ã€‚æœªæ¥ä¸¤ç§ä»»åŠ¡ç»“åˆä¾æ—§æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ç ”ç©¶æ–¹å‘å’Œçƒ­ç‚¹ã€‚</p>
<h1 id="Bootstrapped-Text-level-Named-Entity-Recognition-for-Literature"><a href="#Bootstrapped-Text-level-Named-Entity-Recognition-for-Literature" class="headerlink" title="Bootstrapped Text-level Named Entity Recognition for Literature"></a><a href="http://people.eng.unimelb.edu.au/tbaldwin/pubs/acl2016-ner.pdf" target="_blank" rel="external">Bootstrapped Text-level Named Entity Recognition for Literature</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Julian Brookeï¼ŒTimothy Baldwinï¼ŒAdam Hammond</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>English and Comparative Literature San Diego State University<br>Computing and Information Systems The University of Melbourne</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>NERï¼ŒBrown clusteringï¼ŒText-level context classifier</p>
<h2 id="æ–‡ç« æ¥æº-2"><a href="#æ–‡ç« æ¥æº-2" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ACL2016</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>åœ¨æ— æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œå¯¹Literatureåšå‘½åå®ä½“è¯†åˆ«</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æ¨¡å‹ä¸»è¦åˆ†ä¸ºå››ä¸ªéƒ¨åˆ†ï¼š<br>1ã€Corpus preparation and segmentation<br>ä½¿ç”¨GutenTag toolå¯¹è¯­æ–™åšåŸºæœ¬çš„åç§°åˆ‡åˆ†<br>2ã€Brown clustering<br>åœ¨é¢„å…ˆåˆ‡åˆ†å¥½çš„é¢„æ–™ä¸ŠåšBrown clusteringã€‚æ ¹æ®Brown clusteringçš„èšç±»ä¸­çš„æ¯ä¸ªç±»çš„rankå€¼ï¼Œå°†èšç±»ç»“æœåˆ†æˆä¸‰ä¸ªç±»åˆ«ï¼ˆPERSONï¼ŒLOCATIONï¼Œcatch- all categoryï¼‰å¹¶å°†å…¶ä½œä¸ºBootstrapçš„ç§å­è¿›è¡Œè®­ç»ƒã€‚<br>3ã€Text-level context classifier<br>ä¸ºäº†è§£å†³Brown clusteringèšç±»ç»“æœå¯èƒ½å‡ºç°çš„ä¸€äº›confusionï¼Œå¼•å…¥äº†Text-level context classifierçš„æ€æƒ³ã€‚æ„å»ºåç§°ç‰¹å¾å‘é‡ï¼Œå°†ç§å­é›†æ•°æ®æ”¾åˆ°LRæ¨¡å‹ä¸­è¿›è¡Œè®­ç»ƒï¼Œå¾—åˆ°åˆ†ç±»æ¨¡å‹ã€‚<br>4ã€Improved phrase classification<br>ä¸ºè§£å†³æ¨¡å‹å¯¹çŸ­è¯­åè¯åˆ†ç±»ä¸å‡†ç¡®é—®é¢˜ï¼Œå¼•å…¥äº†æ”¹è¿›çš„çŸ­è¯­åç§°åˆ†ç±»æ–¹æ³•ï¼Œåœ¨LRæ¨¡å‹å¾—åˆ°çš„p(t|r)å€¼çš„åŸºç¡€ä¸Šè¿›ä¸€æ­¥å¯¹å…¶ä¼˜åŒ–å¾—åˆ°ä¿®æ­£çš„pâ€™(t|r) ï¼Œä¿®æ­£æ–¹æ³•å¦‚ä¸‹ï¼š<br> <img src="media/imag1.png" alt="imag1"></p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>1ã€datasetï¼š<a href="https://www.gutenberg.org" target="_blank" rel="external">https://www.gutenberg.org</a><br>2ã€GutenTag toolï¼š<a href="http://www.projectgutentag.org" target="_blank" rel="external">http://www.projectgutentag.org</a>   </p>
<h2 id="ç›¸å…³å·¥ä½œ-1"><a href="#ç›¸å…³å·¥ä½œ-1" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>åœ¨Literatureä¸ŠåšNERä»»åŠ¡çš„å·¥ä½œåŒ…æ‹¬ï¼š<br>1ã€(He et al., 2013)character speech identification<br>2ã€(Bamman et al., 2014)analysis of characterization<br>3ã€(Vala et al., 2015)character identification<br>4ã€(Vala et al. 2015)character identification deal the multiple aliases of the same character problem</p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºï¼Œä½¿ç”¨äº†æ— ç›‘ç£å­¦ä¹ æ¨¡å‹å¯¹ç‰¹å®šé¢†åŸŸ(fiction)çŸ¥è¯†åšNERï¼Œå¹¶å–å¾—äº†å¾ˆå¥½çš„æ•ˆæœã€‚ä½†æ˜¯æœ¬æ–‡æ–¹æ³•ä¸»è¦ç ”ç©¶ç‰¹å®šé¢†åŸŸçŸ¥è¯†çš„NERï¼Œå› æ­¤æœ¬æ–¹æ³•ä½¿ç”¨åœ¨è·¨é¢†åŸŸè·¨è¯­è¨€çš„NERè¯†åˆ«ä»»åŠ¡ä¸­å¹¶ä¸èƒ½è¾¾åˆ°å¾ˆå¥½çš„æ•ˆæœï¼Œæ–¹æ³•å…·æœ‰ä¸€å®šçš„å±€é™æ€§ã€‚</p>
<h1 id="Recognizing-Named-Entities-in-Tweets"><a href="#Recognizing-Named-Entities-in-Tweets" class="headerlink" title="Recognizing Named Entities in Tweets"></a><a href="http://people.dbmi.columbia.edu/~szhang/P11-1037.pdf" target="_blank" rel="external">Recognizing Named Entities in Tweets</a></h1><h2 id="ä½œè€…-3"><a href="#ä½œè€…-3" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Xiaohua Liu, Shaodian Zhang, Furu Wei, Ming Zhou</p>
<h2 id="å•ä½-3"><a href="#å•ä½-3" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Harbin Institute of Technology,<br>Shanghai Jiao Tong University,<br>Microsoft Research Asia</p>
<h2 id="å…³é”®è¯-3"><a href="#å…³é”®è¯-3" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Named Entity Recognition, Semi-Supervised Learning</p>
<h2 id="æ–‡ç« æ¥æº-3"><a href="#æ–‡ç« æ¥æº-3" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ACL, 2011</p>
<h2 id="é—®é¢˜-3"><a href="#é—®é¢˜-3" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•å»ºç«‹ä¸€ç§åŠç›‘ç£å­¦ä¹ çš„æ¨¡å‹å¯¹ä½¿ç”¨éæ­£å¼è¯­è¨€çš„tweetè¿›è¡Œå‘½åå®ä½“è¯†åˆ«ï¼Ÿ</p>
<h2 id="æ¨¡å‹-3"><a href="#æ¨¡å‹-3" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>ç°æœ‰çš„åˆ†è¯ã€è¯æ€§æ ‡æ³¨ã€NERå·¥å…·è§£å†³éæ­£å¼è¯­è¨€å ä¸»å¯¼çš„tweetæ—¶å¸¸å¸¸ä¼šå¤±æ•ˆï¼Œå¾—ä¸åˆ°ä»¤äººæ»¡æ„çš„ç»“æœï¼Œè€Œtwitterä½œä¸ºä¸€ç§ä¸»æµçš„ç¤¾äº¤åª’ä½“ï¼Œæœ‰ç€ä¸°å¯Œçš„è¯­æ–™å’Œéå¸¸é«˜çš„ç ”ç©¶ä»·å€¼ã€‚æœ¬æ–‡ä»¥tweetä¸ºç ”ç©¶å¯¹è±¡ï¼Œæå‡ºäº†ä¸€ç§åŸºäºbootstrappingçš„åŠç›‘ç£å­¦ä¹ æ–¹æ¡ˆã€‚</p>
<p>tweetçš„NERä»»åŠ¡åŒ…æ‹¬å››ç±»å®ä½“ï¼šPersonã€Locationã€Organizationå’ŒProductï¼Œæ ‡æ³¨æ–¹æ³•ç”¨BILOUæ ‡æ³¨æ³•ï¼Œè€Œæ²¡æœ‰ç”¨ç»å…¸çš„IOBæ ‡æ³¨æ³•ã€‚</p>
<p>æœ¬æ–‡æ–¹æ¡ˆçš„å…·ä½“æ€è·¯å¦‚ä¸‹ï¼š</p>
<p><img src="media/knn-crf.png" alt="knn-crf"></p>
<p>1ã€KNNåˆ†ç±»å™¨</p>
<p>å°†tweetä¸­çš„æ¯ä¸ªè¯ç”¨è¯è¢‹æ¨¡å‹è¡¨ç¤ºï¼Œè¾“å…¥åˆ°KNNä¸­å¾—åˆ°ä¸€ä¸ªåˆ†ç±»æ ‡ç­¾ï¼Œè¿™ä¸ªæ ‡ç­¾ä½œä¸ºCRFæ ‡æ³¨æ—¶çš„è¾“å…¥ã€‚</p>
<p>2ã€CRFæ ‡æ³¨å™¨</p>
<p>NERæ˜¯ä¸€ä¸ªå…¸å‹çš„åºåˆ—æ ‡æ³¨ä»»åŠ¡ï¼ŒCRFæ˜¯è§£å†³åºåˆ—æ ‡æ³¨é—®é¢˜çš„ä¸€ä¸ªå…¸å‹æ–¹æ³•ã€‚</p>
<p>3ã€è®­ç»ƒè¿‡ç¨‹ï¼š</p>
<p>ï¼ˆ1ï¼‰å…ˆæ ¹æ®å·²æœ‰æ ‡æ³¨æ•°æ®ï¼Œè®­ç»ƒå¥½åˆå§‹çš„KNNå’ŒCRFæ¨¡å‹ã€‚<br>ï¼ˆ2ï¼‰è·å¾—æœªæ ‡æ³¨çš„tweetï¼Œæ¯æ¡tweetä¸­çš„æ¯ä¸ªè¯éƒ½ç»è¿‡KNNåˆ†ç±»å™¨ï¼Œå¾—åˆ°ä¸€ä¸ªåˆ†ç±»æ ‡ç­¾å’Œç›¸åº”çš„æ¦‚ç‡ï¼Œå¦‚æœè¿™ä¸ªæ¦‚ç‡å¤§äºé¢„è®¾é˜ˆå€¼ï¼Œåˆ™æ›´æ–°è¿™ä¸ªæ ‡ç­¾ç»™è¯¥è¯ã€‚æ•´ä¸ªtweetç»è¿‡KNNä¹‹åï¼Œä½œä¸ºç‰¹å¾è¾“å…¥åˆ°CRFæ¨¡å‹ä¸­è¿›è¡Œé¢„æµ‹ï¼Œå¦‚æœé¢„æµ‹å‡ºçš„ç»“æœæ¦‚ç‡å¤§äºé¢„è®¾é˜ˆå€¼ï¼Œåˆ™è®¤ä¸ºè¯¥æ ‡æ³¨ç»“æœå¯é ï¼ŒåŠ å…¥å¯é ç»“æœé›†ä¸­ã€‚<br>ï¼ˆ3ï¼‰å½“å¯é ç»“æœé›†çš„æ•°é‡è¾¾åˆ°N=1000æ—¶ï¼Œåˆ™é‡æ–°è®­ç»ƒKNNå’ŒCRFæ¨¡å‹ï¼Œå¹¶ä¸”æ¸…ç©ºå¯é ç»“æœé›†ï¼Œç»§ç»­ï¼ˆ2ï¼‰çš„è¿‡ç¨‹ã€‚</p>
<h2 id="ç›¸å…³å·¥ä½œ-2"><a href="#ç›¸å…³å·¥ä½œ-2" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>åŸºäºbootstrappingåšNERä»»åŠ¡çš„å·¥ä½œè¿˜åŒ…æ‹¬ï¼š</p>
<p>1ã€Instance weighting for domain adaptation in nlp, 2007<br>2ã€Domain adaption bootstrapping for named entity recognition, 2009</p>
<h2 id="ç®€è¯„-3"><a href="#ç®€è¯„-3" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡æ˜¯æ¯”è¾ƒæ—©çš„æ–‡ç« äº†ï¼Œç®—æ˜¯æ¯”è¾ƒæ—©åœ°æ¢ç´¢tweetæ–‡æœ¬æŒ–æ˜ã€‚bootstrappingæ˜¯ä¸€ç§ç»å…¸çš„åŠç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡ä»å¤§é‡çš„éæ ‡æ³¨æ–‡æœ¬ä¸­è¿›è¡Œå­¦ä¹ å’Œè¡¥å……ï¼Œæ¥æé«˜è®­ç»ƒæ•°æ®é›†çš„è§„æ¨¡ã€‚tweetæ˜¯ä¸€ç§éæ­£å¼è¯­è¨€çš„æ–‡æœ¬ï¼Œç°æœ‰çš„NLPå·¥å…·åŸºæœ¬ä¸Šéƒ½ä¸å¥½ç”¨ï¼ŒåŒ…æ‹¬å¾®åšã€è®ºå›çš„æ–‡æœ¬éƒ½é¢ä¸´è¿™æ ·çš„é—®é¢˜ï¼Œè€Œä¸”è¿™æ ·çš„æ–‡æœ¬å æ®ç€æ›´å¤§çš„æ¯”é‡ï¼Œéå¸¸æœ‰å¿…è¦å¯¹ç±»ä¼¼çš„æ–‡æœ¬è¿›è¡ŒNLPå·¥å…·çš„ç ”ç©¶ï¼Œå¤§æ¦‚æƒ³äº†ä¸¤ç§æ€è·¯ï¼Œè¦ä¹ˆä¸“é—¨åœ°æ¥ç ”ç©¶ä¸€å¥—é€‚åˆè¿™ç§éæ­£å¼æ–‡æœ¬çš„å·¥å…·ï¼Œè¦ä¹ˆæƒ³åŠæ³•å°†è¿™æ ·çš„æ–‡æœ¬è½¬åŒ–ä¸ºæ­£å¼çš„è¯­è¨€ï¼Œç”¨ç°æœ‰çš„å·¥å…·æ¥è§£å†³é—®é¢˜ã€‚ç°åœ¨å¾ˆç«çš„chatbotå¯¹è¯ç†è§£ä¹Ÿé¢ä¸´è¿™æ ·çš„é—®é¢˜ï¼Œå¤§å®¶åœ¨å’Œbotå¯¹è¯çš„æ—¶å€™è¯´çš„è¯ä¹Ÿæ˜¯ç±»ä¼¼çš„éæ­£å¼è¯­è¨€ï¼Œå¦‚ä½•å‡†ç¡®ç†è§£å’Œåˆ†æè¿™ç±»è¯ï¼Œå¯¹äºchatbotèƒ½å¦çœŸçš„è¢«åº”ç”¨è‡³å…³é‡è¦ã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>NERçš„åº”ç”¨åœºæ™¯éå¸¸å¹¿æ³›ï¼ŒåŸºäºç›‘ç£å­¦ä¹ çš„è®­ç»ƒæ–¹æ³•æ˜¯æœ€ç®€å•ã€æœ€æœ‰æ•ˆçš„æ–¹æ³•ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­å¸¸å¸¸ä¼šé‡åˆ°è®­ç»ƒæ•°æ®éš¾ä»¥è·å¾—çš„å°´å°¬å¢ƒåœ°ï¼Œé‚£ä¹ˆåŠç›‘ç£å’Œæ— ç›‘ç£å­¦ä¹ çš„ç ”ç©¶æ­£æ˜¯ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå€¼å¾—å…³æ³¨ï¼æ„Ÿè°¢@é«˜æ¡“ @éŸ©å…¶ç› @min279 @zhangjun å››ä½ç«¥é‹çš„è¾›å‹¤å·¥ä½œã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-12-04T18:06:33.000Z"><a href="/2016/12/04/æœ¬å‘¨å€¼å¾—è¯»-2016-11-28-2016-12-02/">2016-12-04</a></time>
      
      
  
    <h1 class="title"><a href="/2016/12/04/æœ¬å‘¨å€¼å¾—è¯»-2016-11-28-2016-12-02/">æœ¬å‘¨å€¼å¾—è¯»(2016.11.28-2016.12.02)</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="ä¸€å‘¨å€¼å¾—è¯»"><a href="#ä¸€å‘¨å€¼å¾—è¯»" class="headerlink" title="ä¸€å‘¨å€¼å¾—è¯»"></a>ä¸€å‘¨å€¼å¾—è¯»</h1><h2 id="A-Simple-Fast-Diverse-Decoding-Algorithm-for-Neural-Generation"><a href="#A-Simple-Fast-Diverse-Decoding-Algorithm-for-Neural-Generation" class="headerlink" title="A Simple, Fast Diverse Decoding Algorithm for Neural Generation "></a><a href="http://t.cn/Rfj8F3k" target="_blank" rel="external">A Simple, Fast Diverse Decoding Algorithm for Neural Generation </a></h2><p>ã€beam searchã€‘åœ¨ç”¨seq2seqåšä¸€äº›nlpä»»åŠ¡çš„æ—¶å€™ï¼Œè§£ç å™¨è´Ÿè´£å°†ç»“æœä¸€ä¸ªä¸ªåœ°è§£å‡ºæ¥ã€‚è§£ç å‡ºçš„ç»“æœåº”è¯¥å…·æœ‰å¤šæ ·æ€§çš„ç‰¹ç‚¹ï¼Œå°¤å…¶æ˜¯åœ¨chatbotåº”ç”¨ä¸­ä½“ç°æ›´ä¸ºçªå‡ºã€‚ä¼ ç»Ÿçš„beam searchç®—æ³•åœ¨è§£ç æ—¶å¸¸å¸¸ä¼šè§£å‡ºä¸€äº›éå¸¸å®‰å…¨ä½†æ˜¯æ²¡æœ‰å®é™…æ„ä¹‰çš„responseï¼Œç±»ä¼¼äºâ€œå‘µå‘µå‘µâ€ï¼Œâ€œæˆ‘è®¤ä¸ºæ˜¯è¿™æ ·çš„â€è¿™é‡Œçš„è¯ã€‚æœ¬æ–‡çš„å·¥ä½œé’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ”¹è¿›ç‰ˆçš„beam searchç®—æ³•ï¼Œé€šè¿‡å¼•å…¥ä¸€ä¸ªæƒ©ç½šå› å­æ¥å½±å“æ’åºç»“æœï¼Œä»è€Œä½¿å¾—è§£ç å‡ºçš„ç»“æœæ›´åŠ å¤šæ ·æ€§ã€‚å»ºè®®ç ”ç©¶seq2seqæˆ–è€…å°è¯•ç”¨å®ƒæ¥è§£å†³ä¸€äº›é—®é¢˜çš„ç«¥é‹å¯ä»¥ç²¾è¯»æ­¤æ–‡ã€‚æœ¬æ–‡æ¥è‡ªJiwei Liã€‚</p>
<h2 id="Dialogue-Learning-With-Human-In-The-Loop"><a href="#Dialogue-Learning-With-Human-In-The-Loop" class="headerlink" title="Dialogue Learning With Human-In-The-Loop "></a><a href="http://t.cn/Rf8XOcr" target="_blank" rel="external">Dialogue Learning With Human-In-The-Loop </a></h2><p>ã€å¯¹è¯ç³»ç»Ÿã€‘ã€åœ¨çº¿å­¦ä¹ ã€‘åœ¨çº¿å­¦ä¹ æ˜¯chatbotåœ¨ä¸äººäº¤äº’çš„è¿‡ç¨‹ä¸­è‡ªåŠ¨å­¦ä¹ çš„ä¸€ç§æ–¹æ³•ï¼Œå¿«é€Ÿè€Œä¸”æœ‰æ•ˆã€‚æœ¬æ–‡ç»™å‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„åœ¨çº¿äº¤äº’å­¦ä¹ æ–¹æ¡ˆï¼Œä½œè€…æ˜¯Jiwei Liã€‚å»ºè®®ç ”ç©¶æˆ–è€…åšchatbotåº”ç”¨çš„ç«¥é‹å¯ä»¥å¥½å¥½ç ”è¯»æ­¤æ–‡ã€‚</p>
<h2 id="Visual-Dialog"><a href="#Visual-Dialog" class="headerlink" title="Visual Dialog "></a><a href="http://t.cn/RfH7BWW" target="_blank" rel="external">Visual Dialog </a></h2><p>ã€å¤šæ¨¡æ€å¯¹è¯ã€‘å¤šæ¨¡æ€é—®ç­”ï¼ˆVQAï¼‰æ˜¯ä¸€ä¸ªæ¯”è¾ƒå¥½ç©çš„ä»»åŠ¡ï¼Œæœ¬æ–‡åœ¨æ­¤åŸºç¡€ä¸Šæå‡ºäº†ä¸€ä¸ªæ›´åŠ å¤æ‚è€Œä¸”æœ‰æ„æ€çš„ä»»åŠ¡ï¼Œå³ç»™å®šä¸€å¼ å›¾åƒï¼Œç»™å‡ºè‹¥å¹²ä¸ªé—®å’Œç­”çš„å†å²å¯¹è¯ï¼Œæå‡ºä¸€ä¸ªæ–°é—®é¢˜ï¼Œè¦æ±‚ç»™å‡ºæ­£ç¡®ç­”æ¡ˆã€‚é—®é¢˜ä¸ä»…ä»…éœ€è¦ç†è§£å›¾ç‰‡ï¼Œè€Œä¸”éœ€è¦ç†è§£å†å²å¯¹è¯ã€‚æ–°çš„ä»»åŠ¡æ„å‘³ç€æ–°çš„å‘ï¼Œæ–‡ä¸­ç»™å‡ºäº†ä¸€äº›å¸¸è§NNæ¨¡å‹ä½œä¸ºbaselineï¼Œæ„Ÿå…´è¶£çš„ç«¥é‹å¯ä»¥å…¥å‘ã€‚</p>
<h2 id="Neural-Machine-Translation-with-Latent-Semantic-of-Image-and-Text"><a href="#Neural-Machine-Translation-with-Latent-Semantic-of-Image-and-Text" class="headerlink" title="Neural Machine Translation with Latent Semantic of Image and Text "></a><a href="http://t.cn/RfjRQMP" target="_blank" rel="external">Neural Machine Translation with Latent Semantic of Image and Text </a></h2><p>ã€Visual NMTã€‘å°±åœ¨NMTè¢«è®¨è®ºåœ°å¦‚ç«å¦‚è¼çš„æ—¶å€™ï¼Œè¿˜æœ‰ä¸€éƒ¨åˆ†å·¥ä½œæ˜¯ç»“åˆå¤šæ¨¡æ€ï¼ˆå›¾ç‰‡ï¼‰æ¥åšæœºå™¨ç¿»è¯‘ï¼Œå› ä¸ºäººç±»è·å–ä¿¡æ¯ä¸ä»…ä»…å¯ä»¥é€šè¿‡æ–‡å­—ï¼Œå›¾ç‰‡ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„å­¦ä¹ èµ„æºã€‚</p>
<h2 id="Scalable-Bayesian-Learning-of-Recurrent-Neural-Networks-for-Language-Modeling"><a href="#Scalable-Bayesian-Learning-of-Recurrent-Neural-Networks-for-Language-Modeling" class="headerlink" title="Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling "></a><a href="http://t.cn/RfjELTY" target="_blank" rel="external">Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling </a></h2><p>ã€è´å¶æ–¯å­¦ä¹ ã€‘é€šè¿‡BPTTæ¥è®­ç»ƒçš„RNNåœ¨è§£å†³é—®é¢˜ä¸Šä¼šå­˜åœ¨è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼Œä¸€ä¸ªä¸»è¦åŸå› æ˜¯éšæœºä¼˜åŒ–è®­ç»ƒæ— æ³•ç»™å‡ºæ¨¡å‹æƒé‡çš„æ¦‚ç‡ä¼°è®¡ï¼Œæœ¬æ–‡é€šè¿‡æœ€è¿‘stochastic gradient Markov Chain Monte Carloçš„ç ”ç©¶æ¥è¯•ç€å­¦ä¹ æ¨¡å‹æƒé‡çš„æ¦‚ç‡ã€‚è¯­è¨€æ¨¡å‹çš„å®éªŒç»“æœå’Œå…¶ä»–çš„ç›¸å…³å®éªŒç»“æœè¡¨æ˜æœ¬æ–‡æ‰€ç”¨çš„æ–¹æ³•ç¡®å®æœ‰æ•ˆã€‚</p>
<h2 id="Learning-Python-Code-Suggestion-with-a-Sparse-Pointer-Network"><a href="#Learning-Python-Code-Suggestion-with-a-Sparse-Pointer-Network" class="headerlink" title="Learning Python Code Suggestion with a Sparse Pointer Network "></a><a href="http://t.cn/RfjEjY5" target="_blank" rel="external">Learning Python Code Suggestion with a Sparse Pointer Network </a></h2><p>ã€ä»£ç è¡¥å…¨ã€‘æœ¬æ–‡ç ”ç©¶çš„é—®é¢˜éå¸¸æœ‰æ„æ€ï¼Œå°±æ˜¯å¤§å®¶å¸¸è§çš„IDEä»£ç è¡¥å…¨åŠŸèƒ½ã€‚ç°æœ‰çš„IDEå¯¹é™æ€ç¼–ç¨‹è¯­è¨€æ”¯æŒçš„æ¯”è¾ƒå¥½ï¼Œå¯¹äºåŠ¨æ€ç¼–ç¨‹è¯­è¨€æ”¯æŒçš„ä¸€èˆ¬ï¼Œè€Œä¸”ä¸€èˆ¬éƒ½æ˜¯è¡¥å…¨æŸä¸ªå‡½æ•°æˆ–è€…æ–¹æ³•ä¹‹ç±»çš„ï¼Œè€Œä¸èƒ½ç»™å‡ºæ›´å¤æ‚çš„ä»£ç ã€‚æœ¬æ–‡é’ˆå¯¹è¿™ä¸ªé—®é¢˜ï¼Œæ„é€ äº†ä¸€ä¸ªå¤§å‹çš„python codeæ•°æ®é›†ï¼Œå¹¶ä¸”ç”¨äº†æ¯”è¾ƒæµè¡Œçš„Pointer Networkæ¨¡å‹æ¥åšç«¯åˆ°ç«¯çš„è®­ç»ƒï¼Œå–å¾—äº†ä¸é”™çš„æ•ˆæœã€‚ä»£ç è¡¥å…¨åœ¨å®é™…åº”ç”¨ä¸­éå¸¸æœ‰ç”¨ï¼Œä½†æƒ³åšåˆ°å¾ˆå¤æ‚ã€å¾ˆæ™ºèƒ½çš„è¡¥å…¨è¿˜æœ‰å¾ˆé•¿çš„è·¯ã€‚ä¸è¿‡è¿™ä¸ªtopicè¿˜æ˜¯ä¸€ä¸ªéå¸¸æœ‰æ„æ€çš„ä¸œè¥¿ã€‚</p>
<h2 id="Joint-Copying-and-Restricted-Generation-for-Paraphrase"><a href="#Joint-Copying-and-Restricted-Generation-for-Paraphrase" class="headerlink" title="Joint Copying and Restricted Generation for Paraphrase "></a><a href="http://t.cn/RfHAsim" target="_blank" rel="external">Joint Copying and Restricted Generation for Paraphrase </a></h2><p>ã€NLGã€‘æœ¬æ–‡çš„æ€è·¯ä¸Pointer Networkæˆ–è€…Copynetç±»ä¼¼ï¼Œåœ¨ç”¨seq2seqåšè‡ªç„¶è¯­è¨€ç”Ÿæˆæ—¶ï¼Œå¢åŠ ä¸€ä¸ªåˆ¤æ–­çš„ç¯èŠ‚ï¼Œæ¥å†³å®šæ¥ä¸‹æ¥çš„è¿™ä¸ªè¯æ˜¯ä»sourceæ¥copyè¿˜æ˜¯ç”¨decoderæ¥rewriteã€‚</p>
<h2 id="Context-aware-Natural-Language-Generation-with-Recurrent-Neural-Networks"><a href="#Context-aware-Natural-Language-Generation-with-Recurrent-Neural-Networks" class="headerlink" title="Context-aware Natural Language Generation with Recurrent Neural Networks "></a><a href="http://t.cn/RfEClfC" target="_blank" rel="external">Context-aware Natural Language Generation with Recurrent Neural Networks </a></h2><p>ã€NLGã€‘è®ºæ–‡çš„æ–¹æ³•ã€æ¨¡å‹æ²¡æœ‰å¤ªå¤šçš„å€¼å¾—è¯´çš„åœ°æ–¹ï¼Œå€’æ˜¯åº”ç”¨çš„ç‚¹éå¸¸æœ‰æ„æ€ï¼Œæ ¹æ®å•†å“çš„ä¸Šä¸‹æ–‡æ¥ä¼ªé€ è¯„è®ºï¼Œäººå·¥è¯„åˆ¤æ—¶æœ‰50%ä»¥ä¸Šçš„ä¼ªé€ è¯„è®ºéƒ½é€šè¿‡äº†ï¼Œ90%ä»¥ä¸Šéª—è¿‡äº†ç°æœ‰çš„è¯†åˆ«ç®—æ³•ã€‚æœ‰ç‚¹é“é«˜ä¸€å°ºé­”é«˜ä¸€ä¸ˆçš„æ„Ÿè§‰ï¼Œå¦‚æœè¿™ç¯‡paperçš„ç»“æœç¡®å®è¿™ä¹ˆç‰›çš„è¯ï¼Œç¡®å®å¾ˆæœ‰æ„æ€ï¼Œå€¼å¾—ç ”ç©¶ä¸€ä¸‹ã€‚</p>
<h2 id="MS-MARCO-A-Human-Generated-MAchine-Reading-COmprehension-Dataset"><a href="#MS-MARCO-A-Human-Generated-MAchine-Reading-COmprehension-Dataset" class="headerlink" title="MS MARCO: A Human Generated MAchine Reading COmprehension Dataset "></a><a href="http://t.cn/RfH2eXu" target="_blank" rel="external">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset </a></h2><p>ã€æœºå™¨é˜…è¯»ç†è§£ã€‘ã€æ•°æ®ç¦åˆ©ã€‘å¾®è½¯æ”¾å‡ºäº†ä¸€ä¸ª100kè§„æ¨¡çš„æœºå™¨é˜…è¯»ç†è§£æ•°æ®é›†ï¼Œæ•°æ®æ¥æºäºçœŸå®çš„Bingæœç´¢queryã€‚æ•°æ®åŒ…æ‹¬ï¼šqueryã€10ä¸ªç›¸å…³çš„passageå’Œqueryå¯¹åº”çš„answerã€‚</p>
<h2 id="NewsQA-A-Machine-Comprehension-Dataset"><a href="#NewsQA-A-Machine-Comprehension-Dataset" class="headerlink" title="NewsQA: A Machine Comprehension Dataset "></a><a href="http://t.cn/Rf8MPnf" target="_blank" rel="external">NewsQA: A Machine Comprehension Dataset </a></h2><p>ã€æœºå™¨é˜…è¯»ç†è§£ã€‘ã€æ•°æ®ç¦åˆ©ã€‘Maluubaå…¬å¸æ”¾å‡ºä¸€ä¸ªæ–°çš„æœºå™¨é˜…è¯»ç†è§£çš„æ•°æ®é›†ï¼Œè§„æ¨¡åœ¨100kå·¦å³ï¼Œæ•°æ®æ¥æºä¸ºCNNæ–°é—»ã€‚é€šè¿‡ç”¨å¤šä¸ªä¹‹å‰è¡¨ç°æ¯”è¾ƒå¥½çš„NNæ¨¡å‹å’Œäººå·¥ç»“æœå¯¹æ¯”ï¼Œå‘ç°F1æŒ‡æ ‡å­˜åœ¨25.3%çš„å·®è·ï¼Œè¯´æ˜æœ¬æ•°æ®é›†éœ€è¦æ›´å¥½çš„æ¨¡å‹æ¥è¿›è¡Œç ”ç©¶ã€‚æ•°æ®é›†å·²å…¬å¼€ï¼Œåœ°å€æ˜¯ï¼š<a href="http://datasets.maluuba.com/NewsQA" target="_blank" rel="external">http://datasets.maluuba.com/NewsQA</a></p>
<h1 id="ä¸€å‘¨èµ„æº"><a href="#ä¸€å‘¨èµ„æº" class="headerlink" title="ä¸€å‘¨èµ„æº"></a>ä¸€å‘¨èµ„æº</h1><h2 id="ä¸­å›½äººå·¥æ™ºèƒ½å­¦ä¼šé€šè®¯"><a href="#ä¸­å›½äººå·¥æ™ºèƒ½å­¦ä¼šé€šè®¯" class="headerlink" title="ä¸­å›½äººå·¥æ™ºèƒ½å­¦ä¼šé€šè®¯"></a><a href="http://t.cn/Rf8Yvwn" target="_blank" rel="external">ä¸­å›½äººå·¥æ™ºèƒ½å­¦ä¼šé€šè®¯</a></h2><p>ã€Šä¸­å›½äººå·¥æ™ºèƒ½å­¦ä¼šé€šè®¯ã€‹ï¼Œæœ¬æœŸä¸ºå­¦ä¼šä¼˜ç§€åšå£«è®ºæ–‡ä¸“åˆŠ</p>
<h2 id="C-wrapper"><a href="#C-wrapper" class="headerlink" title="C++ wrapper"></a><a href="http://t.cn/RfEIAdZ" target="_blank" rel="external">C++ wrapper</a></h2><p>TensorFlowä½¿ç”¨swigä½œä¸ºC++ wrapperï¼Œæœ€è¿‘Googleåˆæ¨å‡ºäº†pyclifï¼Œå®£ç§°â€œitâ€™s much cleaner and easierâ€ </p>
<h2 id="æ™ºèƒ½æ—¶ä»£çš„è‡ªç„¶è¯­è¨€å¤„ç†"><a href="#æ™ºèƒ½æ—¶ä»£çš„è‡ªç„¶è¯­è¨€å¤„ç†" class="headerlink" title="æ™ºèƒ½æ—¶ä»£çš„è‡ªç„¶è¯­è¨€å¤„ç†"></a><a href="http://t.cn/Rfm4hJb" target="_blank" rel="external">æ™ºèƒ½æ—¶ä»£çš„è‡ªç„¶è¯­è¨€å¤„ç†</a></h2><p>ä»Šå¤©ADLå‰æ²¿è®²ä¹ ç­ã€Šæ™ºèƒ½æ—¶ä»£çš„è‡ªç„¶è¯­è¨€å¤„ç†ã€‹Zhengdong Luçš„æŠ¥å‘Šï¼Œé¢˜ç›®Recent Progress on Deep Learning for NLPã€‚</p>
<h2 id="è‡ªç„¶è¯­è¨€å¤„ç†ä¸­æ·±åº¦å­¦ä¹ æ´»è·ƒé¢†åŸŸçš„è¯¾ç¨‹è®²ä¹‰"><a href="#è‡ªç„¶è¯­è¨€å¤„ç†ä¸­æ·±åº¦å­¦ä¹ æ´»è·ƒé¢†åŸŸçš„è¯¾ç¨‹è®²ä¹‰" class="headerlink" title="è‡ªç„¶è¯­è¨€å¤„ç†ä¸­æ·±åº¦å­¦ä¹ æ´»è·ƒé¢†åŸŸçš„è¯¾ç¨‹è®²ä¹‰"></a><a href="http://www.zishu010.com/z/newdetail/9404521.html" target="_blank" rel="external">è‡ªç„¶è¯­è¨€å¤„ç†ä¸­æ·±åº¦å­¦ä¹ æ´»è·ƒé¢†åŸŸçš„è¯¾ç¨‹è®²ä¹‰</a></h2><p>æœ¬æ–‡æ˜¯çº½çº¦å¤§å­¦åŠ©ç†æ•™æˆ Sam Bowman å…³äºè‡ªç„¶è¯­è¨€å¤„ç†ä¸­æ·±åº¦å­¦ä¹ æ´»è·ƒé¢†åŸŸçš„è¯¾ç¨‹è®²ä¹‰PPTã€‚å¯¹æ·±åº¦å­¦ä¹ NLPé¢†åŸŸæœ€è¿‘è¾ƒä¸ºæ´»è·ƒçš„ç ”ç©¶è¿›è¡Œäº†ç»¼è¿°ï¼Œå…¶ä¸­åŒ…æ‹¬Attention æ¨¡å‹ã€ç»“æ„åŒ–è®°å¿†ã€è¯æ°´å¹³ä»¥ä¸Šçš„æ— ç›‘ç£å­¦ä¹ ç­‰ç­‰ã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-12-03T18:08:45.000Z"><a href="/2016/12/03/PaperWeekly-ç¬¬åå…­æœŸ/">2016-12-03</a></time>
      
      
  
    <h1 class="title"><a href="/2016/12/03/PaperWeekly-ç¬¬åå…­æœŸ/">PaperWeekly ç¬¬åå…­æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•è¨€"><a href="#å¼•è¨€" class="headerlink" title="å¼•è¨€"></a>å¼•è¨€</h1><p>æœ¬æœŸPaperWeeklyå°†å¸¦ç€å¤§å®¶æ¥çœ‹ä¸€ä¸‹ICLR 2017çš„å…­ç¯‡paperï¼Œå…¶ä¸­åŒ…æ‹¬å½“ä¸‹éå¸¸ç«çƒ­çš„GANåœ¨NLPä¸­çš„åº”ç”¨ï¼Œå¼€æ”¾åŸŸèŠå¤©æœºå™¨äººå¦‚ä½•ç”Ÿæˆæ›´é•¿æ›´ä¸°å¯Œçš„å›ç­”ï¼Œå¦‚ä½•ç”¨å¼ºåŒ–å­¦ä¹ æ¥æ„å»ºæ ‘ç»“æ„çš„ç¥ç»ç½‘ç»œå’Œå±‚æ¬¡åŒ–çš„è®°å¿†ç½‘ç»œç­‰å†…å®¹ã€‚å…­ç¯‡paperåˆ†åˆ«æ˜¯ï¼š</p>
<p>1ã€A SELF-ATTENTIVE SENTENCE EMBEDDING<br>2ã€Adversarial Training Methods for Semi-Supervised Text Classification<br>3ã€GENERATING LONG AND DIVERSE RESPONSES WITH NEURAL CONVERSATION MODELS<br>4ã€Hierarchical Memory Networks<br>5ã€Mode Regularized Generative Adversarial Networks<br>6ã€Learning to compose words into sentences with reinforcement learning</p>
<h1 id="A-SELF-ATTENTIVE-SENTENCE-EMBEDDING"><a href="#A-SELF-ATTENTIVE-SENTENCE-EMBEDDING" class="headerlink" title="A SELF-ATTENTIVE SENTENCE EMBEDDING"></a><a href="http://openreview.net/pdf?id=BJC_jUqxe" target="_blank" rel="external">A SELF-ATTENTIVE SENTENCE EMBEDDING</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou &amp; Yoshua Bengio</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>IBM Watson<br>UniversitÂ´e de MontrÂ´eal</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>self-attention, sentence embedding, author profiling, sentiment classification, textual entailment</p>
<h2 id="æ–‡ç« æ¥æº"><a href="#æ–‡ç« æ¥æº" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ICLR 2017</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æœ¬æ–‡æå‡ºä¸€ç§åœ¨æ²¡æœ‰é¢å¤–è¾“å…¥çš„æƒ…å†µä¸‹å¦‚ä½•åˆ©ç”¨attentionæ¥æé«˜æ¨¡å‹è¡¨ç°çš„å¥å­è¡¨ç¤ºæ–¹æ³•ã€‚</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æœ¬æ–‡æå‡ºçš„æ¨¡å‹ç»“æ„åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œ</p>
<ol>
<li>BLSTM<br>è¿™éƒ¨åˆ†é‡‡ç”¨åŒå‘LSTMå¯¹è¾“å…¥çš„æ–‡æœ¬è¿›è¡Œå¤„ç†ï¼Œæœ€åå¾—åˆ°BLSTMçš„æ‰€æœ‰éšå±‚çŠ¶æ€Hã€‚</li>
<li>Self-attention mechanism<br>åŒattentionæœºåˆ¶ç±»ä¼¼ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—ä¸€ä¸ªæƒé‡å‘é‡aï¼Œç„¶åé€šè¿‡å¯¹éšå±‚çŠ¶æ€HåŠ æƒæ±‚å’Œå¾—åˆ°å¥å­çš„è¡¨ç¤ºå‘é‡ã€‚è¿™ä¸ªè¿‡ç¨‹å¦‚ä¸‹å…¬å¼æ‰€ç¤ºï¼š<br><img src="media/equation1.png" alt="equation1"><br>ä½†æ˜¯å®é™…ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸å¯èƒ½ä¼šå¯¹ä¸€ä¸ªå¥å­è¯­ä¹‰çš„å¤šä¸ªæ–¹é¢æ„Ÿå…´è¶£ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹é¢çš„å…¬å¼ï¼Œè·å¾—å¤šä¸ªæƒé‡å‘é‡ç»„æˆçš„çŸ©é˜µAã€‚<br><img src="media/equation2.png" alt="equation2"><br>ç„¶åæ¯ä¸€ä¸ªæƒé‡å‘é‡aéƒ½å¯ä»¥å¾—åˆ°ä¸€ä¸ªå¥å­è¡¨ç¤ºå‘é‡vï¼Œæ‰€æœ‰å¥å­è¡¨ç¤ºå‘é‡ç»„åˆåœ¨ä¸€èµ·å°±å¯ä»¥è·å¾—å¥å­è¡¨ç¤ºçŸ©é˜µMã€‚<br><img src="media/equation3.png" alt="equation3"><br>æœ¬æ–‡çš„æ¨¡å‹åœ¨author profiling, sentiment classificationå’Œtextual entailmentä¸‰ä¸ªä»»åŠ¡ä¸Šè¿›è¡ŒéªŒè¯ï¼Œéƒ½å–å¾—äº†è¾ƒå¥½çš„æ•ˆæœã€‚</li>
</ol>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>1ã€[Yelp]<br>(<a href="https://www.yelp.com/dataset" target="_blank" rel="external">https://www.yelp.com/dataset</a> challenge)<br>2ã€ [SNLI]<br>(<a href="http://nlp.stanford.edu/projects/snli/" target="_blank" rel="external">http://nlp.stanford.edu/projects/snli/</a>)</p>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>A large annotated<br>corpus for learning natural language inference</p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡æå‡ºçš„self-attentionæ–¹æ³•ç”¨ä¸€ä¸ªmatrixè¡¨ç¤ºä¸€ä¸ªå¥å­ï¼Œå¹¶ä¸”matrixä¸­çš„æ¯ä¸€ä¸ªvectoréƒ½æ˜¯å¥å­è¯­ä¹‰æŸä¸€æ–¹é¢çš„è¡¨ç¤ºï¼Œå¢å¼ºäº†sentence embeddingçš„å¯è§£é‡Šæ€§ã€‚</p>
<h1 id="Adversarial-Training-Methods-for-Semi-Supervised-Text-Classification"><a href="#Adversarial-Training-Methods-for-Semi-Supervised-Text-Classification" class="headerlink" title="Adversarial Training Methods for Semi-Supervised Text Classification"></a><a href="https://arxiv.org/abs/1605.07725" target="_blank" rel="external">Adversarial Training Methods for Semi-Supervised Text Classification</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Takeru Miyato, Andrew M. Dai, Ian Goodfellow</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Google Brain, Kyoto Universityå’ŒOpenAI</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Adversarial training, text classification, semi-supervised learning</p>
<h2 id="æ–‡ç« æ¥æº-1"><a href="#æ–‡ç« æ¥æº-1" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ICLR 2017</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>Adversarial trainingå’Œvirtual adversarial trainingéƒ½éœ€è¦å¯¹è¾“å…¥çš„æ•°å­—å½¢å¼åšå°çš„perturbationï¼Œä¸é€‚ç”¨äºé«˜ç»´ç¨€ç–è¾“å…¥ï¼Œæ¯”å¦‚one-hot word representationsã€‚æ–‡ç« æ‰©å±•å›¾åƒé¢†åŸŸæµè¡Œçš„è¿™ä¸¤ç§æ–¹æ³•åˆ°æ–‡æœ¬é¢†åŸŸï¼Œå¯¹word embeddingè¿›è¡Œperturbationæ¥ä½œä¸ºLSTMçš„è¾“å…¥ï¼Œå–ä»£åŸæœ¬çš„è¾“å…¥å‘é‡ã€‚å¯ä»¥æŠŠè¿™ä¸¤ç§æ–¹æ³•çœ‹åšæ˜¯æ­£åˆ™åŒ–çš„æ–¹æ³•ï¼Œä¸ºè¾“å…¥åŠ å…¥å™ªå£°ï¼Œå¯ä»¥ç”¨æ¥å®ç°semi-supervisedçš„ä»»åŠ¡ã€‚</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>ä»¥adversarial trainingä¸ºä¾‹ï¼Œæ–‡ç« å¯¹word embeddingsè¿›è¡Œadversarial perturbationï¼Œè€Œä¸æ˜¯ç›´æ¥åº”ç”¨åœ¨è¾“å…¥ä¸Šã€‚å‡è®¾normalizedä¹‹åçš„è¾“å…¥åºåˆ—ä¸ºsï¼Œç»™å®šsï¼Œyçš„æ¡ä»¶æ¦‚ç‡ä¸ºp(y|s;theta)ï¼Œå…¶ä¸­thetaä¸ºæ¨¡å‹å‚æ•°ï¼Œåˆ™sä¸Šçš„adversarial perturbation r_advä¸ºï¼š<br><img src="media/16-1-1.png" alt="16-1"></p>
<p>åº”ç”¨åœ¨LSTMä¸Šï¼Œå¦‚ä¸‹å›¾(b)æ‰€ç¤ºã€‚å®šä¹‰å…¶adversarial losså¦‚ä¸‹ï¼š</p>
<p><img src="media/adversarial1.png" alt="adversaria"></p>
<p><img src="media/16-2.png" alt="16-2"></p>
<p>å…¶ä¸­Nä¸ºlabeledçš„ä¾‹å­çš„æ•°ç›®ã€‚é€šè¿‡éšæœºæ¢¯åº¦ä¸‹é™æ¥è¿›è¡Œtrainingã€‚</p>
<p>æ–‡ç« ä¹Ÿæä¾›äº†virtual adversarial trainingçš„æ–¹æ³•ã€‚</p>
<h2 id="èµ„æº-1"><a href="#èµ„æº-1" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>1ã€<a href="http://ai.stanford.edu/~amaas/data/sentiment/" target="_blank" rel="external">IMDB</a><br>2ã€<a href="http://riejohnson.com/cnn_data.html" target="_blank" rel="external">Elec</a><br>3ã€<a href="http://snap.stanford.edu/data/web-Amazon.html" target="_blank" rel="external">Rotten Tomatoes</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-1"><a href="#ç›¸å…³å·¥ä½œ-1" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>ä¸»è¦åˆ—ä¸‰ç¯‡workï¼š<br>1ã€2015å¹´NIPS, SA-LSTMã€‚Semi-supervised sequence learning<br>2ã€2015å¹´NIPSï¼ŒOne-hot CNNã€‚Semi-supervised convolutional neural networks for text categorization via region<br>embedding<br>3ã€2016å¹´ICMLï¼ŒOne-hot bi-LSTMã€‚Supervised and semi-supervised text categorization using LSTM for region<br>embeddings</p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>ä½œè€…å°†å›¾åƒé¢†åŸŸçš„adversarial trainingåº”ç”¨åœ¨äº†æ–‡æœ¬é¢†åŸŸï¼Œæ”¹å–„äº†word embeddingã€‚ä¼ ç»Ÿçš„word embeddingè¢«è¯­æ³•ç»“æ„å½±å“ï¼Œå³ä½¿ä¸¤ä¸ªå®Œå…¨ç›¸åçš„è¯ï¼ˆæ¯”å¦‚â€goodâ€å’Œâ€badâ€ï¼‰åœ¨è¡¨ç¤ºå½¢å¼ä¸Šä¹Ÿæ˜¯ç›¸è¿‘çš„ï¼Œæ²¡æœ‰è¡¨ç¤ºå‡ºè¯æœ¬èº«çš„æ„æ€ã€‚Adversarial trainingä½¿å¾—æœ‰ç›¸è¿‘è¯­æ³•ç»“æ„ä½†æ˜¯ä¸åŒæ„ä¹‰çš„è¯èƒ½å¤Ÿè¢«åˆ†å¼€ï¼Œå¯ä»¥ç”¨æ¥åšæƒ…æ„Ÿåˆ†ç±»å’Œsequence modelç­‰ã€‚</p>
<h1 id="GENERATING-LONG-AND-DIVERSE-RESPONSES-WITH-NEURAL-CONVERSATION-MODELS"><a href="#GENERATING-LONG-AND-DIVERSE-RESPONSES-WITH-NEURAL-CONVERSATION-MODELS" class="headerlink" title="GENERATING LONG AND DIVERSE RESPONSES WITH NEURAL CONVERSATION MODELS"></a><a href="http://openreview.net/pdf?id=HJDdiT9gl" target="_blank" rel="external">GENERATING LONG AND DIVERSE RESPONSES WITH NEURAL CONVERSATION MODELS</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Louis Shao, Stephan Gouws, Denny Britz, Anna Goldie, Brian Strope, Ray Kurzweil1</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Google Research, Google Brain</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Long and Diverse Responses</p>
<h2 id="æ–‡ç« æ¥æº-2"><a href="#æ–‡ç« æ¥æº-2" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ICLR 2017</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¼€æ”¾åŸŸèŠå¤©æœºå™¨äººå¦‚ä½•ç”Ÿæˆæ›´é•¿ä¸”è¾ƒä¸ºä¸°å¯Œçš„å›ç­”ï¼Ÿ</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æœ¬æ–‡æ¨¡å‹æ˜¯åŸºäºç»å…¸çš„seq2seq+attentionæ¡†æ¶ï¼Œåœ¨å…¶åŸºç¡€ä¸Šè¿›è¡Œäº†è‹¥å¹²ä¿®æ”¹ï¼Œå¾—åˆ°äº†æ»¡æ„çš„æ•ˆæœã€‚ä¸åŒäºä¹‹å‰æ¨¡å‹çš„åœ°æ–¹æœ‰ä¸¤ç‚¹ï¼š</p>
<p>1ã€encoderä¸ä»…ä»…åŒ…æ‹¬æ•´ä¸ªsourceï¼Œè¿˜åŒ…æ‹¬ä¸€éƒ¨åˆ†targetï¼Œè¿™æ ·attentionä¸ä»…ä»…è€ƒè™‘äº†sourceï¼Œè€Œä¸”è€ƒè™‘äº†éƒ¨åˆ†targetã€‚</p>
<p><img src="media/16-3.png" alt="16-3"></p>
<p>ç»å…¸çš„seq2seq+attentionåœ¨decodingéƒ¨åˆ†ä¼šå°†sourceä¸­çš„æ¯ä¸ªtokenéƒ½è€ƒè™‘åˆ°attentionä¸­æ¥ï¼Œä¹‹å‰æœ‰ä¸€ç§åšæ³•æ˜¯å°†æ•´ä¸ªtargetéƒ¨åˆ†ä¹ŸåŠ å…¥åˆ°attentionä¸­ï¼Œæ•ˆæœä¸Šè™½ç„¶æœ‰ä¸€å®šçš„æå‡ï¼Œä½†éšç€æ•°æ®è§„æ¨¡åœ°å¢åŠ ï¼Œå†…å­˜ä»£ä»·å¤ªå¤§ã€‚æœ¬æ–‡æ­£æ˜¯é’ˆå¯¹è¿™ä¸€ä¸ªé—®é¢˜ï¼Œæå‡ºäº†æ‰€è°“çš„â€œglimpseâ€æ¨¡å‹ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œåœ¨encoderéƒ¨åˆ†åŠ å…¥äº†targetçš„å‰å‡ ä¸ªtokenï¼Œç›¸å½“äºæ˜¯ä¸Šé¢ä¸¤ç§æ–¹æ¡ˆçš„ä¸€ç§æŠ˜ä¸­ã€‚</p>
<p>2ã€æå‡ºäº†ä¸€ç§åŸºäºsamplingçš„beam search decodingæ–¹æ¡ˆã€‚</p>
<p>ç»å…¸çš„beam searchåœ¨decodingéƒ¨åˆ†ï¼Œæ˜¯åŸºäºMAPï¼ˆæœ€å¤§åéªŒæ¦‚ç‡ï¼‰è¿›è¡Œè´ªå©ªè§£ç çš„ï¼Œè¿™ç§æ–¹æ¡ˆç”Ÿæˆçš„responseså…·æœ‰ç®€çŸ­ã€æ— ä¿¡æ¯é‡ä»¥åŠé«˜é¢‘çš„ç‰¹ç‚¹ï¼Œé€šä¿—åœ°è®²ä¼šç”Ÿæˆå¾ˆå¤šçš„ç±»ä¼¼â€œå‘µå‘µâ€çš„è¯ï¼Œæ²¡æœ‰å¤ªå¤šè¥å…»å’Œä»·å€¼ã€‚(Jiwei Li,2015)åœ¨è§£å†³è¿™ä¸ªé—®é¢˜æ—¶ï¼Œåœ¨decodingéƒ¨åˆ†é€šè¿‡MMIï¼ˆäº’ä¿¡æ¯ï¼‰å¯¹N-bestç»“æœè¿›è¡Œé‡æ’åºï¼Œè¿™ç§æ–¹æ³•å¯¹äºç”ŸæˆçŸ­æ–‡æœ¬æ•ˆæœæ˜¾è‘—ï¼Œä½†å¯¹äºç”Ÿæˆé•¿æ–‡æœ¬æ•ˆæœä¸ä½³ã€‚å› ä¸ºï¼ŒåŸºäºMAPçš„beam searchå¤©ç„¶å­˜åœ¨è¿™æ ·çš„é—®é¢˜ï¼ŒN-bestå’Œé‡æ’åºéƒ½è§£å†³ä¸äº†æ ¹æœ¬æ€§çš„é—®é¢˜ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºsamplingçš„beam searchè§£ç æ–¹æ¡ˆï¼Œsamplingå³åœ¨æ¯ä¸€æ­¥è§£ç æ—¶éƒ½sampleå‡ºDä¸ªtokenä½œä¸ºå€™é€‰ï¼Œæœç´¢å®Œæ¯•æˆ–è¾¾åˆ°é¢„è®¾çš„é•¿åº¦ä¹‹åï¼Œç”ŸæˆBä¸ªå€™é€‰responsesï¼Œç„¶åè¿›è¡Œé‡æ’åºã€‚</p>
<p>æœ¬æ–‡çš„å¦å¤–ä¸€å¤§äº®ç‚¹æ˜¯ç”¨äº†å¤§é‡çš„å¯¹è¯æ•°æ®ï¼Œç”¨äº†å¾ˆå¤§è§„æ¨¡å‚æ•°çš„æ¨¡å‹è¿›è¡Œäº†å®éªŒã€‚å®éªŒè¯„ä»·æ ‡å‡†ï¼Œåœ¨è‡ªåŠ¨è¯„ä»·è¿™éƒ¨åˆ†ï¼Œè®¾è®¡äº†ä¸€ä¸ªNé€‰1çš„å®éªŒï¼Œç»™å®šä¸€ä¸ªè¾“å…¥ï¼Œå°†æ­£ç¡®è¾“å‡ºå’Œé”™è¯¯è¾“å‡ºæ··åœ¨ä¸€èµ·ï¼Œæ¨¡å‹éœ€è¦ä»ä¸­é€‰æ‹©æ­£ç¡®çš„è¾“å‡ºï¼Œç”¨é€‰æ‹©å‡†ç¡®ç‡æ¥ä½œä¸ºè‡ªåŠ¨è¯„ä»·æŒ‡æ ‡ã€‚æœ¬æ–‡æ²¡æœ‰ç”¨åˆ°ç»å…¸çš„BLEUæŒ‡æ ‡ï¼Œå› ä¸ºè¿™ä¸ªæŒ‡æ ‡ç¡®å®ä¸é€‚åˆè¯„ä»·å¯¹è¯çš„ç”Ÿæˆè´¨é‡ã€‚ä¸ºäº†æ›´æœ‰è¯´æœåŠ›ï¼Œæœ¬æ–‡ç”¨äººå·¥å¯¹ç»“æœè¿›è¡Œè¯„ä»·ã€‚</p>
<h2 id="èµ„æº-2"><a href="#èµ„æº-2" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æœ¬æ–‡ç”¨åˆ°çš„å¯¹è¯æ•°æ®ï¼š<br>1ã€<a href="https://redd.it/3bxlg7" target="_blank" rel="external">Reddit Data</a><br>2ã€<a href="http://opus.lingfil.uu.se/OpenSubtitles.php" target="_blank" rel="external">2009 Open Subtitles data</a><br>3ã€<a href="https://data.stackexchange.com/" target="_blank" rel="external">Stack Exchange data</a><br>4ã€æœ¬æ–‡ä½œè€…ä»WebæŠ½å–çš„å¯¹è¯æ•°æ®ï¼ˆå¾…å…¬å¼€ï¼‰</p>
<h2 id="ç›¸å…³å·¥ä½œ-2"><a href="#ç›¸å…³å·¥ä½œ-2" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>ç”¨seq2seqæ–¹æ³•ç ”ç©¶ç”Ÿæˆå¯¹è¯çš„è´¨é‡ï¼ˆåŒ…æ‹¬é•¿åº¦ã€å¤šæ ·æ€§ï¼‰çš„å·¥ä½œå¹¶ä¸å¤šï¼Œå…·æœ‰ä»£è¡¨æ€§çš„æœ‰ä¸‹é¢ä¸¤ä¸ªå·¥ä½œï¼š<br>1ã€Wu,2016 æå‡ºäº†ç”¨length-normalizationçš„æ–¹æ¡ˆæ¥ç”Ÿæˆæ›´é•¿çš„å¯¹è¯<br>2ã€Jiwei Li,2015 æå‡ºäº†åœ¨è§£ç é˜¶æ®µç”¨MMIï¼ˆäº’ä¿¡æ¯ï¼‰å¯¹N-bestç»“æœè¿›è¡Œé‡æ’åºï¼Œæ—¨åœ¨è·å¾—ä¿¡æ¯é‡æ›´å¤§çš„å¯¹è¯ã€‚</p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡æ¨¡å‹éƒ¨åˆ†å¹¶æ²¡æœ‰å¤ªå¤šçš„åˆ›æ–°ï¼Œå› ä¸ºæ˜¯å·¥ä¸šéƒ¨é—¨çš„paperï¼Œæ‰€ä»¥æ›´å¤šçš„æ˜¯è€ƒè™‘å®ç”¨æ€§ï¼Œå³èƒ½å¦åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šåº”ç”¨è¯¥æ¨¡å‹ï¼Œé›†ä¸­ä½“ç°åœ¨glimpseæ¨¡å‹ä¸Šã€‚ä¸ºäº†ç”Ÿæˆæ›´åŠ é•¿ã€æ›´åŠ å¤šæ ·æ€§çš„å¯¹è¯ï¼Œåœ¨åŸæœ‰beam search + é‡æ’åºçš„åŸºç¡€ä¸Šï¼Œå¼•å…¥äº†samplingæœºåˆ¶ï¼Œç»™ç”Ÿæˆè¿‡ç¨‹å¢åŠ äº†æ›´å¤šçš„å¯èƒ½æ€§ï¼Œä¹Ÿæ˜¯å·¥ç¨‹ä¸Šçš„trickã€‚å¯¹è¯æ•ˆæœçš„è¯„ä»·æ˜¯ä¸€ä»¶å¾ˆéš¾çš„äº‹æƒ…ï¼Œäººç±»å¸Œæœ›botå¯ä»¥ç”Ÿæˆç±»äººçš„å¯¹è¯ï¼Œå›å¤çš„é•¿åº¦å¯ä»¥å®šé‡æè¿°ï¼Œä½†å¤šæ ·æ€§ã€ç”ŸåŠ¨æ€§ã€æ‹ŸäººåŒ–ç­‰ç­‰éƒ½éš¾ä»¥å®šé‡æè¿°ï¼Œæ‰€ä»¥åœ¨æ¢ç´¢ç”Ÿæˆå¯¹è¯çš„è¿™ä¸ªæ–¹å‘ä¸Šè¿˜æœ‰å¾ˆé•¿çš„è·¯è¦èµ°ã€‚</p>
<h1 id="Hierarchical-Memory-Networks"><a href="#Hierarchical-Memory-Networks" class="headerlink" title="Hierarchical Memory Networks"></a><a href="https://arxiv.org/pdf/1605.07427v1.pdf" target="_blank" rel="external">Hierarchical Memory Networks</a></h1><h2 id="ä½œè€…-3"><a href="#ä½œè€…-3" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Sarath Chandar, Sungjin Ahn, Hugo Larochelle, Pascal Vincent, Gerald Tesauro, Yoshua Bengio</p>
<h2 id="å•ä½-3"><a href="#å•ä½-3" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>1ã€UniversitÃ© de MontrÃ©al, Canada.<br>2ã€Twitter Cortex, USA.<br>3ã€IBM Watson Research Center, USA.<br>4ã€CIFAR, Canada.  </p>
<h2 id="å…³é”®è¯-3"><a href="#å…³é”®è¯-3" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Hierarchical Memory Networksï¼ŒMaximum Inner Product Search (MIPS)</p>
<h2 id="æ–‡ç« æ¥æº-3"><a href="#æ–‡ç« æ¥æº-3" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ICLR 2017</p>
<h2 id="é—®é¢˜-3"><a href="#é—®é¢˜-3" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>è®°å¿†ç½‘ç»œä¸»è¦åŒ…æ‹¬hard attentionå’Œsoft attenionä¸¤ç§ï¼Œç„¶è€Œhardä¸èƒ½ç”¨äºåå‘ä¼ æ’­ç®—æ³•è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒï¼Œæ‰€ä»¥åªèƒ½ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•è¿›è¡Œè®­ç»ƒï¼›softæ‰€æ¶‰åŠçš„è®¡ç®—å‚æ•°åˆå¾ˆå¤§ï¼Œåªé€‚åˆäºå°‘é‡Memoryã€‚æœ¬æ–‡æå‡ºHierarchical Memory Networks(HMN)æ¨¡å‹ï¼Œç®—æ˜¯softå’Œhardçš„ä¸€ä¸ªæ··åˆæ¨¡å‹ï¼Œè®¡ç®—é‡å‡å°‘ä¸”è®­ç»ƒæ›´åŠ å®¹æ˜“ï¼Œ<br>å®éªŒç»“æœä¹Ÿå¾ˆå¥½ã€‚</p>
<h2 id="æ¨¡å‹-3"><a href="#æ¨¡å‹-3" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>soft attentionæ˜¯å¯¹æ‰€æœ‰çš„memoryéƒ½è¦è¿›è¡Œattentionçš„è®¡ç®—ï¼Œå¯¹å…¨é›†è®¡ç®—ä½¿è®¡ç®—é‡å¾ˆå¤§ã€‚HMNåˆ©ç”¨å±‚æ¬¡åŒ–ç»“æ„ä½¿å¾—attentionçš„é›†åˆç¼©å°ï¼Œåˆ©ç”¨MaximumInner Product Search(MIPS)çš„æ–¹æ³•ä»å…¨é›†ä¸­è·å¾—ä¸€ä¸ªæœ€ä¼˜å­é›†ï¼Œåœ¨å­é›†ä¸Šé¢å»åšattentionå°±å¤§å¤§é™ä½è®¡ç®—é‡ã€‚è¿™æ ·çš„æ–¹å¼åˆå’Œhard attentioné¢„æµ‹å…³æ³¨ç‚¹çš„æ–¹æ³•æœ‰äº›ç±»ä¼¼ï¼Œå°†æ³¨æ„åŠ›æ”¾åœ¨æœ€ç›¸å…³çš„é‚£éƒ¨åˆ†ï¼Œè¿™ä¸ªçš„åšæ³•ä¹Ÿæ›´æ¥è¿‘äºäººçš„æ³¨æ„åŠ›æ€ç»´ã€‚  æ–‡ç« çš„æ ¸å¿ƒéƒ¨åˆ†åœ¨äºå¦‚ä½•è·å–ä¸queryæœ€ç›¸è¿‘çš„å­é›†ã€‚</p>
<p>ä¸»å®éªŒä¸»è¦åŒ…æ‹¬ä¸¤ä¸ª:<br>1ã€Exact K-MIPSï¼šè®¡ç®—å¤æ‚åº¦ä¾ç„¶å’Œsoft attentionå·®ä¸å¤šã€‚<br>2ã€Approximate K-MIPSï¼šåˆ©ç”¨Maximum Cosine Similarity Search(MCSS)çš„æ–¹æ³•ä»£æ›¿MIPSçš„æ–¹æ³•ï¼Œç‰ºç‰²ä¸€äº›ç²¾ç¡®åº¦ï¼Œé™ä½å¤æ‚åº¦å’ŒåŠ å¿«è®­ç»ƒé€Ÿåº¦ã€‚  </p>
<p>MIPSæœ‰ä¸‰ç§æ–¹æ³•ï¼Œåˆ†åˆ«æ˜¯åŸºäºhash,åŸºäºtree,åŸºäºclusteringï¼ŒåŸºäºä¸Šè¿°ä¸‰ç§æ–¹æ³•æ–‡ä¸­åˆåšäº†å‡ ç»„ç»„å¯¹æ¯”å®éªŒï¼Œæœ€åå®éªŒç»“æœæ˜¾ç¤ºåŸºäºclusteringçš„æ•ˆæœæ˜¯æœ€å¥½çš„ã€‚</p>
<p>æ–‡ç« å¾—åˆ°çš„å®éªŒç»“æœå¦‚ä¸‹ï¼š<br><img src="media/HMN_Result.png" alt="HMN_Result"></p>
<h2 id="èµ„æº-ï¼ˆå¯é€‰ï¼‰"><a href="#èµ„æº-ï¼ˆå¯é€‰ï¼‰" class="headerlink" title="èµ„æº ï¼ˆå¯é€‰ï¼‰"></a>èµ„æº ï¼ˆå¯é€‰ï¼‰</h2><p>1ã€<a href="https://www.dropbox.com/s/tohrsllcfy7rch4/SimpleQuestions_v2.tgz" target="_blank" rel="external">The SimpleQuestions dataset</a>(ä½¿ç”¨çš„æ˜¯Large-scale simple question answering with memory networksæ–‡ç« ä¸­çš„æ•°æ®é›†)<br>2ã€<a href="https://research.facebook.com/research/babi/" target="_blank" rel="external">babi</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-3"><a href="#ç›¸å…³å·¥ä½œ-3" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>1ã€arXiv 2014, soft attention,ã€ŠNeural turing machinesã€‹<br>2ã€CoRR 2015, hard attention,ã€ŠReinforcement learning neural turing machineã€‹<br>3ã€ICLR 2015, memory network,ã€ŠMemory networksã€‹<br>4ã€arXiv 2015,ã€ŠEnd-to-end memory networksã€‹,å¼•å…¥åŠç›‘ç£è®°å¿†ç½‘ç»œå¯ä»¥è‡ªå­¦æ‰€éœ€è¦çš„factsã€‚<br>5ã€CoRR 2016, DMN, ã€ŠDynamic memory networks for visual and textual question<br>answeringã€‹,å¢åŠ äº†ä¸€ä¸ªepisodic memory ä½¿å¾—å¯ä»¥åŠ¨æ€æ›´æ–°memoryé‡Œé¢çš„å†…å®¹ã€‚</p>
<h2 id="ç®€è¯„-3"><a href="#ç®€è¯„-3" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æ–‡ç« çš„åˆ›æ–°ä¸»è¦åœ¨äºä¿®æ”¹äº†ä¸¤ä¸ªæ¨¡å—ï¼šMemoryå’ŒReaderã€‚<br>1ã€å°†memoryçš„ç»“æ„ä»a flat of arrayå˜æˆäº†hierarchical memory structureã€‚å°†memoryåˆ†æˆè‹¥å¹²groups,è¿™äº›groupsåˆå¯ä»¥åœ¨è¿›è¡Œæ›´é«˜çº§åˆ«çš„ç»„åˆã€‚<br>2ã€readeræ˜¯ä»MIPSé€‰å‡ºçš„å­é›†ä¸­ä½¿ç”¨soft attentionã€‚MIPSä»memoryä¸­é€‰å‡ºä¸€<br>ä¸ªgroupå­é›†ä½œä¸ºæœ€ç›¸å…³çš„å­é›†ã€‚</p>
<h1 id="Mode-Regularized-Generative-Adversarial-Networks"><a href="#Mode-Regularized-Generative-Adversarial-Networks" class="headerlink" title="Mode Regularized Generative Adversarial Networks "></a><a href="http://openreview.net/pdf?id=HJKkY35le" target="_blank" rel="external">Mode Regularized Generative Adversarial Networks </a></h1><h2 id="ä½œè€…-4"><a href="#ä½œè€…-4" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Tong Che; Yanran Li</p>
<h2 id="å•ä½-4"><a href="#å•ä½-4" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Montreal Institute for Learning Algorithms;<br>Department of Computing, The Hong Kong Polytechnic University</p>
<h2 id="å…³é”®è¯-4"><a href="#å…³é”®è¯-4" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>GAN, Regularizers</p>
<h2 id="æ–‡ç« æ¥æº-4"><a href="#æ–‡ç« æ¥æº-4" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ICLR 2017</p>
<h2 id="é—®é¢˜-4"><a href="#é—®é¢˜-4" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æœ¬æ–‡é’ˆå¯¹çš„é—®é¢˜æ˜¯ï¼š1ã€GAN çš„è®­ç»ƒè¿‡ç¨‹å¾ˆä¸ç¨³å®š 2ã€GAN ç”Ÿæˆçš„æ ·æœ¬å±€é™äºè®­ç»ƒæ ·æœ¬ä¸­çš„å¤§ model ä¸Šï¼Œä¸èƒ½å¹³è¡¡æ•°æ®çš„åˆ†å¸ƒï¼ˆmissing model problemï¼‰ã€‚<br>ä¸¤ä¸ªé—®é¢˜äº’ç›¸å½±å“ï¼Œå¯¼è‡´è®­ç»ƒç»“æœä¸å¥½ã€‚</p>
<h2 id="æ¨¡å‹-4"><a href="#æ¨¡å‹-4" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>é’ˆå¯¹ä¸Šé¢çš„é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸¤ç§ regularizers å»æ§åˆ¶ GAN çš„è®­ç»ƒè¿‡ç¨‹ã€‚<br>ç¬¬ä¸€ä¸ª regularizer ä¹Ÿè¢«ä½œè€…ç§°ä¸º Regularized-GANã€‚ä½œè€…è®¤ä¸ºå¯ä»¥ä» generator å…¥æ‰‹ï¼Œç»™ generator å¢åŠ  regularizerï¼Œä½¿å¾—å…¶å…·æœ‰æ›´å¥½çš„ gradient ï¼Œè¿™æ · G å’Œ D éƒ½èƒ½ç¨³å®šè®­ç»ƒã€‚<br>å…·ä½“çš„æ–¹æ³•æ˜¯å¢åŠ ä¸€ä¸ª encoder E(x) : X â†’ Z.å³æŠŠåŸå…ˆçš„ noise vector z æ”¹ä¸º z = encoder(X) ï¼Œå³ç„¶åå† G(encoder(X))ã€‚å¦‚ä¸‹å›¾ï¼š<br><img src="media/16-5.png" alt="16-5"></p>
<p>è¿™æ ·åšæœ‰ä¸¤ä¸ªå¥½å¤„ã€‚ç¬¬ä¸€ï¼ŒåŸå§‹çš„æ¨¡å‹å¾ˆå®¹æ˜“å‡ºç°æ¢¯åº¦æ¶ˆå¤±çš„æƒ…å†µï¼Œå› ä¸º discriminator D ç‰¹åˆ«å®¹æ˜“åŒºåˆ†çœŸå®æ•°æ®å’Œç”Ÿæˆæ•°æ®å¯¼è‡´ generator å°±å¾—ä¸åˆ° D çš„æ¢¯åº¦ã€‚ä½œè€…çš„æ¨¡å‹å¤šäº†ä¸€ä¸ª reconstruction çš„éƒ¨åˆ†ï¼Œè¿™æ ·ç”Ÿæˆå‡ºæ¥æ•°æ®ä¸å†é‚£æ ·å®¹æ˜“è¢« D è¯†åˆ«å‡ºæ¥ã€‚æ‰€ä»¥ D å’Œ G å°±éƒ½èƒ½ä¸€ç›´æœ‰ gradient å»è®­ç»ƒï¼Œä»è€Œæé«˜ç¨³å®šæ€§ã€‚ç¬¬äºŒï¼Œå¯¹äº x ï¼ŒG(E(x)) ä¼šå°½é‡å»ç”Ÿæˆ x åŸæœ¬æ‰€å±çš„ç±»ï¼Œä»è€Œä¸€å®šç¨‹åº¦è§£å†³äº† missing model problemã€‚<br>ç¬¬äºŒä¸ª regularizer åŸºäºç¬¬ä¸€ä¸ª regularizer æ—¨åœ¨æ”¹è¿›è®­ç»ƒçš„æ–¹æ³•ï¼Œä¹Ÿè¢«ä½œè€…ç§°ä¸º manifold-diffusion GANã€‚åˆ†ä¸ºä¸¤æ­¥ï¼Œç¬¬ä¸€æ­¥ manifold step è®­ç»ƒ discriminator D1 ï¼Œç›®çš„æ˜¯å‡å°‘ G(Enc(X)) å’Œ X çš„çš„å·®åˆ«ï¼›ç¬¬äºŒæ­¥ diffusion å°±æ˜¯è®­ç»ƒ D2 è®© G(Enc(X)) å’Œ G(z) åˆ†å¸ƒçš„è·ç¦»æ¥è¿‘ã€‚å¦‚ä¸‹å›¾ï¼š</p>
<p><img src="media/16-6.png" alt="16-6"></p>
<p>æœ€åï¼Œä½œè€…æŠŠ GAN çš„ç½‘ç»œè®­ç»ƒåå¡Œçš„æƒ…å†µè€ƒè™‘è¿›å»ï¼Œæå‡ºäº†æ–°çš„ evaluation metricã€‚</p>
<h2 id="ç›¸å…³å·¥ä½œ-4"><a href="#ç›¸å…³å·¥ä½œ-4" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>æœ¬ç¯‡æ–‡ç« çš„ä½œè€…æå«£ç„¶å†™è¿‡ä¸€ç¯‡éå¸¸æ£’çš„<a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;mid=2650325352&amp;idx=1&amp;sn=90fb15cee44fa7175a804418259d352e&amp;mpshare=1&amp;scene=1&amp;srcid=0829ixEhnGChNKAl5kgz6b9V#rd" target="_blank" rel="external">ç»¼è¿°</a> ,åœ¨è¿™é‡Œå°±ä¸ç´¯èµ˜é˜è¿°äº†ã€‚</p>
<h2 id="ç®€è¯„-4"><a href="#ç®€è¯„-4" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>å½“ä¸‹ GAN çš„ç ”ç©¶éå¸¸ç«çˆ†ï¼Œå‡ºç°äº†è®¸è®¸å¤šå¤šå¯¹ GAN çš„æ”¹è¿›ï¼Œæœ¬ç¯‡æ–‡ç« çš„æå‡ºçš„ä¸¤ç§ regularizers éå¸¸æœ‰æ•ˆçš„æé«˜äº† GAN çš„ç¨³å®šæ€§ï¼ˆå…¶ä¸­ regularizer çš„æ€æƒ³ä¹Ÿå—åˆ°äº†ç›‘ç£å­¦ä¹ çš„å¯å‘ï¼‰ï¼Œå€¼å¾—å¯¹ GAN æ„Ÿå…´è¶£çš„åŒå­¦ç ”è¯»ã€‚</p>
<h2 id="å®Œæˆäººä¿¡æ¯"><a href="#å®Œæˆäººä¿¡æ¯" class="headerlink" title="å®Œæˆäººä¿¡æ¯"></a>å®Œæˆäººä¿¡æ¯</h2><p>professorshui@gmail.com</p>
<h1 id="Learning-to-compose-words-into-sentences-with-reinforcement-learning"><a href="#Learning-to-compose-words-into-sentences-with-reinforcement-learning" class="headerlink" title="Learning to compose words into sentences with reinforcement learning"></a><a href="https://openreview.net/forum?id=Skvgqgqxe" target="_blank" rel="external">Learning to compose words into sentences with reinforcement learning</a></h1><h2 id="ä½œè€…-5"><a href="#ä½œè€…-5" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Dani Yogatama, Phil Blunsom, Chris Dyer, Edward Grefenstette, Wang Ling</p>
<h2 id="å•ä½-5"><a href="#å•ä½-5" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Google</p>
<h2 id="å…³é”®è¯-5"><a href="#å…³é”®è¯-5" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Tree-LSTM, Reinforcement Learning</p>
<h2 id="æ–‡ç« æ¥æº-5"><a href="#æ–‡ç« æ¥æº-5" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ICLR 2017</p>
<h2 id="é—®é¢˜-5"><a href="#é—®é¢˜-5" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥æ„å»ºæ ‘ç»“æ„çš„ç¥ç»ç½‘ç»œTree-LSTMï¼Œå­¦ä¹ è‡ªç„¶è¯­è¨€çš„å¥å­è¡¨ç¤º</p>
<h2 id="æ¨¡å‹-5"><a href="#æ¨¡å‹-5" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æ¨¡å‹åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼šTree-LSTMå’Œå¼ºåŒ–å­¦ä¹ æ¨¡å‹<br>åº”ç”¨Tree-LSTM(å¯ä»¥é€šè¿‡LSTMçš„å¿˜è®°é—¨æœºåˆ¶ï¼Œè·³è¿‡æ•´æ£µå¯¹ç»“æœå½±å“ä¸å¤§çš„å­æ ‘)ï¼Œå¹¶ç»“åˆ{SHIFTï¼ŒREDUCE}æ“ä½œï¼ŒSHIFTæ“ä½œå¯¹åº”å°†ä¸€ä¸ªèŠ‚ç‚¹å‹å…¥æ ˆï¼ŒREDUCEå¯¹åº”å°†ä¸¤ä¸ªå…ƒç´ ç»„åˆï¼Œä»è€Œå»ºç«‹æ ‘ç»“æ„</p>
<p>å¼ºåŒ–å­¦ä¹ ç”¨æ¥å¯»æ‰¾æœ€ä½³çš„èŠ‚ç‚¹ç»„åˆæƒ…å†µï¼ŒRLæ¨¡å‹ä¸­çš„çŠ¶æ€så³å½“å‰æ„å»ºçš„æ ‘ç»“æ„ï¼Œaä¸º{SHIFTï¼ŒREDUCE}æ“ä½œï¼Œrewardå¯¹åº”ä¸åŒdownstream<br> task(ä¾‹ï¼šè‹¥æ˜¯ç”¨è¯¥å¥å­è¡¨ç¤ºè¿›è¡Œåˆ†ç±»ä»»åŠ¡ï¼Œåˆ™rå¯¹åº”ä»ç­–ç•¥ç½‘ç»œä¸­é‡‡æ ·å¾—åˆ°å¥å­è¡¨ç¤ºçš„åˆ†ç±»å‡†ç¡®æ€§çš„æ¦‚ç‡)</p>
<h2 id="èµ„æº-3"><a href="#èµ„æº-3" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>ä½œè€…å°†è¯¥å·¥ä½œè¿›è¡Œäº†å››ç»„å®éªŒï¼Œæƒ…æ„Ÿåˆ†ç±»ï¼Œè¯­ä¹‰ç›¸å…³æ€§åˆ¤æ–­ï¼Œè‡ªç„¶è¯­è¨€æ¨ç†ï¼Œå¥å­ç”Ÿæˆ<br>åˆ†åˆ«åº”ç”¨Stanford Sentiment Treebankï¼ŒSentences Involving Compositional Knowledge corpusï¼ŒStanford Natural Language Inference corpusï¼ŒIMDB movie review corpus</p>
<h2 id="ç›¸å…³å·¥ä½œ-5"><a href="#ç›¸å…³å·¥ä½œ-5" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>ä¸Socherç­‰äººä¹‹å‰æå‡ºçš„Recursive NN,MV-RNN,RNTNï¼ŒTree-LSTMç­‰å·¥ä½œä¸€è„‰ç›¸æ‰¿ï¼Œæœ¬æ–‡åˆåŠ å…¥äº†RLæ–¹å¼æ„å»ºæ ‘å½¢ç»“æ„</p>
<h2 id="ç®€è¯„-5"><a href="#ç®€è¯„-5" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>å°†å¼ºåŒ–å­¦ä¹ å¼•å…¥å¥å­è¡¨ç¤ºå­¦ä¹ ä¹‹ä¸­ï¼Œå­¦ä¹ æ„å»ºæ ‘çš„ä¸åŒæ–¹å¼ï¼Œä»å·¦å‘å³ï¼Œä»å³å‘å·¦ï¼ŒåŒå‘ï¼Œæœ‰ç›‘ç£ã€åŠç›‘ç£ã€é¢„å…ˆæ— ç»“æ„ç­‰æ–¹å¼å»æ„å»ºæ ‘ç»“æ„ï¼Œä½†æ˜¯è®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼Œåœ¨å‡ ä¸ªä»»åŠ¡ä¸Šæ•ˆæœæå‡ä¸æ˜¯ç‰¹åˆ«æ˜æ˜¾ã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>GANæ˜¯å½“ä¸‹çš„ç ”ç©¶çƒ­ç‚¹ä¹‹ä¸€ï¼Œåœ¨å›¾åƒé¢†åŸŸä¸­ç ”ç©¶è¾ƒå¤šï¼Œæœ¬æœŸçš„ä¸¤ç¯‡paperæ¢è®¨äº†GANåœ¨NLPä¸­çš„åº”ç”¨ï¼Œå€¼å¾—å…³æ³¨å’ŒæœŸå¾…ã€‚æœ€åæ„Ÿè°¢@destinwangã€@gcyydxfã€@chunhualiuã€@tonyaã€@suhuiå’Œ@zhangjunå…­ä½ç«¥é‹çš„è¾›å‹¤å·¥ä½œã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-11-29T17:49:50.000Z"><a href="/2016/11/29/ä¸­æ–‡åˆ†è¯å·¥å…·æµ‹è¯„/">2016-11-29</a></time>
      
      
  
    <h1 class="title"><a href="/2016/11/29/ä¸­æ–‡åˆ†è¯å·¥å…·æµ‹è¯„/">ä¸­æ–‡åˆ†è¯å·¥å…·æµ‹è¯„</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•è¨€"><a href="#å¼•è¨€" class="headerlink" title="å¼•è¨€"></a>å¼•è¨€</h1><p>åˆ†è¯å¯¹äºç ”ç©¶å’Œåº”ç”¨ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†çš„ç«¥é‹æ¥è¯´ï¼Œéƒ½æ˜¯ä¸€ä¸ªéå¸¸éå¸¸åŸºç¡€çš„éƒ¨ä»¶ï¼Œåˆ†è¯çš„è´¨é‡ç›´æ¥å½±å“åˆ°åç»­è¯æ€§æ ‡æ³¨ã€å‘½åå®ä½“è¯†åˆ«ã€å¥æ³•åˆ†æç­‰éƒ¨ä»¶çš„å‡†ç¡®æ€§ã€‚ä½œä¸ºä¸€ä¸ªåŸºç¡€éƒ¨ä»¶ï¼Œå­¦æœ¯ç•Œå¯¹åˆ†è¯çš„ç ”ç©¶å·²ç»éå¸¸ä¹…äº†ï¼Œå¸‚é¢ä¸Šæµè¡Œçš„å‡ å¤§å¼€æºåˆ†è¯å·¥å…·ä¹Ÿè¢«å·¥ä¸šç•Œçš„å„å¤§å…¬å¸åº”ç”¨å¾ˆå¤šå¹´äº†ã€‚æœ€è¿‘ï¼Œä¸­æ–‡åˆ†è¯éšç€ä¸€ç¯‡åšæ–‡çš„å‘è¡¨è¢«æ¨åˆ°äº†é£å£æµªå°–ï¼Œå¼•å‘ä¼—å¤šå¤§ç‰›åœ¨å¾®åšã€å¾®ä¿¡ç¾¤é‡Œçš„æ¿€çƒˆè®¨è®ºã€‚æœ¬æ–‡å¹¶ä¸æƒ³å¯¹è¿™ç¯‡åšæ–‡è¿›è¡Œè¿‡å¤šè¯„è®ºï¼Œåªæ˜¯æƒ³ç”¨å…¬å¼€çš„æ•°æ®é›†å¯¹å„å¤§åˆ†è¯å·¥å…·è¿›è¡Œä¸€ä¸ªå®¢è§‚åœ°æµ‹è¯„ï¼Œä»¥ä¾›å¤§å®¶åœ¨é€‰æ‹©å·¥å…·æ—¶æœ‰æ‰€ä¾æ®ã€‚</p>
<h1 id="ä¸­æ–‡åˆ†è¯å·¥å…·"><a href="#ä¸­æ–‡åˆ†è¯å·¥å…·" class="headerlink" title="ä¸­æ–‡åˆ†è¯å·¥å…·"></a>ä¸­æ–‡åˆ†è¯å·¥å…·</h1><p>æœ¬æ–‡é€‰æ‹©äº†4ä¸ªå¸¸è§çš„åˆ†è¯å·¥å…·ï¼Œåˆ†åˆ«æ˜¯ï¼šå“ˆå·¥å¤§LTPã€ä¸­ç§‘é™¢è®¡ç®—æ‰€NLPIRã€æ¸…åå¤§å­¦THULACå’Œjiebaï¼Œä¸ºäº†å¯¹æ¯”åˆ†è¯é€Ÿåº¦ï¼Œé€‰æ‹©äº†è¿™å››ä¸ªå·¥å…·çš„c++ç‰ˆæœ¬è¿›è¡Œè¯„æµ‹ã€‚</p>
<p>1ã€LTP <a href="https://github.com/HIT-SCIR/ltp" target="_blank" rel="external">https://github.com/HIT-SCIR/ltp</a><br>2ã€NLPIR <a href="https://github.com/NLPIR-team/NLPIR" target="_blank" rel="external">https://github.com/NLPIR-team/NLPIR</a><br>3ã€THULAC <a href="https://github.com/thunlp/THULAC" target="_blank" rel="external">https://github.com/thunlp/THULAC</a><br>4ã€jieba <a href="https://github.com/yanyiwu/cppjieba" target="_blank" rel="external">https://github.com/yanyiwu/cppjieba</a></p>
<h1 id="æµ‹è¯•æ•°æ®é›†"><a href="#æµ‹è¯•æ•°æ®é›†" class="headerlink" title="æµ‹è¯•æ•°æ®é›†"></a>æµ‹è¯•æ•°æ®é›†</h1><p>1ã€SIGHAN Bakeoff 2005 MSR, 560KB  <a href="http://sighan.cs.uchicago.edu/bakeoff2005/" target="_blank" rel="external">http://sighan.cs.uchicago.edu/bakeoff2005/</a><br>2ã€SIGHAN Bakeoff 2005 PKU, 510KB  <a href="http://sighan.cs.uchicago.edu/bakeoff2005/" target="_blank" rel="external">http://sighan.cs.uchicago.edu/bakeoff2005/</a><br>3ã€äººæ°‘æ—¥æŠ¥ 2014, 65MB  <a href="https://pan.baidu.com/s/1hq3KKXe" target="_blank" rel="external">https://pan.baidu.com/s/1hq3KKXe</a></p>
<p>å‰ä¸¤ä¸ªæ•°æ®é›†æ˜¯SIGHANäº2005å¹´ç»„ç»‡çš„ä¸­æ–‡åˆ†è¯æ¯”èµ›æ‰€ç”¨çš„æ•°æ®é›†ï¼Œä¹Ÿæ˜¯å­¦æœ¯ç•Œæµ‹è¯•åˆ†è¯å·¥å…·çš„æ ‡å‡†æ•°æ®é›†ï¼Œæœ¬æ–‡ç”¨äºæµ‹è¯•å„å¤§åˆ†è¯å·¥å…·çš„å‡†ç¡®æ€§ï¼Œè€Œæœ€åä¸€ä¸ªæ•°æ®é›†è§„æ¨¡è¾ƒå¤§ï¼Œç”¨äºæµ‹è¯•åˆ†è¯é€Ÿåº¦ã€‚</p>
<h1 id="æµ‹è¯•æ–¹æ³•"><a href="#æµ‹è¯•æ–¹æ³•" class="headerlink" title="æµ‹è¯•æ–¹æ³•"></a>æµ‹è¯•æ–¹æ³•</h1><p>ç”¨SIGHAN Bakeoff 2005æ¯”èµ›ä¸­æ‰€è‡ªå¸¦çš„scoreè„šæœ¬ã€test goldæ•°æ®å’Œtraining wordsæ•°æ®å¯¹4ä¸ªå·¥å…·è¿›è¡Œå‡†ç¡®æ€§æµ‹è¯•ï¼Œå…·ä½“ä½¿ç”¨æ–¹æ³•å¯å‚è€ƒï¼š<a href="http://sighan.cs.uchicago.edu/bakeoff2005/data/icwb2-data.zip" target="_blank" rel="external">http://sighan.cs.uchicago.edu/bakeoff2005/data/icwb2-data.zip</a> ä¸­çš„readmeæ–‡ä»¶ã€‚</p>
<h1 id="æµ‹è¯•ç¡¬ä»¶"><a href="#æµ‹è¯•ç¡¬ä»¶" class="headerlink" title="æµ‹è¯•ç¡¬ä»¶"></a>æµ‹è¯•ç¡¬ä»¶</h1><p>Intel Core i7-6700 CPU@3.40GHz*8</p>
<h1 id="æµ‹è¯•ç»“æœ"><a href="#æµ‹è¯•ç»“æœ" class="headerlink" title="æµ‹è¯•ç»“æœ"></a>æµ‹è¯•ç»“æœ</h1><p>1ã€MSRæµ‹è¯•ç»“æœ<br><img src="media/1.png" alt="1"></p>
<p>2ã€PKUæµ‹è¯•ç»“æœ<br><img src="media/2.png" alt="2"></p>
<p>3ã€äººæ°‘æ—¥æŠ¥æµ‹è¯•ç»“æœ<br><img src="media/3.png" alt="3"></p>
<h1 id="æµ‹è¯•ç»“è®º"><a href="#æµ‹è¯•ç»“è®º" class="headerlink" title="æµ‹è¯•ç»“è®º"></a>æµ‹è¯•ç»“è®º</h1><p>1ã€ä¸€ä¸ªå¥½çš„åˆ†è¯å·¥å…·ä¸åº”è¯¥åªèƒ½åœ¨ä¸€ä¸ªæ•°æ®é›†ä¸Šå¾—åˆ°ä¸é”™çš„æŒ‡æ ‡ï¼Œè€Œåº”è¯¥åœ¨å„ä¸ªæ•°æ®é›†éƒ½æœ‰å¾ˆä¸é”™çš„è¡¨ç°ã€‚ä»è¿™ä¸€ç‚¹æ¥çœ‹ï¼Œthulacå’Œltpéƒ½è¡¨ç°éå¸¸ä¸é”™ã€‚</p>
<p>2ã€å› ä¸ºåˆ†è¯æ˜¯ä¸ªåŸºç¡€éƒ¨ä»¶ï¼Œåˆ†è¯é€Ÿåº¦å¯¹äºä¸€ä¸ªåˆ†è¯å·¥å…·æ¥è¯´ä¹Ÿè‡³å…³é‡è¦ã€‚ä»è¿™ä¸€ç‚¹æ¥çœ‹ï¼Œthulacå’Œjiebaè¡¨ç°çš„ä¸é”™ã€‚</p>
<p>3ã€å¤§å®¶éƒ½çŸ¥é“ï¼ŒåŸºæœ¬çš„åˆ†è¯ä¾èµ–æ¨¡å‹ï¼Œä½†çœŸæ­£æƒ³ç”¨åˆ†è¯å·¥å…·æ¥è§£å†³åº”ç”¨å±‚é¢ä¸Šçš„é—®é¢˜ï¼Œéƒ½éœ€è¦å€ŸåŠ©äºè¯åº“ï¼Œæœ¬æ–‡æµ‹è¯•çš„4ä¸ªå·¥å…·å‡æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰è¯åº“ã€‚</p>
<p>4ã€ç‰¹åˆ«éœ€è¦å¼ºè°ƒçš„ä¸€ç‚¹æ˜¯ï¼Œå“ˆå·¥å¤§çš„ltpæ”¯æŒåˆ†è¯æ¨¡å‹çš„åœ¨çº¿è®­ç»ƒï¼Œå³åœ¨ç³»ç»Ÿè‡ªå¸¦æ¨¡å‹çš„åŸºç¡€ä¸Šå¯ä»¥ä¸æ–­åœ°å¢åŠ è®­ç»ƒæ•°æ®ï¼Œæ¥å¾—åˆ°æ›´åŠ ä¸°å¯Œã€æ›´åŠ ä¸ªæ€§åŒ–çš„åˆ†è¯æ¨¡å‹ã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>äº‰è®ºæ˜¯ä¸€ä¸ªå¥½çš„äº‹æƒ…ï¼Œå°¤å…¶æ˜¯ä¸åŒèƒŒæ™¯çš„äººç«™åœ¨ä¸åŒçš„è§’åº¦å¯¹åŒä¸€ä¸ªäº‹æƒ…è¿›è¡Œäº‰è®ºï¼Œå¸¸å¸¸ä¼šç¢°æ’å‡ºçŸ¥è¯†çš„ç«èŠ±ï¼Œå¯¹äºè¿™ä¸ªé¢†åŸŸçš„å‘å±•æœ‰æ›´å¥½åœ°æ¨åŠ¨ä½œç”¨ã€‚å¸Œæœ›ç±»ä¼¼çš„äº‰è®ºå¯ä»¥å¤šä¸€äº›ï¼Œè®©åˆšåˆšå…¥é—¨çš„æˆ–è€…å‡†å¤‡å…¥é—¨çš„ç«¥é‹å¯ä»¥æ›´åŠ å®¢è§‚åœ°çœ‹åˆ°ä¸€ä¸ªé¢†åŸŸçš„å‘å±•ç°çŠ¶ï¼Œè€Œä¸æ˜¯ç›²ç›®åœ°è¢«ä¸€äº›çƒ­é—¨çš„è¯è’™è”½åŒçœ¼ï¼Œå¤±å»åˆ¤æ–­ã€‚å¯¹äºåˆ†è¯æ¥è¯´ï¼Œæœ€è¿‘å‡ å¹´å¤§çƒ­çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¹¶ä¸ä¼šæ¯”ä¹‹å‰ä¼ ç»Ÿçš„crfæ¨¡å‹æœ‰å¤šå¤§æ€§èƒ½ä¸Šçš„çªç ´ï¼Œæ‰€ä»¥å¤§å®¶åº”è¯¥ç†æ€§åœ°çœ‹å¾…æ·±åº¦å­¦ä¹ ä»¥åŠäººå·¥æ™ºèƒ½ï¼Œæ§å¾—è¶Šé«˜å¯èƒ½æ‘”å¾—è¶Šæƒ¨ã€‚</p>
<h1 id="å‚è€ƒæ–‡çŒ®"><a href="#å‚è€ƒæ–‡çŒ®" class="headerlink" title="å‚è€ƒæ–‡çŒ®"></a>å‚è€ƒæ–‡çŒ®</h1><p>1ã€Zhongguo Li, Maosong Sun. Punctuation as Implicit Annotations for Chinese Word Segmentation. Computational Linguistics, vol. 35, no. 4, pp. 505-512, 2009.<br>2ã€Meishan Zhang, Yue Zhang, Guohong Fu. Transition-Based Neural Word Segmentation<br><a href="http://www.aclweb.org/anthology/P/P16/P16-1040.pdf" target="_blank" rel="external">http://www.aclweb.org/anthology/P/P16/P16-1040.pdf</a><br>3ã€Meishan Zhang, Zhilong Dengï¼ŒWanxiang Che, and Ting Liu. Combining Statistical Model and Dictionary for Domain Adaption of Chinese Word Segmentation. Journal of Chinese Information Processing. 2012, 26 (2) : 8-12 (in Chinese)<br>4ã€Wanxiang Che, Zhenghua Li, and Ting Liu. LTP: A Chinese Language Technology Platform. In Proceedings of the Coling 2010:Demonstrations. 2010.08, pp13-16, Beijing, China.</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-11-27T06:12:34.000Z"><a href="/2016/11/26/æœ¬å‘¨å€¼å¾—è¯»-2016-11-21-2016-11-25/">2016-11-26</a></time>
      
      
  
    <h1 class="title"><a href="/2016/11/26/æœ¬å‘¨å€¼å¾—è¯»-2016-11-21-2016-11-25/">æœ¬å‘¨å€¼å¾—è¯»(2016.11.21-2016.11.25)</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="ä¸€å‘¨å€¼å¾—è¯»"><a href="#ä¸€å‘¨å€¼å¾—è¯»" class="headerlink" title="ä¸€å‘¨å€¼å¾—è¯»"></a>ä¸€å‘¨å€¼å¾—è¯»</h1><h2 id="Generative-Deep-Neural-Networks-for-Dialogue-A-Short-Review"><a href="#Generative-Deep-Neural-Networks-for-Dialogue-A-Short-Review" class="headerlink" title="Generative Deep Neural Networks for Dialogue: A Short Review"></a><a href="http://t.cn/RfX2bms" target="_blank" rel="external">Generative Deep Neural Networks for Dialogue: A Short Review</a></h2><p>ã€å¯¹è¯ç³»ç»Ÿã€‘æœ¬æ–‡å¯¹seq2seqæ–¹æ³•åœ¨å¯¹è¯ç³»ç»Ÿä¸­çš„åº”ç”¨åšäº†ä¸€ä¸ªç®€çŸ­çš„å¯¹æ¯”å’Œç»¼è¿°ï¼Œä¸»è¦æ˜¯é’ˆå¯¹å‡ ä½ä½œè€…æå‡ºçš„ä¸‰ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼šHREDã€VHREDå’ŒMrRNNï¼Œå®éªŒæ•°æ®ç”¨äº†Ubuntu Dialogue Corpuså’ŒTwitter Corpusã€‚ä¸ç®¡æ˜¯ç”¨seq2seqç”Ÿæˆä¹Ÿå¥½ï¼Œè¿˜æ˜¯å¥—ç”¨æ¨¡æ¿ä¹Ÿç½¢ï¼Œå¯¹è¯ç³»ç»Ÿçš„éš¾ç‚¹ä»æ˜¯ä¸Šä¸‹æ–‡çš„ç†è§£å’Œå¦‚ä½•è¾“å‡ºä¸€äº›é«˜è´¨é‡çš„å¯¹è¯ï¼Œæœ‰äº›åº”ç”¨åœºæ™¯å¯¹responseçš„è¦æ±‚æ²¡é‚£ä¹ˆé«˜ï¼Œåªè¦å¯ä»¥è¾¾åˆ°ä¸€å®šå®é™…æ•ˆæœå³å¯ï¼Œè€Œæœ‰çš„åˆ™éœ€è¦ç”Ÿæˆæ›´åŠ æ¥è¿‘äººç±»çš„å¯¹è¯ã€‚æœ¬æ–‡é€‚åˆç ”ç©¶æ·±åº¦seq2seqçš„ç«¥é‹ä»¥åŠæƒ³çœ‹çœ‹å„ç§seq2seqæ•ˆæœå¦‚ä½•çš„ç«¥é‹æ¥è¯»ã€‚æœ¬æ–‡æ€»ç»“çš„ä¸‰ä¸ªæ¨¡å‹åŸæ–‡é“¾æ¥ï¼š</p>
<p>(a) MrRNN: <a href="https://arxiv.org/pdf/1606.00776.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1606.00776.pdf</a><br>(b) VHRED: <a href="https://arxiv.org/pdf/1605.06069v3.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1605.06069v3.pdf</a><br>(c) HRED: <a href="https://arxiv.org/pdf/1507.04808v3.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1507.04808v3.pdf</a></p>
<h2 id="Coherent-Dialogue-with-Attention-based-Language-Models"><a href="#Coherent-Dialogue-with-Attention-based-Language-Models" class="headerlink" title="Coherent Dialogue with Attention-based Language Models"></a><a href="http://t.cn/Rfag1Jx" target="_blank" rel="external">Coherent Dialogue with Attention-based Language Models</a></h2><p>ã€å¯¹è¯ç³»ç»Ÿã€‘è€ƒè™‘å¹¶ç†è§£ä¸Šä¸‹æ–‡æ˜¯Chatbotçš„ä¸€å¤§éš¾ç‚¹ï¼Œä¹Ÿæ˜¯ç›®å‰ç»å¤§å¤šæ•°chatbotä¸æ™ºèƒ½çš„ä¸»è¦åŸå› ä¹‹ä¸€ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŠ¨æ€çš„attentionæ¨¡å‹ï¼Œåœ¨ç†è§£ç”¨æˆ·è¯·æ±‚çš„æ—¶å€™ï¼ŒåŠ¨æ€åœ°è€ƒè™‘å†å²ä¿¡æ¯ã€‚æœ¬æ–‡ç”¨åˆ°äº†ä¸¤ä¸ªå¼€æ”¾æ•°æ®é›†ï¼Œåˆ†åˆ«æ˜¯MovieTripleså’ŒUbuntu Troubleshoot datasetã€‚å»ºè®®å¯¹chatbotæ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥ç²¾è¯»æ­¤æ–‡ã€‚</p>
<h2 id="Visualizing-and-Understanding-Curriculum-Learning-for-Long-Short-Term-Memory-Networks"><a href="#Visualizing-and-Understanding-Curriculum-Learning-for-Long-Short-Term-Memory-Networks" class="headerlink" title="Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks"></a><a href="http://t.cn/RfXLHIP" target="_blank" rel="external">Visualizing and Understanding Curriculum Learning for Long Short-Term Memory Networks</a></h2><p>ã€è¯¾ç¨‹å­¦ä¹ ã€‘Curriculum Learningæ˜¯ä¸€ç±»æ¨¡æ‹Ÿå°å­©å­å­¦ä¹ è¿‡ç¨‹çš„å­¦ä¹ ç®—æ³•ï¼Œç®€å•åœ°è¯´æ˜¯æŒ‡åœ¨è®­ç»ƒæ¨¡å‹æ˜¯ä»ç®€å•çš„æ ·æœ¬å¼€å§‹ï¼Œé€æ¸å¢åŠ å­¦ä¹ æ ·æœ¬çš„éš¾åº¦ã€‚æœ¬æ–‡ä»¥æƒ…æ„Ÿåˆ†æä¸ºç ”ç©¶å¯¹è±¡ï¼Œå¯¹Curriculum Learningå¦‚ä½•æå‡LSTMæ¨¡å‹åœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸Šçš„æ•ˆæœè¿›è¡Œäº†å®éªŒç ”ç©¶ï¼Œå¹¶ç»™å‡ºäº†å¯è§†åŒ–çš„ç»“æœã€‚æœ¬æ–‡é€‚åˆç ”ç©¶Curriculum Learningçš„ç«¥é‹ä»¥åŠåœ¨è®­ç»ƒæ¨¡å‹ä¸­æƒ³å°è¯•ä¸‹Curriculum Learningæ€è·¯çš„ç«¥é‹ç ”è¯»ã€‚</p>
<h2 id="Variable-Computation-in-Recurrent-Neural-Networks"><a href="#Variable-Computation-in-Recurrent-Neural-Networks" class="headerlink" title="Variable Computation in Recurrent Neural Networks"></a><a href="http://t.cn/RfXUmyN" target="_blank" rel="external">Variable Computation in Recurrent Neural Networks</a></h2><p>ã€RNNç ”ç©¶ã€‘RNNåœ¨è§£å†³åºåˆ—å»ºæ¨¡é—®é¢˜æœ‰ç€å¤©ç„¶çš„ä¼˜åŠ¿ï¼Œä½†æœ‰äº›åºåˆ—æ•°æ®å­˜åœ¨å‘¨æœŸæ€§çš„å˜åŒ–ï¼Œæˆ–è€…çŸ­æ—¶é—´å†…å˜åŒ–å¹¶ä¸æ˜æ˜¾ï¼Œæ¯”å¦‚è§†é¢‘æ•°æ®ï¼Œå› æ­¤å›ºå®šä¸å˜çš„RNNè®­ç»ƒæ–¹æ¡ˆä¼šæµªè´¹è®¡ç®—èµ„æºï¼Œæœ¬æ–‡é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§RNNå˜è®¡ç®—è®­ç»ƒæ–¹æ¡ˆï¼Œå³åœ¨è®¡ç®—ä¸‹ä¸€ä¸ªtime stepçš„hidden stateæ—¶ï¼Œä¸éœ€è¦ä¸Šä¸€ä¸ªtime stepæ‰€æœ‰çš„ç»´åº¦ï¼Œåªå–ä¸€éƒ¨åˆ†æ¥è®¡ç®—ï¼Œå…¶ä»–çš„ç»´åº¦å¤åˆ¶è¿‡æ¥å³å¯ã€‚è¿™ç¯‡å·¥ä½œçš„ç›¸å…³çš„å‰äººç ”ç©¶åŒ…æ‹¬ï¼š2014å¹´çš„A Clockwork RNNï¼Œé“¾æ¥å¦‚ä¸‹ï¼š<a href="https://arxiv.org/pdf/1402.3511.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1402.3511.pdf</a></p>
<h2 id="Learning-to-Distill-The-Essence-Vector-Modeling-Framework"><a href="#Learning-to-Distill-The-Essence-Vector-Modeling-Framework" class="headerlink" title="Learning to Distill: The Essence Vector Modeling Framework"></a><a href="http://t.cn/RfoWk0K" target="_blank" rel="external">Learning to Distill: The Essence Vector Modeling Framework</a></h2><p>ã€è¡¨ç¤ºå­¦ä¹ ã€‘æœ¬æ–‡ç ”ç©¶çš„å†…å®¹åŒ…æ‹¬ä¸¤ä¸ªç‚¹ï¼Œä¸€ä¸ªæ˜¯æ— ç›‘ç£å­¦ä¹ ï¼Œä¸€ä¸ªæ˜¯æ–‡æ¡£è¡¨ç¤ºã€‚è¯è¡¨ç¤ºã€å¥å­è¡¨ç¤ºéƒ½æœ‰æ¯”è¾ƒå¤šçš„è§£å†³æ–¹æ¡ˆï¼Œä½†å®é™…åº”ç”¨ä¸­æ–‡æ¡£çº§åˆ«çš„è¡¨ç¤ºéå¸¸é‡è¦ï¼Œæ¯”å¦‚æƒ…æ„Ÿåˆ†æã€æ–‡æœ¬æ‘˜è¦ç­‰ä»»åŠ¡ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— ç›‘ç£çš„æ–¹æ³•å¯¹æ–‡æ¡£ä»¥åŠèƒŒåæ‰€è•´è—çš„èƒŒæ™¯çŸ¥è¯†è¿›è¡Œä½ç»´è¡¨ç¤ºã€‚è‡ªç„¶è¯­è¨€éšç€å…ƒç´ çº§åˆ«åœ°æå‡ï¼ˆä»å­—ã€è¯ã€çŸ­è¯­ã€å¥å­åˆ°æ–‡æ¡£ï¼‰ï¼Œç ”ç©¶çš„éš¾åº¦éšä¹‹å¢åŠ ï¼Œå®ç”¨ç¨‹åº¦éšä¹‹å‡å°‘ã€‚å»ºè®®æƒ³ä»æ— ç›‘ç£å­¦ä¹ æ–¹æ³•æœ‰æ‰€çªç ´ä»¥åŠæƒ³è¯•è¯•æ–‡æ¡£è¡¨ç¤ºçš„ç«¥é‹å¯ä»¥æ¥è¯»æœ¬æ–‡ã€‚</p>
<h2 id="Unsupervised-Learning-of-Sentence-Representations-using-Convolutional-Neural-Networks"><a href="#Unsupervised-Learning-of-Sentence-Representations-using-Convolutional-Neural-Networks" class="headerlink" title="Unsupervised Learning of Sentence Representations using Convolutional Neural Networks"></a><a href="http://t.cn/Rf9VNdk" target="_blank" rel="external">Unsupervised Learning of Sentence Representations using Convolutional Neural Networks</a></h2><p>ã€å¥å­è¡¨ç¤ºã€‘æœ¬æ–‡çš„è´¡çŒ®åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„CNN-LSTM auto-encoderï¼Œä½œä¸ºä¸€ç§æ— ç›‘ç£çš„å¥å­å­¦ä¹ æ¨¡å‹ã€‚</p>
<h2 id="Emergent-Logical-Structure-in-Vector-Representations-of-Neural-Readers"><a href="#Emergent-Logical-Structure-in-Vector-Representations-of-Neural-Readers" class="headerlink" title="Emergent Logical Structure in Vector Representations of Neural Readers"></a><a href="http://t.cn/Rf9Vwi7" target="_blank" rel="external">Emergent Logical Structure in Vector Representations of Neural Readers</a></h2><p>ã€é—®ç­”ç³»ç»Ÿã€‘é’ˆå¯¹æœ€è¿‘æå‡ºçš„å„ç§å„æ ·çš„attention based reader models,æœ¬æ–‡ä½œè€…åšäº†ä¸€ä¸ªæ¯”è¾ƒå…¨é¢çš„æ€»ç»“å’Œåˆ†æï¼Œå¹¶ä¸”é€šè¿‡æ•°å­¦åˆ†æå’Œå®éªŒå±•ç¤ºäº†æ¨¡å‹ä¹‹é—´çš„ç›¸å…³æ€§ã€‚PaperWeeklyç¬¬åå››æœŸçš„æ–‡ç« æœ‰ç›¸å…³çš„paper noteå¯ä»¥å‚è€ƒ<a href="http://rsarxiv.github.io/2016/11/19/PaperWeekly-%E7%AC%AC%E5%8D%81%E5%9B%9B%E6%9C%9F/">åœ°å€</a></p>
<h1 id="å…¬ç›Šå¹¿å‘Š"><a href="#å…¬ç›Šå¹¿å‘Š" class="headerlink" title="å…¬ç›Šå¹¿å‘Š"></a>å…¬ç›Šå¹¿å‘Š</h1><p>ç¾å›½å›½ç«‹å«ç”Ÿç ”ç©¶é™¢æ‹›åšå£«åï¼Œç ”ç©¶é¢†åŸŸåŒ…æ‹¬ï¼šNLPã€text miningå’Œmachine learningï¼Œæ„Ÿå…´è¶£çš„ç«¥é‹å¯ä»¥çœ‹è¿‡æ¥ï¼Œè¯¦æƒ…è¯·æˆ³<a href="https://www.stat.washington.edu/jobs/archive/2013/may/05.20.13_NIH_E_B_NLP_Post_Doc_Ad_PDF_May_20_2013.pdf" target="_blank" rel="external">è¿™é‡Œ</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-11-26T18:37:08.000Z"><a href="/2016/11/26/PaperWeekly-ç¬¬åäº”æœŸ/">2016-11-26</a></time>
      
      
  
    <h1 class="title"><a href="/2016/11/26/PaperWeekly-ç¬¬åäº”æœŸ/">PaperWeekly ç¬¬åäº”æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•è¨€"><a href="#å¼•è¨€" class="headerlink" title="å¼•è¨€"></a>å¼•è¨€</h1><p>NMTæ˜¯çƒ­é—¨ç ”ç©¶é¢†åŸŸä¹‹ä¸€ï¼Œå°¤å…¶æ˜¯Googleå’Œç™¾åº¦éƒ½æ¨å‡ºäº†è‡ªå·±çš„NMTç¿»è¯‘ç³»ç»Ÿï¼Œåœ¨å·¥ä¸šç•Œã€å­¦æœ¯ç•Œå’Œç¿»è¯‘ç•Œéƒ½å¼•èµ·äº†è½©ç„¶å¤§æ³¢ï¼Œä¸€æ—¶é—´å¯¹NMTæŠ€æœ¯çš„ç ”ç©¶å’Œè®¨è®ºè¾¾åˆ°äº†é¡¶å³°ã€‚Attentionæ¨¡å‹åœ¨NLPä¸­æœ€æ—©çš„ä½¿ç”¨æ­£æ˜¯åœ¨NMTé¢†åŸŸå‡ºç°çš„ï¼ŒåŒ…æ‹¬æ¨ªæ‰«å¾ˆå¤šé¢†åŸŸçš„seq2seq+attentionè§£å†³æ–¹æ¡ˆï¼Œéƒ½æ˜¯åœ¨NMTæ¨¡å‹çš„åŸºç¡€ä¸Šè¿›è¡Œç›¸åº”çš„ä¸€äº›å°æ”¹åŠ¨è€Œæˆçš„ã€‚æ‰€ä»¥ï¼Œæœ¬æœŸPaperWeeklyå¸¦å¤§å®¶çœ‹ä¸€çœ‹æœ€è¿‘ä¸¤å¹´Attentionæ¨¡å‹åœ¨NMTé¢†åŸŸä¸­çš„ç ”ç©¶è¿›å±•ï¼Œæœ¬æ–‡åŒ…æ‹¬ä»¥ä¸‹paperï¼š</p>
<p>1ã€Neural Machine Translation by Jointly Learning to Align and Translate, 2015<br>2ã€Effective approaches to attention-based neural machine translation, 2015<br>3ã€Modeling Coverage for Neural Machine Translation,  2016<br>4ã€Agreement-based Joint Training for Bidirectional Attention-based Neural Machine Translation, 2016<br>5ã€Improving Attention Modeling with Implicit Distortion and Fertility for Machine Translation, 2016</p>
<h1 id="Neural-Machine-Translation-by-Jointly-Learning-to-Align-and-Translate"><a href="#Neural-Machine-Translation-by-Jointly-Learning-to-Align-and-Translate" class="headerlink" title="Neural Machine Translation by Jointly Learning to Align and Translate"></a><a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="external">Neural Machine Translation by Jointly Learning to Align and Translate</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Dzmitry Bahdanau, KyungHyun Cho and Yoshua Bengio</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Jacobs University Bremen, Germany<br><br>Universite Ì de Montre Ìal</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>NMT, attention</p>
<h2 id="æ–‡ç« æ¥æº"><a href="#æ–‡ç« æ¥æº" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ICLR 2015</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>è¿™ç¯‡è®ºæ–‡é¦–æ¬¡æå‡ºåœ¨NMTä¸­ä½¿ç”¨attentionçš„æœºåˆ¶ï¼Œå¯ä»¥ä½¿æ¨¡å‹è‡ªåŠ¨ç¡®å®šæºå¥å­ä¸­å’Œç›®æ ‡è¯è¯­æœ€ç›¸å…³çš„éƒ¨åˆ†ï¼Œç›¸æ¯”äºåŸºæœ¬çš„encoder-decoderæ–¹æ³•æé«˜äº†ç¿»è¯‘æ•ˆæœã€‚</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>è¯¥è®ºæ–‡ä½¿ç”¨çš„åŸºæœ¬æ¨¡å‹æ˜¯ä¸€ä¸ªåŒå‘RNNçš„encoder-decoderçš„ç»“æ„ã€‚åœ¨è¿™ç¯‡è®ºæ–‡ä¹‹å‰ï¼Œencoderéƒ¨åˆ†éƒ½æ˜¯ç›´æ¥æŠŠè¾“å…¥å¥å­encodeæˆä¸€ä¸ªå›ºå®šé•¿åº¦çš„ä¸Šä¸‹æ–‡å‘é‡cï¼Œç„¶ådecoderå†æ ¹æ®è¯¥å‘é‡æ¥äº§ç”Ÿç¿»è¯‘ã€‚ä½†æ˜¯ç”±äºå¥å­é•¿åº¦ä¸å®šï¼Œè¿™ç§åšæ³•å¯¹é•¿å¥å­çš„æ•ˆæœä¸ç†æƒ³ã€‚<br><img src="media/model.png" alt="mode"></p>
<p>ä¸Šå›¾æ˜¯è¿™ç¯‡è®ºæ–‡æå‡ºçš„æ¨¡å‹ç»“æ„ï¼Œä½œè€…é¦–æ¬¡æå‡ºäº†åœ¨decoderä¸­åŠ å…¥ä¸€ç§attentionçš„æœºåˆ¶ã€‚ç›´è§‚ä¸Šç†è§£ï¼Œå°±æ˜¯decoderå¯ä»¥å†³å®šæ›´å¤šåœ°æ³¨æ„åŸå¥å­ä¸­çš„æŸäº›éƒ¨åˆ†ï¼Œä»è€Œä¸å¿…æŠŠåŸå¥å­ä¸­çš„æ‰€æœ‰ä¿¡æ¯éƒ½encodeæˆä¸€ä¸ªå›ºå®šçš„å‘é‡ã€‚å…·ä½“æ¥è®²ï¼Œä¸Šä¸‹æ–‡å‘é‡ciç”±ä¸‹å¼è®¡ç®—å¾—å‡ºï¼š<br><img src="media/ci.png" alt="ci"></p>
<p>å…¶ä¸­ï¼Œ<br><img src="media/aij.png" alt="aij"></p>
<p>å…¶ä¸­ï¼Œ<br><img src="media/eij.png" alt="eij"></p>
<p>ä¸Šå¼ä¸­çš„aä¾¿æ˜¯alignment modelï¼Œå¯ä»¥ç”¨æ¥ä¼°è®¡ä½ç½®jé™„è¿‘çš„è¾“å…¥å’Œä½ç½®içš„è¾“å‡ºä¹‹é—´çš„åŒ¹é…ç¨‹åº¦ã€‚æœ¬è®ºæ–‡ä¸­çš„alignment modelæ˜¯ä¸€ä¸ªå‰é¦ˆç¥ç»ç½‘ç»œï¼Œå®ƒå’Œæ¨¡å‹ä¸­çš„å…¶å®ƒéƒ¨åˆ†ä¸€èµ·è¿›è¡Œè®­ç»ƒã€‚</p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>1ã€è‹±æ³•ç¿»è¯‘æ•°æ®é›† <a href="http://www.statmt.org/wmt14/translation-task.html" target="_blank" rel="external">ACL WMT â€™14</a></p>
<p>2ã€ä¸€ä¸ªåŸºæœ¬çš„RNN encoder-decoderæ¨¡å‹çš„å®ç° <a href="https://github.com/lisa-groundhog/GroundHog." target="_blank" rel="external">GroundHog</a></p>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>1ã€2013å¹´ï¼Œä¸€ä¸ªç±»ä¼¼çš„aligningçš„æ–¹æ³•è¢«æå‡ºç”¨äºæ‰‹å†™ä½“ç”Ÿæˆã€‚è®ºæ–‡ï¼šGraves(2013) Generating sequences with recurrent neural networks<br>2ã€2014å¹´ï¼Œseq2seqçš„ç¥ç»ç½‘ç»œæ¨¡å‹ç”¨äºæœºå™¨ç¿»è¯‘ã€‚è®ºæ–‡ï¼šSutskever(2014) Sequence to sequence learning with neural networks</p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬è®ºæ–‡åˆ›æ–°æ€§åœ°åœ¨NMTä¸­æå‡ºäº†attentionçš„æœºåˆ¶ï¼Œå¯ä»¥ä½¿æ¨¡å‹åœ¨æ¯ä¸€æ­¥æ³¨æ„åˆ°æºå¥å­ä¸­ä¸åŒçš„éƒ¨åˆ†ï¼Œä»è€Œæé«˜äº†NMTçš„æ•ˆæœï¼Œè¯¥æ•ˆæœçš„æå‡å¯¹äºé•¿å¥å­çš„ç¿»è¯‘å°¤å…¶æ˜æ˜¾ã€‚</p>
<h1 id="Effective-approaches-to-attention-based-neural-machine-translation"><a href="#Effective-approaches-to-attention-based-neural-machine-translation" class="headerlink" title="Effective approaches to attention-based neural machine translation"></a><a href="https://arxiv.org/abs/1508.04025" target="_blank" rel="external">Effective approaches to attention-based neural machine translation</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Minh-Thang Luong, Hieu Pham, Christopher D. Manning</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Computer Science Department, Stanford University</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>NMT;Global Attention;Local Attention</p>
<h2 id="æ–‡ç« æ¥æº-1"><a href="#æ–‡ç« æ¥æº-1" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>EMNLP 2015</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>Attentionæœºåˆ¶å¼•å…¥æå¤§æå‡äº†NMTçš„ç¿»è¯‘è´¨é‡ï¼Œä½†å¯¹äºAttentionå®ç°æ¶æ„çš„è®¨è®ºè¿˜å¾ˆå°‘ï¼Œå°¤å…¶æ˜¯å…¨å±€Attentionçš„è®¡ç®—æ•ˆç‡é—®é¢˜ã€‚æœ¬æ–‡å°±æ˜¯è®¨è®ºå„ç§ä¼˜åŒ–ç­–ç•¥ï¼ŒåŒ…æ‹¬Global Attention, Local Attentionï¼ŒInput-feedingæ–¹æ³•ç­‰ã€‚</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>Global Attenionï¼Œç”Ÿæˆä¸Šä¸‹æ–‡å‘é‡c_tæ—¶ï¼Œè€ƒè™‘åŸæ–‡ç¼–ç è¿‡ç¨‹ä¸­çš„æ‰€æœ‰éšçŠ¶æ€ã€‚<br>  <img src="media/1GlobalAttention.png" alt="1GlobalAttention"></p>
<p>Local Attentionï¼Œå¯¹äºæ¯ä¸ªæ­£åœ¨ç”Ÿæˆçš„è¯‘è¯ï¼Œé¢„æµ‹ä¸€ä¸ªåŸæ–‡å¯¹é½çš„ä½ç½®ï¼Œåªè€ƒè™‘è¯¥ä½ç½®å‰åä¸€ä¸ªçª—å£èŒƒå›´å†…çš„åŸæ–‡ç¼–ç éšçŠ¶æ€ã€‚  </p>
<p><img src="media/2LocalAttention.png" alt="2LocalAttention"></p>
<p>Input-feedingï¼Œç”¨ä¸€ä¸ªé¢å¤–çš„å‘é‡ï¼Œæ¥è®°ä½å“ªäº›è¯æ˜¯å·²ç»ç¿»è¯‘è¿‡çš„ï¼Œå³è€ƒè™‘äº†coverageçš„é—®é¢˜ã€‚  </p>
<p><img src="media/3Input-Feeding.png" alt="3Input-Feeding"></p>
<h2 id="èµ„æº-1"><a href="#èµ„æº-1" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>1ã€è®­ç»ƒæ•°æ®ï¼šWMT14 (4.5Må¥å¯¹ï¼Œ116M è‹±æ–‡è¯ï¼Œ110Må¾·æ–‡è¯)<br>2ã€å¼€å‘é›†ï¼šnewstest2013 (3000å¥)<br>3ã€æµ‹è¯•é›†ï¼šnewstest2014(2737å¥)å’Œnewstest2015(2169å¥)<br>4ã€ä»£ç å’Œæ¨¡å‹å…±äº«åœ¨ï¼š<a href="http://nlp.stanford.edu/projects/nmt/" target="_blank" rel="external">http://nlp.stanford.edu/projects/nmt/</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-1"><a href="#ç›¸å…³å·¥ä½œ-1" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>ä¸»è¦æ˜¯followäº†(Bahdanau et al., 2015; Jean et al., 2015)çš„å·¥ä½œï¼Œå¯¹Attentionçš„æœºåˆ¶è¿›è¡Œäº†æ¢è®¨å’Œæ”¹è¿›ã€‚  </p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>English-Germançš„å®éªŒç»“æœï¼Œè¾ƒä¸ç”¨attentionçš„æ–¹æ³•æå‡äº†5ä¸ªå¤šç‚¹BLEUï¼Œå……åˆ†è¯æ˜äº†attentionçš„æœ‰æ•ˆæ€§ã€‚<br>å®éªŒç»“æœçš„è¡¨æ ¼è¯¦ç»†åˆ—å‡ºäº†å„ç§æ”¹è¿›æ–¹æ³•å¸¦æ¥çš„æ”¶ç›Šï¼Œè·Ÿè¿›è€…ä¸å¦¨ä»”ç»†çœ‹çœ‹ï¼ˆä»¥åŠç¬¬5èŠ‚çš„åˆ†æï¼‰ï¼Œå¯ä»¥å¾ˆå¿«äº†è§£å„ç§æŠ˜è…¾çš„æ–¹å‘ã€‚</p>
<p><img src="media/4ExperimentResult.png" alt="4ExperimentResult"></p>
<h2 id="å®Œæˆäººä¿¡æ¯"><a href="#å®Œæˆäººä¿¡æ¯" class="headerlink" title="å®Œæˆäººä¿¡æ¯"></a>å®Œæˆäººä¿¡æ¯</h2><p>å¾®åš @MyGod9ï¼Œè¯­æ™ºäº‘å¸†åˆ›å§‹äººï¼Œæœºå™¨ç¿»è¯‘è€å…µï¼ŒNMTè¿½éšè€…ï¼Œweiyongpeng@lingosail.com </p>
<h1 id="Modeling-Coverage-for-Neural-Machine-Translation"><a href="#Modeling-Coverage-for-Neural-Machine-Translation" class="headerlink" title="Modeling Coverage for Neural Machine Translation"></a><a href="https://arxiv.org/pdf/1601.04811v6.pdf" target="_blank" rel="external">Modeling Coverage for Neural Machine Translation</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Zhaopeng Tu, Zhengdong Lu, Yang Liu, Xiaohua Liu, Hang Li</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>è¯ºäºšæ–¹èˆŸå®éªŒå®¤ï¼Œæ¸…åå¤§å­¦</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>NMT</p>
<h2 id="æ–‡ç« æ¥æº-2"><a href="#æ–‡ç« æ¥æº-2" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ACL2016</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>è§£å†³ç»å…¸ç¥ç»æœºå™¨ç¿»è¯‘æ¨¡å‹ä¸­å­˜åœ¨çš„over-translationï¼ˆè¿‡åº¦ç¿»è¯‘ï¼‰å’Œunder-translation(ç¿»è¯‘ä¸è¶³ï¼‰çš„é—®é¢˜ã€‚</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>åœ¨ä¼ ç»ŸNMTæ¨¡å‹ä¸­ï¼ŒåŠ å…¥ç»Ÿè®¡æœºå™¨ç¿»è¯‘ç­–ç•¥ä¸­çš„coverageæ–¹æ³•ï¼Œæ¥è¿½è¸ªã€åˆ¤æ–­åŸå§‹å¥å­æ˜¯å¦è¢«ç¿»è¯‘ï¼Œå¦‚ä¸‹å›¾ã€å…¬å¼æ‰€ç¤ºã€‚<br><img src="media/pic1.png" alt="pi"><br><img src="media/pic2.png" alt="pi"><br><img src="media/pic3.png" alt="pi"><br>å…¶ä¸­ï¼ŒCä¸ºæ–°å¼•å…¥çš„coverageå‘é‡ã€‚</p>
<h2 id="ç›¸å…³å·¥ä½œ-2"><a href="#ç›¸å…³å·¥ä½œ-2" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>å‰åºæ–‡ç« ï¼šNeural Machine Translation by Jointly Learning to Align and Translate</p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¯¥æ–‡æ˜¯åŸºäºNeural Machine Translation by Jointly Learning to Align and Translateä¹‹ä¸Šçš„å·¥ä½œï¼Œå¼•å…¥äº†ç»Ÿè®¡æœºå™¨ç¿»è¯‘ä¸­çš„Coverageæ–¹æ³•æ¥å°è¯•é¿å…NMTä¸­çš„ä¸€äº›é—®é¢˜ã€‚æ ¹æ®æ–‡ç« çš„è¯•éªŒç»“æœï¼Œè¿™ç§æ–¹æ³•èƒ½å¤Ÿæå‡ç¿»è¯‘æ•ˆæœã€‚ç”±äºå†™ä½œæ­¤æ–‡æ—¶ç¬”è€…æœªä½œå®éªŒï¼Œå› æ­¤å®é™…æ•ˆæœæœ‰å¾…è¿›ä¸€æ­¥è¡¡é‡ã€‚</p>
<h1 id="Agreement-based-Joint-Training-for-Bidirectional-Attention-based-Neural-Machine-Translation"><a href="#Agreement-based-Joint-Training-for-Bidirectional-Attention-based-Neural-Machine-Translation" class="headerlink" title="Agreement-based Joint Training for Bidirectional Attention-based Neural Machine Translation"></a><a href="https://arxiv.org/abs/1512.04650" target="_blank" rel="external">Agreement-based Joint Training for Bidirectional Attention-based Neural Machine Translation</a></h1><h2 id="ä½œè€…-3"><a href="#ä½œè€…-3" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Yong Cheng, Shiqi Shen, Zhongjun He, Wei He, Hua Wu, Maosong Sun, Yang Liu</p>
<h2 id="å•ä½-3"><a href="#å•ä½-3" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Tsinghua University</p>
<h2 id="å…³é”®è¯-3"><a href="#å…³é”®è¯-3" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Bidirectional NMT; Attention</p>
<h2 id="æ–‡ç« æ¥æº-3"><a href="#æ–‡ç« æ¥æº-3" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>IJCAI 2016</p>
<h2 id="é—®é¢˜-3"><a href="#é—®é¢˜-3" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>ç”±äºè‡ªç„¶è¯­è¨€é”™ç»¼å¤æ‚çš„ç»“æ„ï¼Œå•å‘çš„æ³¨æ„åŠ›æ¨¡å‹åªèƒ½å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„éƒ¨åˆ†regulizationã€‚æ–‡ç« æå‡ºäº†è”åˆè®­ç»ƒåŒå‘çš„æ³¨æ„åŠ›æ¨¡å‹ï¼Œå°½å¯èƒ½ä½¿æ³¨æ„åŠ›åœ¨ä¸¤ä¸ªæ–¹å‘ä¸Šä¿æŒä¸€è‡´ã€‚</p>
<h2 id="æ¨¡å‹-3"><a href="#æ¨¡å‹-3" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æ¨¡å‹çš„ä¸­å¿ƒæ€æƒ³å°±æ˜¯å¯¹äºç›¸åŒçš„training dataï¼Œä½¿source-to-targetå’Œtarget-to-sourceä¸¤ä¸ªæ¨¡å‹åœ¨alignment matricesä¸Šä¿æŒä¸€è‡´ã€‚è¿™æ ·èƒ½å¤Ÿå»æ‰ä¸€äº›æ³¨æ„åŠ›å™ªå£°ï¼Œä½¿æ³¨æ„åŠ›æ›´åŠ é›†ä¸­ã€å‡†ç¡®ã€‚æ›´ç¡®åˆ‡åœ°è¯´ï¼Œä½œè€…å¼•å…¥äº†ä¸€ä¸ªæ–°çš„ç›®æ ‡å‡½æ•°ï¼š</p>
<p><img src="media/1.png" alt="1"></p>
<p>å…¶ä¸­<br><img src="media/2.png" alt="2">è¡¨ç¤ºsource-to-targetåŸºäºæ³¨æ„åŠ›çš„ç¿»è¯‘æ¨¡å‹ï¼Œè€Œ<img src="media/3.png" alt="3">è¡¨ç¤ºtarget-to-sourceçš„æ¨¡å‹ã€‚<img src="media/4.png" alt="4">è¡¨ç¤ºå¯¹äºå¥å­s source-to-targetçš„alignment matrixï¼Œè€Œ<img src="media/5.png" alt="5">è¡¨ç¤ºtarget-to-sourceçš„ã€‚<img src="media/6.png" alt="6">æ˜¯æŸå¤±å‡½æ•°ï¼Œå¯ä»¥è¡¡é‡ä¸¤ä¸ªalignment matrixä¹‹é—´çš„disagreeç¨‹åº¦ã€‚</p>
<p>å¯¹äº<img src="media/6.png" alt="6">,æœ‰å‡ ç§ä¸åŒçš„å®šä¹‰æ–¹æ³•ï¼š<br>1ã€Square of addition(SOA)<br><img src="media/7.png" alt="7"></p>
<p>2ã€Square of subtraction(SOS)<br><img src="media/9.png" alt="9"></p>
<p>3ã€Multiplication(MUL)<br><img src="media/10.png" alt="10"></p>
<h2 id="ç›¸å…³å·¥ä½œ-3"><a href="#ç›¸å…³å·¥ä½œ-3" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>ä½œè€…æ–‡ä¸­è¯´çš„æ˜¯bidirectional translationçš„alignment matricesè¦ä¸€è‡´ï¼›è¿˜æœ‰å¦å¤–ä¸€ç¯‡æ–‡ç« â€œAgreement on Target-bidirectional Neural Machine Translationâ€æ˜¯è¯´decodingçš„æ—¶å€™å¯ä»¥æ­£å‘æˆ–è€…åå‘äº§ç”Ÿç›®æ ‡å¥å­ï¼ŒæŠŠè¿™äºŒè€…è¿›è¡Œè”åˆè®­ç»ƒã€‚å¦å¤–ï¼Œæœ€è¿‘ä¹Ÿæœ‰å¾ˆå¤šå…³äºbidirectional trainingæˆ–è€…ç±»ä¼¼æ€æƒ³çš„æ–‡ç« ï¼Œæ¯”å¦‚â€œDual Learning for Machine Translation. Computation and Languageâ€å°†reinforcementçš„æ¦‚å¿µå¼•å…¥äº†bidirectional trainingå½“ä¸­ï¼Œâ€œNeural Machine Translation with Reconstructionâ€ å¸Œæœ›èƒ½ä»target hidden stateæ¢å¤å‡ºsource sentence</p>
<h2 id="ç®€è¯„-3"><a href="#ç®€è¯„-3" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¿™ç¯‡æ–‡ç« èƒœåœ¨idea,å¾ˆå·§å¦™åœ°æƒ³åˆ°äº†è®©æ­£åå‘çš„æ³¨æ„åŠ›ä¸€è‡´æ¥æ”¹è¿›attentionã€‚</p>
<h1 id="Improving-Attention-Modeling-with-Implicit-Distortion-and-Fertility-for-Machine-Translation"><a href="#Improving-Attention-Modeling-with-Implicit-Distortion-and-Fertility-for-Machine-Translation" class="headerlink" title="Improving Attention Modeling with Implicit Distortion and Fertility for Machine Translation"></a><a href="https://arxiv.org/abs/1601.03317" target="_blank" rel="external">Improving Attention Modeling with Implicit Distortion and Fertility for Machine Translation</a></h1><h2 id="ä½œè€…-4"><a href="#ä½œè€…-4" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Shi Feng, Shujie Liu, Nan Yang, Mu Li, Ming Zhou, Kenny Q.Zhu</p>
<h2 id="å•ä½-4"><a href="#å•ä½-4" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Shanghai Jiao Tong University, Microsoft Research</p>
<h2 id="å…³é”®è¯-4"><a href="#å…³é”®è¯-4" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>NMT, Attention, Fertility, Distortion</p>
<h2 id="æ–‡ç« æ¥æº-4"><a href="#æ–‡ç« æ¥æº-4" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>COLING 2016</p>
<h2 id="é—®é¢˜-4"><a href="#é—®é¢˜-4" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>ä½¿ç”¨attentionæœºåˆ¶è§£å†³NMTä¸­è°ƒåºå’Œç¹è¡ç‡çš„é—®é¢˜ã€‚</p>
<h2 id="æ¨¡å‹-4"><a href="#æ¨¡å‹-4" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æ¨¡å‹éå¸¸ç®€å•ï¼Œå³åœ¨attentionæœºåˆ¶ä¸­å°†å‰ä¸€æ—¶åˆ»çš„context vector cä½œä¸ºè¾“å…¥ä¼ å…¥å½“å‰æ—¶åˆ»attentionä¸­ï¼ˆå‘½åä¸ºRecAttï¼‰ã€‚å¦‚å›¾ï¼š</p>
<p><img src="media/coling.jpg" alt="coling"></p>
<p>é€šè¿‡è¿™æ ·çš„RecAttæœºåˆ¶ï¼Œattentionéƒ¨åˆ†çš„ç½‘ç»œç›¸å½“äºè®°å¿†äº†ä¹‹å‰æ—¶åˆ»çš„contextã€‚</p>
<h2 id="ç›¸å…³å·¥ä½œ-4"><a href="#ç›¸å…³å·¥ä½œ-4" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>ACL 2016æèˆªè€å¸ˆç»„çš„å·¥ä½œ Modeling Coverage for Neural Machine Translationåˆ©ç”¨äº†attentionæœºåˆ¶æ¥è§£å†³äº†NMTä¸­â€œæ¬ ç¿»è¯‘â€å’Œâ€œè¿‡ç¿»è¯‘â€çš„é—®é¢˜ã€‚</p>
<h2 id="ç®€è¯„-4"><a href="#ç®€è¯„-4" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¯¥æ–‡ç« çš„åˆ›æ–°ä¹‹å¤„åœ¨äºæå‡ºå°†attentionè®¡ç®—å¾—åˆ°çš„context vector cä½œä¸ºattentionçš„è¾“å…¥ï¼Œè¿™æ ·å°±æ˜¯çš„attentionæœºåˆ¶å¸¦æœ‰ä¸€ç§recurrentçš„æ„å‘³ã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>æœ¬æœŸPaperWeeklyç²¾é€‰äº†5ç¯‡Attentionæ¨¡å‹åœ¨NMTä»»åŠ¡ä¸Šçš„ç ”ç©¶å·¥ä½œï¼ŒAttentionæ¨¡å‹çš„å‘å±•ä¸ä»…ä»…æ¨åŠ¨ç€NMTçš„è¿›æ­¥ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥å€Ÿé‰´äºå…¶ä»–çš„ä»»åŠ¡ä¸­ï¼Œæ¯”å¦‚QAï¼Œæ¯”å¦‚chatbotã€‚æ„Ÿè°¢@MyGod9 @é›¨ç¥ @susie-nmt @æäº‰ @magic282 äº”ä½ç«¥é‹çš„è¾›å‹¤ä»˜å‡ºã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-11-20T04:47:55.000Z"><a href="/2016/11/19/æ‚‰å°¼ç§‘æŠ€å¤§å­¦åšå£«åæ‹›è˜ä¿¡æ¯/">2016-11-19</a></time>
      
      
  
    <h1 class="title"><a href="/2016/11/19/æ‚‰å°¼ç§‘æŠ€å¤§å­¦åšå£«åæ‹›è˜ä¿¡æ¯/">æ‚‰å°¼ç§‘æŠ€å¤§å­¦åšå£«åæ‹›è˜ä¿¡æ¯</a></h1>
  

    </header>
    <div class="entry">
      
        <p>Hi, I am recruiting a Postdoc in Machine Learning for two (2) years. In brief, the candidate should:</p>
<p>1 Hold a PhD in machine learning and have a good research track record.</p>
<p>2 Have a genuine interest in mathematical modeling.</p>
<p>3 Good communication skills and is willing to help PhD students resolving their mathematical issues.</p>
<p>4 Excellent in programming and experimentation.</p>
<p>The candidate will work with Dr Richard Xu (Yida.Xu@uts.edu.au), where his teamâ€™s recent research themes include: Bayesian Non-Parametric (BNP), Monte-Carlo inference, Matrix (and Tensor) factorization and Deep Learning. The application areas include both computer vision and document. There is no strict requirement that the candidate must align his/her research exactly to Richardâ€™s existing work, i.e., the candidate can continue to work in his/her established field as long as the group benefit from his/her presence.</p>
<p>Please contact Richard to obtain further information, and remember to check out his website:</p>
<p><a href="http://www-staff.it.uts.edu.au/~ydxu/" target="_blank" rel="external">http://www-staff.it.uts.edu.au/~ydxu/</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-11-20T04:30:55.000Z"><a href="/2016/11/19/cs-CL-weekly-2016-11-14-2016-11-18/">2016-11-19</a></time>
      
      
  
    <h1 class="title"><a href="/2016/11/19/cs-CL-weekly-2016-11-14-2016-11-18/">cs.CL weekly 2016.11.14-2016.11.18</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="ä¸€å‘¨å€¼å¾—è¯»"><a href="#ä¸€å‘¨å€¼å¾—è¯»" class="headerlink" title="ä¸€å‘¨å€¼å¾—è¯»"></a>ä¸€å‘¨å€¼å¾—è¯»</h1><h2 id="UTCNN-a-Deep-Learning-Model-of-Stance-Classificationon-on-Social-Media-Text"><a href="#UTCNN-a-Deep-Learning-Model-of-Stance-Classificationon-on-Social-Media-Text" class="headerlink" title="UTCNN: a Deep Learning Model of Stance Classificationon on Social Media Text"></a><a href="http://t.cn/RfGR4GE" target="_blank" rel="external">UTCNN: a Deep Learning Model of Stance Classificationon on Social Media Text</a></h2><p>ã€æ–‡æœ¬åˆ†ç±»ã€‘ã€ç¤¾äº¤ç½‘ç»œã€‘ç¤¾äº¤ç½‘ç»œä¸­è•´è—ç€å¤§é‡çš„éç»“æ„åŒ–çš„æ–‡æœ¬ï¼Œå¯¹ç¤¾äº¤ç½‘ç»œçš„æŒ–æ˜ä¹Ÿæ˜¯ä¸€å—é‡è¦çš„ç ”ç©¶å†…å®¹ã€‚æœ¬æ–‡ç ”ç©¶å†…å®¹ä¸ºç«‹åœºåˆ†ç±»ï¼Œåˆ›æ–°ä¹‹å¤„åœ¨äºåšåˆ†ç±»æ—¶ä¸ä»…ä»…è€ƒè™‘è¯¥æ–‡æœ¬ä¿¡æ¯æœ¬èº«ï¼Œè€Œä¸”è€ƒè™‘äº†ä¸è¯¥æ–‡æœ¬ç›¸å…³çš„è¯„è®ºã€åé¦ˆã€ç”¨æˆ·ä¿¡æ¯ã€è¯é¢˜ç­‰å„ç§æ–‡æœ¬ä¿¡æ¯ã€‚æ¨¡å‹éƒ¨åˆ†æ²¡æœ‰å¤ªå¤šçš„æ–°æ„ï¼Œæ˜¯ç»å…¸çš„CNNã€‚æœ¬æ–‡é€‚åˆåšç¤¾äº¤ç½‘ç»œæ–‡æœ¬æŒ–æ˜çš„ç«¥é‹æ¥è¯»ã€‚</p>
<h2 id="A-Way-out-of-the-Odyssey-Analyzing-and-Combining-Recent-Insights-for-LSTMs"><a href="#A-Way-out-of-the-Odyssey-Analyzing-and-Combining-Recent-Insights-for-LSTMs" class="headerlink" title="A Way out of the Odyssey: Analyzing and Combining Recent Insights for LSTMs"></a><a href="http://t.cn/RfVSmk7" target="_blank" rel="external">A Way out of the Odyssey: Analyzing and Combining Recent Insights for LSTMs</a></h2><p>ã€æ–‡æœ¬åˆ†ç±»ã€‘RNNåŠå…¶æ‰©å±•LSTMåœ¨æ–‡æœ¬åˆ†ç±»ä¸­å¾—åˆ°äº†å¹¿æ³›çš„åº”ç”¨ï¼Œæœ¬æ–‡æ¢ç©¶äº†å¤šç§LSTMçš„å°å˜ç§å¯¹åˆ†ç±»ç»“æœçš„å½±å“ï¼Œä¸€äº›å°æ”¹å˜å¯¹ç»“æœè¿˜æ˜¯æœ‰ä¸€å®šå½±å“çš„ã€‚æœ¬æ–‡é€‚åˆå·¥ç¨‹ä¸Šç”¨LSTMè§£å†³æ–‡æœ¬åˆ†ç±»é—®é¢˜çš„ç«¥é‹ç²¾è¯»ã€‚</p>
<h2 id="Linguistically-Regularized-LSTMs-for-Sentiment-Classification"><a href="#Linguistically-Regularized-LSTMs-for-Sentiment-Classification" class="headerlink" title="Linguistically Regularized LSTMs for Sentiment Classification"></a><a href="http://t.cn/Rf56bpv" target="_blank" rel="external">Linguistically Regularized LSTMs for Sentiment Classification</a></h2><p>ã€æƒ…æ„Ÿåˆ†æã€‘æœ¬æ–‡æœ€å¤§çš„äº®ç‚¹åœ¨äºå°†è¯­è¨€å­¦èµ„æºï¼Œæ¯”å¦‚æƒ…æ„Ÿè¯å…¸ï¼Œå¦å®šè¯ï¼Œè¡¨ç¤ºç¨‹åº¦çš„è¯ç­‰ç­‰ä»¥çº¦æŸæ¡ä»¶çš„å½¢å¼èå…¥åˆ°äº†ç°æœ‰çš„å¥å­çº§åˆ«çš„LSTMåˆ†ç±»æ¨¡å‹ä¸­ï¼Œå–å¾—äº†ä¸é”™çš„æ•ˆæœã€‚æ·±åº¦å­¦ä¹ ç«èµ·æ¥ä¹‹åï¼Œå¤§å®¶éƒ½æ¨å´‡æ•°æ®é©±åŠ¨çš„æ¨¡å‹ï¼Œå¸Œæœ›æ‰¾åˆ°ä¸€ç§ç®€å•ç²—ç³™çš„è§£å†³æ–¹æ¡ˆï¼Œè€Œå¿½è§†äº†ç»å…¸çš„è‡ªç„¶è¯­è¨€èµ„æºå’Œè¯­è¨€å­¦çš„çŸ¥è¯†ã€‚ç»å…¸çš„è¿™äº›èµ„æºéƒ½æ˜¯éå¸¸å®è´µçš„ä¸œè¥¿ï¼Œå¦‚ä½•å°†è¿™äº›çŸ¥è¯†èå…¥åˆ°ç°æœ‰çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­ï¼Œæ˜¯ä¸ªå¾ˆéš¾ä½†å´éå¸¸æœ‰æ„ä¹‰çš„äº‹æƒ…ï¼Œæœ¬æ–‡åœ¨å¥å­çº§åˆ«çš„æƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡ä¸­åšäº†ç›¸å…³çš„æ¢ç´¢ã€‚æ¨èç ”ç©¶æƒ…æ„Ÿåˆ†æçš„ç«¥é‹ç²¾è¯»ã€‚</p>
<h2 id="Googleâ€™s-Multilingual-Neural-Machine-Translation-System-Enabling-Zero-Shot-Translation"><a href="#Googleâ€™s-Multilingual-Neural-Machine-Translation-System-Enabling-Zero-Shot-Translation" class="headerlink" title="Googleâ€™s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation"></a><a href="http://t.cn/Rf5I4nw" target="_blank" rel="external">Googleâ€™s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation</a></h2><p>ã€æœºå™¨ç¿»è¯‘ã€‘Google NMTç³»ç»Ÿæ”¯æŒZero-Shotç¿»è¯‘ï¼Œä»è®­ç»ƒé›†å……è¶³çš„A-&gt;Bï¼ŒB-&gt;Cä¸¤ä¸ªç¿»è¯‘æ¨¡å‹ä¸­å¯ä»¥æ¨å‡ºä¸€ä¸ªè´¨é‡ä¸é”™çš„A-&gt;Cæ¨¡å‹ï¼ŒAå’ŒCå¹¶ä¸éœ€è¦å¾ˆå……è¶³çš„è®­ç»ƒé›†ã€‚</p>
<h2 id="Zero-resource-Machine-Translation-by-Multimodal-Encoder-decoder-Network-with-Multimedia-Pivot"><a href="#Zero-resource-Machine-Translation-by-Multimodal-Encoder-decoder-Network-with-Multimedia-Pivot" class="headerlink" title="Zero-resource Machine Translation by Multimodal Encoder-decoder Network with Multimedia Pivot"></a><a href="http://t.cn/Rf5IB9P" target="_blank" rel="external">Zero-resource Machine Translation by Multimodal Encoder-decoder Network with Multimedia Pivot</a></h2><p>ã€å¤šæ¨¡æ€ã€‘ã€æœºå™¨ç¿»è¯‘ã€‘ç°åœ¨çš„äººå·¥æ™ºèƒ½è¿˜è¾¾ä¸åˆ°å¾ˆé«˜çš„æ™ºèƒ½æ°´å¹³ï¼Œä½†æ˜¯å¤„ç†æˆ–è€…ç†è§£ä¸€äº›ç¨å¾®åˆçº§çš„ä¸œè¥¿å¯èƒ½è¿˜è¡Œï¼Œæ¯”å¦‚3å²å­©å­çš„æ•…äº‹ä¹‹ç±»çš„ã€‚ä¹‹å‰èŒç”Ÿä¸€ä¸ªæƒ³æ³•ï¼Œèƒ½ä¸èƒ½é’ˆå¯¹å°å­©å­¦ä¹ ï¼Œæ¯”å¦‚å­¦ä¹ è‹±è¯­ï¼Œä¼ ç»Ÿçš„æ–¹æ³•å¯èƒ½æ˜¯ç»™ä¸€å¥ä¸­æ–‡ï¼Œæ•™ä¸€å¥è‹±è¯­ï¼Œæ„Ÿè§‰ç”¨åˆ°çš„ä¿¡æ¯é‡è¿˜æ˜¯å°‘ï¼Œèƒ½ä¸èƒ½ä¸€è¾¹çœ‹å›¾ï¼Œä¸€è¾¹å­¦ä¹ è‹±è¯­ï¼Œç›¸å½“äºç”¨åˆ°äº†å›¾åƒè¿™ä¸ªä¿¡æ¯ï¼Œå­©å­åœ¨å­¦ä¹ çš„è¿‡ç¨‹ä¸­ä¼šå¤šä¸€äº›ä¿¡æ¯ç»´åº¦ï¼Œå­¦ä¹ æ•ˆæœå¯èƒ½ä¼šæ›´å¥½ä¸€äº›ã€‚æœ¬æ–‡æ­£æ˜¯åšäº†è¿™ä¹ˆä¸€ä»¶äº‹æƒ…ï¼Œå€ŸåŠ©å›¾åƒä½œä¸ºæœºå™¨ç¿»è¯‘çš„æ¡¥æ¢ã€‚</p>
<h2 id="Neural-Machine-Translation-with-Pivot-Languages"><a href="#Neural-Machine-Translation-with-Pivot-Languages" class="headerlink" title="Neural Machine Translation with Pivot Languages"></a><a href="http://t.cn/RftFqja" target="_blank" rel="external">Neural Machine Translation with Pivot Languages</a></h2><p>ã€æœºå™¨ç¿»è¯‘ã€‘å¾ˆå¤šè¯­è¨€çš„æœºå™¨ç¿»è¯‘éƒ½é¢ä¸´ç€ä¸€ä¸ªè¯­è¨€å¯¹æ•°æ®é›†åŒ®ä¹çš„é—®é¢˜ï¼Œä¸€ä¸ªæ¯”è¾ƒç›´è§‚çš„æ€è·¯æ˜¯ï¼Œç”¨ä¸€ç§å¸¸è§çš„è¯­è¨€ä½œä¸ºâ€œæ¡¥æ¢â€ï¼Œè¿æ¥èµ·ä¸¤ç§è¯­è¨€å¯¹æ•°æ®é›†åŒ®ä¹çš„è¯­è¨€ã€‚æ˜¨å¤©Googleçš„zero-shotä¹Ÿæ­£æ˜¯è¿™ä¹ˆä¸€ç§æ€è·¯ï¼Œæœ¬æ–‡ä¹Ÿåœ¨è¿™æ–¹é¢è¿›è¡Œäº†ç ”ç©¶å·¥ä½œï¼Œå³æƒ³åšA-&gt;Cçš„ç¿»è¯‘ï¼Œéœ€è¦æ‹¿ä¸€ä¸ªçƒ­é—¨è¯­è¨€Bä½œä¸ºæ¡¥æ¢ï¼Œæ„é€ ä¸€ä¸ªA-&gt;B,B-&gt;Cçš„è”åˆè®­ç»ƒæ¨¡å‹ï¼Œæœ¬æ–‡ç”¨è‹±è¯­ä½œä¸ºBï¼Œç”¨å¾·è¯­ã€æ³•è¯­ã€è¥¿ç­ç‰™è¯­åˆ†åˆ«ä½œä¸ºAå’ŒCè¿›è¡Œäº†ä¸¤ç»„å®éªŒï¼ŒéªŒè¯äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚è¿™ç§â€œä¸²è¡Œâ€seq2seqçš„æ€è·¯ï¼Œå…¶å®å¯ä»¥å°è¯•ä¸€äº›å…¶ä»–çš„ä»»åŠ¡ï¼Œåšä¸€äº›seq2seq2seqâ€¦çš„æ¨¡å‹å‡ºæ¥ã€‚</p>
<h2 id="Joint-Representation-Learning-of-Text-and-Knowledge-for-Knowledge-Graph-Completion"><a href="#Joint-Representation-Learning-of-Text-and-Knowledge-for-Knowledge-Graph-Completion" class="headerlink" title="Joint Representation Learning of Text and Knowledge for Knowledge Graph Completion"></a><a href="http://t.cn/Rf5J12U" target="_blank" rel="external">Joint Representation Learning of Text and Knowledge for Knowledge Graph Completion</a></h2><p>ã€çŸ¥è¯†è¡¨ç¤ºã€‘â€œè”åˆå­¦ä¹ â€æ˜¯ä¸ªçƒ­é—¨è¯ï¼Œâ€œè”åˆå­¦ä¹ â€å¯ä»¥é¿å…ä¸€äº›è¯­è¨€åˆ†æè¿‡ç¨‹ï¼ˆæ¯”å¦‚ï¼šå¥æ³•ä¾å­˜åˆ†æï¼‰å¸¦æ¥çš„è¯¯å·®ã€‚æœ¬æ–‡åœ¨å­¦ä¹ è¯ã€å®ä½“å’Œå…³ç³»è¡¨ç¤ºæ—¶åŒæ—¶ç”¨åˆ°äº†textå’ŒçŸ¥è¯†å›¾è°±ä¿¡æ¯ï¼Œå¾—åˆ°äº†ä¸é”™çš„æ•ˆæœã€‚</p>
<h2 id="Multi-lingual-Knowledge-Graph-Embeddings-for-Cross-lingual-Knowledge-Alignment"><a href="#Multi-lingual-Knowledge-Graph-Embeddings-for-Cross-lingual-Knowledge-Alignment" class="headerlink" title="Multi-lingual Knowledge Graph Embeddings for Cross-lingual Knowledge Alignment"></a><a href="http://t.cn/Rf5XVuD" target="_blank" rel="external">Multi-lingual Knowledge Graph Embeddings for Cross-lingual Knowledge Alignment</a></h2><p>ã€çŸ¥è¯†å›¾è°±ã€‘ä¸€ä¸ªæ–°æ¨¡å‹æ¥å¡«å‘ï¼ŒTransç³»åˆ—çš„æ–°æˆå‘˜â€”â€”MTransE </p>
<h2 id="End-to-End-Neural-Sentence-Ordering-Using-Pointer-Network"><a href="#End-to-End-Neural-Sentence-Ordering-Using-Pointer-Network" class="headerlink" title="End-to-End Neural Sentence Ordering Using Pointer Network"></a><a href="http://t.cn/RftkYoF" target="_blank" rel="external">End-to-End Neural Sentence Ordering Using Pointer Network</a></h2><p>ã€å¥å­æ’åºã€‘ã€æ–‡æœ¬æ‘˜è¦ã€‘å¥å­æ’åºæ˜¯ä¸€é¡¹é‡è¦çš„åŸºæœ¬å·¥ä½œï¼Œå°¤å…¶æ˜¯åœ¨åšå•æ–‡æ¡£å’Œå¤šæ–‡æ¡£æ–‡æœ¬æŠ½å–å¼æ‘˜è¦æ—¶æ˜¾å¾—ç‰¹åˆ«é‡è¦ã€‚ç»å…¸çš„æ’åºæ–¹æ³•å‡ ä¹éƒ½æ˜¯è€ƒè™‘å•ä¸ªå¥å­æ‰€åŒ…å«çš„ä¿¡æ¯è¿›è¡Œæ’åºï¼Œå¿½ç•¥äº†å¥å­çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚æœ¬æ–‡å·¥ä½œå€Ÿé‰´äº†Pointer Networkçš„æ€è·¯ï¼Œæå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯æ’åºæ¨¡å‹ï¼Œåœ¨æ’åºæ—¶è€ƒè™‘å¥å­çš„ä¸Šä¸‹æ–‡ã€‚é€šè¿‡ä¸¤ç»„å®éªŒéªŒè¯äº†æœ¬æ–‡ç®—æ³•çš„æœ‰æ•ˆæ€§ã€‚æœºå™¨ç¿»è¯‘ä¸­çš„seq2seq+attentionå·²ç»æˆåŠŸçš„åº”ç”¨åœ¨äº†å¾ˆå¤šä»»åŠ¡ä¸Šï¼Œä½†é’ˆå¯¹å…·ä½“ä»»åŠ¡ä¸åŒçš„ç‰¹ç‚¹è¿›è¡Œé’ˆå¯¹æ€§åœ°ä¿®æ­£ä¼šå¸¦æ¥æ¯”è¾ƒç†æƒ³çš„ç»“æœã€‚å»ºè®®ç ”ç©¶æ–‡æœ¬æ‘˜è¦çš„ç«¥é‹è¯»æœ¬æ–‡ã€‚</p>
<h2 id="The-Amazing-Mysteries-of-the-Gutter-Drawing-Inferences-Between-Panels-in-Comic-Book-Narratives"><a href="#The-Amazing-Mysteries-of-the-Gutter-Drawing-Inferences-Between-Panels-in-Comic-Book-Narratives" class="headerlink" title="The Amazing Mysteries of the Gutter: Drawing Inferences Between Panels in Comic Book Narratives"></a><a href="http://t.cn/RfVoHOF" target="_blank" rel="external">The Amazing Mysteries of the Gutter: Drawing Inferences Between Panels in Comic Book Narratives</a></h2><p>ã€é—®ç­”ç³»ç»Ÿã€‘åŸºäºä¸Šä¸‹æ–‡çš„é—®ç­”å·²ç»æœ‰å¾ˆå¤šæ•°æ®é›†äº†ï¼ŒåŸºäºå›¾åƒçš„é—®ç­”ä¹Ÿæœ‰ä¸€äº›æ•°æ®é›†äº†ã€‚æ¼«ç”»æ˜¯ä¸€ç±»å¤§å®¶å°æ—¶å€™éƒ½å–œæ¬¢çš„è¯»ç‰©ï¼ŒåŒ…å«äº†ä¸°å¯Œçš„å›¾åƒå’Œæ–‡æœ¬æ•°æ®ï¼ˆå¯¹è¯ï¼‰ã€‚æœ¬æ–‡ç»™å‡ºäº†ä¸€ä¸ªå¤§å‹æ•°æ®é›†ï¼ŒåŒ…æ‹¬äº†ä¸°å¯Œçš„å›¾åƒå’Œæ–‡æœ¬ï¼Œè§„æ¨¡åœ¨120ä¸‡ï¼ˆ120GBï¼‰å·¦å³ã€‚æ•°æ®ç»™å‡ºäº†å‡ ä¸ªä»»åŠ¡ï¼ŒåŸºäºå›¾åƒçš„é—®ç­”ä»»åŠ¡ï¼ŒåŸºäºå¯¹è¯æ–‡æœ¬çš„é—®ç­”ä»»åŠ¡å’Œæ–‡æœ¬æ’åºä»»åŠ¡ã€‚å¯¹é—®ç­”æ„Ÿå…´è¶£ï¼Œæƒ³æ‰¾ä¸€äº›æ–°æ•°æ®æ¥åˆ·ä¸€åˆ·æ¦œçš„ç«¥é‹å¯ä»¥çœ‹è¿‡æ¥ã€‚</p>
<h1 id="ä¸€å‘¨èµ„æº"><a href="#ä¸€å‘¨èµ„æº" class="headerlink" title="ä¸€å‘¨èµ„æº"></a>ä¸€å‘¨èµ„æº</h1><h2 id="Highlights-of-EMNLP-2016-Dialogue-deep-learning-and-more"><a href="#Highlights-of-EMNLP-2016-Dialogue-deep-learning-and-more" class="headerlink" title="Highlights of EMNLP 2016: Dialogue, deep learning, and more"></a><a href="http://blog.aylien.com/highlights-emnlp-2016-dialogue-deeplearning-and-more/" target="_blank" rel="external">Highlights of EMNLP 2016: Dialogue, deep learning, and more</a></h2><p>NLPæŠ€æœ¯æœåŠ¡å…¬å¸Aylienå†™çš„EMNLP 2016æ€»ç»“</p>
<h1 id="ä¸€å¥è¯å…¬ç›Šå¹¿å‘Š"><a href="#ä¸€å¥è¯å…¬ç›Šå¹¿å‘Š" class="headerlink" title="ä¸€å¥è¯å…¬ç›Šå¹¿å‘Š"></a>ä¸€å¥è¯å…¬ç›Šå¹¿å‘Š</h1><p>æ‚‰å°¼ç§‘æŠ€å¤§å­¦Dr Richard Xuæ‹›æœºå™¨å­¦ä¹ åšå£«åï¼Œæ„Ÿå…´è¶£çš„ç«¥é‹çœ‹è¿‡æ¥ã€‚å…·ä½“ä¿¡æ¯è¯·ç‚¹é˜…è¯»åŸæ–‡<a href="http://rsarxiv.github.io/2016/11/19/%E6%82%89%E5%B0%BC%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E5%8D%9A%E5%A3%AB%E5%90%8E%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF/">æŸ¥çœ‹é“¾æ¥</a>ã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-11-19T17:58:02.000Z"><a href="/2016/11/19/PaperWeekly-ç¬¬åå››æœŸ/">2016-11-19</a></time>
      
      
  
    <h1 class="title"><a href="/2016/11/19/PaperWeekly-ç¬¬åå››æœŸ/">PaperWeekly ç¬¬åå››æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•è¨€"><a href="#å¼•è¨€" class="headerlink" title="å¼•è¨€"></a>å¼•è¨€</h1><p>PaperWeeklyå·²ç»ä»‹ç»è¿‡ä¸å°‘Question Answeringçš„ç›¸å…³å·¥ä½œã€‚ä¸»è¦æœ‰DeepMind Attentive Readerï¼ŒFAIR Memory Networksï¼ŒDanqiâ€™s Stanford Reader, Attention Sum Reader, Gated Attention Sum Reader, Attention Over Attention Reader, etc. è¿™äº›æ¨¡å‹å…³è”æ€§å¾ˆå¤§ï¼Œæˆ–å¤šæˆ–å°‘å­˜åœ¨ç›¸ä¼¼ä¹‹å¤„ã€‚æœ¬æ–‡ç»™å¤§å®¶ä»‹ç»ä¸€ä¸‹Toyota Technological Institute at Chicago (TTIC)åœ¨Question Answeringæ–¹é¢çš„ç›¸å…³å·¥ä½œï¼Œå…±æœ‰3ç¯‡paperï¼š</p>
<p>1ã€Who did What: A Large-Scale Person-Centered Cloze Dataset, 2016<br>2ã€Broad Context Language Modeling as Reading Comprehension, 2016<br>3ã€Emergent Logical Structure in Vector Representations of Neural Readers, 2016</p>
<h1 id="Who-did-What-A-Large-Scale-Person-Centered-Cloze-Dataset"><a href="#Who-did-What-A-Large-Scale-Person-Centered-Cloze-Dataset" class="headerlink" title="Who did What: A Large-Scale Person-Centered Cloze Dataset"></a><a href="https://tticnlp.github.io/who_did_what/" target="_blank" rel="external">Who did What: A Large-Scale Person-Centered Cloze Dataset</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Takeshi Onishi, Hai Wang, Mohit Bansal, Kevin Gimpel, David McAllester</p>
<h2 id="æ–‡ç« æ¥æº"><a href="#æ–‡ç« æ¥æº" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>EMNLP 2016</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æ–‡ç« æ„å»ºäº†ä¸€ä¸ªæ–°çš„Question Answering datasetï¼Œâ€Who did Whatâ€ã€‚</p>
<p>sample instanceå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚<br><img src="media/example.png" alt="example"></p>
<p>é—®é¢˜çš„å¥å­æ€»æ˜¯æŒ–æ‰äº†ä¸€äº›named entitiesï¼Œç„¶åç»™å‡ºåœ¨æ–‡ä¸­å‡ºç°è¿‡çš„åˆ«çš„named entitiesä½œä¸ºé€‰é¡¹ã€‚è¿™ä¸€ä¸ªdatasetçš„éš¾åº¦è¦é«˜äºä¹‹å‰çš„CNN/DM datasetï¼Œå¯ä»¥ä½œä¸ºåˆ›å»ºæ–°æ¨¡å‹çš„å‚è€ƒæ•°æ®é›†ã€‚</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æ„å»ºæ­¤æ•°æ®é›†çš„æ–¹æ³•ä¸CNN/DMä¸åŒï¼Œé—®é¢˜å¹¶ä¸æ˜¯context passgeçš„ä¸€ä¸ªsummaryã€‚é—®é¢˜ä¸contextå‡æ¥è‡ªGigaword Corpusï¼Œä»–ä»¬æ˜¯ä¸¤ç¯‡éå¸¸ç›¸å…³çš„æ–‡ç« ã€‚</p>
<p>å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å…ˆæ‰¾åˆ°ä¸€ç¯‡æ–‡ç« ï¼Œä½œä¸ºquestionæ–‡ç« ã€‚ç„¶åæå–å‡ºæ–‡ä¸­ç¬¬ä¸€å¥è¯çš„named entitiesï¼Œåˆ é™¤å…¶ä¸­çš„ä¸€ä¸ªnamed entityä½œä¸ºå°†è¦è¢«é¢„æµ‹çš„ç­”æ¡ˆã€‚ç„¶ååˆ©ç”¨è¿™ä¸€å¥question sentenceï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ä¸€äº›Information Retrievalç³»ç»Ÿä»Gigaword Corpusæ‰¾åˆ°ä¸€ç¯‡ç›¸å…³çš„æ–‡ç« ä½œä¸ºpassageã€‚è¿™ç¯‡æ–‡ç« ä¸questionæ–‡ç« ä¸åŒï¼Œä½†æ˜¯åŒ…å«ç€ä¸question sentenceéå¸¸ç±»ä¼¼çš„ä¿¡æ¯ã€‚</p>
<p>æœ‰äº†passageä¹‹åï¼Œæˆ‘ä»¬å†ä»passageä¸­æ‰¾å‡ºnamed entitiesä½œä¸ºcandidate answersã€‚</p>
<p>ä¸ºäº†ä½¿ä»»åŠ¡éš¾åº¦æ›´å¤§ï¼Œæˆ‘ä»¬ç”¨ä¸€äº›ç®€å•çš„baseline (First person in passage, etc) å°†ä¸€äº›å¾ˆå®¹æ˜“åšå‡ºçš„é—®é¢˜åˆ æ‰ï¼Œåªç•™ä¸‹æ¯”è¾ƒå›°éš¾çš„instancesã€‚è¿™æ ·æ„å»ºçš„æ•°æ®æ¯”CNN/DMä¼šå›°éš¾ä¸å°‘ã€‚</p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>ç›¸ä¿¡ä½œè€…åˆ›å»ºçš„æ–°æ•°æ®é›†ä¼šç»™Machine comprehensionå¸¦æ¥ä¸€äº›æ–°çš„é—®é¢˜ä¸æŒ‘æˆ˜ï¼Œæ˜¯å¾ˆæœ‰ä»·å€¼çš„èµ„æºã€‚æ–‡ç« é‡‡ç”¨çš„baseline suppresionæ–¹æ³•å¯ä»¥ç”¨æ¯”è¾ƒå°çš„ä»£ä»·åŠ å¤§é—®é¢˜çš„éš¾åº¦ï¼Œå€¼å¾—å‚è€ƒã€‚</p>
<h1 id="Broad-Context-Language-Modeling-as-Reading-Comprehension"><a href="#Broad-Context-Language-Modeling-as-Reading-Comprehension" class="headerlink" title="Broad Context Language Modeling as Reading Comprehension"></a><a href="https://arxiv.org/abs/1610.08431" target="_blank" rel="external">Broad Context Language Modeling as Reading Comprehension</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Zewei Chu, Hai Wang, Kevin Gimpel, David McAllester</p>
<h2 id="æ–‡ç« æ¥æº-1"><a href="#æ–‡ç« æ¥æº-1" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>ä¸ä¹…å‰å‘å¸ƒçš„<a href="https://arxiv.org/abs/1606.06031" target="_blank" rel="external">LAMBADA dataset</a>ä¸­ï¼Œä½œè€…å°è¯•çš„å„ç§baseline modelséƒ½ç»™å‡ºäº†æ¯”è¾ƒå·®çš„ç»“æœã€‚</p>
<p>æ¯ä¸€ä¸ªLAMBADA instanceå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p>
<p><img src="media/LAMBADA.png" alt="LAMBADA"></p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>åœ¨è§‚å¯Ÿäº†LAMBADA datasetä¹‹åï¼Œæˆ‘ä»¬è®¤ä¸ºå¯ä»¥åˆ©ç”¨Reading comprehension modelsæ¥æå‡å‡†ç¡®ç‡ï¼Œè€Œä¸å¿…ä½¿ç”¨ä¼ ç»Ÿçš„language modelã€‚</p>
<p>ç”±äºstate of the art reading comprehension modelséœ€è¦ç»™å‡ºcandidate answersï¼Œç„¶åä»ä¸­é€‰å‡ºä¸€ä¸ªä½œä¸ºé¢„æµ‹çš„ç­”æ¡ˆï¼Œæˆ‘ä»¬å°±å°†æ‰€æœ‰åœ¨contextä¸­å‡ºç°è¿‡çš„å•è¯éƒ½ä½œä¸ºä¸€ä¸ªcandidate answerã€‚</p>
<p>LAMBADAç»™å‡ºçš„è®­ç»ƒé›†æ˜¯ä¸€äº›å°è¯´çš„æ–‡æœ¬ã€‚ä¸ºäº†ä½¿è®­ç»ƒé›†ä¸æµ‹è¯•é›†çš„æ•°æ®ç±»å‹ä¿æŒä¸€è‡´ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªbiased training setã€‚å…·ä½“çš„åšæ³•æ˜¯ï¼Œæˆ‘ä»¬å°†training setåˆ’åˆ†æˆ4-5å¥è¯çš„contextï¼Œç„¶åä¿è¯target wordåœ¨context passageä¸­å‡ºç°ï¼Œåªä¿ç•™è¿™æ ·çš„è®­ç»ƒæ•°æ®ã€‚æˆ‘ä»¬åœ¨æ–°æ„å»ºçš„training setä¸Šè®­ç»ƒå„ç§attention based models,å¾—åˆ°äº†æ¯”åŸä½œè€…å¥½å¾—å¤šçš„æµ‹è¯•ç»“æœã€‚</p>
<p><img src="media/zewei-results.png" alt="zewei-results"></p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¿™ç¯‡æ–‡ç« ä¸­ï¼Œä½œè€…åˆ©ç”¨äº†ç®€å•çš„æ–¹æ³•å’Œæ¨¡å‹å°†LAMBADA datasetçš„å‡†ç¡®ç‡ä»7.3%æé«˜åˆ°45.4%ï¼Œéå¸¸ç®€å•æœ‰æ•ˆã€‚</p>
<h1 id="Emergent-Logical-Structure-in-Vector-Representations-of-Neural-Readers"><a href="#Emergent-Logical-Structure-in-Vector-Representations-of-Neural-Readers" class="headerlink" title="Emergent Logical Structure in Vector Representations of Neural Readers"></a><a href="http://openreview.net/pdf?id=ryWKREqxx" target="_blank" rel="external">Emergent Logical Structure in Vector Representations of Neural Readers</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Hai Wang, Takeshi Onishi, Kevin Gimpel, David McAllester</p>
<h2 id="æ–‡ç« æ¥æº-2"><a href="#æ–‡ç« æ¥æº-2" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ICLR 2017 Submission</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æœ€è¿‘æå‡ºçš„å„ç§å„æ ·çš„attention based reader models,æœ¬æ–‡ä½œè€…åšäº†ä¸€ä¸ªæ¯”è¾ƒå…¨é¢çš„æ€»ç»“å’Œåˆ†æï¼Œå¹¶ä¸”é€šè¿‡æ•°å­¦åˆ†æå’Œå®éªŒå±•ç¤ºäº†æ¨¡å‹ä¹‹é—´çš„ç›¸å…³æ€§ã€‚</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æœ¬æ–‡ä½œè€…è®¤ä¸ºï¼Œå½“å‰çš„attention based modelså¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼Œaggregation readers(åŒ…æ‹¬attentive readerså’Œstanford readers)ä»¥åŠexplicit reference readers(åŒ…æ‹¬attention sum readerå’Œgated attention sum reader)ã€‚</p>
<p>è¿™ä¸¤ç§readerå¯ä»¥ç”¨å¦‚ä¸‹çš„å…¬å¼è”ç³»åœ¨ä¸€èµ·ã€‚</p>
<p><img src="media/formula1.png" alt="formula1"></p>
<p>è¦æ»¡è¶³ä¸Šè¿°ç­‰å¼ï¼Œåªéœ€è¦æ»¡è¶³ä¸‹é¢çš„å…¬å¼ã€‚</p>
<p><img src="media/formula2.png" alt="formula2"></p>
<p>ä¹Ÿå°±æ˜¯è¯´ï¼Œåªæœ‰æ­£ç¡®ç­”æ¡ˆæ‰€åœ¨çš„hidden vectorå’Œquestion vectorå¾—åˆ°çš„inner productæ‰èƒ½ç»™å‡ºä¸ä¸ºé›¶çš„å¸¸æ•°ã€‚ä»¥ä¸‹å®éªŒç»“è®ºæ”¯æŒäº†è¿™ä¸€å‡è®¾ã€‚</p>
<p><img src="media/experiment.png" alt="experiment"></p>
<p>ç”±äºCNN/DMåœ¨è®­ç»ƒå’Œæµ‹è¯•ä¸­ç»è¿‡äº†anonymizationï¼Œä½œè€…è®¤ä¸ºæ­¤inner productå…¶å®å¯ä»¥åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†ä¸anonymized token IDæœ‰å…³ï¼Œå¦ä¸€éƒ¨åˆ†ä¸IDæ— å…³ã€‚ä¸IDç›¸å…³çš„é‚£ä¸€éƒ¨åˆ†åœ¨inner productåº”è¯¥ç›´æ¥ç»™å‡º0çš„ç­”æ¡ˆã€‚å¦‚ä¸‹è¿°å…¬å¼æ‰€ç¤ºã€‚</p>
<p><img src="media/formula3.png" alt="formula3"></p>
<p>æœ¬æ–‡çš„å¦ä¸€éƒ¨åˆ†å·¥ä½œæ˜¯åœ¨attention readersä¸ŠåŠ å…¥ä¸€äº›linguistic featuresæå‡å„ä¸ªæ•°æ®é›†çš„å‡†ç¡®è¯»ï¼Œè¿™é‡Œä¸ä»”ç»†æè¿°ã€‚</p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡æ˜¯å¯¹äºå„ä¸ªattetion based neural reader modelså¾ˆå¥½çš„æ€»ç»“ï¼Œå®ƒå¾ˆå¥½åœ°è¿æ¥äº†å„ä¸ªä¸åŒçš„modelï¼Œè¯´æ˜äº†ä¸ºä½•çœ‹ä¼¼ä¸åŒçš„modelèƒ½å¤Ÿç»™å‡ºéå¸¸ç±»ä¼¼çš„ç»“æœã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>é—®ç­”ç³»ç»Ÿæ˜¯ä¸€ç±»å¤§çš„é—®é¢˜ï¼Œä¹Ÿæ˜¯ç›®å‰NLPåº”ç”¨çš„ç ”ç©¶çƒ­ç‚¹ä¹‹ä¸€ã€‚æœ¬æ–‡ä½œè€…ä»‹ç»äº†TTICåœ¨QAç ”ç©¶ä¸­çš„ä¸€äº›æˆæœï¼Œå…¶ä¸­ç¬¬äºŒç¯‡æ˜¯æœ¬æ–‡ä½œè€…è¿‘æœŸçš„paperã€‚æ„Ÿè°¢æ¥è‡ªèŠåŠ å“¥å¤§å­¦çš„@ZeweiChuç«¥é‹è¾›å‹¤çš„åŠ³åŠ¨ã€‚</p>
<h1 id="å…¬ç›Šå¹¿å‘Š"><a href="#å…¬ç›Šå¹¿å‘Š" class="headerlink" title="å…¬ç›Šå¹¿å‘Š"></a>å…¬ç›Šå¹¿å‘Š</h1><p>æ¸…åå¤§å­¦è®¡ç®—æœºç³»è‡ªç„¶è¯­è¨€å¤„ç†å®éªŒå®¤æ‹›è˜åšå£«å</p>
<h2 id="å°†ä»äº‹çš„ç ”ç©¶æ–¹å‘"><a href="#å°†ä»äº‹çš„ç ”ç©¶æ–¹å‘" class="headerlink" title="å°†ä»äº‹çš„ç ”ç©¶æ–¹å‘"></a>å°†ä»äº‹çš„ç ”ç©¶æ–¹å‘</h2><p>å›´ç»•è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­ä¹‰åˆ†æã€ç»Ÿè®¡æœºå™¨ç¿»è¯‘æˆ–ç¤¾ä¼šè®¡ç®—å¼€å±•æ·±å…¥çš„ç ”ç©¶å·¥ä½œã€‚å®éªŒå®¤å…·ä½“ä¿¡æ¯è§ï¼š<a href="http://nlp.csai.tsinghua.edu.cn" target="_blank" rel="external">http://nlp.csai.tsinghua.edu.cn</a></p>
<h2 id="åº”è˜æ¡ä»¶"><a href="#åº”è˜æ¡ä»¶" class="headerlink" title="åº”è˜æ¡ä»¶"></a>åº”è˜æ¡ä»¶</h2><p>1ã€å…·æœ‰è®¡ç®—æœºç§‘å­¦æŠ€æœ¯æˆ–ç›¸å…³å­¦ç§‘åšå£«å­¦ä½ï¼ˆåšå£«æ¯•ä¸šä¸¤å¹´å†…ï¼‰ï¼›<br>2ã€ç†Ÿæ‚‰è‡ªç„¶è¯­è¨€å¤„ç†æˆ–æœºå™¨å­¦ä¹ çš„åŸºæœ¬ç†è®ºã€æ¨¡å‹ä¸ç®—æ³•ï¼Œæ›¾åœ¨å›½å†…å¤–é‡è¦å­¦æœ¯åˆŠç‰©æˆ–é‡è¦å›½é™…ä¼šè®®ï¼ˆCCF Aç±»ï¼‰ä¸Šå‘è¡¨ï¼ˆå«å·²å½•ç”¨ï¼‰é«˜æ°´å¹³å­¦æœ¯è®ºæ–‡ï¼›<br>3ã€åœ¨å¥æ³•åˆ†æã€è¯­ä¹‰åˆ†ææ–¹é¢æœ‰è¾ƒå¥½ç ”ç©¶åŸºç¡€è€…ä¼˜å…ˆï¼›<br>4ã€å…·æœ‰è¾ƒå¼ºçš„ç¼–ç¨‹èƒ½åŠ›åŠé¡¹ç›®ç ”å‘èƒ½åŠ›ï¼›<br>5ã€è´£ä»»å¿ƒå¼ºï¼Œå…·æœ‰è¾ƒå¥½çš„å›¢é˜Ÿåˆä½œç²¾ç¥å’Œåˆ›æ–°æ„è¯†ï¼Œè‹±è¯­é˜…è¯»åŠå†™ä½œèƒ½åŠ›è¾ƒå¼ºï¼›<br>6ã€ç¬¦åˆæ¸…åå¤§å­¦åšå£«åæ‹›æ”¶æ¡ä»¶ã€‚</p>
<h2 id="å·¥èµ„å¾…é‡"><a href="#å·¥èµ„å¾…é‡" class="headerlink" title="å·¥èµ„å¾…é‡"></a>å·¥èµ„å¾…é‡</h2><p>äº«å—æ¸…åå¤§å­¦åšå£«åå¾…é‡åŠè¯¾é¢˜ç»„æ´¥è´´ã€‚å…¨åŠ›æ”¯æŒç”³è¯·å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘ã€å…¨å›½åšå£«åç®¡å§”ä¼šã€åŒ—äº¬å¸‚ã€æ¸…åå¤§å­¦çš„ç›¸å…³ç ”ç©¶è®¡åˆ’ã€‚</p>
<h2 id="ç”³è¯·ææ–™"><a href="#ç”³è¯·ææ–™" class="headerlink" title="ç”³è¯·ææ–™"></a>ç”³è¯·ææ–™</h2><p>1ã€ä¸ªäººç®€å†ã€å­¦ä½è¯ä¹¦åŠæˆç»©å•å¤å°ä»¶ï¼›<br>2ã€æœ€å…·ä»£è¡¨æ€§çš„è®ºæ–‡2ç¯‡ï¼›<br>3ã€åšå£«åæœŸé—´ç ”ç©¶è®¾æƒ³ï¼ˆç®€æ˜æ‰¼è¦ï¼‰ï¼›<br>4ã€å…¶å®ƒä»»ä½•æ”¯æŒææ–™ã€‚</p>
<h2 id="å¯¼å¸ˆåŠè”ç³»æ–¹å¼"><a href="#å¯¼å¸ˆåŠè”ç³»æ–¹å¼" class="headerlink" title="å¯¼å¸ˆåŠè”ç³»æ–¹å¼"></a>å¯¼å¸ˆåŠè”ç³»æ–¹å¼</h2><p>åˆä½œå¯¼å¸ˆï¼šå­™èŒ‚æ¾æ•™æˆã€åˆ˜çŸ¥è¿œåŠ©ç†æ•™æˆ<br>è”ç³»äººï¼šåˆ˜çŸ¥è¿œ<br>ç”µå­é‚®ä»¶ï¼š liuzy@tsinghua.edu.cn</p>
<p>æœ‰æ„è€…è¯·å°†ç”³è¯·ææ–™å‘è‡³ç”µå­é‚®ç®±ï¼Œè¯·åœ¨é‚®ä»¶ä¸»é¢˜ä¸­æ³¨æ˜å§“åå’Œâ€œç”³è¯·åšå£«åâ€ã€‚ææ–™é€šè¿‡åˆé€‰è€…è¿›è¡Œé¢è°ˆï¼ˆé¢è°ˆæ—¶é—´å¦è¡Œé€šçŸ¥ï¼‰ï¼Œç„¶åèµ°æ¸…åå¤§å­¦åšå£«åç”³è¯·ç¨‹åºã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-11-13T19:10:19.000Z"><a href="/2016/11/13/cs-CL-weekly-2016-11-07-2016-11-11/">2016-11-13</a></time>
      
      
  
    <h1 class="title"><a href="/2016/11/13/cs-CL-weekly-2016-11-07-2016-11-11/">cs.CL weekly 2016.11.07-2016.11.11</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="ä¸€å‘¨å€¼å¾—è¯»"><a href="#ä¸€å‘¨å€¼å¾—è¯»" class="headerlink" title="ä¸€å‘¨å€¼å¾—è¯»"></a>ä¸€å‘¨å€¼å¾—è¯»</h1><h2 id="Learning-Recurrent-Span-Representations-for-Extractive-Question-Answering"><a href="#Learning-Recurrent-Span-Representations-for-Extractive-Question-Answering" class="headerlink" title="Learning Recurrent Span Representations for Extractive Question Answering"></a><a href="https://arxiv.org/pdf/1611.01436v1.pdf" target="_blank" rel="external">Learning Recurrent Span Representations for Extractive Question Answering</a></h2><p>ã€æœºå™¨é˜…è¯»ã€‘ä¸åŒçš„é˜…è¯»ç†è§£æ•°æ®é›†äº§ç”Ÿç­”æ¡ˆçš„æ–¹å¼ä¸åŒï¼Œæœ‰çš„æ˜¯ç»™å®šNä¸ªå€™é€‰ç­”æ¡ˆï¼Œæœ‰çš„æ˜¯è§„å®šä»åŸæ–‡ä¸­çš„entityä¸­è¿›è¡Œé€‰æ‹©ï¼Œæœ‰çš„æ˜¯ä»åŸæ–‡ä¸­çš„ä»»æ„tokenè¿›è¡Œé€‰æ‹©ç­‰ç­‰ã€‚æœ¬æ–‡æ‰€ç”¨çš„æ•°æ®é›†æ˜¯SQuADï¼Œå€™é€‰ç­”æ¡ˆæ˜¯åŸæ–‡ä¸­çš„ä»»æ„å­—ç¬¦ä¸²ï¼Œéš¾åº¦è¾ƒå¤§ï¼Œç­”æ¡ˆå¯èƒ½æ˜¯ä¸€ä¸ªè¯æˆ–è€…å‡ ä¸ªè¯éƒ½æœ‰å¯èƒ½ã€‚æœ¬æ–‡åœ¨å‰äººç ”ç©¶çš„åŸºç¡€ä¸Šæå‡ºäº†ä¸€ç§æ˜¾å¼è¡¨ç¤ºanswer spançš„æ¨¡å‹ï¼Œå–å¾—äº†ä¸é”™çš„æ•ˆæœã€‚</p>
<h2 id="Answering-Complicated-Question-Intents-Expressed-in-Decomposed-Question-Sequences"><a href="#Answering-Complicated-Question-Intents-Expressed-in-Decomposed-Question-Sequences" class="headerlink" title="Answering Complicated Question Intents Expressed in Decomposed Question Sequences"></a><a href="https://arxiv.org/pdf/1611.01242v1.pdf" target="_blank" rel="external">Answering Complicated Question Intents Expressed in Decomposed Question Sequences</a></h2><p>ã€å¤æ‚é—®ç­”ã€‘åŸºäºè¯­ä¹‰åˆ†æçš„é—®ç­”ç³»ç»Ÿæœ€è¿‘æµè¡Œäºè§£å†³é•¿ã€éš¾é—®é¢˜ï¼Œæœ¬æ–‡ç ”ç©¶çš„å†…å®¹æ˜¯å¦‚ä½•å¤„ç†å¤šä¸ªç›¸äº’å…³è”çš„ç®€å•é—®é¢˜ï¼Ÿï¼ˆå³å°†å¤æ‚é—®é¢˜åˆ†è§£æˆå¤šä¸ªç›¸å…³ç®€ç­”é—®é¢˜ï¼‰å¹¶ç»™å‡ºäº†ä¸€ä¸ªä»»åŠ¡æ•°æ®é›†ã€‚è¿™ä¸ªé—®é¢˜çš„ä¸€å¤§éš¾ç‚¹åœ¨äºç›¸äº’å…³è”çš„é—®é¢˜éœ€è¦å…±æŒ‡æ¶ˆè§£çš„å·¥ä½œã€‚æœ¬æ–‡å°†å•è½®é—®ç­”å¯¹è¯åˆ†è§£æˆå¤šè½®é—®é¢˜è¿‡ç¨‹ï¼Œä¸Šä¸‹æ–‡çš„å¤„ç†éå¸¸é‡è¦ã€‚å»ºè®®ç ”ç©¶èŠå¤©æœºå™¨äººçš„ç«¥é‹æ¥ç²¾è¯»æ­¤æ–‡ã€‚</p>
<h2 id="Unsupervised-Pretraining-for-Sequence-to-Sequence-Learning"><a href="#Unsupervised-Pretraining-for-Sequence-to-Sequence-Learning" class="headerlink" title="Unsupervised Pretraining for Sequence to Sequence Learning"></a><a href="https://arxiv.org/pdf/1611.02683v1.pdf" target="_blank" rel="external">Unsupervised Pretraining for Sequence to Sequence Learning</a></h2><p>ã€seq2seqã€‘ã€æ–‡æœ¬æ‘˜è¦ã€‘seq2seqæ˜¯ä¸€ç§æ•ˆæœéå¸¸ä¸é”™çš„æ¡†æ¶ï¼Œå°¤å…¶æ˜¯è¾“å…¥-è¾“å‡ºæ•°æ®éå¸¸å……åˆ†çš„æ—¶å€™ã€‚ä½†å¾ˆå¤šè¯­è¨€ç¿»è¯‘é—®é¢˜å¹¶ä¸èƒ½æ‹¿åˆ°éå¸¸å¤šçš„è®­ç»ƒæ•°æ®ï¼Œæ•ˆæœå°±ä¼šæ‰“æŠ˜æ‰£ã€‚æœ¬æ–‡é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œåœ¨åŸæœ‰seq2seqæ¡†æ¶ä¸Šæå‡ºäº†ä¸€ç§å°æ”¹åŠ¨ã€‚ encoderå’Œdecoderçš„åˆå§‹å€¼ç”¨è®­ç»ƒå¥½çš„è¯­è¨€æ¨¡å‹æ¥èµ‹å€¼ï¼Œç”¨å¯ä»¥è·å¾—çš„å°‘é‡è®­ç»ƒæ•°æ®å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œè°ƒä¼˜ï¼Œæœ¬æ–‡æ–¹æ³•çš„æ•ˆæœåœ¨æœºå™¨ç¿»è¯‘ä»»åŠ¡å’Œabstractiveå¼æ‘˜è¦ä»»åŠ¡ä¸­å¾—åˆ°äº†éªŒè¯ã€‚ä»æœ¬æ–‡ä¸­ä¹Ÿå¯ä»¥çœ‹å‡ºï¼Œä¸€ä¸ªå¥½çš„åˆå€¼ä¸ä»…å¯ä»¥ä½¿å¾—è®­ç»ƒæ›´å¿«ï¼Œè€Œä¸”å¯ä»¥å¾—åˆ°æ›´å¥½çš„ç»“æœã€‚æœ¬æ–‡é€‚åˆç”¨seq2seqè§£å†³å·¥ç¨‹é—®é¢˜çš„ç«¥é‹è¯»ã€‚</p>
<h2 id="Sentence-Ordering-using-Recurrent-Neural-Networks"><a href="#Sentence-Ordering-using-Recurrent-Neural-Networks" class="headerlink" title="Sentence Ordering using Recurrent Neural Networks"></a><a href="https://arxiv.org/pdf/1611.02654v1.pdf" target="_blank" rel="external">Sentence Ordering using Recurrent Neural Networks</a></h2><p>ã€å¥å­æ’åºã€‘ã€æ–‡æœ¬æ‘˜è¦ã€‘å¥å­æ’åºä»»åŠ¡å¯¹äºç ”ç©¶æ–‡æ¡£çš„è¿è´¯æ€§éå¸¸æœ‰æ„ä¹‰ï¼Œè€Œè¿è´¯æ€§å¯¹äºå¾ˆå¤šä»»åŠ¡éå¸¸é‡è¦ï¼Œæ¯”å¦‚æ–‡æœ¬æ‘˜è¦ã€‚æœ¬æ–‡åœ¨è¿™ä¸ªä»»åŠ¡ä¸Šç”¨äº†æµè¡Œçš„seq2seqæ–¹æ³•ï¼Œå¹¶ä¸”ç»™å‡ºäº†ä¸€ç§å¯è§†åŒ–çš„å¥å­è¡¨ç¤ºæ•ˆæœã€‚å»ºè®®ç ”ç©¶æ‘˜è¦çš„ç«¥é‹è¯»ã€‚</p>
<h2 id="Modeling-Coverage-for-Neural-Machine-Translation"><a href="#Modeling-Coverage-for-Neural-Machine-Translation" class="headerlink" title="Modeling Coverage for Neural Machine Translation"></a><a href="https://arxiv.org/pdf/1601.04811v6.pdf" target="_blank" rel="external">Modeling Coverage for Neural Machine Translation</a></h2><p>ã€æœºå™¨ç¿»è¯‘ã€‘é’ˆå¯¹ç¥ç»ç½‘ç»œæœºå™¨ç¿»è¯‘ï¼ˆNMTï¼‰è¯‘æ–‡ä¸­ç»å¸¸å‡ºç°çš„é—æ¼ç¿»è¯‘ï¼ˆunder-translationï¼‰å’Œè¿‡åº¦ç¿»è¯‘ï¼ˆover-translationï¼‰é—®é¢˜ï¼Œåä¸ºè¯ºäºšæ–¹èˆŸå®éªŒå®¤é¦–æ¬¡æå‡ºå¯¹è¦†ç›–ç‡ï¼ˆcoverageï¼‰è¿›è¡Œå»ºæ¨¡ã€‚è¯¥æ–¹æ³•çš„ä¸»è¦æ€æƒ³æ˜¯ä¸ºæ¯ä¸ªæºç«¯è¯ç»´æŠ¤ä¸€ä¸ªcoverage vectorä»¥è¡¨ç¤ºè¯¥è¯è¢«ç¿»è¯‘ï¼ˆæˆ–è¦†ç›–ï¼‰çš„ç¨‹åº¦ã€‚åœ¨è§£ç è¿‡ç¨‹ä¸­è¯¥è¦†ç›–ç‡ä¿¡æ¯ä¼šä¼ å…¥attention modelï¼Œä»¥ä½¿å®ƒæ›´å…³æ³¨äºæœªè¢«ç¿»è¯‘çš„æºç«¯è¯ï¼Œå®éªŒè¡¨ç¤ºè¯¥æ–¹æ³•èƒ½æ˜¾è‘—å‡å°‘é—æ¼ç¿»è¯‘å’Œè¿‡åº¦ç¿»è¯‘é”™è¯¯æ•°é‡ï¼Œè¯¥å·¥ä½œå‘è¡¨åœ¨ACL 2016ä¸Šã€‚</p>
<h2 id="Efficient-Summarization-with-Read-Again-and-Copy-Mechanism"><a href="#Efficient-Summarization-with-Read-Again-and-Copy-Mechanism" class="headerlink" title="Efficient Summarization with Read-Again and Copy Mechanism"></a><a href="https://arxiv.org/pdf/1611.03382.pdf" target="_blank" rel="external">Efficient Summarization with Read-Again and Copy Mechanism</a></h2><p>ã€æ–‡æœ¬æ‘˜è¦ã€‘æœ¬æ–‡é€‚åˆç ”ç©¶æ–‡æœ¬æ‘˜è¦ï¼Œå°¤å…¶æ˜¯ç”¨seq2seqæ¥è§£å†³å¥å­çº§æ‘˜è¦çš„ç«¥é‹è¿›è¡Œç ”è¯»ã€‚</p>
<h1 id="ä¸€å‘¨èµ„æº"><a href="#ä¸€å‘¨èµ„æº" class="headerlink" title="ä¸€å‘¨èµ„æº"></a>ä¸€å‘¨èµ„æº</h1><h2 id="åˆ˜çŸ¥è¿œè€å¸ˆåœ¨å°†é—¨çš„talk"><a href="#åˆ˜çŸ¥è¿œè€å¸ˆåœ¨å°†é—¨çš„talk" class="headerlink" title="åˆ˜çŸ¥è¿œè€å¸ˆåœ¨å°†é—¨çš„talk"></a><a href="http://nlp.csai.tsinghua.edu.cn/~lzy/index_cn.html" target="_blank" rel="external">åˆ˜çŸ¥è¿œè€å¸ˆåœ¨å°†é—¨çš„talk</a></h2><p>å¯¹â€œè¡¨ç¤ºå­¦ä¹ å’ŒçŸ¥è¯†è·å–â€æ„Ÿå…´è¶£çš„ç«¥é‹å¯ä»¥çœ‹è¿‡æ¥ã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-11-11T02:50:42.000Z"><a href="/2016/11/10/PaperWeekly-ç¬¬åä¸‰æœŸ/">2016-11-10</a></time>
      
      
  
    <h1 class="title"><a href="/2016/11/10/PaperWeekly-ç¬¬åä¸‰æœŸ/">PaperWeekly ç¬¬åä¸‰æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•è¨€"><a href="#å¼•è¨€" class="headerlink" title="å¼•è¨€"></a>å¼•è¨€</h1><p>æœ¬æœŸçš„PaperWeeklyä¸€å…±åˆ†äº«å››ç¯‡æœ€è¿‘arXivä¸Šæ”¾å‡ºçš„é«˜è´¨é‡paperï¼ŒåŒ…æ‹¬ï¼šæœºå™¨ç¿»è¯‘ã€è¡¨ç¤ºå­¦ä¹ ã€æ¨èç³»ç»Ÿå’ŒèŠå¤©æœºå™¨äººã€‚äººå·¥æ™ºèƒ½åŠå…¶ç›¸å…³ç ”ç©¶æ—¥æ–°æœˆå¼‚ï¼Œæœ¬æ–‡å°†å¸¦ç€å¤§å®¶äº†è§£ä¸€ä¸‹ä»¥ä¸Šå››ä¸ªç ”ç©¶æ–¹å‘éƒ½æœ‰å“ªäº›æœ€æ–°è¿›å±•ã€‚å››ç¯‡paperåˆ†åˆ«æ˜¯ï¼š</p>
<p>1ã€A General Framework for Content-enhanced Network Representation Learning, 2016.10</p>
<p>2ã€Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in the Blanks, 2016.11</p>
<p>3ã€Dual Learning for Machine Translation, 2016.11</p>
<p>4ã€Two are Better than One: An Ensemble of Retrieval- and Generation-Based Dialog Systems, 2016.10</p>
<h1 id="A-General-Framework-for-Content-enhanced-Network-Representation-Learning"><a href="#A-General-Framework-for-Content-enhanced-Network-Representation-Learning" class="headerlink" title="A General Framework for Content-enhanced Network Representation Learning"></a><a href="https://arxiv.org/abs/1610.02906" target="_blank" rel="external">A General Framework for Content-enhanced Network Representation Learning</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Xiaofei Sun, Jiang Guo, Xiao Ding and Ting Liu</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>network representation, content-enhanced</p>
<h2 id="æ–‡ç« æ¥æº"><a href="#æ–‡ç« æ¥æº" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>åŒæ—¶åˆ©ç”¨ç½‘ç»œç»“æ„ç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾æ¥å­¦ä¹ ç½‘ç»œä¸­èŠ‚ç‚¹çš„embedding</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æ€»çš„æ¥è¯´è¿™ç¯‡paperçš„æ€è·¯æ¯”è¾ƒæ¸…æ™°ï¼Œå­¦ä¹ çš„æ–¹æ³•ä¸Šå¾ˆå¤§ç¨‹åº¦ä¸Šå‚è€ƒäº†word2vecçš„æ–¹æ³•ã€‚å¯¹äºä¸€ä¸ªèŠ‚ç‚¹vï¼Œå°†ä¸vç›¸è¿çš„èŠ‚ç‚¹å½“åšæ­£ä¾‹ï¼Œä¸æƒ³è¿çš„èŠ‚ç‚¹å½“åšè´Ÿä¾‹ã€‚é‚£ä¹ˆå¦‚ä½•èå…¥å†…å®¹å‘¢ï¼Ÿåœ¨ç½‘ç»œä¸­è®¾ç½®è™šæ‹Ÿçš„å†…å®¹èŠ‚ç‚¹cï¼Œå°†æè¿°vèŠ‚ç‚¹çš„æ–‡æœ¬å†…å®¹c_vå½“åšæ­£ä¾‹ï¼Œå…¶ä»–çš„å½“åšè´Ÿä¾‹c_vâ€™ã€‚åœ¨ä¼˜åŒ–æ—¶åŒæ—¶è€ƒè™‘ç½‘ç»œç›¸ä¼¼æ€§å’Œæ–‡æœ¬ç›¸ä¼¼æ€§ï¼Œè®©vçš„å‘é‡é è¿‘æ­£ä¾‹è¿œç¦»è´Ÿä¾‹ã€‚</p>
<p><img src="media/network-illustration.png" alt="network-illustration"></p>
<p>æ€»çš„ä¼˜åŒ–å‡½æ•°å¦‚ä¸‹æ‰€ç¤ºï¼Œç”±ä¸¤ä¸ªéƒ¨åˆ†L_nn(èŠ‚ç‚¹ä¸èŠ‚ç‚¹è¿æ¥)å’ŒL_nc(èŠ‚ç‚¹ä¸å†…å®¹è¿æ¥)çº¿æ€§ç»„åˆè€Œæˆï¼Œalphaè¶Šå¤§åˆ™è€ƒè™‘ç½‘ç»œç»“æ„è¶Šå¤šæ–‡æœ¬å†…å®¹è¶Šå°‘ã€‚</p>
<p><img src="media/joint-learning.png" alt="joint-learning"></p>
<p>L_nnå’ŒL_ncå¤§ä½“æ€æƒ³å¦‚ä¸Šé¢æ‰€è¨€ï¼Œä¸¤è€…æŸå¤±å‡½æ•°ä¸€è‡´ï¼Œå°½é‡æ¥è¿‘æ­£ä¾‹è¿œç¦»åä¾‹ã€‚ä½†æ˜¯ä¸¤è€…åœ¨æè¿°èŠ‚ç‚¹æ¦‚ç‡ï¼ˆç›¸ä¼¼åº¦ï¼‰ä¸Šä¼šæœ‰æ‰€ä¸åŒã€‚</p>
<p><img src="media/node-node-link.png" alt="node-node-link"></p>
<p>å¯¹äºèŠ‚ç‚¹ä¸èŠ‚ç‚¹ä¹‹é—´çš„æ¦‚ç‡ï¼Œç”±äºç½‘ç»œç»“æ„è¦è€ƒè™‘æœ‰å‘æ€§ï¼Œå› æ­¤å°†èŠ‚ç‚¹çš„embeddingåˆ‡åˆ†æˆinå’Œoutä¸¤åŠï¼Œç”¨sigmoidç®—ä¸¤ä¸ªèŠ‚ç‚¹çš„ç›¸ä¼¼åº¦ã€‚</p>
<p><img src="media/node-node-probability.png" alt="node-node-probability"></p>
<p>èŠ‚ç‚¹ä¸å†…å®¹çš„æ¦‚ç‡ä¹Ÿæ˜¯ç±»ä¼¼ï¼Œä¸è¿‡å†…å®¹èŠ‚ç‚¹çš„embeddingæ˜¯å›ºå®šçš„ï¼Œé€šè¿‡é¢å¤–çš„æ–‡æœ¬æ¨¡å‹è®­ç»ƒå‡ºæ¥çš„ã€‚è¿™é‡Œå°è¯•çš„æ–‡æœ¬modelåŒ…æ‹¬word2vecï¼ŒRNNå’ŒBiRNNã€‚</p>
<p><img src="media/node-content-probability.png" alt="node-content-probability"></p>
<p>æœ€ååœ¨èŠ‚ç‚¹åˆ†ç±»ä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„æµ‹ï¼ŒåŒæ—¶ç»“åˆç½‘ç»œç»“æ„ç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾ç¡®å®å¸¦æ¥äº†æ˜æ˜¾çš„æé«˜ã€‚</p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>ç”¨åˆ°çš„æ•°æ®é›†æ˜¯DBLPï¼ˆcn.aminer.org/citationï¼‰å’Œè‡ªå·±é‡‡é›†çš„çŸ¥ä¹ç”¨æˆ·ç½‘ç»œã€‚</p>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>è¿™ä¸¤å¹´network representationçš„å·¥ä½œå¦‚é›¨åæ˜¥ç¬‹ï¼Œåœ¨DeepWalkä¹‹åæœ‰åä½™ç¯‡è®ºæ–‡å‡ºç°ã€‚è¿™ç¯‡æ–‡ç« åœ¨ç›¸å…³å·¥ä½œé‡Œæœ‰ç›¸å¯¹å…¨é¢çš„è¦†ç›–ï¼Œå¯¹è¿™æ–¹é¢å·¥ä½œæœ‰å…´è¶£çš„åŒå­¦å€¼å¾—å‚è€ƒã€‚</p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>å°½ç®¡ç›¸å…³æ¨¡å‹å±‚å‡ºè¿­è§ï¼Œä½†ç•¥æ„Ÿé—æ†¾çš„æ˜¯æ„Ÿè§‰ç›®å‰å¹¶æ²¡æœ‰åœ¨network embeddingä¹‹ä¸Šçš„è¾ƒä¸ºæˆåŠŸçš„åº”ç”¨ï¼Œå¤§å¤šbenchmarkéƒ½æ˜¯èŠ‚ç‚¹åˆ†ç±»å’Œé“¾æ¥é¢„æµ‹ï¼Œåº”ç”¨ä»·å€¼æœ‰é™ã€‚ååˆ†æœŸå¾…ä¸€äº›æ›´ä¸ºæ–°é¢–çš„benchmarkçš„å‡ºç°ã€‚</p>
<h1 id="Collaborative-Recurrent-Autoencoder-Recommend-while-Learning-to-Fill-in-the-Blanks"><a href="#Collaborative-Recurrent-Autoencoder-Recommend-while-Learning-to-Fill-in-the-Blanks" class="headerlink" title="Collaborative Recurrent Autoencoder Recommend while Learning to Fill in the Blanks"></a><a href="https://arxiv.org/pdf/1611.00454v1.pdf" target="_blank" rel="external">Collaborative Recurrent Autoencoder Recommend while Learning to Fill in the Blanks</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Hao Wang, Xingjian Shi, Dit-Yan Yeung</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>HKUST</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Recommendation, Collaborative Filtering, RNN</p>
<h2 id="æ–‡ç« æ¥æº-1"><a href="#æ–‡ç« æ¥æº-1" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>Arxiv, to appear at NIPSâ€™16</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºcollaborative recurrent autoencoder (CRAE)ï¼Œå°†CF (collaborative filtering)è·ŸRNNç»“åˆåœ¨ä¸€èµ·ï¼Œæé«˜æ¨èçš„å‡†ç¡®ç‡ï¼Œå¹¶ä¸”å¯ä»¥ç”¨äºsequence generation taskã€‚</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>ä¼ ç»Ÿçš„LSTMæ¨¡å‹æ²¡æœ‰è€ƒè™‘è¿›å™ªå£°ï¼Œå¯¹ä¸è¶³çš„è®­ç»ƒæ•°æ®ç¨³å®šæ€§ä¸å¥½ï¼Œæ–‡ç« æå‡ºRRN (robust recurrent networks)ï¼Œä¸ºRNNçš„åŠ å™ªç‰ˆæœ¬ï¼ŒRRNä¸­çš„å™ªå£°ç›´æ¥åœ¨ç½‘ç»œä¸­å‘å‰æˆ–è€…å‘åä¼ æ’­ï¼Œä¸éœ€è¦åˆ†å¼€çš„ç½‘ç»œæ¥ä¼°è®¡latent variablesçš„åˆ†å¸ƒï¼Œæ›´å®¹æ˜“å®ç°ä¸”æ•ˆç‡é«˜ã€‚CAREçš„æ¨¡å‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåºåˆ—å¤„ç†çš„ä¿¡æ¯ä¿å­˜åœ¨cell state s_tå’Œè¾“å‡ºçŠ¶æ€h_tä¸­ï¼Œä¸¤ä¸ªRRNå¯ä»¥ç»„åˆå½¢æˆç¼–ç è¯‘ç ç»“æ„ã€‚</p>
<p><img src="media/collaborative1.png" alt="collaborative1"></p>
<p>Wildcard denoisingçš„ç›®çš„æ˜¯ç¼“è§£overfittingï¼Œåšæ³•æ˜¯éšæœºé€‰æ‹©ä¸€äº›è¯ï¼Œæ›¿æ¢æˆ<wildcard>ï¼Œè€Œä¸æ˜¯ç›´æ¥æ‰”æ‰è¯ï¼Œå®éªŒéªŒè¯å‡†ç¡®ç‡ä¼šææˆ20%å·¦å³ã€‚Beta-poolingçš„ç›®çš„æ˜¯å°†å‘é‡åºåˆ—poolæˆå›ºå®šé•¿åº¦ä¸º2K_Wçš„å•å‘é‡ï¼Œå¸®åŠ©rating matrixçš„çŸ©é˜µåˆ†è§£ï¼›å› ä¸ºä¸åŒåºåˆ—å¯èƒ½éœ€è¦ä¸åŒå¤§å°çš„æƒé‡ï¼Œæ‰€ä»¥éœ€è¦å˜é•¿çš„betaå‘é‡æ¥å¸®åŠ©poolingï¼Œæ–‡ç« é‡‡ç”¨betaåˆ†å¸ƒã€‚</wildcard></p>
<p>Learningçš„è¿‡ç¨‹é‡‡ç”¨MAPï¼Œç±»ä¼¼äºCDLå’ŒDTRã€‚å­¦åˆ°çŸ©é˜µUå’ŒVä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥é¢„è®¡è¯„åˆ†çŸ©é˜µRã€‚</p>
<h2 id="èµ„æº-1"><a href="#èµ„æº-1" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>1ã€<a href="http://www.citeulike.org/faq/data.adp" target="_blank" rel="external">CiteULike</a><br>2ã€<a href="http://www.wanghao.in/" target="_blank" rel="external">Netflix</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-1"><a href="#ç›¸å…³å·¥ä½œ-1" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>é€‰å–å½“ä¸­ä¸¤ä¸ªæ¯”è¾ƒæœ‰æ„æ€çš„workã€‚<br>1ã€CTR (collaborative topic reguression)<br>å°†topic modelå’Œprobabilistic matrix factorization (PMF)ï¼Œä½†æ˜¯CTRé‡‡ç”¨bag-of-wordsçš„è¡¨ç¤ºå½¢å¼ï¼Œå¿½ç•¥äº†è¯åºå’Œæ¯ä¸ªè¯çš„å±€éƒ¨è¯­å¢ƒï¼Œè€Œè¿™äº›å¯¹æ–‡ç« è¡¨ç¤ºå’Œword embeddingsèƒ½æä¾›æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚<br>2ã€CDL (collaborative deep learning)<br>å°†CFå’Œprobabilistic stacked denoising autoencoder (SDAE)ç»“åˆèµ·æ¥ï¼Œæ˜¯ä¸€ä¸ªä»¥bag-of-wordsä¸ºè¾“å…¥çš„feedforwardæ¨¡å‹ï¼Œå¹¶ä¸èƒ½è§£å†³sequence generationçš„é—®é¢˜ã€‚</p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¿™ç¯‡æ–‡ç« å°†RNNç”¨äºrecommendationï¼Œå¹¶ä¸”ä¸rating matrixç»“åˆèµ·æ¥ï¼Œæ¯”è¾ƒæœ‰æ„æ€ï¼Œè€Œä¸”è€ƒè™‘äº†æ•°æ®ç¨€ç–çš„æƒ…å†µï¼Œpoolingçš„æ–¹æ³•ä¹Ÿå€¼å¾—å€Ÿé‰´ã€‚</p>
<h1 id="Dual-Learning-for-Machine-Translation"><a href="#Dual-Learning-for-Machine-Translation" class="headerlink" title="Dual Learning for Machine Translation"></a><a href="https://arxiv.org/pdf/1611.00179.pdf" target="_blank" rel="external">Dual Learning for Machine Translation</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Yingce Xia1, Di He, Tao Qin, Liwei Wang, Nenghai Yu1, Tie-Yan Liu, Wei-Ying Ma</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>1.University of Science and Technology of China<br>2.Key Laboratory of Machine Perception (MOE), School of EECS, Peking University<br>3.Microsoft Research</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Dual Learning, Machine Translation, Deep Reinforcement Learning</p>
<h2 id="æ–‡ç« æ¥æº-2"><a href="#æ–‡ç« æ¥æº-2" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv, 1 Nov 2016 </p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æ–‡ç« é’ˆå¯¹æœºå™¨ç¿»è¯‘æ—¶éœ€è¦çš„äººå·¥æ ‡æ³¨çš„åŒè¯­å¹³è¡Œè¯­æ–™è·å–ä»£ä»·é«˜çš„é—®é¢˜ï¼Œæå‡ºäº†Dual Learning Modelä½¿ç”¨å•è¯­è¯­æ–™æ¥è¿›è¡Œè®­ç»ƒï¼Œå–å¾—äº†æ¯”ä½¿ç”¨åŒè¯­å¹³è¡Œè¯­æ–™è®­ç»ƒçš„æ¨¡å‹æ›´å¥½çš„ç»“æœã€‚</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æ¨¡å‹çš„æ ¸å¿ƒæ€æƒ³è§ä¸‹å›¾ï¼š<br><img src="media/Dual_Learning.png" alt="Dual_Learning"></p>
<p>(æ³¨:ä¸Šå›¾æ¥è‡ªCCL2016é©¬ç»´è‹±è€å¸ˆPPT)<br>å¯¹ä¸Šå›¾çš„è¯¦ç»†è§£é‡Šï¼š<br>æ¨¡å‹ä¸­æœ‰ä¸¤ä¸ªAgentï¼ŒAgengt_Aå’ŒAgent_B,Agent_Aåªèƒ½å¤Ÿç†è§£Aè¯­è¨€ï¼ŒAgent_Båªèƒ½ç†è§£Bè¯­è¨€ï¼Œmodel fæ˜¯å°†Aè¯­è¨€ç¿»è¯‘æˆBè¯­è¨€çš„ç¿»è¯‘æ¨¡å‹ï¼Œmodel fæ˜¯å°†Bè¯­è¨€ç¿»è¯‘æˆAè¯­è¨€çš„ç¿»è¯‘æ¨¡<br>å‹ã€‚ä¸Šå›¾çš„æ‰§è¡Œè¿‡ç¨‹å¯ä»¥æŒ‰ç…§ä¸‹é¢çš„è§£é‡Šè¿›è¡Œï¼š<br>1ã€Agent_A å‘é€ä¸€å¥Aè¯­è¨€çš„è‡ªç„¶è¯­è¨€çš„è¯X1<br>2ã€model få°†Xè½¬æ¢æˆä¸ºBè¯­è¨€çš„è‡ªç„¶è¯­è¨€Y<br>3ã€Agent_Bæ”¶åˆ°Yï¼Œå¹¶å°†Y ä¼ é€ç»™model g<br>4ã€model gå°†Yè½¬æ¢æˆæºè¯­è¨€Açš„è‡ªç„¶è¯­è¨€X2<br>5ã€æ¯”è¾ƒX1å’ŒX2çš„å·®å¼‚æ€§ï¼Œå¹¶ç»™å‡ºåé¦ˆ.å¹¶è¿›è¡Œ1åˆ°4çš„åå¤è®­ç»ƒ</p>
<p>æ¨¡å‹çš„ç®—æ³•è¿‡ç¨‹ï¼š<br><img src="media/Dual_Learning_Algorithm.png" alt="Dual_Learning_Algorith"></p>
<p>åœ¨step8çš„æ—¶å€™å¯¹ç¿»è¯‘æ¨¡å‹ç¿»è¯‘çš„ç»“æœä½¿ç”¨è¯­è¨€æ¨¡å‹åšäº†ä¸€ä¸ªåˆ¤å®šï¼Œåˆ¤å®šä¸€ä¸ªå¥å­åœ¨å¤šå¤§ç¨‹åº¦ä¸Šæ˜¯è‡ªç„¶è¯­è¨€ã€‚step9æ˜¯ç»™communicationä¸€ä¸ªrewardï¼Œstep10å°†step8å’Œstep9åŠ æƒå…±åŒä½œä¸ºæ ·ä¾‹çš„reward.ç„¶åä½¿ç”¨policy gradientè¿›è¡Œä¼˜åŒ–ã€‚<br>éœ€è¦è¯´æ˜çš„model få’Œmodel gæ˜¯å·²æœ‰çš„æ¨¡å‹æˆ–è€…è¯´åœ¨åˆšå¼€å§‹çš„æ—¶å€™ä½¿ç”¨å°‘é‡çš„åŒè¯­è¯­æ–™è¿›è¡Œè®­ç»ƒå¾—åˆ°å—ï¼Œç„¶åé€æ¸åŠ å¤§å•è¯­è¯­æ–™çš„æ¯”ä¾‹ã€‚</p>
<h2 id="èµ„æº-2"><a href="#èµ„æº-2" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>NMT code:<a href="https://github.com/nyu-dl" target="_blank" rel="external">https://github.com/nyu-dl</a><br>compute BLEU score by the multi-bleu.perl:<a href="https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl" target="_blank" rel="external">https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-2"><a href="#ç›¸å…³å·¥ä½œ-2" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>1ã€the standard NMT, Neural machine translation by jointly learning to align<br>and translate. ICLR, 2015.<br>2ã€pseudo-NMT, Improving neural machine translation models with monolingual data. In ACL, 2016.</p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡çš„æ€æƒ³å¾ˆåˆ›æ–°ï¼Œåˆ©ç”¨äº†æœºå™¨ç¿»è¯‘ä¸­çš„dual mechinismï¼Œä»…ä»…åˆ©ç”¨å°‘éƒ¨åˆ†åŒè¯­è¯­æ–™å’Œå¤§éƒ¨åˆ†å•è¯­è¯­æ–™å°±å¯ä»¥è¾¾åˆ°ä¹‹å‰NMTçš„æ•ˆæœï¼Œç”šè‡³è¿˜é«˜äº†2åˆ°3ä¸ªç™¾åˆ†ç‚¹ã€‚<br>dualçš„æ€æƒ³ä¸ä»…å¯ä»¥ç”¨äºæœºå™¨ç¿»è¯‘ä¸­ï¼Œè¿˜å¯ä»¥ç”¨äºå›¾ç‰‡ã€è¯­éŸ³ã€æ–‡å­—ç­‰å¤šç§è¯­è¨€çš„å…±åŒå­¦ä¹ ï¼Œè¿™æ ·çš„ç›¸äº’ä½œç”¨å…±åŒå­¦ä¹ æ›´æ¥è¿‘äºäººç±»å¯¹å‘¨å›´ä¸–ç•Œè®¤è¯†çš„æ–¹å¼ï¼Œæ¥å—æ¥è‡ªå„ä¸ªæ–¹é¢çš„ä¿¡å¿ƒï¼Œç»¼åˆè¿›è¡Œå­¦ä¹ ã€‚</p>
<h1 id="Two-are-Better-than-One-An-Ensemble-of-Retrieval-and-Generation-Based-Dialog"><a href="#Two-are-Better-than-One-An-Ensemble-of-Retrieval-and-Generation-Based-Dialog" class="headerlink" title="Two are Better than One: An Ensemble of Retrieval and Generation-Based Dialog"></a><a href="https://arxiv.org/pdf/1610.07149v1.pdf" target="_blank" rel="external">Two are Better than One: An Ensemble of Retrieval and Generation-Based Dialog</a></h1><h2 id="ä½œè€…-3"><a href="#ä½œè€…-3" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Yiping Song, Rui Yan, Xiang Li, Dongyan Zhao, Ming Zhang</p>
<h2 id="å•ä½-3"><a href="#å•ä½-3" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>åŒ—äº¬å¤§å­¦</p>
<h2 id="å…³é”®è¯-3"><a href="#å…³é”®è¯-3" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>å¯¹è¯ç³»ç»Ÿã€open domainã€chatbot</p>
<h2 id="æ–‡ç« æ¥æº-3"><a href="#æ–‡ç« æ¥æº-3" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv</p>
<h2 id="é—®é¢˜-3"><a href="#é—®é¢˜-3" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¯¹è¯ç³»ç»Ÿä¸­å¯å°†é—®é¢˜å’Œæ£€ç´¢çš„ç»“æœåŒæ—¶ä½œä¸ºè¾“å…¥Encoderä¹‹åè¿›è¡Œè§£ç Decoderï¼Œå†å°†ç”Ÿæˆçš„ç»“æœå’ŒåŸæ£€ç´¢ç»“æœé‡æ’åº</p>
<h2 id="æ¨¡å‹-3"><a href="#æ¨¡å‹-3" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p><img src="media/14788352072241.jpg" alt=""><br><img src="media/14788352189655.jpg" alt=""></p>
<h2 id="ç›¸å…³å·¥ä½œ-3"><a href="#ç›¸å…³å·¥ä½œ-3" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p><img src="media/14788352485111.jpg" alt=""><br><img src="media/14788352559281.jpg" alt=""></p>
<h2 id="ç®€è¯„-3"><a href="#ç®€è¯„-3" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>ä½œè€…çš„æ€è·¯éå¸¸ç®€å•ï¼ŒåŸæ¥çš„å›å¤ç”Ÿæˆæ¨¡å‹å®¹æ˜“å‘ç”Ÿå›å¤å†…å®¹çŸ­æˆ–è€…å›å¤ä¿¡æ¯æ— æ„ä¹‰çš„é—®é¢˜ï¼Œåœ¨æ­¤ä½œè€…å°†å€™é€‰ç»“æœå’ŒåŸæ¥çš„é—®å¥åŒæ—¶ä½œä¸ºRNNç”Ÿæˆå™¨çš„è¾“å…¥ï¼Œç”Ÿæˆç»“æœåå†å°†æœ¬æ¬¡ç”Ÿæˆçš„ç»“æœåŠ å…¥åŸæ£€ç´¢å€™é€‰é›†ä¸­ï¼Œè¿›è¡Œé‡æ–°æ’åºï¼Œå®éªŒç»“æœè¯æ˜æ­¤ç§æ–¹æ³•æ¯”å•ç‹¬ä½¿ç”¨æ£€ç´¢æˆ–å•ç‹¬ä½¿ç”¨ç”Ÿæˆæ•ˆæœæœ‰å¤§å¹…æå‡ã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>æ–°çš„ç ”ç©¶æˆæœä¸è§å¾—å¯ä»¥ç›´æ¥åº”ç”¨äºå·¥ç¨‹ä¸­ï¼Œä½†æ–°çš„paperï¼Œå°¤å…¶æ˜¯é«˜è´¨é‡paperä¸­ï¼Œä¸€å®šä¼šæœ‰å¾ˆå¤šçš„åˆ›æ–°ç‚¹ï¼Œæ¯ä¸€ä¸ªåˆ›æ–°ç‚¹éƒ½å¯èƒ½ä¼šä¸ºåç»­çš„ç ”ç©¶ã€å·¥ç¨‹å®ç°ç­‰å¸¦æ¥å¯å‘ï¼Œç”šè‡³æ˜¯ä¸€äº›æŠ€æœ¯ä¸Šçš„çªç ´ã€‚ä»æœ¬æœŸå¼€å§‹ï¼ŒPaperWeeklyä¼šä¸å®šæœŸåœ°åˆ†äº«ç±»ä¼¼çš„å†…å®¹ï¼Œä»¥æ–¹ä¾¿å¤§å®¶äº†è§£æœ€æ–°çš„ç ”ç©¶æˆæœã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-11-05T16:40:05.000Z"><a href="/2016/11/05/cs-CL-weekly-2016-10-31-2016-11-04/">2016-11-05</a></time>
      
      
  
    <h1 class="title"><a href="/2016/11/05/cs-CL-weekly-2016-10-31-2016-11-04/">cs.CL weekly 2016.10.31-2016.11.04</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="ä¸€å‘¨å€¼å¾—è¯»"><a href="#ä¸€å‘¨å€¼å¾—è¯»" class="headerlink" title="ä¸€å‘¨å€¼å¾—è¯»"></a>ä¸€å‘¨å€¼å¾—è¯»</h1><h2 id="Neural-Machine-Translation-in-Linear-Time"><a href="#Neural-Machine-Translation-in-Linear-Time" class="headerlink" title="Neural Machine Translation in Linear Time"></a><a href="https://arxiv.org/pdf/1610.10099v1.pdf" target="_blank" rel="external">Neural Machine Translation in Linear Time</a></h2><p>ã€æœºå™¨ç¿»è¯‘ã€‘æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„encoder-decoderæ¨¡å‹ByteNetã€‚å®ƒæ˜¯ç”±ä¸¤ä¸ªæ‰©å¼ ï¼ˆdilatedï¼‰å·ç§¯ç¥ç»ç½‘ç»œå †å èµ·æ¥çš„ã€‚ByteNetçš„ä¼˜åŠ¿åœ¨äºæ—¶é—´å¤æ‚åº¦æ˜¯çº¿æ€§çš„ã€‚å·¥ä½œæ¥è‡ªdeepmindã€‚å»ºè®®ç ”ç©¶æœºå™¨ç¿»è¯‘ä»¥åŠä½¿ç”¨MTæ¨¡å‹åšå…¶ä»–ä»»åŠ¡çš„ç«¥é‹ç²¾è¯»ã€‚</p>
<h2 id="Dual-Learning-for-Machine-Translation"><a href="#Dual-Learning-for-Machine-Translation" class="headerlink" title="Dual Learning for Machine Translation"></a><a href="https://arxiv.org/pdf/1611.00179v1.pdf" target="_blank" rel="external">Dual Learning for Machine Translation</a></h2><p>ã€æœºå™¨ç¿»è¯‘ã€‘ã€å¢å¼ºå­¦ä¹ ã€‘æœ¬æ–‡è§£å†³çš„é—®é¢˜æ˜¯æœºå™¨ç¿»è¯‘ä¸­åŒè¯­è®­ç»ƒè¯­æ–™éœ€æ±‚è¿‡å¤šçš„é—®é¢˜ï¼Œæ—¨åœ¨é€šè¿‡ä¸€ç§æ‰‹æ®µæ¥å‡å°‘æ•°æ®æ ‡æ³¨å·¥ä½œã€‚ä½œè€…é‡‡ç”¨çš„æ–¹æ³•æ˜¯ç°åœ¨é‡æ–°æµè¡Œçš„å¢å¼ºå­¦ä¹ æ–¹æ³•ï¼Œç¿»è¯‘é€šå¸¸æ˜¯ä¸€ä¸ªå¯¹å¶è¿‡ç¨‹ï¼Œæ¯”å¦‚ï¼šè‹±ç¿»æ³•å’Œæ³•ç¿»è‹±ã€‚æ•´ä¸ªå­¦ä¹ è¿‡ç¨‹å¯ä»¥ç®€å•çš„æè¿°å¦‚ä¸‹ï¼šå¯¹å¶çš„ä¸¤ä¸ªç¿»è¯‘ä»»åŠ¡å¯ä»¥å½“åšæ˜¯ä¸¤ä¸ªagent Aå’ŒBï¼Œé€šè¿‡å°‘é‡çš„åŒè¯­æ ‡æ³¨æ•°æ®å¯ä»¥å­¦ä¹ å‡ºä¸€ä¸ªåˆçº§çš„ç¿»è¯‘æ¨¡å‹ï¼ŒåŒæ—¶é€šè¿‡å¤§é‡çš„å•è¯­æ•°æ®ï¼ˆæ— éœ€æ ‡æ³¨ï¼‰æ¥å­¦ä¹ å‡ºç›¸åº”çš„è¯­è¨€æ¨¡å‹ï¼›Aå°†å•è¯­æ•°æ®ç¿»è¯‘æˆBï¼ŒBé€šè¿‡è‡ªèº«çš„è¯­è¨€æ¨¡å‹å¯¹Açš„ç¿»è¯‘ç»“æœè¿›è¡Œè¯¯å·®åé¦ˆï¼ŒAè¿›è¡Œå­¦ä¹ ï¼›åŒç†ï¼ŒBä¹Ÿå¯ä»¥å‘Aå­¦ä¹ ï¼Œç›´åˆ°æ”¶æ•›ã€‚æ•´ä¸ªå­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œè®­ç»ƒäº†A-&gt;Bå’ŒB-&gt;Aä¸¤ä¸ªç¿»è¯‘æ¨¡å‹ï¼Œä½†æ˜¯ç”¨åˆ°çš„åŒè¯­æ ‡æ³¨æ•°æ®å°±ä¼šæ¯”è¾ƒå°‘ã€‚</p>
<h2 id="End-to-End-Reading-Comprehension-with-Dynamic-Answer-Chunk-Ranking"><a href="#End-to-End-Reading-Comprehension-with-Dynamic-Answer-Chunk-Ranking" class="headerlink" title="End-to-End Reading Comprehension with Dynamic Answer Chunk Ranking"></a><a href="https://arxiv.org/pdf/1610.09996v2.pdf" target="_blank" rel="external">End-to-End Reading Comprehension with Dynamic Answer Chunk Ranking</a></h2><p>ã€æœºå™¨é˜…è¯»ã€‘æœ¬æ–‡ç ”ç©¶çš„é—®é¢˜æ˜¯æœ€è¿‘ä¸€å¹´éå¸¸æµè¡Œçš„æœºå™¨é˜…è¯»ç†è§£é—®é¢˜ï¼Œç»™å®šä¸€æ®µæ–‡æœ¬å’Œä¸€ä¸ªé—®é¢˜ï¼Œè¾“å‡ºä¸€ä¸ªç­”æ¡ˆï¼ˆé€‰æ‹©ã€ç”Ÿæˆï¼‰ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¨¡å‹ï¼Œç›¸æ¯”ä¹‹å‰æ¨¡å‹æ¥è¯´ï¼Œæ”¹è¿›çš„åœ°æ–¹æ˜¯å¯ä»¥ç»™å‡ºå˜é•¿åº¦çš„ç­”æ¡ˆã€‚åœ¨ä¹‹å‰æ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œæ·»åŠ äº†ä¸€ä¸ªentityè¡¨ç¤ºæ¨¡å—ï¼Œå¹¶ä¸”å¯¹å€™é€‰çš„entityè¿›è¡Œæ’åºï¼Œå¾—åˆ°æ­£ç¡®ç­”æ¡ˆã€‚æœ¬æ–‡åœ¨SQuADä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œæ‹¿åˆ°äº†æœ€å¥½çš„ç»“æœã€‚å»ºè®®ç ”ç©¶QAå’Œæœºå™¨é˜…è¯»çš„ç«¥é‹æ¥ç²¾è¯»è¿™ç¯‡æ–‡ç« ï¼Œå¹¶ä¸”å¼€å§‹æ–°ä¸€è½®SQuADåˆ·æ¦œã€‚</p>
<h2 id="Knowledge-Questions-from-Knowledge-Graphs"><a href="#Knowledge-Questions-from-Knowledge-Graphs" class="headerlink" title="Knowledge Questions from Knowledge Graphs"></a><a href="https://arxiv.org/pdf/1610.09935v2.pdf" target="_blank" rel="external">Knowledge Questions from Knowledge Graphs</a></h2><p>ã€é—®é¢˜ç”Ÿæˆã€‘ã€çŸ¥è¯†å›¾è°±ã€‘æœ¬æ–‡ç ”ç©¶çš„å†…å®¹æ˜¯ä»çŸ¥è¯†å›¾è°±ä¸­è‡ªåŠ¨ç”Ÿæˆä¸€äº›å…·æœ‰ä¸€å®šéš¾åº¦ä¸”ç­”æ¡ˆå”¯ä¸€çš„é—®é¢˜ï¼Œç”¨äºæ•™è‚²æˆ–è¯„ä¼°ã€‚é—®é¢˜çš„ç¬¬ä¸€ä¸ªéš¾ç‚¹åœ¨äºå¦‚ä½•ç¡®ä¿ä»å›¾è°±ä¸­é€‰æ‹©çš„ç­”æ¡ˆå…·æœ‰å”¯ä¸€æ€§ï¼Œç¬¬äºŒä¸ªéš¾ç‚¹æ˜¯å¦‚ä½•è¯„ä»·æ‰€ç”Ÿæˆé—®é¢˜çš„éš¾åº¦ã€‚è¿™ä¸ªä»»åŠ¡éå¸¸æœ‰è¶£ï¼Œä¹Ÿæ˜¯çŸ¥è¯†å›¾è°±åœ¨å®é™…ä¸­çš„ä¸€ä¸ªåº”ç”¨åœºæ™¯ã€‚ä»»åŠ¡æœ¬èº«æ¯”æ–‡ç« çš„æ¨¡å‹å’Œæ–¹æ³•æ›´å€¼å¾—æ€è€ƒã€‚è¿˜æ˜¯è¯´å›chatbotï¼ŒQA chatbotï¼Œéƒ½è¯´ç¼ºå°‘æ•°æ®ï¼Œå·²æ„å»ºå¥½çš„çŸ¥è¯†å›¾è°±æœ¬èº«å°±æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„æ•°æ®æºï¼Œå¦‚ä½•åˆ©ç”¨å®ƒï¼Œå¦‚ä½•å°†å…¶æ›´å¥½åœ°ç”¨äºç”Ÿæˆæœ‰ç”¨çš„è®­ç»ƒæ•°æ®ï¼Œæœ¬æ–‡çš„ä»»åŠ¡ä¹Ÿè®¸ä¼šå¸¦æ¥ä¸€äº›å¯å‘ã€‚è¿™ä¸ªä»»åŠ¡ä¹Ÿä¸ç®—é¦–åˆ›ï¼Œä¹‹å‰KBQAçš„å·¥ä½œéƒ½æœ‰é€šè¿‡çŸ¥è¯†åº“å‡ºå‘æ¥ç”Ÿæˆé—®é¢˜ï¼Œä¸”é€šè¿‡å¹³è¡Œè¯­æ–™æ‰©å±•ï¼ŒåŒ…æ‹¬Percy liangç­‰ä¸å°‘å¤§ç‰›çš„å·¥ä½œéƒ½è€ƒè™‘äº†è¿™ç‚¹ï¼Œè¿™é‡Œç›¸å½“äºå»¶ç»­ï¼Œé‡åŒ–äº†éš¾åº¦ç¡®ä¿äº†ç­”æ¡ˆå”¯ä¸€æ€§ç­‰</p>
<h2 id="LightRNN-Memory-and-Computation-Efficient-Recurrent-Neural-Networks"><a href="#LightRNN-Memory-and-Computation-Efficient-Recurrent-Neural-Networks" class="headerlink" title="LightRNN: Memory and Computation-Efficient Recurrent Neural Networks"></a><a href="https://arxiv.org/pdf/1610.09893v1.pdf" target="_blank" rel="external">LightRNN: Memory and Computation-Efficient Recurrent Neural Networks</a></h2><p>ã€æ–°RNNã€‘æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ€è·¯æ¥æé«˜RNNçš„æ•ˆæœï¼ŒåŒ…æ‹¬æ—¶é—´å’Œç©ºé—´ä¸Šçš„ã€‚æœ€æ ¸å¿ƒçš„ç‚¹åœ¨äºæ„å»ºäº†ä¸€ç§å…¨æ–°çš„word embeddingè¡¨ç¤ºæ–¹å¼ï¼Œä¼ ç»Ÿçš„æ–¹æ³•æ˜¯è¯è¡¨ä¸­çš„æ¯ä¸ªè¯éƒ½ç”¨ä¸€ä¸ªå‘é‡è¡¨ç¤ºã€‚å°†æ¯ä¸ªè¯éƒ½æ”¾å…¥åˆ°ä¸€å¼ äºŒç»´è¡¨ä¸­ï¼Œè¡¨ä¸­çš„æ¯ä¸ªè¯éƒ½æœ‰å…¶æ‰€åœ¨çš„è¡Œå‘é‡å’Œåˆ—å‘é‡å…±åŒè¡¨ç¤ºï¼Œå¦‚å›¾1æ‰€ç¤ºã€‚ä»è€Œå°†è¯è¡¨ç¤ºçš„è§„æ¨¡ä»|V|ä¸ªå‘é‡é™åˆ°äº†2*sqrt(V)ã€‚æœ¬æ–‡è¿˜é’ˆå¯¹è¿™ç§è¡¨ç¤ºæ–¹æ³•ï¼Œæ„å»ºäº†ä¸€ç§æ–°çš„RNNæ¨¡å‹LightRNNï¼Œå¹¶åœ¨å¤§å‹æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯­è¨€æ¨¡å‹ä»»åŠ¡çš„è¯„æµ‹ï¼ŒéªŒè¯äº†æœ¬æ–‡æ–¹æ³•åœ¨æ—¶é—´å’Œç©ºé—´ä¸Šçš„æ€§èƒ½æå‡ã€‚ </p>
<h2 id="Chinese-Poetry-Generation-with-Planning-based-Neural-Network"><a href="#Chinese-Poetry-Generation-with-Planning-based-Neural-Network" class="headerlink" title="Chinese Poetry Generation with Planning based Neural Network"></a><a href="https://arxiv.org/pdf/1610.09889v1.pdf" target="_blank" rel="external">Chinese Poetry Generation with Planning based Neural Network</a></h2><p>ã€è¯—è¯ç”Ÿæˆã€‘æœ¬æ–‡ç ”ç©¶çš„ä»»åŠ¡éå¸¸æœ‰è¶£ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œæ¨¡å‹æ¥ç”Ÿæˆå”è¯—ï¼Œç±»ä¼¼åœ°å¯ä»¥å¼€å±•å®‹è¯ç­‰ä»»åŠ¡ã€‚ç«¯åˆ°ç«¯åœ°è®­ç»ƒã€å­¦ä¹ å…·æœ‰å¾ˆå¼ºçš„åº”ç”¨æ€§ï¼Œåªè¦èƒ½å¤Ÿç»™å®šè¾“å…¥åºåˆ—å’Œè¾“å‡ºåºåˆ—ï¼Œæ‰“å¼€è„‘æ´ï¼Œåšä»»ä½•å¥½ç©çš„ä»»åŠ¡éƒ½æœ‰å¯èƒ½ã€‚</p>
<h2 id="MusicMood-Predicting-the-mood-of-music-from-song-lyrics-using-machine-learning"><a href="#MusicMood-Predicting-the-mood-of-music-from-song-lyrics-using-machine-learning" class="headerlink" title="MusicMood: Predicting the mood of music from song lyrics using machine learning"></a><a href="https://arxiv.org/pdf/1611.00138v1.pdf" target="_blank" rel="external">MusicMood: Predicting the mood of music from song lyrics using machine learning</a></h2><p>ã€éŸ³ä¹æ¨èç³»ç»Ÿã€‘æœ¬æ–‡ç ”ç©¶å†…å®¹ä¸ºé€šè¿‡æœºå™¨å­¦ä¹ æ–¹æ³•ä»æ­Œè¯ä¸­æ¥é¢„æµ‹éŸ³ä¹çš„æƒ…ç»ªï¼Œç®—æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†åœ¨éŸ³ä¹ä¸­çš„åº”ç”¨ã€‚è¿™ç§ç®€å•çš„åº”ç”¨ï¼Œå¯ä»¥ä¸ºéŸ³ä¹æ¨èç³»ç»Ÿæä¾›ä¸€äº›ç‰¹å¾ï¼Œç°æœ‰çš„éŸ³ä¹æ¨èç³»ç»Ÿå¯ä»¥åšå‚è€ƒã€‚</p>
<h2 id="Detecting-Context-Dependent-Messages-in-a-Conversational-Environment"><a href="#Detecting-Context-Dependent-Messages-in-a-Conversational-Environment" class="headerlink" title="Detecting Context Dependent Messages in a Conversational Environment"></a><a href="https://arxiv.org/pdf/1611.00483v2.pdf" target="_blank" rel="external">Detecting Context Dependent Messages in a Conversational Environment</a></h2><p>ã€chatbotã€‘ã€ä¸Šä¸‹æ–‡ã€‘chatbotçš„éš¾ç‚¹ä¹‹ä¸€åœ¨äºå¦‚ä½•å‡†ç¡®ç†è§£â€œäººè¯â€ï¼Œâ€œäººè¯â€æœ‰ä¸ªæ˜¾è‘—çš„ç‰¹ç‚¹æ˜¯ç®€çŸ­è€Œä¸”éæ­£å¼ï¼Œå¸¸è§çš„NLPåˆ†ææ–¹æ³•ï¼Œè¯æ€§æ ‡æ³¨ã€å¥æ³•åˆ†æç­‰éƒ½ä¸å¥½ç”¨ã€‚ç†è§£â€œäººè¯â€éœ€è¦ç»“åˆä¸Šä¸‹æ–‡ã€‚é‚£ä¹ˆï¼Œç¬¬ä¸€ä¸ªé—®é¢˜æ¥äº†ï¼Œç†è§£æŸå¥è¯åº”è¯¥å–å“ªå‡ å¥historyä½œä¸ºä¸Šä¸‹æ–‡ï¼Œç¬¬äºŒä¸ªé—®é¢˜æ˜¯å¦‚ä½•ç†è§£ä¸Šä¸‹æ–‡ï¼Ÿæœ¬æ–‡æ—¨åœ¨è§£å†³ç¬¬ä¸€ä¸ªé—®é¢˜ï¼Œè¿™ä¸ªé—®é¢˜ç ”ç©¶ç©ºé—´æ¯”è¾ƒå¤§ï¼Œæœ¬æ–‡åšäº†åˆæ­¥å°è¯•ã€‚å¯¹chatbotæ„Ÿå…´è¶£çš„ç«¥é‹ï¼Œä¸ç®¡æ˜¯å­¦æœ¯ç•Œè¿˜æ˜¯å·¥ä¸šç•Œçš„ç«¥é‹éƒ½å¯ä»¥è¯»ä¸€ä¸‹æœ¬æ–‡ï¼Œæˆ–è®¸ä¼šå¸¦æ¥ä¸€äº›å¯å‘å’Œæ€è€ƒã€‚</p>
<h2 id="Natural-Parameter-Networks-A-Class-of-Probabilistic-Neural-Networks"><a href="#Natural-Parameter-Networks-A-Class-of-Probabilistic-Neural-Networks" class="headerlink" title="Natural-Parameter Networks: A Class of Probabilistic Neural Networks"></a><a href="https://arxiv.org/pdf/1611.00448v1.pdf" target="_blank" rel="external">Natural-Parameter Networks: A Class of Probabilistic Neural Networks</a></h2><p>ã€NIPS2016ã€‘æœ¬æ–‡æå‡ºäº†ä¸€ç±»æ¦‚ç‡ç¥ç»ç½‘ç»œï¼ˆè´å¶æ–¯ï¼‰ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç¥ç»ç½‘ç»œåœ¨æ•°æ®è§„æ¨¡å°çš„æ—¶å€™å®¹æ˜“è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚</p>
<h2 id="Collaborative-Recurrent-Autoencoder-Recommend-while-Learning-to-Fill-in-the-Blanks"><a href="#Collaborative-Recurrent-Autoencoder-Recommend-while-Learning-to-Fill-in-the-Blanks" class="headerlink" title="Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in the Blanks"></a><a href="https://arxiv.org/pdf/1611.00454v1.pdf" target="_blank" rel="external">Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in the Blanks</a></h2><p>ã€æ¨èç³»ç»Ÿã€‘æœ¬æ–‡çš„äº®ç‚¹åœ¨äºå°†RNNå’ŒååŒè¿‡æ»¤æ— ç¼ç»“åˆèµ·æ¥ã€‚</p>
<h1 id="ä¸€å‘¨èµ„æº"><a href="#ä¸€å‘¨èµ„æº" class="headerlink" title="ä¸€å‘¨èµ„æº"></a>ä¸€å‘¨èµ„æº</h1><h2 id="èŠå¤©æœºå™¨äººèµ„æ–™æ±‡æ€»"><a href="#èŠå¤©æœºå™¨äººèµ„æ–™æ±‡æ€»" class="headerlink" title="èŠå¤©æœºå™¨äººèµ„æ–™æ±‡æ€»"></a><a href="https://www.52ml.net/20510.html" target="_blank" rel="external">èŠå¤©æœºå™¨äººèµ„æ–™æ±‡æ€»</a></h2><p>æ¥è‡ª52mlæ±‡æ€»çš„èŠå¤©æœºå™¨äººèµ„æ–™</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-11-04T02:47:13.000Z"><a href="/2016/11/03/PaperWeekly-ç¬¬åäºŒæœŸ/">2016-11-03</a></time>
      
      
  
    <h1 class="title"><a href="/2016/11/03/PaperWeekly-ç¬¬åäºŒæœŸ/">PaperWeekly ç¬¬åäºŒæœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•"><a href="#å¼•" class="headerlink" title="å¼•"></a>å¼•</h1><p>æ–‡æœ¬æ‘˜è¦æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†çš„ä¸€å¤§ç»å…¸ä»»åŠ¡ï¼Œç ”ç©¶çš„å†å²æ¯”è¾ƒé•¿ã€‚éšç€ç›®å‰äº’è”ç½‘ç”Ÿäº§å‡ºçš„æ–‡æœ¬æ•°æ®è¶Šæ¥è¶Šå¤šï¼Œæ–‡æœ¬ä¿¡æ¯è¿‡è½½é—®é¢˜è¶Šæ¥è¶Šä¸¥é‡ï¼Œå¯¹å„ç±»æ–‡æœ¬è¿›è¡Œä¸€ä¸ªâ€œé™ç»´â€å¤„ç†æ˜¾å¾—éå¸¸å¿…è¦ï¼Œæ–‡æœ¬æ‘˜è¦ä¾¿æ˜¯å…¶ä¸­ä¸€ä¸ªé‡è¦çš„æ‰‹æ®µã€‚ä¼ ç»Ÿçš„æ–‡æœ¬æ‘˜è¦æ–¹æ³•ï¼Œä¸ç®¡æ˜¯å¥å­çº§åˆ«ã€å•æ–‡æ¡£è¿˜æ˜¯å¤šæ–‡æ¡£æ‘˜è¦ï¼Œéƒ½ä¸¥é‡ä¾èµ–ç‰¹å¾å·¥ç¨‹ï¼Œéšç€æ·±åº¦å­¦ä¹ çš„æµè¡Œä»¥åŠseq2seq+attentionæ¨¡å‹åœ¨æœºå™¨ç¿»è¯‘é¢†åŸŸä¸­çš„çªç ´ï¼Œæ–‡æœ¬æ‘˜è¦ä»»åŠ¡ä¹Ÿè¿æ¥äº†ä¸€ç§å…¨æ–°çš„æ€è·¯ã€‚æœ¬æœŸPaperWeeklyå°†ä¼šåˆ†äº«4ç¯‡åœ¨è¿™æ–¹é¢åšå¾—éå¸¸å‡ºè‰²çš„paperï¼š</p>
<p>1ã€A Neural Attention Model for Abstractive Sentence Summarization, 2015<br>2ã€Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond, 2016<br>3ã€Neural Summarization by Extracting Sentences and Words, 2016<br>4ã€AttSum: Joint Learning of Focusing and Summarization with Neural Attention, 2016</p>
<h1 id="A-Neural-Attention-Model-for-Abstractive-Sentence-Summarization"><a href="#A-Neural-Attention-Model-for-Abstractive-Sentence-Summarization" class="headerlink" title="A Neural Attention Model for Abstractive Sentence Summarization"></a><a href="https://aclweb.org/anthology/D/D15/D15-1044.pdf" target="_blank" rel="external">A Neural Attention Model for Abstractive Sentence Summarization</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Rush, A. M., Chopra, S., &amp; Weston, J.</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Facebook AI Research / Harvard SEAS</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Neural Attention, Abstractive Sentence Summarization</p>
<h2 id="æ–‡ç« æ¥æº"><a href="#æ–‡ç« æ¥æº" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>EMNLP 2015</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>è¿™ç¯‡æ¥è‡ªFacebookçš„paperçš„ä¸»é¢˜æ˜¯åŸºäºattention based NNçš„ç”Ÿæˆå¼å¥å­æ‘˜è¦/å‹ç¼©ã€‚</p>
<p><img src="media/emnlp.JPG" alt="1"></p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>è¯¥å·¥ä½œä½¿ç”¨æå‡ºäº†ä¸€ç§encoder-decoderæ¡†æ¶ä¸‹çš„å¥å­æ‘˜è¦æ¨¡å‹ã€‚</p>
<p><img src="media/emnlp2.JPG" alt="encoder"></p>
<p>ä½œè€…åœ¨æ–‡ç« ä¸­ä»‹ç»äº†ä¸‰ç§ä¸åŒçš„encodingæ–¹æ³•ï¼Œåˆ†åˆ«ä¸ºï¼š</p>
<ol>
<li>Bag-of-Words Encoderã€‚è¯è¢‹æ¨¡å‹å³å°†è¾“å…¥å¥å­ä¸­è¯çš„è¯å‘é‡è¿›è¡Œå¹³å‡ã€‚</li>
<li>CNN encoder</li>
<li>Attention-Based Encoderã€‚è¯¥encoderä½¿ç”¨CNNå¯¹å·²ç”Ÿæˆçš„æœ€è¿‘cï¼ˆcä¸ºçª—å£å¤§å°ï¼‰ä¸ªè¯è¿›è¡Œç¼–ç ,å†ç”¨ç¼–ç å‡ºæ¥çš„contextå‘é‡å¯¹è¾“å…¥å¥å­åšattentionï¼Œä»è€Œå®ç°å¯¹è¾“å…¥çš„åŠ æƒå¹³å‡ã€‚</li>
</ol>
<p>æ¨¡å‹ä¸­çš„decoderä¸ºä¿®æ”¹è¿‡çš„NNLMï¼Œå…·ä½“åœ°ï¼š</p>
<p><img src="media/emnlp3.JPG" alt="1"></p>
<p>å¼ä¸­$$y_c$$ä¸ºå·²ç”Ÿæˆçš„è¯ä¸­å¤§å°ä¸ºcçš„çª—å£ï¼Œä¸encoderä¸­çš„Attention-Based EncoderåŒä¹‰ã€‚</p>
<p>ä¸ç›®å‰ä¸»æµçš„åŸºäºseq2seqçš„æ¨¡å‹ä¸åŒï¼Œè¯¥æ¨¡å‹ä¸­encoderå¹¶æœªé‡‡ç”¨æµè¡Œçš„RNNã€‚</p>
<h2 id="æ•°æ®"><a href="#æ•°æ®" class="headerlink" title="æ•°æ®"></a>æ•°æ®</h2><p>è¯¥æ–‡ç« ä½¿ç”¨äº†English Gigawordä½œä¸ºè¯­æ–™ï¼Œé€‰æ‹©æ–°é—»ä¸­çš„é¦–å¥ä½œä¸ºè¾“å…¥ï¼Œæ–°é—»æ ‡é¢˜ä½œä¸ºè¾“å‡ºï¼Œä»¥æ­¤æ„å»ºå¹³è¡Œè¯­æ–™ã€‚<br>å…·ä½“çš„æ•°æ®æ„å»ºæ–¹æ³•å‚è§æ–‡ç« ã€‚</p>
<p>æ­¤å¤–ï¼Œè¯¥æ–‡ç« è¿˜ä½¿ç”¨äº†DUC2004ä½œä¸ºæµ‹è¯•é›†ã€‚</p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>åœ¨è°ƒç ”èŒƒå›´å†…ï¼Œè¯¥æ–‡ç« æ˜¯ä½¿ç”¨attentionæœºåˆ¶è¿›è¡Œæ‘˜è¦çš„ç¬¬ä¸€ç¯‡ã€‚ä¸”ä½œè€…æå‡ºäº†åˆ©ç”¨Gigawordæ„å»ºå¤§é‡å¹³è¡Œå¥å¯¹çš„æ–¹æ³•ï¼Œä½¿å¾—åˆ©ç”¨ç¥ç»ç½‘ç»œè®­ç»ƒæˆä¸ºå¯èƒ½ï¼Œä¹‹åå¤šç¯‡å·¥ä½œéƒ½ä½¿ç”¨äº†è¯¥æ–¹æ³•æ„å»ºè®­ç»ƒæ•°æ®ã€‚</p>
<h1 id="Abstractive-Text-Summarization-using-Sequence-to-sequence-RNNs-and-Beyond"><a href="#Abstractive-Text-Summarization-using-Sequence-to-sequence-RNNs-and-Beyond" class="headerlink" title="Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond"></a><a href="https://aclweb.org/anthology/K/K16/K16-1028.pdf" target="_blank" rel="external">Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Nallapati, Ramesh, et al.</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>IBM Watson</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>seq2seq, Summarization</p>
<h2 id="æ–‡ç« æ¥æº-1"><a href="#æ–‡ç« æ¥æº-1" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>In CoNLL 2016</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>è¯¥å·¥ä½œä¸»è¦ç ”ç©¶äº†åŸºäºseq2seqæ¨¡å‹çš„ç”Ÿæˆå¼æ–‡æœ¬æ‘˜è¦ã€‚<br>è¯¥æ–‡ç« ä¸ä»…åŒ…æ‹¬äº†å¥å­å‹ç¼©æ–¹é¢çš„å·¥ä½œï¼Œè¿˜ç»™å‡ºäº†ä¸€ä¸ªæ–°çš„æ–‡æ¡£åˆ°å¤šå¥å­çš„æ•°æ®é›†ã€‚</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p><img src="media/conll.JPG" alt=""></p>
<p>è¯¥æ–‡ç« ä½¿ç”¨äº†å¸¸ç”¨çš„seq2seqä½œä¸ºåŸºæœ¬æ¨¡å‹ï¼Œå¹¶åœ¨å…¶åŸºç¡€ä¸Šæ·»åŠ äº†å¾ˆå¤šfeatureï¼š</p>
<ol>
<li>Large Vocabulary Trickã€‚<br>å‚è§SÃ©bastien Jean, Kyunghyun Cho, Roland Memisevic, and Yoshua Bengio. 2014. On using very large target vocabulary for neural machine translation. CoRR, abs/1412.2007.</li>
<li><p>æ·»åŠ featureã€‚ä¾‹å¦‚POS tagï¼Œ TFã€IDFï¼Œ NER tagç­‰ã€‚è¿™äº›featureä¼šè¢«embedä¹‹åä¸è¾“å…¥å¥å­çš„è¯å‘é‡æ‹¼æ¥èµ·æ¥ä½œä¸ºencoderçš„è¾“å…¥ã€‚</p>
</li>
<li><p>pointing / copy æœºåˆ¶ã€‚ä½¿ç”¨ä¸€ä¸ªgateæ¥åˆ¤æ–­æ˜¯å¦è¦ä»è¾“å…¥å¥å­ä¸­æ‹·è´è¯æˆ–è€…ä½¿ç”¨decoderç”Ÿæˆè¯ã€‚å‚è§ACL 2016çš„ä¸¤ç¯‡ç›¸å…³paperã€‚</p>
</li>
<li><p>Hierarchical Attentionã€‚è¿™æ˜¯ç”¨äºæ–‡ç« æ‘˜è¦ä¸­å¤šå¥å­çš„attentionï¼Œæ€è·¯å€Ÿé‰´äº†Jiwei Liçš„ä¸€ç¯‡auto encoderçš„å·¥ä½œã€‚å¤§è‡´æ€è·¯ä¸ºä½¿ç”¨å¥å­çº§åˆ«çš„weightå¯¹å¥å­ä¸­çš„è¯è¿›è¡Œre-scaleã€‚</p>
</li>
</ol>
<h2 id="æ•°æ®-1"><a href="#æ•°æ®-1" class="headerlink" title="æ•°æ®"></a>æ•°æ®</h2><ol>
<li>English Gigaword</li>
<li>DUC 2004</li>
<li>æå‡ºäº†CNN/Daily Mail Corpus</li>
</ol>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¯¥å·¥ä½œä¸ºåœ¨ç¬¬ä¸€ç¯‡æ–‡ç« åŸºç¡€ä¸Šçš„æ”¹è¿›å·¥ä½œï¼Œåšäº†å¤§é‡çš„å®éªŒï¼Œéå¸¸æ‰å®ã€‚æ–‡ç« æå‡ºçš„feature-rich encoderå¯¹å…¶ä»–å·¥ä½œä¹Ÿæœ‰å‚è€ƒæ„ä¹‰ï¼Œå³å°†ä¼ ç»Ÿæ–¹æ³•ä¸­çš„ç‰¹å¾æ˜¾ç¤ºåœ°ä½œä¸ºç¥ç»ç½‘ç»œçš„è¾“å…¥ï¼Œæé«˜äº†æ•ˆæœã€‚</p>
<h1 id="Neural-Summarization-by-Extracting-Sentences-and-Words"><a href="#Neural-Summarization-by-Extracting-Sentences-and-Words" class="headerlink" title="Neural Summarization by Extracting Sentences and Words"></a><a href="https://aclweb.org/anthology/P/P16/P16-1046.pdf" target="_blank" rel="external">Neural Summarization by Extracting Sentences and Words</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Cheng, Jianpeng, and Mirella Lapata.</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>University of Edinburgh</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Extractive Summarization, Neural Attention</p>
<h2 id="æ–‡ç« æ¥æº-2"><a href="#æ–‡ç« æ¥æº-2" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ACL 2016</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡ŒæŠ½å–å¼æ‘˜è¦ï¼Œåˆ†åˆ«ä¸ºå¥å­æŠ½å–å’Œå•è¯æŠ½å–ã€‚</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p><img src="media/extractModel1.JPG" alt=""></p>
<h3 id="å¥å­æŠ½å–"><a href="#å¥å­æŠ½å–" class="headerlink" title="å¥å­æŠ½å–"></a>å¥å­æŠ½å–</h3><p>ç”±äºè¯¥å·¥ä½œä¸ºæ–‡æ¡£çš„æ‘˜è¦ï¼Œæ•…å…¶ä½¿ç”¨äº†ä¸¤å±‚encoderï¼Œåˆ†åˆ«ä¸ºï¼š</p>
<ol>
<li>è¯çº§åˆ«çš„encoderï¼ŒåŸºäºCNNã€‚å³å¯¹å¥å­åšå·ç§¯å†åšmax poolingä»è€Œè·å¾—å¥å­çš„è¡¨ç¤ºã€‚</li>
<li>å¥å­çº§åˆ«çš„encoderï¼ŒåŸºäºRNNã€‚å°†å¥å­çš„è¡¨ç¤ºä½œä¸ºè¾“å…¥ï¼Œå³è·å¾—æ–‡æ¡£çš„è¡¨ç¤ºã€‚</li>
</ol>
<p>ç”±äºæ˜¯æŠ½å–å¼æ‘˜è¦ï¼Œå…¶ä½¿ç”¨äº†ä¸€ä¸ªRNN decoderï¼Œä½†å…¶ä½œç”¨å¹¶éç”Ÿæˆï¼Œè€Œæ˜¯ç”¨ä½œsequence labelingï¼Œå¯¹è¾“å…¥çš„å¥å­åˆ¤æ–­æ˜¯å¦è¿›è¡ŒæŠ½å–ï¼Œç±»ä¼¼äºpointer networkã€‚</p>
<h3 id="è¯çš„æŠ½å–"><a href="#è¯çš„æŠ½å–" class="headerlink" title="è¯çš„æŠ½å–"></a>è¯çš„æŠ½å–</h3><p>å¯¹äºè¯çš„æŠ½å–ï¼Œè¯¥æ¨¡å‹åŒæ ·é€‚ç”¨äº†hierarchical attentionã€‚ä¸å¥å­æŠ½å–ä¸åŒï¼Œè¯çš„æŠ½å–æ›´ç±»ä¼¼äºç”Ÿæˆï¼Œåªæ˜¯å°†è¾“å…¥æ–‡æ¡£çš„å•è¯ä½œä¸ºdecoderçš„è¯è¡¨ã€‚</p>
<h2 id="æ•°æ®-2"><a href="#æ•°æ®-2" class="headerlink" title="æ•°æ®"></a>æ•°æ®</h2><p>ä»DailyMail newsä¸­æ ¹æ®å…¶highlightæ„å»ºæŠ½å–å¼æ‘˜è¦æ•°æ®é›†ã€‚</p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¯¥å·¥ä½œçš„ç‰¹åˆ«ä¹‹å¤„åœ¨äºå¯¹attentionæœºåˆ¶çš„ä½¿ç”¨ã€‚è¯¥paperä¹‹å‰çš„è®¸å¤šå·¥ä½œä¸­çš„attentionæœºåˆ¶éƒ½ä¸Bahdanauçš„å·¥ä½œç›¸åŒï¼Œå³ç”¨attentionå¯¹æŸäº›å‘é‡æ±‚weighted sumã€‚è¯¥å·¥ä½œåˆ™ç›´æ¥ä½¿ç”¨attentionçš„åˆ†æ•°è¿›è¡Œå¯¹æ–‡æ¡£ä¸­å¥å­è¿›è¡Œé€‰æ‹©ï¼Œå®é™…ä¸Šä¸pointer networksæ„æ€ç›¸è¿‘ã€‚</p>
<h1 id="AttSum-Joint-Learning-of-Focusing-and-Summarization-with-Neural-Attention"><a href="#AttSum-Joint-Learning-of-Focusing-and-Summarization-with-Neural-Attention" class="headerlink" title="AttSum: Joint Learning of Focusing and Summarization with Neural Attention"></a><a href="http://www4.comp.polyu.edu.hk/~cszqcao/data/attsum.pdf" target="_blank" rel="external">AttSum: Joint Learning of Focusing and Summarization with Neural Attention</a></h1><h2 id="ä½œè€…-3"><a href="#ä½œè€…-3" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Cao, Ziqiang, et al.</p>
<h2 id="å•ä½-3"><a href="#å•ä½-3" class="headerlink" title="å•ä½"></a>å•ä½</h2><p> The Hong Kong Polytechnic University, Peking University, Microsoft Research</p>
<h2 id="å…³é”®è¯-3"><a href="#å…³é”®è¯-3" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Query-focused Summarization</p>
<h2 id="æ–‡ç« æ¥æº-3"><a href="#æ–‡ç« æ¥æº-3" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>COLING 2016</p>
<h2 id="é—®é¢˜-3"><a href="#é—®é¢˜-3" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>Query-focusedå¤šæ–‡æ¡£æŠ½å–å¼æ‘˜è¦</p>
<h2 id="æ¨¡å‹-3"><a href="#æ¨¡å‹-3" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p><img src="media/coling.JPG" alt=""></p>
<p>ç”±äºè¯¥ä»»åŠ¡ä¸ºé’ˆå¯¹æŸä¸ªqueryæŠ½å–å‡ºå¯ä»¥å›ç­”è¯¥queryçš„æ‘˜è¦ï¼Œæ¨¡å‹ä½¿ç”¨äº†attentionæœºåˆ¶å¯¹å¥å­è¿›è¡ŒåŠ æƒï¼ŒåŠ æƒçš„ä¾æ®ä¸ºæ–‡æ¡£å¥å­å¯¹queryçš„ç›¸å…³æ€§ï¼ˆåŸºäºattentionï¼‰ï¼Œä»è€Œå¯¹å¥å­rankingï¼Œè¿›è€ŒæŠ½å–å‡ºæ‘˜è¦ã€‚å…·ä½“åœ°ï¼š</p>
<ol>
<li>ä½¿ç”¨CNNå¯¹å¥å­è¿›è¡Œencoding</li>
<li>åˆ©ç”¨queryï¼Œå¯¹å¥å­è¡¨ç¤ºè¿›è¡Œweighted sum poolingã€‚</li>
<li>ä½¿ç”¨cosine similarityå¯¹å¥å­æ’åºã€‚</li>
</ol>
<h2 id="æ•°æ®-3"><a href="#æ•°æ®-3" class="headerlink" title="æ•°æ®"></a>æ•°æ®</h2><p>DUC 2005 âˆ¼ 2007 query-focused summarization benchmark datasets</p>
<h2 id="ç®€è¯„-3"><a href="#ç®€è¯„-3" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¯¥æ–‡ç« çš„äº®ç‚¹ä¹‹å¤„åœ¨äºä½¿ç”¨attentionæœºåˆ¶å¯¹æ–‡æ¡£ä¸­å¥å­è¿›è¡Œweighted-sum poolingï¼Œä»¥æ­¤å®Œæˆquery-focusedçš„å¥å­è¡¨ç¤ºå’Œrankingã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>æœ¬æ¬¡ä¸»è¦ä»‹ç»äº†å››ç¯‡æ–‡æœ¬æ‘˜è¦çš„å·¥ä½œï¼Œå‰ä¸¤ç¯‡ä¸ºç”Ÿæˆå¼ï¼ˆabstractiveï¼‰æ‘˜è¦ï¼Œåä¸¤ç¯‡ä¸ºæŠ½å–å¼ï¼ˆextractiveï¼‰æ‘˜è¦ã€‚å¯¹äºç”Ÿæˆå¼æ‘˜è¦ï¼Œç›®å‰ä¸»è¦æ˜¯åŸºäºencoder-decoderæ¨¡å¼çš„ç”Ÿæˆï¼Œä½†è¿™ç§æ–¹æ³•å—é™äºè¯­æ–™çš„è·å¾—ï¼Œè€ŒRushç­‰æå‡ºäº†åˆ©ç”¨English Gigawordï¼ˆå³æ–°é—»æ•°æ®ï¼‰æ„å»ºå¹³è¡Œå¥å¯¹è¯­æ–™åº“çš„æ–¹æ³•ã€‚IBMåœ¨Facebookå·¥ä½œå¯å‘ä¸‹ï¼Œç›´æ¥ä½¿ç”¨äº†seq2seq with attentionæ¨¡å‹è¿›è¡Œæ‘˜è¦çš„ç”Ÿæˆï¼Œè·å¾—äº†æ›´å¥½çš„æ•ˆæœã€‚å¯¹äºæŠ½å–å¼æ‘˜è¦ï¼Œç¥ç»ç½‘ç»œæ¨¡å‹çš„ä½œç”¨å¤šç”¨æ¥å­¦ä¹ å¥å­è¡¨ç¤ºè¿›è€Œç”¨äºåç»­çš„å¥å­rankingã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-10-28T23:35:04.000Z"><a href="/2016/10/28/cs-CL-weekly-2016-10-24-2016-10-28/">2016-10-28</a></time>
      
      
  
    <h1 class="title"><a href="/2016/10/28/cs-CL-weekly-2016-10-24-2016-10-28/">cs.CL weekly 2016.10.24-2016.10.28</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="ä¸€å‘¨å€¼å¾—è¯»"><a href="#ä¸€å‘¨å€¼å¾—è¯»" class="headerlink" title="ä¸€å‘¨å€¼å¾—è¯»"></a>ä¸€å‘¨å€¼å¾—è¯»</h1><h2 id="Iterative-Refinement-for-Machine-Translation"><a href="#Iterative-Refinement-for-Machine-Translation" class="headerlink" title="Iterative Refinement for Machine Translation"></a><a href="https://arxiv.org/pdf/1610.06602v2.pdf" target="_blank" rel="external">Iterative Refinement for Machine Translation</a></h2><p>ã€æœºå™¨ç¿»è¯‘ã€‘æœ¬æ–‡çš„ç ”ç©¶å†…å®¹é’ˆå¯¹æœºå™¨ç¿»è¯‘åœ¨è§£ç é˜¶æ®µå•è°ƒæ€»æ˜¯å•è°ƒã€ä¸å›æº¯åœ°ç”Ÿæˆç¿»è¯‘ç»“æœçš„é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§ç¿»è¯‘æ–¹æ¡ˆï¼Œåœ¨è§£ç æ—¶ä¸æ–­åœ°å›æº¯å¹¶ä¸”ä¿®æ­£å…ˆå‰ç”Ÿæˆçš„ç»“æœã€‚æ¨¡å‹æ˜¯CNN+attentionã€‚æœ¬æ–‡å·¥ä½œæ¥è‡ªFacebook AI Researchã€‚</p>
<h2 id="Bridging-Neural-Machine-Translation-and-Bilingual-Dictionaries"><a href="#Bridging-Neural-Machine-Translation-and-Bilingual-Dictionaries" class="headerlink" title="Bridging Neural Machine Translation and Bilingual Dictionaries"></a><a href="https://arxiv.org/pdf/1610.07272v1.pdf" target="_blank" rel="external">Bridging Neural Machine Translation and Bilingual Dictionaries</a></h2><p>ã€æœºå™¨ç¿»è¯‘ã€‘æœ¬æ–‡ç ”ç©¶çš„å†…å®¹æ˜¯æœºå™¨ç¿»è¯‘ä¸­å¦‚ä½•åº”ç”¨ä¸¤é—¨è¯­è¨€ä¸­ç½•è§è¯å’Œæœªç™»å½•è¯è¯å…¸çš„é—®é¢˜ï¼Œæœ¬æ–‡é’ˆå¯¹è¿™ä¸€é—®é¢˜æå‡ºäº†ä¸¤ç§æ–¹æ³•ã€‚æœ¬æ–‡å·¥ä½œæ¥è‡ªä¸­ç§‘é™¢@å¼ å®¶ä¿ŠMT è€å¸ˆã€‚</p>
<h2 id="Two-are-Better-than-One-An-Ensemble-of-Retrieval-and-Generation-Based-Dialog-Systems"><a href="#Two-are-Better-than-One-An-Ensemble-of-Retrieval-and-Generation-Based-Dialog-Systems" class="headerlink" title="Two are Better than One: An Ensemble of Retrieval- and Generation-Based Dialog Systems"></a><a href="https://arxiv.org/pdf/1610.07149v1.pdf" target="_blank" rel="external">Two are Better than One: An Ensemble of Retrieval- and Generation-Based Dialog Systems</a></h2><p>ã€chatbotã€‘å¼€æ”¾åŸŸèŠå¤©æœºå™¨äººåœ¨å›å¤æ—¶æœ‰ä¸¤ç§å¸¸è§çš„æ€è·¯ï¼š1ã€åŸºäºæ£€ç´¢ 2ã€åŸºäºç”Ÿæˆã€‚ç¬¬ä¸€ç§æ–¹æ³•æ¯”è¾ƒç®€å•ä½†ç­”æ¡ˆç›¸å¯¹æ­»æ¿ï¼Œç¬¬äºŒç§æ–¹æ³•çµæ´»ä½†å¸¸å¸¸å‡ºç°â€œå‘µå‘µâ€å¼çš„å›ç­”ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é›†æˆæ–¹æ³•ï¼Œæ£€ç´¢åˆ°çš„ç­”æ¡ˆå’Œç”¨æˆ·çš„queryä¸€èµ·ä½œä¸ºè¾“å…¥ï¼Œå–‚å…¥æ¨¡å‹ï¼ˆRNNï¼‰ä¸­ï¼Œç„¶åç”Ÿæˆå›ç­”ï¼Œæ–°ç”Ÿæˆçš„å›ç­”ä½œä¸ºcandidateä¸€èµ·é‡æ’åºæ¥å†³å®šæœ€ç»ˆçš„å›å¤ã€‚å®éªŒç»“æœè¯æ˜äº†æœ¬æ–‡çš„æ–¹æ³•è¦æ¯”å•ç§æ–¹æ³•æ›´æœ‰æ•ˆã€‚æ¯ä¸ªæ¨¡å‹éƒ½æœ‰å…¶ä¼˜ç‚¹å’Œç¼ºç‚¹ï¼Œè¿™ç§é›†æˆå¼çš„æ–¹æ³•å°†å„ä¸ªæ¨¡å‹çš„ä¼˜ç‚¹é›†æˆèµ·æ¥ï¼Œæ•ˆæœä¼šå¾ˆä¸é”™ã€‚</p>
<h2 id="EmojiNet-Building-a-Machine-Readable-Sense-Inventory-for-Emoji"><a href="#EmojiNet-Building-a-Machine-Readable-Sense-Inventory-for-Emoji" class="headerlink" title="EmojiNet: Building a Machine Readable Sense Inventory for Emoji"></a><a href="https://arxiv.org/pdf/1610.07710v1.pdf" target="_blank" rel="external">EmojiNet: Building a Machine Readable Sense Inventory for Emoji</a></h2><p>ã€è¯­ä¹‰ç½‘ã€‘æœ¬æ–‡æ„å»ºçš„EmojiNetç±»ä¼¼äºè¯çš„WordNetï¼ŒåŒä¸€ä¸ªEmojiè¡¨æƒ…åœ¨ä¸åŒçš„ä¸Šä¸‹æ–‡ä¸­æœ‰ç€ä¸åŒçš„æ„æ€ï¼Œè€Œç¤¾äº¤ç½‘ç»œéå¸¸æµè¡ŒEmojiè¡¨æƒ…ï¼Œæ„å»ºè¿™ä¹ˆä¸€ä¸ªè¯­ä¹‰ç½‘éå¸¸æœ‰æ„ä¹‰ã€‚é¡¹ç›®åœ°å€ï¼š<a href="http://emojinet.knoesis.org./" target="_blank" rel="external">http://emojinet.knoesis.org./</a></p>
<h2 id="Can-Active-Memory-Replace-Attention"><a href="#Can-Active-Memory-Replace-Attention" class="headerlink" title="Can Active Memory Replace Attention?"></a><a href="https://arxiv.org/pdf/1610.08613v1.pdf" target="_blank" rel="external">Can Active Memory Replace Attention?</a></h2><p>ã€Memory Networksã€‘Memory Networkså’ŒAttentionæ˜¯è§£å†³é•¿è·ç¦»ä¾èµ–é—®é¢˜çš„ä¸¤å¤§æ–¹æ³•ï¼ŒAttentionæ¨¡å‹åœ¨NLPçš„å¾ˆå¤šä»»åŠ¡ä¸­éƒ½æœ‰æ›´å¥½çš„è¡¨ç°ï¼Œæœ¬æ–‡å¯¹Memory Networksç±»æ¨¡å‹çš„ç¼ºç‚¹è¿›è¡Œäº†åˆ†æï¼Œå¹¶ä¸”æå‡ºäº†ä¸€ç§æ”¹è¿›æ¨¡å‹ã€‚æ”¹è¿›ç‰ˆçš„memoryæ¨¡å‹æœ‰ä¸é”™çš„è¡¨ç°ï¼Œå¹¶ä¸”åœ¨é•¿å¥å­æœºå™¨ç¿»è¯‘ä»»åŠ¡ä¸­å¾—åˆ°äº†éªŒè¯ã€‚æœ¬æ–‡ä½œè€…æ¥è‡ªGoogle Brainã€‚å»ºè®®å…³æ³¨è‡ªç„¶è¯­è¨€å¤„ç†çš„ç«¥é‹ï¼Œä¸ç®¡æ˜¯å…³æ³¨ä»€ä¹ˆä»»åŠ¡ï¼Œéƒ½åº”è¯¥ç²¾è¯»ä¸€ä¸‹æœ¬æ–‡ã€‚</p>
<h2 id="CoType-Joint-Extraction-of-Typed-Entities-and-Relations-with-Knowledge-Bases"><a href="#CoType-Joint-Extraction-of-Typed-Entities-and-Relations-with-Knowledge-Bases" class="headerlink" title="CoType: Joint Extraction of Typed Entities and Relations with Knowledge Bases"></a><a href="https://arxiv.org/pdf/1610.08763v1.pdf" target="_blank" rel="external">CoType: Joint Extraction of Typed Entities and Relations with Knowledge Bases</a></h2><p>ã€ä¿¡æ¯æŠ½å–ã€‘æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºDistant Supervisionå¯¹æ–‡æœ¬ä¸­å‘½åå®ä½“å’Œå…³ç³»è”åˆæŠ½å–çš„æ¡†æ¶ï¼Œå…‹æœäº†ä¹‹å‰å°†ä¸¤ä¸ªä»»åŠ¡åˆ†å¼€åšå¸¦æ¥çš„è¯¯å·®å½±å“ï¼Œæ¡†æ¶å…·æœ‰è¾ƒå¼ºçš„æ‰©å±•æ€§å’Œè¿ç§»æ€§ï¼Œå»ºè®®ç²¾è¯»ã€‚</p>
<h1 id="ä¸€å‘¨èµ„æº"><a href="#ä¸€å‘¨èµ„æº" class="headerlink" title="ä¸€å‘¨èµ„æº"></a>ä¸€å‘¨èµ„æº</h1><h2 id="Redditå¤§å‹è¯„è®ºæ•°æ®é›†"><a href="#Redditå¤§å‹è¯„è®ºæ•°æ®é›†" class="headerlink" title="Redditå¤§å‹è¯„è®ºæ•°æ®é›†"></a><a href="https://www.reddit.com/r/datasets/comments/59039y/updated_reddit_comment_dataset_up_to_201608/" target="_blank" rel="external">Redditå¤§å‹è¯„è®ºæ•°æ®é›†</a></h2><p>ã€æ•°æ®é›†ã€‘Redditå¤§å‹è¯„è®ºæ•°æ®é›†ï¼Œç”¨äºæƒ…æ„Ÿåˆ†æç ”ç©¶ã€‚</p>
<h2 id="å¾®è½¯lightGBMæ¡†æ¶çš„pythonæ¥å£"><a href="#å¾®è½¯lightGBMæ¡†æ¶çš„pythonæ¥å£" class="headerlink" title="å¾®è½¯lightGBMæ¡†æ¶çš„pythonæ¥å£"></a><a href="https://github.com/ArdalanM/pyLightGBM" target="_blank" rel="external">å¾®è½¯lightGBMæ¡†æ¶çš„pythonæ¥å£</a></h2><p>ã€å¼€æºæ¡†æ¶ã€‘ArdalanM/pyLightGBM: Python binding for Microsoft LightGBM </p>
<h2 id="ä¸­æ–‡å¯¹ç™½è¯­æ–™ï¼šå¯ç”¨ä½œèŠå¤©æœºå™¨äººè®­ç»ƒè¯­æ–™"><a href="#ä¸­æ–‡å¯¹ç™½è¯­æ–™ï¼šå¯ç”¨ä½œèŠå¤©æœºå™¨äººè®­ç»ƒè¯­æ–™" class="headerlink" title="ä¸­æ–‡å¯¹ç™½è¯­æ–™ï¼šå¯ç”¨ä½œèŠå¤©æœºå™¨äººè®­ç»ƒè¯­æ–™"></a><a href="https://github.com/rustch3n/dgk_lost_conv" target="_blank" rel="external">ä¸­æ–‡å¯¹ç™½è¯­æ–™ï¼šå¯ç”¨ä½œèŠå¤©æœºå™¨äººè®­ç»ƒè¯­æ–™</a></h2><p>ã€æ•°æ®é›†ã€‘chinese conversation corpus by BiNgFeng GitHub</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-10-28T04:54:20.000Z"><a href="/2016/10/27/PaperWeekly-ç¬¬åä¸€æœŸ/">2016-10-27</a></time>
      
      
  
    <h1 class="title"><a href="/2016/10/27/PaperWeekly-ç¬¬åä¸€æœŸ/">PaperWeekly ç¬¬åä¸€æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•è¨€"><a href="#å¼•è¨€" class="headerlink" title="å¼•è¨€"></a>å¼•è¨€</h1><p>Memory Networksæ˜¯ç”±Facebookçš„Jason Westonç­‰äººæå‡ºçš„ä¸€ä¸ªç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥é•¿æœŸè®°å¿†ç»„ä»¶(long-term memory component)æ¥è§£å†³ç¥ç»ç½‘ç»œé•¿ç¨‹è®°å¿†å›°éš¾çš„é—®é¢˜ã€‚åœ¨æ­¤æ¡†æ¶åŸºç¡€ä¸Šï¼Œå‘å±•å‡ºè®¸å¤šMemory Networksçš„å˜ä½“æ¨¡å‹ï¼Œæœ¬æœŸç²¾é€‰äº†5ç¯‡Memory Networksç›¸å…³çš„è®ºæ–‡ï¼Œåˆ†åˆ«å¦‚ä¸‹ï¼š</p>
<p>1ã€Memory Networks<br>2ã€End-To-End Memory Networks<br>3ã€Ask Me Anything: Dynamic Memory Networks for Natural Language Processing<br>4ã€THE GOLDILOCKS PRINCIPLE: READING CHILDRENâ€™S BOOKS WITH EXPLICIT MEMORY REPRESENTATIONS<br>5ã€Key-Value Memory Networks for Directly Reading Documents</p>
<h1 id="Memory-Networks"><a href="#Memory-Networks" class="headerlink" title="Memory Networks"></a><a href="https://arxiv.org/abs/1410.3916" target="_blank" rel="external">Memory Networks</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Jason Weston, Sumit Chopra, Antoine Bordes</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Facebook AI Research</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Question Answering, Memory Network</p>
<h2 id="æ–‡ç« æ¥æº"><a href="#æ–‡ç« æ¥æº" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ICLR 2015</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>ä¸ºè§£å†³é•¿æœŸè®°å¿†é—®é¢˜, æå‡ºä¸€ç±»ç§°ä¸ºMemory Networksçš„æ¨¡å‹æ¡†æ¶, åŸºäºè¯¥æ¡†æ¶æ„é€ çš„æ¨¡å‹å¯ä»¥æ‹¥æœ‰é•¿æœŸ(å¤§é‡)å’Œæ˜“äºè¯»å†™çš„è®°å¿†ã€‚</p>
<h2 id="æ¨¡å‹å’Œæ€è·¯"><a href="#æ¨¡å‹å’Œæ€è·¯" class="headerlink" title="æ¨¡å‹å’Œæ€è·¯"></a>æ¨¡å‹å’Œæ€è·¯</h2><p>Memory Networkså¯ä»¥ç†è§£ä¸ºä¸€ç§æ„é€ æ¨¡å‹çš„æ¡†æ¶, è¯¥ç±»æ¨¡å‹ç”±å¦‚ä¸‹äº”éƒ¨åˆ†ç»„æˆ:</p>
<p>1ã€è®°å¿†m: æ¨¡å‹è®°å¿†çš„è¡¨ç¤º,ç”±ä¸€ä¸ªè®°å¿†æ§½åˆ—è¡¨[m<sub>1</sub>-m<sub>i</sub>]ç»„æˆ,å¯è¢«G,Oç»„ä»¶è¯»å†™<br>2ã€ç»„ä»¶I (input feature map): å°†æ¨¡å‹è¾“å…¥è½¬åŒ–æ¨¡å‹å†…éƒ¨ç‰¹å¾ç©ºé—´ä¸­ç‰¹å¾è¡¨ç¤º<br>3ã€ç»„ä»¶G (generalization): åœ¨æ¨¡å‹è·å–æ–°è¾“å…¥æ—¶æ›´æ–°è®°å¿†mï¼Œå¯ä»¥ç†è§£ä¸ºè®°å¿†å­˜å‚¨<br>4ã€ç»„ä»¶O (output feature map): æ ¹æ®æ¨¡å‹è¾“å…¥å’Œè®°å¿†mè¾“å‡ºå¯¹åº”äºæ¨¡å‹å†…éƒ¨ç‰¹å¾ç©ºé—´ä¸­ç‰¹å¾è¡¨ç¤ºï¼Œå¯ä»¥ç†è§£ä¸ºè¯»å–è®°å¿†<br>5ã€ç»„ä»¶R(response): å°†Oç»„ä»¶è¾“å‡ºçš„å†…éƒ¨ç‰¹å¾ç©ºé—´çš„è¡¨ç¤ºè½¬åŒ–ä¸ºç‰¹å®šæ ¼å¼ï¼Œæ¯”å¦‚æ–‡æœ¬ã€‚å¯ä»¥ç†è§£ä¸ºæŠŠè¯»å–åˆ°æŠ½è±¡çš„è®°å¿†è½¬åŒ–ä¸ºå…·è±¡çš„è¡¨ç¤ºã€‚</p>
<p>å‡è®¾æ¨¡å‹è¾“å…¥ä¸ºx:</p>
<ul>
<li>è®°å¿†çš„æ›´æ–°è¿‡ç¨‹è¡¨ç¤ºä¸º m<sub>H(x)</sub> = G(m<sub>i</sub>, I(X), m), âˆ€i, H(x)ä¸ºé€‰æ‹©è®°å¿†å’Œé—å¿˜æœºåˆ¶</li>
<li>è®°å¿†çš„è¯»å–è¿‡ç¨‹è¡¨ç¤ºä¸º r = R(O(I(x), m))</li>
</ul>
<p>å†æ¬¡å¼ºè°ƒMemory Networksæ˜¯ä¸€ç±»æ¨¡å‹æ¡†æ¶, ç»„ä»¶I,G,R,Oå¯ä»¥ä½¿ç”¨ä¸åŒçš„å®ç°</p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><ul>
<li><a href="https://github.com/facebook/MemNN" target="_blank" rel="external">facebook MemNNå®ç°</a></li>
</ul>
<h2 id="ç›¸å…³å·¥ä½œåŠå¼•ç”¨"><a href="#ç›¸å…³å·¥ä½œåŠå¼•ç”¨" class="headerlink" title="ç›¸å…³å·¥ä½œåŠå¼•ç”¨"></a>ç›¸å…³å·¥ä½œåŠå¼•ç”¨</h2><ul>
<li>Facebook AIçš„è¿›ä¸€æ­¥å·¥ä½œ, åŸºäºMemory Networksæ¡†æ¶å’Œç¥ç»ç½‘ç»œå®ç°äº†End-To-Endçš„è®­ç»ƒå­¦ä¹ <br>Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus. End-To-End Memory Networks. arXiv:1503.08895  </li>
</ul>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æ–‡ç« æå‡ºäº†ä¸€ä¸ªé€šç”¨çš„è§£å†³é•¿æœŸè®°å¿†é—®é¢˜çš„ç®—æ³•æ¡†æ¶, æ¡†æ¶ä¸­çš„æ¯ä¸€ä¸ªæ¨¡å—éƒ½å¯ä»¥å˜æ›´æˆæ–°çš„å®ç°, å¯ä»¥æ ¹æ®ä¸åŒçš„åº”ç”¨åœºæ™¯è¿›è¡Œé€‚é…ã€‚ </p>
<h1 id="End-To-End-Memory-Networks"><a href="#End-To-End-Memory-Networks" class="headerlink" title="End-To-End Memory Networks"></a><a href="https://arxiv.org/pdf/1503.08895v5.pdf" target="_blank" rel="external">End-To-End Memory Networks</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston,  Rob Fergus</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Dept. of Computer Science Courant Institute, New York University<br>Facebook AI Research</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Memory Networks, End-to-end, Question Answer</p>
<h2 id="æ–‡ç« æ¥æº-1"><a href="#æ–‡ç« æ¥æº-1" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>NIPS 2015</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå¯ä»¥ç«¯åˆ°ç«¯è®­ç»ƒçš„Memory Networksï¼Œå¹¶ä¸”åœ¨è®­ç»ƒé˜¶æ®µæ¯”åŸå§‹çš„Memory Networkséœ€è¦æ›´å°‘çš„ç›‘ç£ä¿¡æ¯ã€‚</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æœ¬æ–‡æå‡ºçš„æ¨¡å‹åŒ…æ‹¬å•å±‚å’Œå¤šå±‚ä¸¤ç§æƒ…å†µã€‚ä¸‹é¢å…ˆä»‹ç»å•å±‚æƒ…å†µï¼Œ<br>1ã€å•å±‚<br>å¦‚å›¾(a)æ‰€ç¤ºï¼Œè¾“å…¥çš„åºåˆ—å¯ä»¥é€šè¿‡ä¸åŒçš„EmbeddingçŸ©é˜µAå’ŒCåˆ†åˆ«è¢«è¡¨ç¤ºæˆInputå’ŒOutputå‘é‡çš„é›†åˆã€‚åŒæ ·çš„ï¼Œé€šè¿‡EmbeddingçŸ©é˜µBï¼Œæˆ‘ä»¬å°†Questionè¡¨ç¤ºæˆä¸€ä¸ªå‘é‡uï¼Œå‘é‡uå’ŒInputå‘é‡é›†åˆä¸­çš„æ¯ä¸ªå‘é‡è®¡ç®—å†…ç§¯ï¼Œç„¶åé€šè¿‡softmaxå¾—åˆ°ä¸€ä¸ªæ¦‚ç‡å‘é‡pï¼ˆattentionè¿‡ç¨‹ï¼‰ï¼Œæ¦‚ç‡å‘é‡pä¸­çš„æ¯ä¸€ä¸ªæ¦‚ç‡å€¼è¡¨ç¤ºæ¯ä¸ªOutputå‘é‡å¯¹åº”è¾“å‡ºçš„æƒé‡å¤§å°ã€‚é€šè¿‡på’ŒOutputå‘é‡é›†åˆï¼Œå¯¹Outputä¸­çš„å‘é‡è¿›è¡ŒåŠ æƒæ±‚å’Œå¾—åˆ°è¾“å‡ºå‘é‡oï¼Œå°†è¾“å‡ºå‘é‡oå’Œé—®é¢˜å‘é‡uç›¸åŠ ï¼Œå†æœ€åé€šè¿‡ä¸€ä¸ªæƒå€¼çŸ©é˜µWå’Œsoftmaxæ¥é¢„æµ‹æœ€ç»ˆçš„labelã€‚</p>
<p><img src="media/end_to_end.png" alt="end_to_end"></p>
<p>2ã€ å¤šå±‚<br>å¤šå±‚çš„æƒ…å†µå¦‚å›¾(b)æ‰€ç¤ºï¼Œæ¯å±‚çš„è¾“å‡ºå‘é‡o<sup>i</sup>å’Œé—®é¢˜å‘é‡u<sup>i</sup>ç›¸åŠ è·å¾—æ–°çš„é—®é¢˜è¡¨ç¤ºu<sup>i+1</sup>ï¼Œç„¶åé‡å¤ä¸Šè¿°å•å±‚çš„è¿‡ç¨‹,ç›´åˆ°æœ€åä¸€å±‚é€šè¿‡softmaxæ¥é¢„æµ‹labelã€‚</p>
<p>æœ¬æ–‡åœ¨bAbiæ•°æ®é›†ã€Penn Treebankä»¥åŠText8ä¸‰ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒï¼Œå‡å–å¾—äº†è¾ƒå¥½çš„å®éªŒæ•ˆæœã€‚</p>
<h2 id="èµ„æº-1"><a href="#èµ„æº-1" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><ul>
<li>[bAbi]<br>(<a href="https://research.facebook.com/research/babi/" target="_blank" rel="external">https://research.facebook.com/research/babi/</a>)</li>
</ul>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>Memory Networks<br>Neural Turing Machines</p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬ç¯‡è®ºæ–‡æå‡ºçš„æ¨¡å‹æ˜¯åœ¨Facebookæå‡ºçš„åŸå§‹Memory networksåŸºç¡€ä¸Šè¿›è¡Œçš„æ”¹è¿›ã€‚åœ¨Memory networksçš„æ¡†æ¶ä¸‹ï¼Œå°†åŸæ¥ä¾èµ–äºä¸­é—´ç›‘ç£ä¿¡æ¯çš„éç«¯åˆ°ç«¯Memory networksæ”¹è¿›ä¸ºç«¯åˆ°ç«¯çš„Memory networksã€‚åŸºç¡€æ¨¡å‹ä¹‹å¤–ï¼Œæœ¬æ–‡é’ˆå¯¹æ—¶åºç¼–ç æå‡ºäº†ä¸€äº›æœ‰è¶£çš„trickï¼Œå¯ä½œå‚è€ƒã€‚</p>
<h1 id="Ask-Me-Anything-Dynamic-Memory-Networks-for-Natural-Language-Processing"><a href="#Ask-Me-Anything-Dynamic-Memory-Networks-for-Natural-Language-Processing" class="headerlink" title="Ask Me Anything: Dynamic Memory Networks for Natural Language Processing"></a><a href="https://arxiv.org/abs/1506.07285" target="_blank" rel="external">Ask Me Anything: Dynamic Memory Networks for Natural Language Processing</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury, Ishaan Gulrajani, Victor Zhong, Romain Paulus, Richard Socher</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>MetaMind</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Memory Networks, Neural Networks, Question Answering</p>
<h2 id="æ¥æº"><a href="#æ¥æº" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>arXiv</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>Question Answering: ç»™å®šä¸€æ®µContextï¼Œä¸€ä¸ªä¸æ­¤Contextç›¸å…³çš„Questionï¼Œåˆ©ç”¨æ¨¡å‹ç”Ÿæˆä¸€ä¸ªå•è¯çš„Answerã€‚</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>ä¸‹å›¾ç»™å‡ºäº†dynamic memory networksçš„æ¡†æ¶ã€‚</p>
<p><img src="media/model-image.png" alt="model-image"></p>
<p>é¦–å…ˆContextå’ŒQuestionéƒ½ç»è¿‡Gated Recurrent Unit(GRU)è½¬æ¢æˆæˆvectorå½¢å¼ï¼Œåˆ†åˆ«ä½œä¸ºepisodic memories eå’Œmå‚¨å­˜ä¸‹æ¥ã€‚eä»£è¡¨çš„æ˜¯ä¸€è¿ä¸²vectorsï¼ŒContextä¸­æ¯å¥è¯éƒ½ä¼šè¢«è½¬æ¢æˆä¸€ä¸ªe vectorï¼Œç„¶è€ŒQuestionåªä¼šè¢«è½¬æ¢æˆä¸€ä¸ªm vectorã€‚</p>
<p>ä¸‹ä¸€æ­¥æ˜¯episodic memory updatesï¼Œåœ¨æ¯ä¸€ä¸ªepisode, æ¯ä¸€ä¸ªe vectorä¼šå’Œmè®¡ç®—ä¸€ä¸ªattentionï¼Œæœ¬æ–‡ä¸­ä½¿ç”¨ä¸€ä¸ªtwo layer feed forward neural networkè®¡ç®—attention scoreã€‚ç„¶ååˆ©ç”¨attention scoresæ¥update episodic memoriesã€‚</p>
<p><img src="media/gate.png" alt="gate"></p>
<p><img src="media/episodic-memory.png" alt="episodic-memory"></p>
<p>è¾“å‡ºç­”æ¡ˆä¹Ÿé‡‡ç”¨äº†ä¸€ä¸ªGRU decoder</p>
<p><img src="media/output.png" alt="output"></p>
<p>è¿™é‡Œçš„a0æ˜¯æœ€åä¸€ä¸ªmemory state mã€‚</p>
<h2 id="èµ„æº-2"><a href="#èµ„æº-2" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p><a href="https://research.facebook.com/research/babi/" target="_blank" rel="external">Facebook bAbI dataset</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-1"><a href="#ç›¸å…³å·¥ä½œ-1" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p><a href="https://arxiv.org/abs/1410.3916" target="_blank" rel="external">Memory Networks</a><br><a href="https://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf" target="_blank" rel="external">Eng-to-End Memory Networks</a><br><a href="https://arxiv.org/abs/1511.02301" target="_blank" rel="external">The Goldilocks Principle: Reading Childrenâ€™s Books with Explicit Memory Representations</a></p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æ€»ä½“æ¥è¯´è¿™æ˜¯ä¸€ç¯‡å¾ˆæœ‰è¶£çš„æ–‡ç« ã€‚å…¶ä¸­åº”ç”¨äº†episodically update memoryçš„æƒ³æ³•ï¼ŒæœŸæœ›æ¨¡å‹èƒ½å¤Ÿå€Ÿæ­¤å­¦åˆ°ä¸€äº›logical reasoningçš„èƒ½åŠ›ã€‚å¹¶ä¸”æ¨¡å‹ä¸­å¤šæ¬¡ç”¨çš„GRUï¼Œæ¯ä¸€å±‚éƒ½ä½¿ç”¨GRUçš„encodingæˆ–è€…decodingï¼Œæ¯”è¾ƒæœ‰è¶£ã€‚</p>
<p>ç„¶åæˆ‘è®¤ä¸ºæœ¬æ–‡çš„å†™ä½œæœ‰ä¸€äº›é—®é¢˜ï¼Œæ¯”å¦‚æˆ‘è‡ªå§‹è‡³ç»ˆä¹Ÿæ²¡æœ‰æ‰¾åˆ°eçš„ä¸‹æ ‡ç©¶ç«Ÿä»£è¡¨ä»€ä¹ˆï¼Œæˆ‘çš„ç†è§£æ˜¯æ¯ä¸€å¥è¯éƒ½è¢«encodeæˆä¸€ä¸ªeä½œä¸ºepisodic memoryï¼Œé‚£ä¹ˆæ¯æ¬¡Update å…¶ä¸­ä¸€ä¸ªeéƒ½è¦ç»è¿‡æ‰€æœ‰å…¶ä»–çš„eæ˜¯ä¸ºäº†æ›´å¥½çš„èåˆæ‰€æœ‰context sentencesçš„ä¿¡æ¯å—ï¼Ÿlooks reasonable to me. </p>
<p>é‚£ä¹ˆæ¯ä¸€å±‚çš„hidden states hç©¶ç«Ÿåˆæ˜¯ä»€ä¹ˆï¼Ÿä¸Šä¸€å±‚çš„hidden stateå¦‚ä½•æ›´æ–°åˆ°ä¸‹ä¸€å±‚ï¼Ÿæ–‡ç« ä¸­ä¼¼ä¹æ²¡æœ‰ç»™å‡ºæ˜ç¡®çš„å…¬å¼ï¼Œä¹Ÿæ²¡æœ‰åœ¨model figureä¸­å±•ç¤ºå‡ºæ¥ï¼Œä¼¼ä¹å†™ä½œä¸å¤Ÿæ˜ç¡®ã€‚æ—¢ç„¶eæ˜¯æœ‰hç©¿è¿‡å±‚å±‚GRUå¾—åˆ°ï¼Œæˆ‘ä¼šæ£æµ‹ä¸‹ä¸€å±‚çš„hæ˜¯ä¸Šä¸€å±‚eçš„ä¸€ä¸ªfunctionã€‚æ€»ä¹‹æ„Ÿè§‰modelè¿™ä¸€å—çš„è§£é‡Šä¸å¤Ÿæ¸…æ™°åˆ°ä½ï¼Œå˜é‡å¤ªå¤šæœ‰äº›æ··ä¹±ã€‚</p>
<p>ç„¶è€Œæ€»ä½“æ¥è¯´ï¼Œæˆ‘è§‰å¾—æœ¬æ–‡è¿˜æ˜¯éå¸¸å€¼å¾—ä¸€è¯»çš„ã€‚</p>
<h1 id="THE-GOLDILOCKS-PRINCIPLE-READING-CHILDRENâ€™S-BOOKS-WITH-EXPLICIT-MEMORY-REPRESENTATIONS"><a href="#THE-GOLDILOCKS-PRINCIPLE-READING-CHILDRENâ€™S-BOOKS-WITH-EXPLICIT-MEMORY-REPRESENTATIONS" class="headerlink" title="THE GOLDILOCKS PRINCIPLE: READING CHILDRENâ€™S BOOKS WITH EXPLICIT MEMORY REPRESENTATIONS"></a><a href="https://arxiv.org/pdf/1511.02301v4.pdf" target="_blank" rel="external">THE GOLDILOCKS PRINCIPLE: READING CHILDRENâ€™S BOOKS WITH EXPLICIT MEMORY REPRESENTATIONS</a></h1><h2 id="ä½œè€…-3"><a href="#ä½œè€…-3" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Felix Hill, Antoine Bordes, Sumit Chopra &amp; JasonWeston</p>
<h2 id="å•ä½-3"><a href="#å•ä½-3" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Facebook AI Research</p>
<h2 id="å…³é”®è¯-3"><a href="#å…³é”®è¯-3" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Memory Networks,self-supervised training,window-based memories,The Childrenâ€™s Book Test(CBT)</p>
<h2 id="æ–‡ç« æ¥æº-2"><a href="#æ–‡ç« æ¥æº-2" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ICLR2016</p>
<h2 id="é—®é¢˜-3"><a href="#é—®é¢˜-3" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æœ¬æ–‡å¯¹äºè¯­è¨€æ¨¡å‹ï¼ˆRNN/LSTM/Memory Networkç”Ÿæˆï¼‰åˆ°åº•èƒ½å¤Ÿå¤šå¥½æˆ–è€…åœ¨å¤šå¤§ç¨‹åº¦ä¸Šè¡¨ç¤ºThe Childrenâ€™s Bookåšäº†ä¸€é¡¹æµ‹è¯•ã€‚æµ‹è¯•ç»“æœè¡¨é¢Memorã€€Networkä¸Šçš„æ•ˆæœæœ€å¥½ã€‚</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æ–‡ä¸­ä¸»è¦å¯¹æ¯”äº†ä¸€ç³»åˆ—state-of-the-artçš„æ¨¡å‹ï¼Œæ¯ä¸ªç”¨ä¸åŒçš„æ–¹å¼å¯¹ä¹‹å‰å·²ç»è¯»è¿‡çš„æ–‡æœ¬è¿›è¡Œç¼–ç ï¼Œç„¶åè¿›è¡ŒCBTè¯„æ¯”ã€‚<br>å®éªŒä¸­ä½¿ç”¨çš„æ¨¡å‹ä»¥åŠç»“æœå¦‚ä¸‹ï¼š</p>
<p><img src="media/CBT.png" alt="CBT"></p>
<p>CBTç®€ä»‹ï¼šæ•°æ®æ¥è‡ªProject Gutenburgæ‰€åˆ›å»ºçš„æ•°æ®é›†ï¼Œé‡Œé¢çš„å†…å®¹éƒ½é€‰è‡ªå„¿ç«¥ä¹¦ç±ã€‚æ¯20å¥è¯äº§ç”Ÿä¸€ä¸ªé—®é¢˜ï¼Œè®©ä¸åŒçš„è¯­è¨€æ¨¡å‹å»è¿›è¡Œé¢„æµ‹ï¼Œçœ‹è°é¢„æµ‹çš„æ•ˆæœæ›´å¥½ã€‚<br>é—®é¢˜äº§ç”Ÿäº20å¥è¯ä¸­çš„æŸä¸€å¥è¯æŠ æ‰ä¸€ä¸ªè¯Aã€‚å€™é€‰é›†äº§ç”Ÿåˆ†ä¸ºå¦‚ä¸‹ä¸¤æ­¥:<br>(1)ä»æ„æˆ20å¥è¯çš„è¯è¡¨ä¸­éšæœºé€‰å‡ºå’ŒæŠ æ‰è¯Aå…·æœ‰ç›¸åŒè¯æ€§çš„è¯é›†åˆC ã€‚<br>(2)ä»Cä¸­éšæœºæŠ½é€‰10ä¸ªè¯ä½œä¸ºç­”æ¡ˆçš„å¤‡é€‰é›†ã€‚<br>å®éªŒæœ€ååœ¨CNN QAçš„è¯­æ–™ä¸Šè¿›è¡Œæµ‹è¯•ï¼Œåœ¨æ–°é—»æ–‡ç« ä¸­è¯†åˆ«å‘½åå®ä½“ï¼Œå¾—åˆ°çš„å‡†ç¡®ç‡èƒ½åˆ°<br>69.4%</p>
<h2 id="èµ„æº-3"><a href="#èµ„æº-3" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>n-gram language model:the KenLM toolkit (Scalable modified Kneser-Ney language<br>model estimation.)</p>
<h2 id="ç›¸å…³å·¥ä½œ-2"><a href="#ç›¸å…³å·¥ä½œ-2" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>(1) MN:arXiv2015,Bordes,Large-scale simple question answering with memory networks.æ–‡ä¸­å…³äºend to endçš„è®­ç»ƒæ–¹æ³•ä»¥åŠmemory networkçš„æ¨¡å‹ä¸»è¦æ¥è‡ªæœ¬ç¯‡<br>(2) NIPS2015,Sukhbaatar,End-to-end memory networks.<br>(3)EMNLP2015,Rush,A neural attention model for abstractive sentence summarization. Contextual LSTMæ¨¡å‹çš„å‚è€ƒæ–‡ç« </p>
<h2 id="ç®€è¯„-3"><a href="#ç®€è¯„-3" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡æä¾›äº†ä¸€ç§æµ‹è¯•è¯­è¨€æ¨¡å‹æ•ˆæœçš„æµ‹è¯•æ–¹æ³•ï¼Œè¿™å¯¹äºè¯­è¨€æ¨¡å‹çš„è¯„åˆ¤åšå‡ºäº†è´¡çŒ®ã€‚<br>åœ¨åšå®éªŒè¿‡ç¨‹ä¸­ï¼Œä½œè€…è¿˜å‘ç°åœ¨å•å±‚è®°å¿†è¡¨ç¤ºä¸­æ–‡æœ¬è¢«ç¼–ç çš„æ•°é‡å¯¹ç»“æœæœ‰å¾ˆå¤§çš„å½±å“ï¼šå­˜åœ¨ä¸€ä¸ªèŒƒå›´ï¼Œä½¿å¾—å•ä¸ªè¯ä¿¡æ¯å’Œæ•´ä¸ªå¥å­çš„ä¿¡æ¯éƒ½å¾—ä»¥è¾ƒå¥½çš„ä¿ç•™ã€‚</p>
<h1 id="Key-Value-Memory-Networks-for-Directly-Reading-Documents"><a href="#Key-Value-Memory-Networks-for-Directly-Reading-Documents" class="headerlink" title="Key-Value Memory Networks for Directly Reading Documents"></a><a href="https://arxiv.org/pdf/1606.03126v2.pdf" target="_blank" rel="external">Key-Value Memory Networks for Directly Reading Documents</a></h1><h2 id="ä½œè€…-4"><a href="#ä½œè€…-4" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Alexander H. Miller, Adam Fisch, Jesse Dodge, Amir-Hossein Karimi, Antoine Bordes, Jason Weston</p>
<h2 id="å•ä½-4"><a href="#å•ä½-4" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Facebook AI Research<br>Language Technologies Institute, Carnegie Mellon University</p>
<h2 id="å…³é”®è¯-4"><a href="#å…³é”®è¯-4" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Memory Networks, Key-Value, Question Answering, Knowledge Bases</p>
<h2 id="æ–‡ç« æ¥æº-3"><a href="#æ–‡ç« æ¥æº-3" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv 2016</p>
<h2 id="é—®é¢˜-4"><a href="#é—®é¢˜-4" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>é‰´äºçŸ¥è¯†åº“æœ‰çŸ¥è¯†ç¨€ç–ã€å½¢å¼å—é™ç­‰é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å¯ä»¥é€šè¿‡ç›´æ¥è¯»å–æ–‡æ¡£æ¥è§£å†³QAé—®é¢˜çš„æ–°æ–¹æ³•Key-Value Memory Networksã€‚</p>
<h2 id="æ¨¡å‹-3"><a href="#æ¨¡å‹-3" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒKey-Value Memory Networks(KV-MemNNs)æ¨¡å‹ç»“æ„ä¸End-to-end Memory Networks(MemN2N)åŸºæœ¬ç›¸åŒï¼ŒåŒºåˆ«ä¹‹å¤„åœ¨äºKV-MemNNsçš„å¯»å€ï¼ˆaddressingï¼‰é˜¶æ®µå’Œè¾“å‡ºé˜¶æ®µé‡‡ç”¨ä¸åŒçš„ç¼–ç ï¼ˆkeyå’Œvalueï¼‰ã€‚<br><img src="media/key_value.png" alt="key_value"></p>
<p>æœ¬æ–‡ä¸»è¦æå‡ºäº†ä»¥ä¸‹å‡ ç§Key-valueæ–¹æ³•ï¼š</p>
<ol>
<li>KB Triple<br>é’ˆå¯¹çŸ¥è¯†åº“ä¸­çš„ä¸‰å…ƒç»„(subject, relation, object),å°†subjectå’Œrelationä½œä¸ºKeyï¼Œobjectä½œä¸ºValueã€‚</li>
<li>Sentence Level<br>å°†æ–‡æ¡£åˆ†å‰²æˆå¤šä¸ªå¥å­ï¼Œæ¯ä¸ªå¥å­å³ä½œä¸ºKeyä¹Ÿä½œä¸ºValueï¼Œè¯¥æ–¹æ³•ä¸MemN2Nç›¸åŒã€‚</li>
<li>Window Level<br>ä»¥æ–‡æ¡£ä¸­æ¯ä¸ªå®ä½“è¯ä¸ºä¸­å¿ƒå¼€ä¸€ä¸ªçª—å£ï¼Œå°†æ•´ä¸ªçª—å£ä½œä¸ºKeyï¼Œä¸­é—´çš„å®ä½“è¯ä½œä¸ºValueã€‚</li>
<li>Window + Center Encoding<br>è¯¥æ–¹æ³•ä¸Window LevelåŸºæœ¬ç›¸åŒï¼ŒåŒºåˆ«ä¹‹å¤„åœ¨äºä¸­å¿ƒå®ä½“è¯ä¸çª—å£ä¸­çš„å…¶ä»–è¯é‡‡ç”¨ä¸åŒçš„Embeddingã€‚</li>
<li>Window + Titile<br>å¾ˆå¤šæƒ…å†µä¸‹æ–‡ç« çš„é¢˜ç›®å¯èƒ½åŒ…å«ç­”æ¡ˆï¼Œå› æ­¤åœ¨ä¸Šè¿°æå‡ºçš„Windowæ–¹æ³•åŸºç¡€ä¸Šï¼Œå†æ·»åŠ å¦‚ä¸‹Key-valueå¯¹ï¼šKeyä¸ºçª—å£ï¼ŒValueä¸ºæ–‡æ¡£å¯¹åº”çš„titleã€‚</li>
</ol>
<p>æœ¬æ–‡ä¸ºäº†æ¯”è¾ƒä½¿ç”¨çŸ¥è¯†åº“ã€ä¿¡æ¯æŠ½å–å’Œç›´æ¥é‡‡ç”¨ç»´åŸºç™¾ç§‘æ–‡æ¡£æ–¹æ³•ä¹‹é—´çš„æ•ˆæœï¼Œæ„å»ºäº†æ–°çš„è¯­æ–™WIKIMOVIESã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒKV-MemNNsç›´æ¥ä»æ–‡æ¡£è¯»å–ä¿¡æ¯æ¯”ä¿¡æ¯æŠ½å–æ–¹æ³•çš„æ•ˆæœå¥½ï¼Œå´ä»æ¯”ç›´æ¥åˆ©ç”¨çŸ¥è¯†åº“çš„æ–¹æ³•å·®ä¸å°‘ã€‚å…¶ä¸­å‡ ç§Key-Valueæ–¹æ³•ä¸­ï¼Œâ€œWindow + Center Encodingâ€æ–¹æ³•æ•ˆæœæœ€å¥½ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜åœ¨WikiQAä¸Šè¿›è¡Œå®éªŒï¼ŒéªŒè¯äº†KV-MemNNsçš„æ•ˆæœã€‚</p>
<h2 id="èµ„æº-4"><a href="#èµ„æº-4" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><ul>
<li>[WikiQA]<br>(<a href="https://www.microsoft.com/en-us/download/details.aspx?id=52419" target="_blank" rel="external">https://www.microsoft.com/en-us/download/details.aspx?id=52419</a>)</li>
<li>[WikiMovies]<br>(<a href="https://research.facebook.com/research/babi/" target="_blank" rel="external">https://research.facebook.com/research/babi/</a>)</li>
</ul>
<h2 id="ç›¸å…³å·¥ä½œ-3"><a href="#ç›¸å…³å·¥ä½œ-3" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>Memory Networks<br>End-TO-End Memory Networks<br>The Goldilocks Principle: Reading Childrenâ€™s Books with Explicit Memory Representations</p>
<h2 id="ç®€è¯„-4"><a href="#ç®€è¯„-4" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåœ¨æ–°çš„Memory Networkså˜ä½“Key-Value Memory Networksï¼Œæ—¨åœ¨æ¢ç´¢åœ¨QAè¿‡ç¨‹ä¸­ï¼Œå¦‚ä½•æ¶ˆé™¤é‡‡ç”¨çŸ¥è¯†åº“å’Œè‡ªç”±æ–‡æœ¬ï¼ˆç»´åŸºç™¾ç§‘ï¼‰ä¹‹é—´çš„æ•ˆæœå·®è·ï¼ˆgapï¼‰ï¼Œå¹¶ä¸ºæ­¤æ„å»ºäº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†WikiMoviesã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>é•¿ç¨‹è®°å¿†ï¼ˆlong-term memoryï¼‰é—®é¢˜ä¸€ç›´æ˜¯æ·±åº¦å­¦ä¹ ä¸­çš„ä¸€ä¸ªéš¾ç‚¹ï¼ŒAttentionæœºåˆ¶å°±æ˜¯è§£å†³è¿™ä¸€é—®é¢˜çš„ç»å…¸æ–¹æ³•ã€‚æœ¬æ–‡ä»‹ç»çš„å‡ ç¯‡Memory Networksè¯•å›¾é€šè¿‡æ„å»ºé•¿æœŸå­˜å‚¨è®°å¿†ç»„ä»¶æ¥è§£å†³è¿‡å»ç¥ç»ç½‘ç»œæ— æ³•å­˜å‚¨è¿‡é•¿å†…å®¹çš„é—®é¢˜ã€‚å¦‚ä½•å­˜å‚¨å¤§é‡çš„å¤–éƒ¨ä¿¡æ¯ä»¥åŠå¦‚ä½•åˆ©ç”¨è¿™äº›å¤–éƒ¨ä¿¡æ¯æ¨æ–­æ˜¯Memory Networksä¹ƒè‡³å¾ˆå¤šNLPä»»åŠ¡çš„éš¾ç‚¹ã€‚æœ¬æœŸå¼•å…¥çš„è¿™å‡ ç¯‡è®ºæ–‡ä¸­ï¼ŒMemory Networksæå‡ºäº†ä¸€ä¸ªæ•´ä½“çš„æ¡†æ¶ï¼ŒEnd-To-End Memory Networksä½¿memory networkså¯ä»¥ç«¯åˆ°ç«¯çš„è®­ç»ƒå­¦ä¹ ã€‚Key-Value Memory Networksä¸»è¦è§£å†³å¤–éƒ¨ä¿¡æ¯å¦‚ä½•å­˜å‚¨è¡¨ç¤ºï¼Œè€ŒTHE GOLDILOCKS PRINCIPLEè¿™ç¯‡è®ºæ–‡åˆ™åœ¨æ¨ç†æ–¹é¢æœ‰æ‰€åˆ›æ–°ï¼Œç›´æ¥åˆ©ç”¨attentionçš„æ‰“åˆ†æ¥é¢„æµ‹ç­”æ¡ˆã€‚ç›®å‰æ·±åº¦å­¦ä¹ æ–¹æ³•ä¸­ï¼Œæ— è®ºæ˜¯å­˜å‚¨æ›´æ–°é•¿æœŸè®°å¿†çš„æ–¹æ³•è¿˜æ˜¯ç»“åˆé•¿æœŸè®°å¿†è¿›è¡Œæ¨ç†çš„æ–¹æ³•éƒ½è¿˜å¾ˆåˆçº§ï¼Œä»éœ€è¯¸å›åŠªåŠ›å‰è¡Œã€‚</p>
<p>ä»¥ä¸Šä¸ºæœ¬æœŸPaperweeklyçš„ä¸»è¦å†…å®¹ï¼Œæ„Ÿè°¢cainã€destinwangã€zeweichuã€chunhualiuç­‰å››ä½åŒå­¦çš„æ•´ç†ã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-10-22T20:11:20.000Z"><a href="/2016/10/22/cs-CL-weekly-2016-10-17-2016-10-21/">2016-10-22</a></time>
      
      
  
    <h1 class="title"><a href="/2016/10/22/cs-CL-weekly-2016-10-17-2016-10-21/">cs.CL weekly 2016.10.17-2016.10.21</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="ä¸€å‘¨å€¼å¾—è¯»"><a href="#ä¸€å‘¨å€¼å¾—è¯»" class="headerlink" title="ä¸€å‘¨å€¼å¾—è¯»"></a>ä¸€å‘¨å€¼å¾—è¯»</h1><h2 id="Cached-Long-Short-Term-Memory-Neural-Networks-for-Document-Level-Sentiment-Classification"><a href="#Cached-Long-Short-Term-Memory-Neural-Networks-for-Document-Level-Sentiment-Classification" class="headerlink" title="Cached Long Short-Term Memory Neural Networks for Document-Level Sentiment Classification"></a><a href="https://arxiv.org/pdf/1610.04989v1.pdf" target="_blank" rel="external">Cached Long Short-Term Memory Neural Networks for Document-Level Sentiment Classification</a></h2><p>ã€æƒ…æ„Ÿåˆ†æã€‘RNNå¤„ç†æ–‡æœ¬è¿™æ ·çš„åºåˆ—æ•°æ®æœ‰å¤©ç„¶ä¼˜åŠ¿ï¼Œä½†å¯¹äºé•¿æ–‡æœ¬æ•ˆæœå´ä¸å°½äººæ„ã€‚æœ¬æ–‡é’ˆå¯¹è¿™ä¸ªé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„LSTMç»“æ„Cached LSTMã€‚é€šè¿‡cacheæœºåˆ¶ï¼Œæ¥æ•æ‰æ•´ä½“è¯­ä¹‰ä¿¡æ¯ï¼Œå°†memoryåˆ†æˆå‡ ç»„ï¼Œå¯¹åº”ä¸åŒçš„forgeté—¨ï¼Œåœ¨æ–‡æ¡£é›†æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸­å–å¾—äº†ä¸é”™çš„ç»“æœã€‚å…¶å®ï¼ŒRNNå¤„ç†é•¿æ–‡æœ¬ä¿¡æ¯éƒ½é¢ä¸´è¿™ä¸ªé—®é¢˜ï¼Œchatbotä¸­å¯¹contextä¿¡æ¯çš„å¤„ç†ä¹Ÿå¯ä»¥è€ƒè™‘å€Ÿé‰´è¿™ä¸ªæ€è·¯ã€‚æœ¬æ–‡æ˜¯FudanvNLPçš„å·¥ä½œã€‚</p>
<h2 id="Lexicon-Integrated-CNN-Models-with-Attention-for-Sentiment-Analysis"><a href="#Lexicon-Integrated-CNN-Models-with-Attention-for-Sentiment-Analysis" class="headerlink" title="Lexicon Integrated CNN Models with Attention for Sentiment Analysis"></a><a href="https://arxiv.org/pdf/1610.06272v1.pdf" target="_blank" rel="external">Lexicon Integrated CNN Models with Attention for Sentiment Analysis</a></h2><p>ã€æƒ…æ„Ÿåˆ†æã€‘æœ¬æ–‡ç ”ç©¶çš„å†…å®¹æ˜¯æƒ…æ„Ÿåˆ†æï¼Œè®ºæ–‡çš„äº®ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„CNN+attentionæ¨¡å‹ã€‚æœ¬æ–‡é€‚åˆåœ¨æƒ…æ„Ÿåˆ†ææ¨¡å‹ä¸Šæœ‰æ‰€çªç ´çš„ç«¥é‹æ¥è¯»ï¼Œä»äº‹ç›¸å…³å·¥ä½œçš„å·¥ç¨‹å¸ˆæˆ–æ•°æ®ç§‘å­¦å®¶ä¹Ÿé€‚åˆç²—è¯»ä¸€ä¸‹ã€‚</p>
<h2 id="A-Language-independent-and-Compositional-Model-for-Personality-Trait-Recognition-from-Short-Texts"><a href="#A-Language-independent-and-Compositional-Model-for-Personality-Trait-Recognition-from-Short-Texts" class="headerlink" title="A Language-independent and Compositional Model for Personality Trait Recognition from Short Texts"></a><a href="https://arxiv.org/pdf/1610.04345v1.pdf" target="_blank" rel="external">A Language-independent and Compositional Model for Personality Trait Recognition from Short Texts</a></h2><p>ã€ç”¨æˆ·ç”»åƒã€‘æœ¬æ–‡ç ”ç©¶çš„é—®é¢˜æ˜¯ä»çŸ­æ–‡æœ¬ä¸­å­¦ä¹ ç”¨æˆ·ç”»åƒï¼Œæå‡ºäº†ä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œæ¨¡å‹ä¸Šä»å­¦æœ¯ä¸Šè®²æ²¡æœ‰å¤ªå¤šäº®ç‚¹ï¼Œé€‚åˆå·¥ä¸šç•Œä»äº‹ç›¸å…³å·¥ä½œçš„ç«¥é‹é˜…è¯»ã€‚</p>
<h2 id="Neural-Machine-Translation-Advised-by-Statistical-Machine-Translation"><a href="#Neural-Machine-Translation-Advised-by-Statistical-Machine-Translation" class="headerlink" title="Neural Machine Translation Advised by Statistical Machine Translation"></a><a href="https://arxiv.org/pdf/1610.05150v1.pdf" target="_blank" rel="external">Neural Machine Translation Advised by Statistical Machine Translation</a></h2><p>ã€æœºå™¨ç¿»è¯‘ã€‘NMTç¿»è¯‘æµåˆ©ä½†æœ‰æ—¶ç¿»è¯‘ä¸å‡†ï¼ŒSMTç¿»è¯‘å‡†ç¡®ä½†ä¸å¤Ÿæµåˆ©ï¼Œä¸¤è€…å„æœ‰ä¼˜åŠ£ã€‚æœ¬æ–‡ç»“åˆäº†ä¸¤ç§æ–¹æ³•çš„ä¼˜ç‚¹ï¼Œæå‡ºäº†åœ¨NMTè§£ç é˜¶æ®µï¼Œç”¨SMTæ¥åšè¾…åŠ©ï¼Œé€šè¿‡ä¸€ç§é—¨æœºåˆ¶æ¥é€‰æ‹©ç”¨SMTè¿˜æ˜¯NMTç”Ÿæˆã€‚</p>
<h2 id="Interactive-Attention-for-Neural-Machine-Translation"><a href="#Interactive-Attention-for-Neural-Machine-Translation" class="headerlink" title="Interactive Attention for Neural Machine Translation"></a><a href="https://arxiv.org/pdf/1610.05011v1.pdf" target="_blank" rel="external">Interactive Attention for Neural Machine Translation</a></h2><p>ã€æœºå™¨ç¿»è¯‘ã€‘ã€æ³¨æ„åŠ›æ¨¡å‹ã€‘æ³¨æ„åŠ›æ¨¡å‹è¯æ˜äº†å…¶å¼ºå¤§å¨åŠ›ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ³¨æ„åŠ›æ¨¡å‹ï¼ŒINTERACTIVE ATTENTIONï¼Œåœ¨encoderå’Œdecoderä¹‹é—´é€šè¿‡è¯»å’Œå†™æ“ä½œè¿›è¡Œäº¤äº’ï¼Œå®éªŒä¸­å¯¹æ¯”äº†å…¶ä»–æ³¨æ„åŠ›æ¨¡å‹ï¼Œç»“æœä¸é”™ã€‚</p>
<h2 id="A-General-Framework-for-Content-enhanced-Network-Representation-Learning"><a href="#A-General-Framework-for-Content-enhanced-Network-Representation-Learning" class="headerlink" title="A General Framework for Content-enhanced Network Representation Learning"></a><a href="https://arxiv.org/pdf/1610.02906v3.pdf" target="_blank" rel="external">A General Framework for Content-enhanced Network Representation Learning</a></h2><p>ã€ç¤¾äº¤ç½‘ç»œã€‘æœ¬æ–‡ç ”ç©¶çš„æ˜¯ç¤¾äº¤ç½‘ç»œä¸­å„ä¸ªèŠ‚ç‚¹çš„è¡¨ç¤ºé—®é¢˜ï¼Œäº®ç‚¹åœ¨äºè€ƒè™‘äº†nodeï¼ˆæ¯”å¦‚ï¼šç”¨æˆ·ï¼‰çš„ç›¸å…³æ–‡æœ¬ä¿¡æ¯ï¼Œä»æ–‡æœ¬ä¸­æŒ–æ˜å‡ºnodeçš„ä¸€äº›ç‰¹æ€§ï¼ˆæ¯”å¦‚ï¼šæ€§åˆ«ã€èŒä¸šã€çˆ±å¥½ç­‰ï¼‰ï¼Œå¯¹nodeçš„åˆ»ç”»æ›´ç²¾å‡†ã€‚åˆ©ç”¨å¯Œæ–‡æœ¬ä¿¡æ¯æ¥åˆ»ç”»ç¤¾äº¤ç½‘ç»œä¸­çš„å„ä¸ªnodeï¼Œåœ¨å¹¿å‘Šã€æ¨èç³»ç»Ÿç­‰åº”ç”¨æ–¹é¢éƒ½ä¼šå¸¦æ¥å¾ˆå¤§çš„ä»·å€¼ï¼Œè¿™ä¹Ÿæ­£æ˜¯nlpçš„ä»·å€¼æ‰€åœ¨ï¼Œä»æ‚ä¹±æ— ç« çš„éç»“æ„æ–‡æœ¬ä¸­æŒ–æ˜å‡ºå¤§é‡çš„æœ‰ç”¨ä¿¡æ¯ï¼Œæœ¬æ–‡é€‚åˆç ”ç©¶ç¤¾äº¤ç½‘ç»œä»·å€¼ã€æ¨èç³»ç»Ÿçš„ç«¥é‹æ·±å…¥é˜…è¯»ã€‚æœ¬æ–‡å·¥ä½œæ¥è‡ªå“ˆå·¥å¤§åˆ˜æŒºè€å¸ˆç»„ã€‚</p>
<h2 id="Reasoning-with-Memory-Augmented-Neural-Networks-for-Language-Comprehension"><a href="#Reasoning-with-Memory-Augmented-Neural-Networks-for-Language-Comprehension" class="headerlink" title="Reasoning with Memory Augmented Neural Networks for Language Comprehension"></a><a href="https://arxiv.org/pdf/1610.06454v1.pdf" target="_blank" rel="external">Reasoning with Memory Augmented Neural Networks for Language Comprehension</a></h2><p>ã€æœºå™¨é˜…è¯»ã€‘æœ¬æ–‡æå‡ºäº†ä¸€ç§åšå‡è®¾æ£€éªŒçš„ç¥ç»ç½‘ç»œæ–¹æ³•ï¼ˆNeural Semantic Encodersï¼‰ï¼Œå¹¶ä¸”åº”ç”¨åœ¨æœºå™¨é˜…è¯»ä»»åŠ¡ä¸Šï¼Œå–å¾—äº†ä¸é”™çš„æ•ˆæœï¼Œæ¶‰åŠçš„æ•°æ®é›†æ˜¯CBTå’ŒWDWã€‚</p>
<h1 id="ä¸€å‘¨èµ„æº"><a href="#ä¸€å‘¨èµ„æº" class="headerlink" title="ä¸€å‘¨èµ„æº"></a>ä¸€å‘¨èµ„æº</h1><h2 id="STCçŸ­æ–‡æœ¬å¯¹è¯æ•°æ®"><a href="#STCçŸ­æ–‡æœ¬å¯¹è¯æ•°æ®" class="headerlink" title="STCçŸ­æ–‡æœ¬å¯¹è¯æ•°æ®"></a><a href="http://ntcirstc.noahlab.com.hk/STC2/stc-cn.htm" target="_blank" rel="external">STCçŸ­æ–‡æœ¬å¯¹è¯æ•°æ®</a></h2><p>ã€ä¸­æ–‡å¯¹è¯æ•°æ®ã€‘å¯¹è¯å¾ˆçƒ­ï¼Œä½†ä¾ç„¶å¾ˆéš¾ï¼åä¸ºè¯ºäºšæ–¹èˆŸå®éªŒå®¤åœ¨NTCIR-13ç»„ç»‡çš„å…³äºçŸ­æ–‡æœ¬å¯¹è¯(Short-Text Conversation)çš„æ¯”èµ›å·²ç»å¼€å§‹æ³¨å†Œäº†ï¼Œè®©æˆ‘ä»¬ä¸€èµ·ä»å¤§æ•°æ®ä¸­æ¢æ±‚äººç±»å¯¹è¯çš„æœ¬è´¨ï¼æ¯”èµ›æœ‰ä¸¤ä¸ªä»»åŠ¡ï¼Œä¸€ä¸ªæ˜¯åŸºäºæ£€ç´¢ç»™å‡ºresponseï¼Œä¸€ä¸ªæ˜¯ç›´æ¥ç”Ÿæˆresponseã€‚æ•°æ®æ¥è‡ªå¾®åšï¼Œè¾“å…¥æ˜¯å¾®åšå†…å®¹ï¼Œè¾“å‡ºæ˜¯è¯„è®ºå†…å®¹ã€‚13å¹´åä¸ºçš„æ–‡ç« æåˆ°çš„çŸ­æ–‡æœ¬å¯¹è¯æ•°æ®é›†å¯èƒ½å°±æ˜¯æŒ‡è¯¥æ•°æ®é›†ï¼Œä¸€ç›´æ„å¯¹è¯æ•°æ®çš„å„ä½å¯ä»¥çœ‹è¿‡æ¥ï¼Œä½ ä»¬ç­‰çš„æ•°æ®æ¥äº†ï¼</p>
<h2 id="DataHub"><a href="#DataHub" class="headerlink" title="DataHub"></a><a href="https://datahub.io/dataset" target="_blank" rel="external">DataHub</a></h2><p>ä¸€ä¸ªæ”¶é›†å„ç§æ•°æ®é›†çš„ç½‘ç«™ã€‚</p>
<h2 id="t-SNEå¯è§†åŒ–å·¥å…·çš„pythonå’Œtorchå°è£…"><a href="#t-SNEå¯è§†åŒ–å·¥å…·çš„pythonå’Œtorchå°è£…" class="headerlink" title="t-SNEå¯è§†åŒ–å·¥å…·çš„pythonå’Œtorchå°è£…"></a><a href="https://github.com/DmitryUlyanov/Multicore-TSNE" target="_blank" rel="external">t-SNEå¯è§†åŒ–å·¥å…·çš„pythonå’Œtorchå°è£…</a></h2><p>DmitryUlyanov/Multicore-TSNE: Parallel t-SNE implementation with Python and Torch wrappers</p>
<h2 id="Jiwei-Liå…³äºèŠå¤©æœºå™¨äººNLGé—®é¢˜çš„slide"><a href="#Jiwei-Liå…³äºèŠå¤©æœºå™¨äººNLGé—®é¢˜çš„slide" class="headerlink" title="Jiwei Liå…³äºèŠå¤©æœºå™¨äººNLGé—®é¢˜çš„slide"></a><a href="http://web.stanford.edu/class/cs224u/materials/cs224u-2016-li-chatbots.pdf" target="_blank" rel="external">Jiwei Liå…³äºèŠå¤©æœºå™¨äººNLGé—®é¢˜çš„slide</a></h2><p>åˆ†äº«ä¸€ä¸ªæ–¯å¦ç¦å¤§å­¦Jiwei Liå…³äºèŠå¤©æœºå™¨äººNLGé—®é¢˜çš„slideï¼ŒJiwei Liæ˜¯ä¸€ä¸ªéå¸¸é«˜äº§çš„ä½œè€…ï¼Œè¿™ä¸ªslideåŒ…æ‹¬äº†éå¸¸å¤šç²¾å½©çš„å†…å®¹ã€‚ </p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-10-22T00:42:53.000Z"><a href="/2016/10/21/PaperWeeklyåæœŸæ€»ç»“/">2016-10-21</a></time>
      
      
  
    <h1 class="title"><a href="/2016/10/21/PaperWeeklyåæœŸæ€»ç»“/">PaperWeeklyåæœŸæ€»ç»“</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•"><a href="#å¼•" class="headerlink" title="å¼•"></a>å¼•</h1><p>é¦–å…ˆï¼Œæ„Ÿè°¢å¤§å®¶å…³æ³¨PaperWeeklyå’Œé˜…è¯»æœ¬æ–‡ï¼Œæœ¬æ–‡çš„é˜…è¯»å¤§æ¦‚èŠ±è´¹æ‚¨10åˆ†é’Ÿæ—¶é—´ï¼Œæ¥çœ‹ä¸€ä¸‹PaperWeeklyè¿™åæœŸï¼ˆä¸¤ä¸ªå¤šæœˆï¼‰å†…å®¹èµ°è¿‡æ¥æ‰€ç»å†çš„ä¸€äº›ã€‚</p>
<h1 id="ä¸€å¼€å§‹"><a href="#ä¸€å¼€å§‹" class="headerlink" title="ä¸€å¼€å§‹"></a>ä¸€å¼€å§‹</h1><p>PaperWeeklyçš„ç¬¬ä¸€æ­¥æ˜¯ä»ä¸€ç¯‡å¯¹Andrew Ngçš„é‡‡è®¿å¼€å§‹çš„ï¼Œå¤§æ¦‚çš„æ„æ€æ˜¯ç»å¸¸è¯»è®ºæ–‡æ˜¯ä¸€ç§éå¸¸å¥½çš„é•¿æœŸæŠ•èµ„ï¼Œå›æŠ¥ç‡ä¹Ÿä¼šéå¸¸é«˜ã€‚è™½ç„¶ä¹‹å‰ä¹Ÿåœ¨åšå®¢ä¸Šå†™è¿‡ä¸€ç³»åˆ—ã€Šæ–‡æœ¬æ–‡æ‘˜ã€‹çš„æ–‡ç« ï¼Œå¹¶æœ‰å¹¸å¾—åˆ°çˆ±å¯å¯è€å¸ˆçš„è½¬å‘ï¼Œä½†å¹¶æ²¡æœ‰ç³»ç»Ÿåœ°å°†è‡ªå·±æ‰€è¯»çš„paperè¿›è¡Œæ•´ç†ï¼Œå¹¶å†™æˆæ¸…æ™°ã€ç®€çŸ­çš„æ–‡ç« åˆ†äº«å‡ºæ¥ã€‚</p>
<p>PaperWeeklyæœ€å¼€å§‹çš„æ–‡ç« éƒ½æ˜¯å•ç¯‡çš„æ–‡ç« ï¼Œæºè‡ªä¹‹å‰æ‰€è¯»çš„æ–‡æœ¬æ‘˜è¦çš„åšå®¢ï¼Œå½“æ—¶å–weeklyè¿™ä¸ªåå­—æ˜¯å› ä¸ºæƒ³ç»™è‡ªå·±ç•™ä¸‹ä¸€ä¸ªå·æ‡’çš„å€Ÿå£ï¼Œæ¯•ç«Ÿä¸€å‘¨å†™ä¸€ç¯‡å‹åŠ›ä¸ä¼šå¤ªå¤šï¼Œå¦‚æœå¿ƒè¡€æ¥æ½®æˆ–è€…é—²æš‡æ—¶é—´å¤šçš„è¯å¯ä»¥å†™å‡ ç¯‡ã€‚</p>
<p>æ…¢æ…¢åœ°å…»æˆäº†åˆ·arxivçš„ä¹ æƒ¯ï¼Œåˆ·çš„æ–¹å‘ä¸»è¦åŒ…æ‹¬ï¼šcs.CLã€cs.AIã€cs.LGå’Œcs.NEè¿™å››ä¸ªï¼Œæœ€å¤šçš„æ˜¯cs.CLã€‚ä¹ æƒ¯æ˜¯ä¸ªå¯æ€•çš„ä¸œè¥¿ï¼Œå…»æˆäº†ä¹‹åæ˜¯å¾ˆéš¾æ”¹ï¼Œæ¯å¤©ä¸åˆ°arxivä¸Šçœ‹çœ‹ï¼Œå°±ä¼šæ„Ÿè§‰ç”Ÿæ´»ç¼ºäº†ç‚¹ä»€ä¹ˆã€‚</p>
<p>é—»é“æœ‰å…ˆåï¼Œæœ¯ä¸šæœ‰ä¸“æ”»ã€‚æˆ‘ä¸ªäººçš„çœ¼ç•Œå’Œæ‰€å…³æ³¨çš„ä¸œè¥¿æ˜¯æœ‰é™çš„ï¼Œç²¾åŠ›ä¹Ÿæ˜¯æœ‰é™çš„ï¼Œæ‰€ä»¥åœ¨æŒ£æ‰äº†ä¸€æ®µæ—¶é—´ä¹‹åï¼Œç»ˆäºå†³å®šæ‰“å¼€å¤§é—¨ï¼Œæ¬¢è¿åŒæ ·å¯¹è‡ªç„¶è¯­è¨€å¤„ç†å’Œåˆ†äº«çŸ¥è¯†æ„Ÿå…´è¶£å’Œæœ‰çƒ­æƒ…çš„åŒå­¦ä¸€èµ·æ¥åšPaperWeeklyï¼Œè®©æ›´å¤šå¯¹å…¶ä»–é¢†åŸŸæ›´åŠ ä¸“ä¸šçš„åŒå­¦åŠ å…¥è¿›æ¥ï¼Œæ¥ä¸°å¯Œå†…å®¹ï¼ŒåŒæ—¶ä¹Ÿä¼šä¿è¯æ›´é«˜çš„è´¨é‡ï¼Œç›®å‰PaperWeeklyæœ‰30åå·¦å³çš„ç«¥é‹ä¸€èµ·æ¥å†™æ–‡ç« ï¼Œæ ¹æ®åº”ç”¨é¢†åŸŸåˆ†äº†å››ä¸ªç»„ï¼Œå°ç»„åªæ˜¯ä¸ºäº†æ–¹ä¾¿ç»„ç»‡ä¸€æœŸä¸€æœŸçš„topicï¼Œè¿™é‡Œæ¬¢è¿æœ‰æ›´å¤šæ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥åŠ å…¥ï¼Œæ¥å¢åŠ æ›´å¤šçš„ç»„ï¼Œæ¥å†™æ›´å¤šä¸åŒå½¢å¼ã€ä¸åŒé¢†åŸŸçš„æ–‡ç« ã€‚</p>
<p>ç®—ä¸Šå¼€å§‹æˆ‘ä¸ªäººå†™çš„ä¸¤æœŸï¼Œåˆ°æ˜¨å¤©å‘å¸ƒçš„æœ€æ–°ä¸€æœŸï¼Œä¸€å…±æ˜¯åæœŸå†…å®¹ã€‚åæœŸï¼Œæ˜¯æˆ‘ç»™è‡ªå·±å®šçš„ä¸€ä¸ªå°ç›®æ ‡ã€‚å½“æˆ‘å†³å®šè®©æ›´å¤šçš„äººå‚ä¸è¿›æ¥æ—¶ï¼Œæˆ‘ç»™è‡ªå·±è®¾å®šäº†ä¸€ä¸ªå°ç›®æ ‡ï¼Œå°±æ˜¯æˆåŠŸè¿è¥åˆ°ç¬¬åæœŸã€‚æƒ³ä¸€ä»¶äº‹æƒ…å¾ˆç®€å•ï¼Œè¯´ä¸€ä»¶äº‹æƒ…ä¹Ÿä¸éš¾ï¼Œéš¾çš„æ˜¯åšå‡ºæ¥ï¼Œå¹¶ä¸”å¯ä»¥åšæŒä¸€ç›´åšä¸‹å»ã€‚ä»ç¬¬ä¸‰æœŸçš„ACLå€¼å¾—è¯»ï¼Œæ–°å›¢é˜Ÿå°è¯•ç‰›åˆ€ï¼Œå†åˆ°åé¢çš„ä¸€ä¸ªå°ç»„ä¸€æœŸå†…å®¹ï¼Œæ¯ä¸€æœŸå†…å®¹éƒ½å›´ç»•ä¸€ä¸ªtopicå±•å¼€ï¼Œä»æœ€å¼€å§‹çš„ç¼ºä¹å„ç§è§„èŒƒï¼Œåˆ°ç°åœ¨æœ‰äº†ä¸€ä¸ªç¨³å®šçš„ã€ä½†ä¸æ˜¯é‚£ä¹ˆå¥å…¨çš„åˆ¶åº¦æ¥ç¡®ä¿è¿è¥å’Œæ²Ÿé€šçš„é«˜æ•ˆï¼Œæˆ‘æ„Ÿè§‰çš„åˆ°PWæ¯å¤©éƒ½åœ¨æˆé•¿ï¼Œæ¯å¤©éƒ½åœ¨æœç€ä¸€ä¸ªæ›´å¥½çš„æ–¹å‘èµ°ç€ï¼Œè™½ç„¶ä»å­˜åœ¨åœ¨å„ç§å„æ ·çš„ä¸è¶³ï¼Œä½†å®ƒåœ¨è¿›æ­¥ï¼Œå¹¶ä¸”åœ¨ä¸æ–­åŠªåŠ›å˜å¾—æ›´å¥½ã€‚</p>
<h1 id="å…¬ä¼—å·-å¾®ä¿¡ç¾¤"><a href="#å…¬ä¼—å·-å¾®ä¿¡ç¾¤" class="headerlink" title="å…¬ä¼—å·+å¾®ä¿¡ç¾¤"></a>å…¬ä¼—å·+å¾®ä¿¡ç¾¤</h1><p>å…¬ä¼—å·+å¾®ä¿¡ç¾¤çš„æ¨¡å¼å¸¦æ¥äº†å¾ˆå¤šçš„æ–¹ä¾¿ï¼Œæœ€åˆçš„æƒ³æ³•æ˜¯è®©å¯¹PWæ„Ÿå…´è¶£çš„ç«¥é‹èšåœ¨ä¸€èµ·ï¼Œå¯ä»¥å¯¹æŸäº›æ„Ÿå…´è¶£çš„topicè¿›è¡Œè®¨è®ºã€‚å¾®ä¿¡ç¾¤æœ‰ä¸ªå¤©ç„¶çš„ä¼˜åŠ¿åœ¨äºç”¨æˆ·ç²˜æ€§é«˜ï¼Œä¸ç®¡ä»€ä¹ˆæ ·çš„é—®é¢˜ï¼Œå¤§å®¶éƒ½å–œæ¬¢ä¸¢åœ¨ç¾¤é‡Œè®¨è®ºï¼Œä½†ä¹Ÿæœ‰å¤©ç„¶çš„åŠ£åŠ¿ï¼Œè®¨è®ºè¿‡ç¨‹å®¹æ˜“æ··ä¹±ï¼Œå°è¯•è¿‡ç”¨slackæ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œslackçš„åˆ†ç»„è®¨è®ºåŠŸèƒ½éå¸¸é€‚åˆæˆ‘ä»¬çš„åœºæ™¯ï¼Œä½†å¹¶æ²¡æœ‰åŸ¹å…»å‡ºæ¥è¿™ä¸ªä½¿ç”¨ä¹ æƒ¯ï¼Œå°±æ˜¯å› ä¸ºå¾®ä¿¡çš„ç²˜æ€§å¤ªé«˜äº†ï¼Œå¤§å®¶å°±æ˜¯å–œæ¬¢åœ¨è¿™é‡Œäº¤æµã€‚</p>
<h2 id="Issue-1"><a href="#Issue-1" class="headerlink" title="Issue 1"></a>Issue 1</h2><p>ä¸€ä¸ªç¾¤å¾ˆå¿«å°±åˆ°äº†500äººï¼Œå‡ºç°äº†ä¸€ä¸ªæ£˜æ‰‹çš„é—®é¢˜ï¼Œç¬¬äºŒä¸ªç¾¤çš„äººå¦‚æœå¤ªå°‘ï¼Œå‡ ä¹æ²¡æœ‰è®¨è®ºæ„ä¹‰ï¼Œæ‰€ä»¥å°±æƒ³ç”¨ä»€ä¹ˆåŠæ³•å¯ä»¥æ‰“é€šä¸¤ä¸ªç¾¤ï¼Œè®©ä¸¤ä¸ªç¾¤çš„ç«¥é‹åœ¨åŒä¸€æ—¶ç©ºå†…è¿›è¡Œäº¤æµã€‚æŠ›å‡ºè¿™ä¸ªé—®é¢˜ä¹‹åï¼Œå¤§å®¶ç»™å‡ºäº†å¾ˆå¤šçš„å»ºè®®ï¼Œæœ€åç¾¤é‡Œä¼˜ç§€çš„å·¥ç¨‹å¸ˆ@ç¢±é¦’å¤´ç«¥é‹åšäº†ä¸€ä¸ªæ¶ˆæ¯è½¬å‘æœºå™¨äººï¼Œå¹¶ä¸”ç‰ºç‰²äº†è‡ªå·±çš„å¾®ä¿¡å·ï¼Œæ¯å¤©ç»™å¤§å®¶è½¬å‘æ¥è‡ªä¸¤ä¸ªç¾¤é‡Œçš„æ¯ä¸€æ¡æ¶ˆæ¯ã€‚</p>
<h2 id="Issue-2"><a href="#Issue-2" class="headerlink" title="Issue 2"></a>Issue 2</h2><p>ç¾¤é‡Œå¸¸å¸¸ä¼šæœ‰å¾ˆå¤šç²¾å½©çš„è®¨è®ºå’Œé«˜è´¨é‡çš„é—®ç­”å†…å®¹ï¼Œæ˜¯ä¸€ç¬”ä¸å°çš„èµ„æºè´¢å¯Œï¼Œå¦‚ä½•è®©è¿™äº›èµ„æºä¿å­˜å¹¶ä¸”æ•´ç†ä¸‹æ¥æ˜¯ä¸€ä¸ªå¾ˆæœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚æœ€å¼€å§‹çš„æƒ³æ³•æ˜¯ï¼Œå¯ä¸å¯ä»¥åšä¸€ä¸ªæ–‡æœ¬æ‘˜è¦å·¥å…·ï¼Œæ¯å¤©ä»ç¾¤é‡Œæ‘˜è¦å‡ºæœ‰æ„ä¹‰çš„ä¸œè¥¿ï¼Œå¦‚æœæœ‰QAå¯¹ï¼Œæ•´ç†å‡ºQAå¯¹ã€‚å°†é—®é¢˜æŠ›åˆ°ç¾¤é‡Œä¹‹åï¼Œå¤§å®¶ä¹Ÿæ˜¯å„ç§è®¨è®ºï¼Œä½†æœ€åè¿˜æ˜¯æ‹¿ä¸å‡ºä¸€ä¸ªé è°±çš„æ–¹æ¡ˆæ¥ã€‚æˆ‘ä»¬æ•´å¤©éƒ½åœ¨ç”¨æœºå™¨å­¦ä¹ ï¼Œä¹Ÿéƒ½æƒ³é€šè¿‡äººå·¥æ™ºèƒ½æ¥æ”¹å˜è¿™ä¸ªä¸–ç•Œï¼Œæ¥æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»ï¼Œå¾ˆå¤šæ—¶å€™æ¨¡å‹å’Œå·¥å…·éƒ½æœ‰ï¼Œä½†ç¼ºå°‘æ•°æ®å’Œéœ€æ±‚ï¼Œè¿™æ¬¡æœ‰äº†æ•°æ®å’Œéœ€æ±‚ï¼Œæˆ‘ä»¬å´æ— èƒ½ä¸ºåŠ›äº†ï¼Œæ„Ÿè§‰æœ‰ä¸€ç‚¹ç‚¹å°è®½åˆºã€‚</p>
<p>åæ¥æ¢äº†ä¸ªæ€è·¯ï¼Œå¯ä¸å¯ä»¥é€šè¿‡ä¸€äº›ç‰¹æ®Šæ ‡è®°ï¼Œå°†å¤§å®¶çš„QAå¯¹è½¬å‘åˆ°å¦ä¸€ä¸ªåœ°æ–¹ï¼Œå¹¶ä¸”ç»„ç»‡èµ·æ¥å†…å®¹ã€‚æˆ‘æƒ³åˆ°äº†bbsï¼Œæƒ³æ³•å¾ˆç®€å•ï¼Œå°±æ˜¯å¤§å®¶æŠŠQå’ŒAéƒ½é€šè¿‡ä¸€äº›æ ‡è®°èµ·æ¥ï¼Œé€šè¿‡ä¸€ä¸ªå°botå°†ä¿¡æ¯è½¬å‘åˆ°bbsçš„æ•°æ®åº“ä¸­ï¼Œé€šè¿‡bbsæ¥ä¿å­˜è¿™äº›è®¨è®ºä¿¡æ¯ã€‚åœ¨ç¾¤é‡ŒæŠ›å‡ºè¿™ä¸ªé—®é¢˜åï¼Œæœ‰ç«¥é‹å“åº”ï¼Œå¹¶ä¸”æƒ³åšä¸€äº›å°è¯•ï¼Œä»–å°±æ˜¯ç°åœ¨ç¾¤é‡Œçš„è½¬å‘æœºå™¨äºº@ç§ç“œ ç«¥é‹ï¼Œä¸€ä¸ªéå¸¸å–œæ¬¢é’»ç ”é—®é¢˜çš„ç«¥é‹ï¼Œä»–æ˜¯ä¸€ä¸ªbloggerï¼Œè¿™é‡Œæ˜¯ä»–çš„åšå®¢åœ°å€<a href="http://blog.just4fun.site/" target="_blank" rel="external">http://blog.just4fun.site/</a> ã€‚é€šè¿‡ä»–çš„åŠªåŠ›ï¼Œç¾¤é‡Œæ·»åŠ äº†ä¸€ä¸ªçœ‹èµ·æ¥å¾ˆé…·çš„bbs botï¼Œå¾ˆé…·ï¼Œä½†æœ€ç»ˆä»ç„¶æ²¡æœ‰æ”¹å˜å¤§å®¶çš„ä¹ æƒ¯ï¼Œæ¯•ç«Ÿæé—®çš„ç«¥é‹å¹¶æ²¡æœ‰å¤ªé«˜çš„æœŸå¾…ï¼Œå› ä¸ºè¿™ä¸ªç¾¤æ²¡æœ‰äººå›ç­”ï¼Œä»–è½¬èº«å°±ä¼šå°†é—®é¢˜æ‰”åˆ°å¦ä¸€ä¸ªç¾¤ï¼Œæ€»ä¼šæœ‰äººå›ç­”ä»–çš„ï¼Œæ‰€ä»¥å¼ºè¡Œæ¨å¹¿ä½¿ç”¨bbs botå¾ˆéš¾ï¼Œè€Œä¸”bbs botä¼šè‡ªåŠ¨äº§ç”Ÿä¸€äº›çŠ¶æ€ä¿¡æ¯ï¼Œä¼šæ˜¾å¾—ç¾¤é‡Œæœ‰ä¸€äº›æ‚ä¹±ã€‚æ‰€ä»¥ï¼Œç°åœ¨bbs botæˆäº†ç¾¤é‡Œçš„ä¸€ä¸ªå½©è›‹ï¼Œä¸€ä¸ªå¥½ç©çš„ä¸œè¥¿ï¼Œè™½ç„¶æ²¡æœ‰è¢«å¹¿æ³›åº”ç”¨ï¼Œä½†æˆ‘ä»è§‰å¾—è¿™æ˜¯ä¸€ä»¶å¾ˆé…·çš„äº‹æƒ…ã€‚ï¼ˆç°åœ¨botç«ï¼Œå¾ˆå¤šå¹³å°ä¸Šé©»æ‰äº†å¤§å¤§å°å°çš„botä¸Šä¸‡åªï¼Œä½†æœ‰å‡ åªbotå¯ä»¥äº§ç”Ÿç”¨æˆ·ç²˜æ€§å‘¢ï¼Ÿå¤§å¤šæ•°éƒ½æ˜¯ç°è±¡çº§ï¼Œä»è¿™ä¸ªè§’åº¦æ¥çœ‹ï¼Œæ”¹å˜ä¸€ä¸ªç”¨æˆ·çš„ä¹ æƒ¯æ˜¯å¤šä¹ˆå›°éš¾çš„ä¸€ä»¶äº‹æƒ…ï¼ï¼‰</p>
<p>è¯´åˆ°å½©è›‹ï¼Œç¾¤é‡Œè¿˜æœ‰ä¸€ä¸ªå½©è›‹ï¼Œå°±æ˜¯ä¸€ä¸ªåŸºäºStackOverFlowçš„QA botï¼Œé€šè¿‡ç‰¹å®šçš„è¡¨æƒ…ç¬¦å·æ¥æé—®ï¼Œç³»ç»Ÿä¼šè¿”å›ä¸€ä¸ªç›¸å…³çš„ç­”æ¡ˆï¼Œå®ç°çš„å¤§æ¦‚æ€è·¯æ˜¯ç”¨googleåœ¨stackä¸Šæ‰¾ç­”æ¡ˆï¼Œç„¶åå–æ’åæœ€é«˜çš„ç­”æ¡ˆè¿”å›ç»™ç”¨æˆ·ï¼Œä¸ºäº†è®©ç¾¤é‡Œçš„ç«¥é‹å¯ä»¥ç”¨ä¸­æ–‡æ¥æé—®ï¼Œç‰¹æ„åŠ äº†ä¸€å±‚ç¿»è¯‘åŠŸèƒ½ã€‚</p>
<p>å¥½ç©çš„äº‹æƒ…ä¸€ã€ä¸¤ä¸ªäººåœ¨æ²¡æ„æ€ï¼Œè¦æ˜¯æœ‰æ›´å¤šæ„Ÿå…´è¶£çš„ç«¥é‹å¯ä»¥åŠ å…¥ï¼ŒåŠŸèƒ½å°†ä¼šæ›´åŠ ä¸°å¯Œå’Œå®ç”¨ã€‚ï¼ˆæœ‰æ„Ÿå…´è¶£çš„ç«¥é‹å¯ä»¥ç§ä¿¡æˆ‘ï¼‰</p>
<h1 id="ä¸€äº›æ—¶é—´ç‚¹"><a href="#ä¸€äº›æ—¶é—´ç‚¹" class="headerlink" title="ä¸€äº›æ—¶é—´ç‚¹"></a>ä¸€äº›æ—¶é—´ç‚¹</h1><p>2016.05.08 PWå‘å¸ƒç¬¬ä¸€ç¯‡æ–‡ç« ï¼Œã€ŠGenerating News Headlines with Recurrent Neural Networksã€‹</p>
<p>2016.08.05 PWå‘å¸ƒç¬¬ä¸€æœŸæ–‡ç« ï¼ŒåŒ…æ‹¬ä¸‰ç¯‡æ–‡ç« ï¼šã€ŠDeepIntent: Learning Attentions for Online Advertising with Recurrent Neural Networksã€‹ã€ã€ŠA Neural Knowledge Language Modelã€‹ã€ã€ŠNeural Sentence Orderingã€‹</p>
<p>2016.09.01 PWå‘å¸ƒç»„å»ºå›¢é˜Ÿåçš„ç¬¬ä¸€æœŸæ–‡ç« ï¼ŒåŒ…æ‹¬åç¯‡ACL 2016çš„paper</p>
<p>2016.09.17 PWåœ¨ç¾¤é‡Œæ­£å¼ä¸Šçº¿äº†ä¸€ä¸ªåŒæ­¥æ¶ˆæ¯çš„botï¼Œæ„Ÿè°¢@ç¢±é¦’å¤´ ç«¥é‹</p>
<p>2016.09.29 PWåœ¨ç¾¤é‡Œæ­£å¼ä¸Šçº¿äº†ä¸€ä¸ªbbs botï¼Œæ„Ÿè°¢@ç§ç“œ ç«¥é‹</p>
<p>2016.10.07 PWåœ¨ç¾¤é‡Œæ­£å¼ä¸Šçº¿äº†ä¸€ä¸ªQA botï¼Œæ„Ÿè°¢@ç§ç“œ ç«¥é‹</p>
<h1 id="ä¸€äº›æ•°å­—"><a href="#ä¸€äº›æ•°å­—" class="headerlink" title="ä¸€äº›æ•°å­—"></a>ä¸€äº›æ•°å­—</h1><p>PWåœ¨ä¸Šçº¿è¿è¥çš„è¿™å°åŠå¹´ä»¥æ¥ï¼Œä¸€å…±ï¼š</p>
<p>å‘å¸ƒäº†113ç¯‡æ–‡ç« </p>
<p>å®Œæˆäº†101ç¯‡paperçš„è§£è¯»</p>
<p>æ¨èäº†80ç¯‡é«˜è´¨é‡paper</p>
<p>åˆ†äº«äº†20ä¸ªé«˜è´¨é‡èµ„æº</p>
<p>å¸å¼•äº†30ä½å­¦ç”Ÿå’Œå·¥ç¨‹å¸ˆå‚ä¸å†™æ–‡ç« </p>
<h1 id="æ¥ä¸‹æ¥"><a href="#æ¥ä¸‹æ¥" class="headerlink" title="æ¥ä¸‹æ¥"></a>æ¥ä¸‹æ¥</h1><p>PWæ°¸è¿œéƒ½å¤„åœ¨betaçŠ¶æ€ï¼Œå¯èƒ½å˜åŒ–åœ°å¾ˆæ…¢ï¼Œä½†ä¸€å®šåœ¨åŠªåŠ›æœç€ä¸€ä¸ªæ­£ç¡®çš„æ–¹å‘æ”¹å˜ã€‚äºæ˜¯ï¼ŒPWåœ¨åŸæœ‰åŸºç¡€ä¸Šæœ‰äº†ä¸€äº›æ–°çš„æ€è·¯ï¼š</p>
<p>å®šä½ï¼š<br>1ã€å¯¹äºå­¦æœ¯ç•Œï¼Œæ¨èæœ€æ–°çš„é«˜è´¨é‡paperï¼Œèµ·åˆ°ä¸€ä¸ªå¯¼è¯»ä½œç”¨ï¼›åŒæ—¶ä»¥topicä¸ºç‰µå¼•ï¼Œå½’çº³å’Œæ€»ç»“ç›¸ä¼¼topicçš„paperã€‚<br>2ã€å¯¹äºå·¥ä¸šç•Œï¼Œæ¨èå®ç”¨çš„æˆ–è€…æ–°é¢–çš„paperï¼Œèµ·åˆ°ä¸€ä¸ªä»‹ç»ä½œç”¨ï¼›åŒæ—¶ä¸å®šæœŸçš„çº¦ç¨¿å†™æ–‡ç« ï¼Œç³»ç»Ÿåœ°è®²æŸä¸€ä¸ªé¢†åŸŸã€å‰–ææŸä¸€ä¸ªæ¡†æ¶ã€ç²¾è®²æŸä¸€ç¯‡æ–‡ç« ç­‰ç­‰ç­‰ç­‰ã€‚</p>
<p>æ¨¡å¼ï¼š<br>1ã€å°ç»„ï¼ˆä¸å®šæœŸï¼‰ï¼šåŒä¹‹å‰ä¸€æ ·ï¼Œå‘èµ·ä¸€ä¸ªtopicï¼Œåšå‡ ç¯‡ç›¸å…³çš„æ–‡ç« ï¼Œå½¢å¼å˜åŒ–ä¸å¤§ã€‚<br>2ã€arXivï¼ˆå®šæœŸï¼‰ï¼šå†™ä½œå½¢å¼ä¸ä¹‹å‰ä¸€æ ·ï¼Œæ¯å‘¨ä»arXivä¸Šè¿‡æ»¤å‡ºå‡ ç¯‡é«˜è´¨é‡æ–‡ç« ï¼ˆPaperWeeklyå®˜æ–¹å¾®åšä¸Šæ¯å¤©è¿‡æ»¤å‡ºçš„å¥½paperä½œä¸ºå€™é€‰ï¼‰ï¼Œä»¥å‘¨ä¸ºå•ä½è§£è¯»æœ€æ–°çš„paperç»™å¤§å®¶ã€‚<br>3ã€çº¦ç¨¿ï¼ˆä¸å®šæœŸï¼‰ï¼šå†™ä½œå½¢å¼ä¸é™ï¼Œå¯è¯¦ç»†è§£è¯»ä¸€ç¯‡æ–‡ç« ï¼Œå¯å†™ä¸€ä¸ªæ–¹å‘ï¼ˆæ¯”å¦‚ï¼šæ–‡æœ¬æ‘˜è¦ï¼‰ï¼Œä¹Ÿå¯ä»¥ä¸ä»£ç ã€æ¡†æ¶æœ‰å…³çš„å†…å®¹ï¼Œä¹ŸæœŸå¾…å¤§å®¶çš„æŠ•ç¨¿ã€‚</p>
<h1 id="è‡´è°¢"><a href="#è‡´è°¢" class="headerlink" title="è‡´è°¢"></a>è‡´è°¢</h1><p>åæœŸå†…å®¹ï¼Œç»å†äº†ä¸¤ä¸ªå¤šæœˆçš„æ—¶é—´ï¼Œ60å¤šå¤©æ˜¯ä¸€æ®µæ¼«é•¿çš„æ—¶é—´ï¼Œæ„Ÿè°¢å¤§å®¶çš„ä¸€è·¯ç›¸ä¼´å’Œæ”¯æŒã€‚</p>
<p>æ„Ÿè°¢è¸Šè·ƒåŠ å…¥PWå†™ä½œå›¢é˜Ÿçš„ä½ ä»¬ï¼šmagic282subã€é™ˆå“²ä¹¾ã€destinwangã€yangzhiyeã€davidã€brantyzã€AllenCaiã€annglovesã€cheezer94ã€tonyaã€gcyydxfã€guoxhã€EdwardHuxã€hxw2303632ã€jaylee1992ã€jian.zhou.coolã€lshowwayã€memrayã€mygod9ã€ç¾å¥½æ—¶å…‰æµ·è‹”ã€cainã€ç‹è¿ã€xy504ã€Susie-nmtã€è¤šåˆ™ä¼Ÿã€zhang1028kunã€zhaosanqiangã€zhaoyueã€zhoussneuã€zeng<br>ï¼Œä¹ŸæœŸå¾…æ›´å¤šçš„ç«¥é‹å¯ä»¥åŠ å…¥å†™ä½œå›¢é˜Ÿã€‚</p>
<p>æ„Ÿè°¢åŠ å…¥PWè®¨è®ºç¾¤çš„ç«¥é‹ï¼Œæ„Ÿè°¢ä½ ä»¬è´¡çŒ®äº†å¾ˆå¤šç²¾å½©çš„è®¨è®ºã€‚</p>
<p>æ„Ÿè°¢æœºå™¨ä¹‹å¿ƒçš„æ”¯æŒå’Œå®£ä¼ ï¼Œçœ‹ç€ä½ ä»¬ä¸€è·¯èµ°æ¥ï¼Œé€æ¸åœ°æˆé•¿å’Œå£®å¤§ï¼Œæœ‰ä¸€ç§æ¦œæ ·çš„åŠ›é‡ï¼</p>
<p>æ„Ÿè°¢å¸®å¿™åˆ†äº«å’Œæ¨å¹¿çš„å„ç§å¤§ç‰›ä»¬ï¼Œè°¢è°¢ä½ ä»¬è®©æ›´å¤šçš„äººçŸ¥é“äº†PWã€‚</p>
<p>æ„Ÿè°¢ç•™è¨€ææ„è§çš„ç«¥é‹ä»¬ï¼Œæœ‰æ—¶æ—¶é—´ç´§å¼ ï¼Œä¸èƒ½ä¸€ä¸€å›å¤ï¼Œæœ‰æ—¶ç²¾åŠ›æœ‰é™ï¼Œæ— æ³•æ»¡è¶³æ¯ä¸€ä½çš„éœ€æ±‚ï¼Œä½†è¿˜æ˜¯æ„Ÿè°¢ä½ ä»¬çš„æœŸå¾…å’Œæ”¯æŒï¼</p>
<p>ç¬¬ä¸€ä¸ªåæœŸç»“æŸäº†ï¼Œæˆ‘ä¸çŸ¥é“åé¢ä¼šæœ‰å¤šå°‘ä¸ªåæœŸï¼Œå¸Œæœ›å¯ä»¥ä¸€ç›´åšæŒåšä¸‹å»ã€‚æ”¾å¼ƒå¯ä»¥æ‰¾åˆ°å¾ˆå¤šç§å€Ÿå£ï¼Œä½†åšæŒä¸‹æ¥åªéœ€è¦ä¸€ä¸ªç†ç”±ï¼Œå› ä¸ºçƒ­çˆ±ï¼</p>
<h1 id="PW-Ebook"><a href="#PW-Ebook" class="headerlink" title="PW Ebook"></a>PW Ebook</h1><p>æˆ‘å°†PWçš„åæœŸå†…å®¹æ±‡æ€»æˆä¸€æœ¬ç”µå­ä¹¦ï¼Œå¤§å®¶å¯ä»¥ä»<a href="http://www.kancloud.cn/mcgrady164/paperweekly" target="_blank" rel="external">http://www.kancloud.cn/mcgrady164/paperweekly</a> ä¸‹è½½é˜…è¯»ï¼Œé‡Œé¢çš„æ–‡ç« ä¼šéšç€PWçš„æ›´æ–°ä¸æ–­åœ°æ›´æ–°ã€‚</p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-10-21T06:30:26.000Z"><a href="/2016/10/20/PaperWeekly-ç¬¬åæœŸ/">2016-10-20</a></time>
      
      
  
    <h1 class="title"><a href="/2016/10/20/PaperWeekly-ç¬¬åæœŸ/">PaperWeekly ç¬¬åæœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="å¼•"><a href="#å¼•" class="headerlink" title="å¼•"></a>å¼•</h2><p>æœ¬æœŸPaperWeeklyçš„ä¸»é¢˜æ˜¯åŸºäºç¿»è¯‘æ¨¡å‹(Transç³»åˆ—)çš„çŸ¥è¯†è¡¨ç¤ºå­¦ä¹ ï¼Œä¸»è¦ç”¨æ¥è§£å†³çŸ¥è¯†è¡¨ç¤ºå’Œæ¨ç†çš„é—®é¢˜ã€‚è¡¨ç¤ºå­¦ä¹ æ—¨åœ¨å°†ç ”ç©¶å¯¹è±¡çš„è¯­ä¹‰ä¿¡æ¯è¡¨ç¤ºä¸ºç¨ å¯†ä½ç»´å®å€¼å‘é‡ï¼ŒçŸ¥è¯†è¡¨ç¤ºå­¦ä¹ ä¸»è¦æ˜¯é¢å‘çŸ¥è¯†å›¾è°±ä¸­çš„å®ä½“å’Œå…³ç³»è¿›è¡Œè¡¨ç¤ºå­¦ä¹ ã€‚ä½¿ç”¨å»ºæ¨¡æ–¹æ³•å°†å®ä½“å’Œå‘é‡è¡¨ç¤ºåœ¨ä½ç»´ç¨ å¯†å‘é‡ç©ºé—´ä¸­ï¼Œç„¶åè¿›è¡Œè®¡ç®—å’Œæ¨ç†ã€‚ä¸€èˆ¬è€Œè¨€çš„åº”ç”¨ä»»åŠ¡ä¸ºtriplet classification å’Œlink prediction.è‡ªä»2013å¹´TransEæ¨¡å‹æå‡ºåï¼Œäº§ç”Ÿäº†ä¸€ç³»åˆ—æ¨¡å‹å¯¹TransEæ¨¡å‹è¿›è¡Œæ”¹è¿›å’Œè¡¥å……,æ¯”å¦‚TransHã€TransGç­‰ç­‰ã€‚æœ¬æœŸPaperWeeklyä¸»è¦æä¾›äº†Transç³»åˆ—çš„7ç¯‡æ–‡ç« ä¾›å¤§å®¶èµè¯»ã€‚</p>
<p>paperç›®å½•ï¼š<br>ï¼ˆ1ï¼‰TransEï¼ŒNIPS2013ï¼ŒTranslating embeddings for modeling multi-relational dataã€‚<br>ï¼ˆ2ï¼‰TransHï¼ŒAAAI2014ï¼ŒKnowledge graph embedding by translating on hyperplanesã€‚<br>ï¼ˆ3ï¼‰TransDï¼ŒACL2015ï¼ŒKnowledge graph embedding via dynamic mapping matrixã€‚<br>ï¼ˆ4ï¼‰TransAï¼ŒarXiv2015ï¼ŒAn adaptive approach for knowledge graph embeddingã€‚<br>ï¼ˆ5ï¼‰TransGï¼Œarxiv2015ï¼ŒA Generative Mixture Model for Knowledge Graph Embedding)<br>ï¼ˆ6ï¼‰KG2Eï¼ŒCIKM2015ï¼ŒLearning to represent knowledge graphs with gaussian embeddingã€‚<br>ï¼ˆ7ï¼‰TranSparseï¼ŒAAAI2016ï¼ŒKnowledge graph completion with adaptive sparse transfer matrixã€‚ </p>
<h1 id="TransE-Translating-Embeddings-for-Modeling-Multi-relational-Data"><a href="#TransE-Translating-Embeddings-for-Modeling-Multi-relational-Data" class="headerlink" title="TransE:Translating Embeddings for Modeling Multi-relational Data"></a><a href="http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf" target="_blank" rel="external">TransE:Translating Embeddings for Modeling Multi-relational Data</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>A Bordes, N Usunier, A Garcia-Duran, J Weston, O Yakhnenko</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>CNRS, Google inc.</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Embedding entities and relationships, Multi-relational data, link prediction</p>
<h2 id="æ–‡ç« æ¥æº"><a href="#æ–‡ç« æ¥æº" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>NIPS 2013/12</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•å»ºç«‹ç®€å•ä¸”æ˜“æ‹“å±•çš„æ¨¡å‹æŠŠçŸ¥è¯†åº“ä¸­çš„å®ä½“å’Œå…³ç³»æ˜ å°„åˆ°ä½ç»´å‘é‡ç©ºé—´ä¸­ï¼Œä»è€Œè®¡ç®—å‡ºéšå«çš„å…³ç³»ï¼Ÿ</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>ä¼ ç»Ÿè®­ç»ƒçŸ¥è¯†åº“ä¸­ä¸‰å…ƒç»„(head,relation,tail)å»ºæ¨¡çš„æ–¹æ³•å‚æ•°ç‰¹åˆ«å¤šï¼Œå¯¼è‡´æ¨¡å‹å¤ªå¤æ‚éš¾ä»¥è§£é‡Šï¼Œå¹¶ä¸”éœ€è¦å¾ˆå¤§çš„è®¡ç®—ä»£ä»·ï¼Œå¾ˆå®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆæˆ–æ¬ æ‹Ÿåˆé—®é¢˜ã€‚è€Œç®€å•çš„æ¨¡å‹åœ¨è¡¨ç°ä¸Šä¸å¤æ‚çš„æ¨¡å‹å‡ ä¹ä¸€æ ·ï¼Œä½†æ›´æ˜“æ‹“å±•ã€‚TransEçš„è®­ç»ƒè¿‡ç¨‹å¦‚ä¸‹å›¾ï¼š</p>
<p><img src="media/TransE_1.png" alt=""></p>
<p>TransEæ¨¡å‹çš„è®­ç»ƒä¸­ï¼Œç¬¬12æ­¥æ˜¯æŸå¤±å‡½æ•°ï¼Œå¯¹Eå’ŒLåšuniformåˆå§‹åŒ–ä¹‹åï¼Œè®©æ­£ç¡®çš„h+l-tç»“æœè¶‹è¿‘äº0ï¼Œè®©é”™è¯¯çš„hâ€˜+l-tâ€™çš„ç»“æœå˜å¤§ï¼ŒæŸå¤±å‡½æ•°ç»“æœå¤§äº0å–åŸå€¼ï¼Œå°äº0åˆ™å–0ï¼Œè¿™ç§hinge loss functionå¯ä»¥å°½å¯èƒ½çš„å°†å¯¹å’Œé”™åˆ†å¼€ï¼Œæ¨¡å‹ä½¿ç”¨SGDè®­ç»ƒï¼Œæ¯æ¬¡æ›´æ–°å¯ä»¥åªæ›´æ–°è¿™ä¸ªbatché‡Œçš„ä¸‰å…ƒç»„çš„å‘é‡ï¼Œå› ä¸ºå‚æ•°ä¹‹é—´å¹¶æ²¡æœ‰å†²çªã€‚</p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æ•°æ®é›† WordNet    <a href="http://wordnet.princeton.edu/wordnet/download/" target="_blank" rel="external">http://wordnet.princeton.edu/wordnet/download/</a><br>æ•°æ®é›† Freebase   <a href="http://developers.google.com/freebase/" target="_blank" rel="external">http://developers.google.com/freebase/</a><br>Code: <a href="https://github.com/thunlp/KB2E" target="_blank" rel="external">https://github.com/thunlp/KB2E</a></p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡æå‡ºäº†ä¸€ç§å°†å®ä½“ä¸å…³ç³»åµŒå…¥åˆ°ä½ç»´å‘é‡ç©ºé—´ä¸­çš„ç®€å•æ¨¡å‹ï¼Œå¼¥è¡¥äº†ä¼ ç»Ÿæ–¹æ³•è®­ç»ƒå¤æ‚ã€ä¸æ˜“æ‹“å±•çš„ç¼ºç‚¹ã€‚å°½ç®¡ç°åœ¨è¿˜ä¸æ¸…æ¥šæ˜¯å¦æ‰€æœ‰çš„å…³ç³»ç§ç±»éƒ½å¯ä»¥è¢«æœ¬æ–¹æ³•å»ºæ¨¡ï¼Œä½†ç›®å‰è¿™ç§æ–¹æ³•ç›¸å¯¹äºå…¶ä»–æ–¹æ³•è¡¨ç°ä¸é”™ã€‚TransEæ›´æ˜¯ä½œä¸ºçŸ¥è¯†åº“vectoråŒ–çš„åŸºç¡€ï¼Œè¡ç”Ÿå‡ºæ¥äº†å¾ˆå¤šå˜ä½“ã€‚</p>
<h1 id="TransH-Knowledge-Graph-Embedding-by-Translating-on-Hyperplanes"><a href="#TransH-Knowledge-Graph-Embedding-by-Translating-on-Hyperplanes" class="headerlink" title="TransH:Knowledge Graph Embedding by Translating on Hyperplanes"></a><a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/view/8531" target="_blank" rel="external">TransH:Knowledge Graph Embedding by Translating on Hyperplanes</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Zhen Wang1, Jianwen Zhang2, Jianlin Feng1, Zheng Chen2</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Sun Yat-sen University<br>microsoft</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>knowledge graph embedding, Multi-relational data</p>
<h2 id="æ–‡ç« æ¥æº-1"><a href="#æ–‡ç« æ¥æº-1" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>AAAI 2014</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¯¹çŸ¥è¯†åº“ä¸­çš„å®ä½“å…³ç³»å»ºæ¨¡,ç‰¹åˆ«æ˜¯ä¸€å¯¹å¤š,å¤šå¯¹ä¸€,å¤šå¯¹å¤šçš„å…³ç³»ã€‚è®¾è®¡æ›´å¥½çš„å»ºç«‹è´Ÿç±»çš„åŠæ³•ç”¨äºè®­ç»ƒã€‚ </p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>è¿‡å»æŒ‡ç¤ºå›¾åº“å»ºæ¨¡çš„æ–¹æ³•å‚æ•°è¿‡å¤š, TransEåœ¨ä¸€å®šç¨‹åº¦ä¸Šè§£å†³äº†è¿™ä¸ªé—®é¢˜, ä½†æ˜¯TransEè¿‡äºç®€å•ï¼Œå¾ˆéš¾å¯¹ä¸€å¯¹å¤š,å¤šå¯¹ä¸€å’Œå¤šå¯¹å¤šå…³ç³»å»ºæ¨¡ã€‚æ‰€ä»¥ä¸ºäº†å¹³è¡¡æ¨¡å‹å¤æ‚åº¦å’Œå»ºæ¨¡æ•ˆæœï¼ŒTransHå°†æŠŠå…³ç³»æ˜ å°„åˆ°å¦ä¸€ä¸ªç©ºé—´ï¼ˆå¦‚ä¸‹å›¾ ï¼‰ã€‚ æ³¨æ„: è¿™ç§æƒ³æ³•å’ŒDistant Model (Bordes et al. 2011)å¾ˆç›¸ä¼¼ï¼Œä½†æ˜¯TransHç”¨äº†æ›´å°‘çš„å‚æ•°ï¼Œ å› ä¸ºTransHå‡è®¾å…³ç³»æ˜¯å‘é‡è€Œä¸æ˜¯è·ç¦»ã€‚<br><img src="media/TransH_1.png" alt="TransH_1"></p>
<p>è¿™ä¸ªæ¨¡å‹çš„ä¸€ä¸ªäº®ç‚¹å°±æ˜¯ç”¨å°½é‡å°‘çš„å‚æ•°å¯¹å¤æ‚çš„å…³ç³»å»ºæ¨¡ã€‚ ä¸‹å›¾ç½—åˆ—äº†ç›¸å…³å·¥ä½œçš„æ¨¡å‹ä»¥åŠå¤æ‚åº¦ã€‚å›¾ä¸­å¯ä»¥çœ‹åˆ°ä»TransEåˆ°TransHå¹¶æ²¡æœ‰æ·»åŠ å¤ªå¤šçš„å‚æ•°ï¼ˆUnstructuredåªæ˜¯TransEç®€åŒ–ç‰ˆï¼‰ã€‚Bilinearï¼ŒSingle Layerï¼Œ NTNå¯¹å…³ç³»æˆ–è€…å®ä½“è¿›è¡Œäº†éçº¿æ€§çš„è½¬æ¢ï¼Œä½œè€…è®¤ä¸ºæ˜¯æ²¡æœ‰å¿…è¦çš„ï¼ˆå¢åŠ äº†æ¨¡å‹å¤æ‚åº¦ï¼‰ã€‚</p>
<p><img src="media/TransH_2.png" alt="TransH_2"></p>
<p>TransHæ¨¡å‹çš„è®­ç»ƒå’ŒTransEç±»ä¼¼ ï¼ˆSGDä¼˜åŒ–ï¼‰ ï¼Œä¸‹é¢æ˜¯æŸå¤±å‡½æ•°ï¼ˆå› ä¸ºä¸€äº›é™åˆ¶ï¼Œåé¢åŠ å…¥äº†æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°ï¼‰ã€‚è®ºæ–‡å¦ä¸€ä¸ªäº®ç‚¹æ˜¯è®¾è®¡äº†ä¸€ç§è´Ÿç±»æŠ½æ ·çš„æ–¹æ³•ï¼Œå³ä¸€å¯¹å¤šçš„æ—¶å€™ï¼Œç»™headæ›´å¤šçš„æŠ½æ ·æ¦‚ç‡ï¼Œ åŒæ ·çš„å¤šå¯¹ä¸€çš„æ—¶å€™ï¼Œç»™tailæ›´å¤šæŠ½æ ·æ¦‚ç‡ã€‚<br><img src="media/TransH_3.png" alt="TransH_3"></p>
<h2 id="èµ„æº-1"><a href="#èµ„æº-1" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æ•°æ®é›† WordNet:<a href="http://wordnet.princeton.edu/wordnet/download/" target="_blank" rel="external">http://wordnet.princeton.edu/wordnet/download/</a><br>æ•°æ®é›† Freebase:  <a href="http://developers.google.com/freebase/" target="_blank" rel="external">http://developers.google.com/freebase/</a><br>Code:<a href="https://github.com/thunlp/KB2E" target="_blank" rel="external">https://github.com/thunlp/KB2E</a></p>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>ï¼ˆ1ï¼‰TransE (Bordes et al. 2013b): å’ŒTransHç›¸æ¯”ï¼Œå®ƒæ²¡æœ‰å°†å…³ç³»æ˜ å°„åˆ°å¦ä¸€ä¸ªç©ºé—´ï¼Œå…³ç³»ç”±ä¸€ä¸ªå‘é‡rè¡¨ç¤ºã€‚<br>ï¼ˆ2ï¼‰Unstructured Modelï¼šç®€åŒ–ç‰ˆçš„TransEï¼Œå‡è®¾r = 0ã€‚<br>ï¼ˆ3ï¼‰Structured Embeddingï¼š  ä½¿ç”¨äº†ä¸¤ä¸ªå…³ç³»ç›¸å…³çš„çŸ©é˜µï¼Œåˆ†åˆ«ç”¨äºå¤´hå’Œå°¾tï¼Œè¯„ä¼°å‡½æ•°ä¸º:<br><img src="media/TransH_4.PNG" alt=""><br>è¯¥æ–¹æ³•å¹¶æ²¡æœ‰æŠ“ä½å®ä½“å’Œå…³ç³»ä¹‹é—´çš„å…³ç³»ã€‚<br>ï¼ˆ4ï¼‰Single Layer Model(SLM)ï¼šä½¿ç”¨äº†ç¥ç»ç½‘ç»œï¼Œè¯„ä¼°å‡½æ•°ä¸º:<br><img src="media/TransH_5.PNG" alt=""><br>ï¼ˆ5ï¼‰Distant Model (Bordes et al. 2011)ï¼šå®ƒå°†å®ä½“æ˜ å°„åˆ°å¦ä¸€ä¸ªç©ºé—´ï¼Œç„¶åå‡å®šå…³ç³»æ˜¯è·ç¦»è€Œä¸æ˜¯å‘é‡ï¼ˆå› ä¸ºç”¨äº†2ä¸ªä¸åŒçŸ©é˜µæ˜ å°„å®ä½“ï¼Œæ‰€ä»¥å¯¹å®ä½“å…³ç³»å»ºæ¨¡å¹¶ä¸æ˜¯å¾ˆå¥½ï¼‰ã€‚<br>ï¼ˆ6ï¼‰Bilinear Model (Jenatton et al. 2012; Sutskever, Tenen- baum, and Salakhutdinov 2009)ï¼ŒSingle Layer Model (Socher et al. 2013)ï¼ŒNTN (Socher et al. 2013)ï¼šä»–ä»¬éƒ½æ˜¯ä½¿ç”¨éçº¿æ€§å‡½æ•°æ˜ å°„å®ä½“ï¼Œè¿™æ ·æ¨¡å‹è¡¨è¾¾èƒ½åŠ›è™½ç„¶å¥½ä½†æ˜¯å¤ªå¤šå‚æ•°ä¹Ÿå¤ªå¤æ‚äº†ï¼ˆå®¹æ˜“è¿‡æ‹Ÿåˆï¼‰ã€‚</p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è®ºæ–‡æå‡ºçš„TransHæ¨¡å‹ï¼Œä¸ºäº†è§£å†³TransEå¯¹ä¸€å¯¹å¤šï¼Œå¤šå¯¹ä¸€ï¼Œå¤šå¯¹å¤šå…³ç³»å»ºæ¨¡çš„éš¾é¢˜ã€‚å®ƒæƒè¡¡æ¨¡å‹å¤æ‚åº¦å’Œæ¨¡å‹è¡¨è¾¾èƒ½åŠ›ã€‚è€Œä¸”è¿˜è®¾è®¡äº†å¤æ‚å–æ ·çš„åŠæ³•ç”¨äºè®­ç»ƒã€‚</p>
<h1 id="TransD-knowledge-graph-embedding-via-dynamic-mapping-matrix"><a href="#TransD-knowledge-graph-embedding-via-dynamic-mapping-matrix" class="headerlink" title="TransD: knowledge graph embedding via dynamic mapping matrix"></a><a href="http://www.aclweb.org/anthology/P15-1067.pdf" target="_blank" rel="external">TransD: knowledge graph embedding via dynamic mapping matrix</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Guoliang Ji, Shizhu He, Liheng Xu, Kang Liu and Jun Zhao</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>ä¸­å›½ç§‘å­¦é™¢è‡ªåŠ¨åŒ–ç ”ç©¶æ‰€  National Laboratory of Pattern Recognition (NLPR)</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>knowledge graph embedding, link prediction.</p>
<h2 id="æ–‡ç« æ¥æº-2"><a href="#æ–‡ç« æ¥æº-2" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ACL2015</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>çŸ¥è¯†å›¾è°±ä¸­çš„link predictionã€‚</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>åœ¨link predictionä¸Šçš„TransEæ‰©å±•æ¨¡å‹ï¼Œå‡½æ•°ä»ç„¶ä¸º:   </p>
<p> <img src="media/TransD_1.PNG" alt=""> </p>
<p>ä½†hä¸„å’Œtä¸„ä¸ºentityå‘é‡hå’Œentityå‘é‡tåœ¨è¯¥relation rä¸Šçš„æŠ•å½±è¡¨ç¤ºã€‚æŠ•å½±å®šä¹‰ä¸ºï¼š</p>
<p> <img src="media/TransD_2.PNG" alt=""></p>
<p>å…¶ä¸­(h_p)^Tä¸ºæŸentityçš„æŠ•å½±å‘é‡ï¼Œhä¸ºè¯¥entityçš„è¡¨ç¤ºå‘é‡ã€‚</p>
<h2 id="èµ„æº-2"><a href="#èµ„æº-2" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æ•°æ®é›† WordNet <a href="http://wordnet.princeton.edu/" target="_blank" rel="external">http://wordnet.princeton.edu/</a><br>æ•°æ®é›† FreeBase <a href="https://developers.google.com/freebase/" target="_blank" rel="external">https://developers.google.com/freebase/</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-1"><a href="#ç›¸å…³å·¥ä½œ-1" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>å¦‚æœTransDçš„æ‰€æœ‰æŠ•å½±å‘é‡ä¸º0ï¼ŒTransDå°±æ˜¯TransEã€‚ç±»ä¼¼çš„è¿˜æœ‰TransR/CTransRï¼Œä»–ä»¬å¯¹æ¯ä¸ªrelationå®šä¹‰äº†ä¸€ä¸ªmappingçŸ©é˜µï¼Œå‚æ•°æ›´å¤šè®¡ç®—å¤æ‚åº¦æ›´å¤§ã€‚</p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æ¨¡å‹åªæ¶‰åŠvectorçš„ç›¸ä¹˜ï¼Œå› æ­¤è®¡ç®—å¤æ‚åº¦è¾ƒå°ï¼Œæ•ˆæœä¹Ÿå–å¾—äº†state-of-the-artï¼Œé€‚åˆç”¨äºè§„æ¨¡å¾ˆå¤§çš„çŸ¥è¯†å›¾è°±ã€‚</p>
<h1 id="TransA-An-Adaptive-Approach-for-Knowledge-Graph-Embedding"><a href="#TransA-An-Adaptive-Approach-for-Knowledge-Graph-Embedding" class="headerlink" title="TransA:An Adaptive Approach for Knowledge Graph Embedding"></a><a href="https://arxiv.org/pdf/1509.05490v2.pdf" target="_blank" rel="external">TransA:An Adaptive Approach for Knowledge Graph Embedding</a></h1><h2 id="ä½œè€…-3"><a href="#ä½œè€…-3" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Hao Xian, Minlin  Huang,  Hao Yu,  Xiaoyan  Zhu</p>
<h2 id="å•ä½-3"><a href="#å•ä½-3" class="headerlink" title="å•ä½:"></a>å•ä½:</h2><p> æ¸…åå¤§å­¦  State Key Lab on Intelligent Technology and Systems</p>
<h2 id="å…³é”®è¯ï¼š"><a href="#å…³é”®è¯ï¼š" class="headerlink" title="å…³é”®è¯ï¼š"></a>å…³é”®è¯ï¼š</h2><p>knowledge graph embedding,  elliptical equipotential hypersurfaces,  metric learning.</p>
<h2 id="æ–‡ç« æ¥æº-3"><a href="#æ–‡ç« æ¥æº-3" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv</p>
<h2 id="é—®é¢˜-3"><a href="#é—®é¢˜-3" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•è§£å†³äº†translation-based çŸ¥è¯†è¡¨ç¤ºæ–¹æ³•å­˜åœ¨çš„è¿‡äºç®€åŒ–æŸå¤±åº¦é‡ï¼Œæ²¡æœ‰è¶³å¤Ÿç«äº‰åŠ›å»åº¦é‡çŸ¥è¯†åº“ä¸­å®ä½“/å…³ç³»çš„å¤šæ ·æ€§å’Œå¤æ‚æ€§é—®é¢˜ã€‚</p>
<h2 id="æ¨¡å‹-3"><a href="#æ¨¡å‹-3" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>çŸ¥è¯†å›¾è°±åœ¨AIæœç´¢å’Œåº”ç”¨ä¸­æ‰®æ¼”ç€è¶Šæ¥è¶Šé‡è¦çš„è§’è‰²ï¼Œä½†æ˜¯å®ƒæ˜¯ç¬¦å·è¡¨ç¤ºï¼Œæœ‰ä¸€å®šçš„é€»è¾‘æ€§çš„ï¼Œå› æ­¤å¦‚ä½•è¡¨ç¤ºè¿™äº›å…³ç³»å°±æˆäº†ä¸€ä¸ªå¾ˆå¤§çš„æŒ‘æˆ˜ï¼Œä¸ºäº†è§£å†³è¿™ä¸ªæŒ‘æˆ˜ï¼Œå¾ˆå¤šæ¨¡å‹å¦‚TransE, TransH, TransRçº·çº·è¢«æå‡ºæ¥ï¼Œåœ¨è¿™äº›æ¨¡å‹ä¸­ï¼ŒåŸºäºå‡ ä½•å…³ç³»çš„æ–¹æ³•æ˜¯å¾ˆé‡è¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè€ŒåŸºäºå‡ ä½•å…³ç³»çš„æ–¹æ³•æ˜¯ä½¿ç”¨Kç»´çš„å‘é‡è¡¨ç¤ºå®ä½“æˆ–è€…å…³ç³»ï¼Œç„¶ååˆ©ç”¨ä¸€ä¸ªå‡½æ•°f_r(h,t)æ¥åº¦é‡ä¸‰å…ƒç»„(h, r, t)ï¼Œè€Œä»–ä»¬éƒ½æ˜¯åŸºäºä¸€ä¸ªå‡†åˆ™h+r=tã€‚<br>å› æ­¤å°±ä½¿ç”¨äº†åŒä¸€ä¸ªæŸå¤±åº¦é‡h+r=tï¼Œè¿™ç§æŸå¤±åº¦é‡å…¶å®æ˜¯åˆ©ç”¨äº†åœ¨ä¸€ä¸ªçƒå½¢ç­‰ä»·è¶…å¹³é¢ï¼Œè¶Šæ¥è¿‘ä¸­å¿ƒï¼Œä¸‰å…ƒç»„çš„å¯ä¿¡åº¦è¶Šé«˜ï¼Œå› æ­¤ä»æœªåŒ¹é…çš„tä¸­å¯»æ‰¾åˆé€‚çš„tå°±å˜å¾—å¾ˆè‹¦éš¾ï¼ŒåŒæ—¶è¿™ç§æ–¹æ³•ä¹Ÿå¾ˆéš¾å¤„ç†ä¸€å¯¹å¤šï¼Œå¤šå¯¹ä¸€ï¼Œå¤šå¯¹å¤šçš„å…³ç³»ã€‚å› æ­¤è¿™äº›æ–¹æ³•ä¸å¤Ÿçµæ´»ã€‚<br>å…·ä½“å¯ä»¥ä»å›¾1(a)çœ‹å‡ºã€‚åŒæ—¶è¿™ç§æ–¹æ³•å°†ç­‰ä»·å¯¹å¾…å‘é‡ä¸­çš„æ¯ä¸€ç»´ï¼Œä½†å®é™…ä¸Šå„ä¸ªç»´åº¦çš„é‡è¦æ€§æ˜¯ä¸åŒçš„ï¼Œåªæœ‰ä¸€äº›ç»´åº¦æ˜¯æœ‰æ•ˆçš„ï¼Œå…¶ä»–ç»´åº¦å¯ä»¥è®¤ä¸ºæ˜¯å™ªéŸ³ï¼Œä¼šé™ä½æ•ˆæœï¼Œå…·ä½“è§å›¾2(a).</p>
<p>å› æ­¤ä½œè€…æå‡ºäº†å¦ä¸€ç§æŸå¤±åº¦é‡å‡½æ•°</p>
<p><img src="media/TransA-2.PNG" alt=""></p>
<p>é€šè¿‡å¢åŠ ä¸€ä¸ªçŸ©é˜µWrâ€‹ï¼Œé¦–å…ˆåˆ©ç”¨äº†ä¸€ä¸ªæ¤­åœ†ç­‰ä»·è¶…å¹³é¢ï¼Œè§£å†³äº†ä¸Šè¿°é—®é¢˜1ï¼Œå…·ä½“è§å›¾1(b)ï¼›åŒæ—¶åˆ©ç”¨LDLåˆ†è§£ï¼Œå…¬å¼å˜ä¸º:</p>
<p><img src="media/TransA-3.PNG" alt=""></p>
<p>å…¶ä¸­D_rå°±æ˜¯ä¸€ä¸ªå¯¹è§’é˜µï¼Œè€Œå¯¹è§’é˜µä¸­çš„æ¯ä¸ªå€¼çš„å¤§å°ï¼Œæ­£å¥½è¯´æ˜äº†æ¯ä¸€ç»´çš„ä¸åŒé‡è¦ç¨‹åº¦ï¼Œä¹Ÿå°±è§£å†³äº†ä¸Šè¿°é—®é¢˜2ï¼Œå…·ä½“å‡å›¾2(b)ã€‚</p>
<p><img src="media/TransA-4.JPG" alt="figure 1"><br>å›¾1<br><img src="media/TransA-5.JPG" alt="figure 2"><br>å›¾2</p>
<h2 id="èµ„æº-3"><a href="#èµ„æº-3" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æ•°æ®é›† Wordnet <a href="http://wordnet.princeton.edu/" target="_blank" rel="external">http://wordnet.princeton.edu/</a><br>æ•°æ®é›† FreeBase <a href="https://developers.google.com/freebase/" target="_blank" rel="external">https://developers.google.com/freebase/</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-2"><a href="#ç›¸å…³å·¥ä½œ-2" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>å¦‚æ¨¡å‹éƒ¨åˆ†ä»‹ç»çš„ï¼Œå½“å‰çš„ä¸€äº›ç°æœ‰æ¨¡å‹éƒ½æ˜¯åŸºäºä¸€ä¸ªå‡†åˆ™h+r=tï¼Œå› æ­¤å°±ä½¿ç”¨äº†åŒä¸€ä¸ªæŸå¤±åº¦é‡h_r+r=t_rï¼Œåªæ˜¯åœ¨h_rå’Œt_rçš„è¡¨ç¤ºä¸Šæœ‰ä¸åŒï¼š</p>
<p>ï¼ˆ1ï¼‰TransE  h_r = h, t_r = t<br>ï¼ˆ2ï¼‰TransH  h_r = h - (w_r)^T.h.w_r,  t_r = t - (w_r)^T.t.w_r<br>ï¼ˆ3ï¼‰TransR  h_r = M_r.h,  t_r = M_r.t<br>ï¼ˆ4ï¼‰TransMåˆ™æ˜¯é¢„å…ˆè®¡ç®—äº†å‡ºæ¯ä¸€ä¸ªè®­ç»ƒä¸‰å…ƒç»„çš„ç›´æ¥æƒé‡</p>
<p>è¿˜æœ‰å¾ˆå¤šç±»ä¼¼çš„æ¨¡å‹ï¼Œè¿™é‡Œå°±ä¸å†ä»‹ç»äº†ã€‚</p>
<h2 id="ç®€è¯„-3"><a href="#ç®€è¯„-3" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æ„Ÿè§‰è¿™ç¯‡æ–‡ç« çš„æ€è·¯æ¯”è¾ƒç®€å•ï¼Œå°±æ˜¯é’ˆå¯¹å½“å‰æ¨¡å‹çš„ä¸€äº›ä¸è¶³ï¼Œæ›´æ¢äº†ä¸€ä¸ªæŸå¤±åº¦é‡å‡½æ•°ã€‚ä½†æ˜¯å‡ ç‚¹è¿˜æ˜¯å€¼å¾—å­¦ä¹ çš„ï¼Œé¦–å…ˆé€šè¿‡å›¾åƒæ¥æè¿°ä¸åŒçš„æŸå¤±åº¦é‡å‡½æ•°ï¼Œç»™äººä¸€ä¸ªæ›´ç›´è§‚çš„æ„Ÿè§‰ï¼›å…¶æ¬¡é’ˆå¯¹å‘é‡è¡¨ç¤ºä¸­çš„åŒºåˆ«å¯¹å¾…ï¼Œæ„Ÿè§‰å¾ˆæœ‰attention mechanismçš„æ„Ÿè§‰ï¼Œå¯¹ä¸åŒçš„tripleå…³æ³¨å‘é‡è¡¨ç¤ºçš„ä¸åŒç»´åº¦ï¼Œä»¥å–å¾—æœ€å¥½çš„æ•ˆæœï¼Œè¿™ç‚¹æ˜¯éå¸¸å€¼å¾—å€Ÿé‰´å‚è€ƒçš„ã€‚</p>
<h1 id="TransG-A-Generative-Mixture-Model-for-Knowledge-Graph-Embedding"><a href="#TransG-A-Generative-Mixture-Model-for-Knowledge-Graph-Embedding" class="headerlink" title="TransG : A Generative Mixture Model for Knowledge Graph Embedding"></a><a href="https://arxiv.org/abs/1509.05488" target="_blank" rel="external">TransG : A Generative Mixture Model for Knowledge Graph Embedding</a></h1><h2 id="ä½œè€…-4"><a href="#ä½œè€…-4" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p> Han Xiao, Minlie Huang, Yu Hao, Xiaoyan Zhu</p>
<h2 id="å•ä½-4"><a href="#å•ä½-4" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>æ¸…åå¤§å­¦  State Key Lab on Intelligent Technology and Systems</p>
<h2 id="å…³é”®è¯-3"><a href="#å…³é”®è¯-3" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>knowledge graph embedding, generative mixture model, multiple relration semantics.</p>
<h2 id="æ–‡ç« æ¥æº-4"><a href="#æ–‡ç« æ¥æº-4" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>arXiv2015</p>
<h2 id="é—®é¢˜-4"><a href="#é—®é¢˜-4" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>è§£å†³å¤šå…³ç³»è¯­ä¹‰(multiple relation semantics)çš„é—®é¢˜ã€‚</p>
<h2 id="æ¨¡å‹-4"><a href="#æ¨¡å‹-4" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>ä¼ ç»Ÿçš„åŸºäºç¿»è¯‘çš„æ¨¡å‹é‡‡ç”¨h_r+r= t_r(å…¶ä¸­ï¼Œh_rä¸ºå¤´éƒ¨å®ä½“ï¼Œt_rä¸ºå°¾éƒ¨å®ä½“ï¼Œrä¸ºå¤´éƒ¨<br>å®ä½“è·Ÿå°¾éƒ¨å®ä½“çš„å…³ç³»)ï¼Œä»…ä»…å¯¹ä¸€ä¸ªå…³ç³»èµ‹äºˆä¸€ç§ç¿»è¯‘å‘é‡ã€‚<br>å®ƒä»¬ä¸èƒ½ç»†åˆ†å¤šå…³ç³»è¯­ä¹‰ï¼Œæ¯”å¦‚ï¼Œ(Atlantics, HasPart, NewYorkBay)å’Œ(Table, HasPart, Leg)ä¸¤ä¸ªçš„å…³ç³»éƒ½æ˜¯HasPartï¼Œä½†æ˜¯è¿™ä¸¤ä¸ªçš„å…³ç³»åœ¨è¯­ä¹‰ä¸Šä¸åŒï¼Œç¬¬ä¸€ä¸ªæ˜¯â€œéƒ¨ä»¶â€çš„å…³ç³»ï¼Œç¬¬äºŒä¸ªæ˜¯â€œä½ç½®â€çš„å…³ç³»ã€‚TransGèƒ½å¤Ÿè§£å†³å…³ç³»çš„å¤šè¯­ä¹‰é—®é¢˜ã€‚å¦‚å›¾æ‰€ç¤ºï¼Œå¤šå…³ç³»è¯­ä¹‰åˆ†æå¯ä»¥æé«˜ä¸‰å…ƒç»„çš„åˆ†ç±»å‡†ç¡®åº¦ã€‚</p>
<p><img src="media/TransG.png" alt="figure 1"></p>
<p>TransGåˆ©ç”¨è´å¶æ–¯éå‚æ•°æ— é™æ··åˆæ¨¡å‹å¯¹ä¸€ä¸ªå…³ç³»ç”Ÿæˆå¤šä¸ªç¿»è¯‘éƒ¨åˆ†ï¼Œæ ¹æ®ä¸‰å…ƒç»„çš„ç‰¹å®šè¯­ä¹‰å¾—åˆ°å½“ä¸­çš„æœ€ä½³éƒ¨åˆ†ã€‚æœ€å¤§æ•°æ®ç›¸ä¼¼åº¦åŸç†ç”¨æ¥è®­ç»ƒï¼Œä¼˜åŒ–é‡‡ç”¨SGDã€‚å®éªŒç»“æœåœ¨link predictionå’Œtriple classificationè¿™ä¸¤ç§ä»»åŠ¡ä¸Šéƒ½ä¼˜äºç›®å‰æœ€å¥½çš„ç»“æœï¼Œè¿è¡Œé€Ÿåº¦ä¸TransE(æœ€å¿«çš„æ–¹æ³•)æˆæ­£ç›¸å…³ï¼Œç³»æ•°ä¸ºå…³ç³»è¯­ä¹‰éƒ¨åˆ†çš„æ•°ç›®ã€‚</p>
<h2 id="èµ„æº-4"><a href="#èµ„æº-4" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æ•°æ®é›† WordNet    <a href="http://wordnet.princeton.edu/wordnet/download/" target="_blank" rel="external">http://wordnet.princeton.edu/wordnet/download/</a><br>æ•°æ®é›† Freebase   <a href="http://developers.google.com/freebase/" target="_blank" rel="external">http://developers.google.com/freebase/</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-3"><a href="#ç›¸å…³å·¥ä½œ-3" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>å¤§å¤šæ•°éƒ½å·²ä»‹ç»ï¼Œè¿™é‡Œå°±åªè¯´æ˜CTransRï¼Œå…¶ä¸­å…³ç³»çš„å®ä½“å¯¹è¢«åˆ†ç±»åˆ°ä¸åŒçš„ç»„ï¼ŒåŒä¸€ç»„çš„å®ä½“å¯¹å…±äº«ä¸€ä¸ªå…³ç³»å‘é‡ã€‚ç›¸æ¯”è¾ƒè€Œè¨€ï¼ŒTransGä¸éœ€è¦å¯¹èšç±»çš„é¢„å¤„ç†ã€‚</p>
<h2 id="ç®€è¯„-4"><a href="#ç®€è¯„-4" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¿™ç¯‡æ–‡ç« çš„ideaæ¯”è¾ƒé‡è¦ï¼Œè€ƒè™‘åˆ°ä¸€ç§å…³ç³»å­˜åœ¨çš„å¤šè¯­ä¹‰é—®é¢˜ï¼Œç›¸å½“äºå¯¹å…³ç³»è¿›è¡Œäº†ç»†åŒ–ï¼Œå°±æ˜¯æ‰¾åˆ°å…³ç³»çš„éšå½¢å«ä¹‰ï¼Œæœ€ç»ˆä»ç»†åŒ–çš„ç»“æœä¸­é€‰å‡ºä¸€ä¸ªæœ€ä½³çš„å…³ç³»è¯­ä¹‰ã€‚è¿™ä¸ªåœ¨åº”ç”¨ä¸­å¾ˆæœ‰æ„ä¹‰ï¼Œä¸åŒçš„è¯­ä¹‰å¯èƒ½éœ€è¦ä¸åŒçš„åº”å¯¹æ–¹æ³•ï¼Œå¯ä»¥å€Ÿé‰´ã€‚</p>
<h1 id="KG2E-KG2E-learning-to-represent-knowledge-graphs-with-gaussian-embedding"><a href="#KG2E-KG2E-learning-to-represent-knowledge-graphs-with-gaussian-embedding" class="headerlink" title="KG2E:KG2E_learning to represent knowledge graphs with gaussian embedding"></a><a href="http://dl.acm.org/citation.cfm?id=2806502" target="_blank" rel="external">KG2E:KG2E_learning to represent knowledge graphs with gaussian embedding</a></h1><h2 id="ä½œè€…-5"><a href="#ä½œè€…-5" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Shizhu He, Kang Liu, Guoliang Ji and Jun Zhao</p>
<h2 id="å•ä½-5"><a href="#å•ä½-5" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>National Laboratory of Pattern Recognition<br>Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China</p>
<h2 id="å…³é”®è¯-4"><a href="#å…³é”®è¯-4" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Distributed Representation, Gaussian Embedding, Knowledge Graph</p>
<h2 id="æ–‡ç« æ¥æº-5"><a href="#æ–‡ç« æ¥æº-5" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>CIKM 2015</p>
<h2 id="é—®é¢˜-5"><a href="#é—®é¢˜-5" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æœ¬æ–‡æ‰€è§£å†³çš„é—®é¢˜æ˜¯çŸ¥è¯†å›¾è°±çš„è¡¨ç¤ºé—®é¢˜ï¼ˆå³å°†çŸ¥è¯†å›¾è°±è¡¨ç¤ºä¸ºä½ç»´è¿ç»­å‘é‡ç©ºé—´ï¼‰ï¼Œæœ¬æ–‡ä½¿ç”¨Gaussian Distribution æ¥è¡¨ç¤ºå®ä½“å’Œå…³ç³»ï¼Œæå‡ºäº†ç”¨Gaussian Distributionçš„åæ–¹å·®æ¥è¡¨ç¤ºå®ä½“å’Œå…³ç³»çš„ä¸ç¡®å®šåº¦çš„æ–°æ€æƒ³ï¼Œæå‡äº†å·²æœ‰æ¨¡å‹åœ¨link predictionå’Œtriplet classificationé—®é¢˜ä¸Šçš„å‡†ç¡®ç‡ã€‚</p>
<h2 id="æ¨¡å‹-5"><a href="#æ¨¡å‹-5" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>ä¼ ç»Ÿçš„è¡¨ç¤ºå­¦ä¹ çš„è¡¨ç¤ºå­¦ä¹ çš„æ–¹æ³•å’Œè®¡ç®—æ¯”è¾ƒå¤æ‚ï¼Œè‡ªTransEæ¨¡å‹è¯ç”Ÿåï¼Œå¾ˆå¤šæ¨¡å‹éƒ½æ˜¯åœ¨TransEçš„åŸºæœ¬æ€æƒ³ä¸ŠåŠ ä»¥æ”¹è¿›ï¼ŒKG2Eæ¨¡å‹ä¹Ÿæ˜¯ä¸€æ ·ã€‚<br>KG2Eæ¨¡å‹ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒæ¥è¡¨ç¤ºå®ä½“å’Œå…³ç³»ã€‚<br>æ¨¡å‹å®ä¾‹è§ä¸‹å›¾ï¼š<br><img src="media/KG2E_example.png" alt="model example"></p>
<p>æ¯ä¸ªåœ†åœˆä»£è¡¨ä¸åŒå®ä½“ä¸å…³ç³»çš„è¡¨ç¤ºï¼Œå®ƒä»¬åˆ†åˆ«äºâ€œBill Clintonâ€æ„æˆä¸‰å…ƒç»„å…³ç³»ï¼Œåœ†åœˆå¤§å°è¡¨ç¤ºçš„æ˜¯ä¸åŒå®ä½“æˆ–å…³ç³»çš„ä¸ç¡®å®šåº¦ã€‚</p>
<p>æ¨¡å‹ç®—æ³•æµç¨‹å›¾å¦‚ä¸‹ï¼š<br><img src="media/KG2E_Algorithm.png" alt="model algorithm"></p>
<p>ç®—æ³•è§£è¯»ï¼š<br>è¾“å…¥ï¼šè®­ç»ƒé›†ä¸‰å…ƒç»„ï¼ŒKGä¸­æ‰€æœ‰çš„å®ä½“å’Œå…³ç³»ï¼Œä»¥åŠå…¶å®ƒçš„ä¸€äº›å‚æ•°ã€‚<br>è¾“å‡ºï¼šKGä¸­æ‰€æœ‰å®ä½“å’Œå…³ç³»å»ºæ¨¡åç”Ÿæˆçš„Gaussian Embeddings.ï¼ˆä¸»è¦åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼Œå‡å€¼ï¼ˆå‘é‡ï¼‰å’Œåæ–¹å·®ï¼ˆçŸ©é˜µï¼‰ï¼‰<br>line 1åˆ°line 4ä¸»è¦æ˜¯æ•°æ®çš„å½’ä¸€åŒ–<br>line 5åˆ°line 15æ˜¯ç®—æ³•å®ç°éƒ¨åˆ†ï¼šæ¨¡å‹é‡‡ç”¨çš„æ˜¯minibatchçš„è®­ç»ƒæ–¹æ³•ï¼Œæ¯ä¸€ä¸ªminibatchçš„è®­ç»ƒä¸­éƒ½ä¼šè¿›è¡Œè´Ÿé‡‡æ ·ï¼Œå¹¶å°†è´Ÿé‡‡æ ·çš„æ ·ä¾‹å’Œæ­£ä¾‹æ ·ä¾‹æ··åˆåœ¨ä¸€èµ·å­¦ä¹ ï¼Œç„¶åä½¿ç”¨è¯„åˆ†å‡½æ•°è¿›è¡Œè¯„ä¼°ï¼Œè¦è¾¾åˆ°çš„ç›®çš„æ˜¯æ­£ä¾‹ä¸‰å…ƒç»„çš„å¾—åˆ†æ¯”è´Ÿä¾‹ä¸‰å…ƒç»„é«˜æˆ–è€…ä½ï¼ˆé«˜ä½å–å†³äºå…·ä½“çš„è¯„åˆ†è€Œå‡½æ•°çš„è®¾å®šï¼‰ã€‚åœ¨ä¸€æ¬¡ä¸€æ¬¡çš„è¿­ä»£ä¸­ä¸æ–­æ›´æ–°ç»“æœï¼Œæœ€åå°†å¾—åˆ°çš„meanså’Œcovarianceè¿›è¡Œæ­£åˆ™åŒ–ã€‚</p>
<p>æ–‡ç« æ ¸å¿ƒå…¬å¼ï¼š<br>ï¼ˆ1ï¼‰è¯„åˆ†å‡½æ•°<br><img src="media/KG2E_Score_function.png" alt="score function"></p>
<p>ï¼ˆ2ï¼‰KLæ•£åº¦çš„èƒ½é‡å‡½æ•°</p>
<p><img src="media/KG2E_KL_function.png" alt="KL energy function"></p>
<p>ï¼ˆ3ï¼‰æœŸæœ›æ¦‚ç‡èƒ½é‡å‡½æ•°<br><img src="media/KG2E_EL_function.png" alt="EL energy function"></p>
<h2 id="èµ„æº-5"><a href="#èµ„æº-5" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æ•°æ®é›†ï¼š<br>    <a href="https://github.com/Mrlyk423/Relation_Extraction/blob/master/data.zip" target="_blank" rel="external">WN18</a><br>    <a href="https://github.com/dddoss/tensorflow-socher-ntn/tree/master/data/Wordnet" target="_blank" rel="external">WN11</a><br>    <a href="https://github.com/dddoss/tensorflow-socher-ntn/tree/master/data/Freebase" target="_blank" rel="external">FB13K</a><br>    <a href="https://github.com/Mrlyk423/Relation_Extraction/blob/master/data.zip" target="_blank" rel="external">FB15K</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-4"><a href="#ç›¸å…³å·¥ä½œ-4" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>ï¼ˆ1ï¼‰TransRï¼Œ2015å¹´AAAIï¼ŒLearning entity and relation embeddings for knowledgh completitionã€‚</p>
<h2 id="ç®€è¯„-5"><a href="#ç®€è¯„-5" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>åˆ›æ–°ç‚¹ï¼š<br>    ï¼ˆ1ï¼‰ä»¥å‰çš„æ–‡ç« æ˜¯å±äºpoint-basedï¼ŒKG2Eæ˜¯å±äºdensity-basedçš„ã€‚<br>    ï¼ˆ2ï¼‰æå‡ºäº†(un)certaintyçš„æ¦‚å¿µï¼Œåœ¨å»ºæ¨¡è¿‡ç¨‹ä¸­èå…¥äº†å…³ç³»å’Œå®ä½“è¯­ä¹‰æœ¬èº«çš„ä¸ç¡®å®šæ€§çš„çŸ¥è¯†ï¼Œä½¿ç”¨é«˜æ–¯åˆ†å¸ƒçš„åæ–¹å·®è¡¨ç¤ºè¯¥å®ä½“æˆ–å…³ç³»çš„ä¸ç¡®å®šåº¦ï¼Œé«˜æ–¯åˆ†å¸ƒçš„å‡å€¼è¡¨ç¤ºå®ä½“æˆ–å…³ç³»åœ¨è¯­ä¹‰ç©ºé—´ä¸­çš„ä¸­å¿ƒå€¼ã€‚<br>    ï¼ˆ3ï¼‰ä½¿ç”¨äº†æ–°çš„score funcitonï¼šKL-divergenceå’Œexpected likelihood<br>åº”ç”¨åœºæ™¯ï¼šlink predictionï¼Œtriplet classification,knowledge reasoning<br>ä¸è¶³ä¹‹å¤„ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨link predictionçš„many-to-many relationsä¸Šçš„é¢„æµ‹æ€§èƒ½ä¸æ˜¯å¾ˆå¥½ï¼Œä¸»è¦åŸå› æ˜¯KG2Eæ¨¡å‹æ²¡æœ‰è€ƒè™‘å®ä½“çš„ç±»å‹å’Œç²’åº¦ã€‚</p>
<p>7.TranSparse</p>
<h1 id="Knowledge-Graph-Completion-with-Adaptive-Sparse-Transfer-Matrix"><a href="#Knowledge-Graph-Completion-with-Adaptive-Sparse-Transfer-Matrix" class="headerlink" title="Knowledge Graph Completion with Adaptive Sparse Transfer Matrix"></a><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11982/11693" target="_blank" rel="external">Knowledge Graph Completion with Adaptive Sparse Transfer Matrix</a></h1><h2 id="ä½œè€…-6"><a href="#ä½œè€…-6" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Guoliang Ji, Kang Liu, Shizhu He, Jun Zhao</p>
<h2 id="å•ä½-6"><a href="#å•ä½-6" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>ä¸­ç§‘é™¢æ¨¡å¼è¯†åˆ«å›½å®¶é‡ç‚¹å®éªŒå®¤</p>
<h2 id="å…³é”®è¯-5"><a href="#å…³é”®è¯-5" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Knowledge Graph Embedding,Sparse Matrix</p>
<h2 id="æ–‡ç« æ¥æº-6"><a href="#æ–‡ç« æ¥æº-6" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>AAAI 2016</p>
<h2 id="é—®é¢˜-6"><a href="#é—®é¢˜-6" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>é’ˆå¯¹ä¸åŒéš¾åº¦çš„å®ä½“é—´å…³ç³»ï¼Œä½¿ç”¨ä¸åŒç¨€ç–ç¨‹åº¦çš„çŸ©é˜µï¼ˆä¸åŒæ•°é‡çš„å‚æ•°ï¼‰æ¥è¿›è¡Œè¡¨å¾ï¼Œä»è€Œé˜²æ­¢å¯¹å¤æ‚å…³ç³»æ¬ æ‹Ÿåˆæˆ–è€…å¯¹ç®€å•å…³ç³»è¿‡æ‹Ÿåˆã€‚</p>
<h2 id="æ¨¡å‹-6"><a href="#æ¨¡å‹-6" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æœ¬æ–‡çš„æ¨¡å‹ä¸TransRç±»ä¼¼ï¼Œå³å¯¹æ¯ä¸€ä¸ªå…³ç³»rå­¦ä¹ ä¸€ä¸ªè½¬æ¢çŸ©é˜µM_r,å°†hå’Œtçš„å‘é‡æ˜ å°„åˆ°å…³ç³»å‘é‡æ‰€åœ¨çš„ç©ºé—´ã€‚</p>
<p>ä¸è¿‡æœ¬æ–‡æ³¨æ„åˆ°knowledge graphä¸­é¢ä¸´ä¸¤ä¸ªé—®é¢˜ï¼Œåˆ†åˆ«æ˜¯heterogeneousï¼ˆæœ‰çš„å®ä½“å…³ç³»ååˆ†å¤æ‚ï¼Œè¿æ¥è®¸å¤šä¸åŒçš„å®ä½“ï¼‰å’Œunbalancedï¼ˆå¾ˆå¤šå…³ç³»è¿æ¥çš„headå’Œtailæ•°ç›®å¾ˆä¸å¯¹ç­‰ï¼‰ã€‚å¦‚æœåªä½¿ç”¨ä¸€ä¸ªæ¨¡å‹åº”å¯¹æ‰€æœ‰æƒ…å†µçš„è¯å¯èƒ½ä¼šå¯¼è‡´å¯¹å¤æ‚å…³ç³»underfitï¼Œå¯¹ç®€å•å…³ç³»overfitã€‚å› æ­¤æœ¬æ–‡è®¤ä¸ºéœ€è¦å¯¹ç—‡ä¸‹è¯ï¼Œå¤æ‚çš„å…³ç³»å°±éœ€è¦ä¸‹çŒ›è¯ï¼ˆç”¨æœ‰æ›´å¤šçš„å‚æ•°çš„å¤æ‚æ¨¡å‹ï¼‰ï¼Œç®€å•å…³ç³»å°±ç®€å•å¤„ç†ï¼ˆè¾ƒå°‘çš„å‚æ•°ï¼‰ã€‚</p>
<p>ä½†æ˜¯æ€ä¹ˆå®ç°è¿™æ ·çµæ´»çš„å»ºæ¨¡ï¼Ÿåœ¨æ–¹æ³•ä¸Šæœ¬æ–‡å€Ÿç”¨äº†SparseMatrixï¼Œå¦‚æœå…³ç³»æ¯”è¾ƒå¤æ‚å°±ç”¨æ¯”è¾ƒç¨ å¯†çš„çŸ©é˜µï¼Œå¦‚æœå…³ç³»ç®€å•åˆ™ç”¨ç¨€ç–çŸ©é˜µè¿›è¡Œè¡¨è¾¾ã€‚æ–‡ç« å‡è®¾å…³ç³»çš„å¤æ‚ç¨‹åº¦æ­£æ¯”äºåŒ…å«è¯¥å…³ç³»çš„tripletæ•°ç›®ï¼Œå¹¶æ ¹æ®ä¸¤ç±»é—®é¢˜æå‡ºäº†å¯¹åº”çš„ç¨€ç–çŸ©é˜µåˆå§‹åŒ–æ–¹æ³•ã€‚ä¸è¿‡å¹¶æ²¡æœ‰æå‡ºåŒæ—¶è§£å†³ä¸¤ç±»é—®é¢˜çš„ç»Ÿä¸€æ–¹æ¡ˆã€‚</p>
<ul>
<li>é’ˆå¯¹heterogeneityé—®é¢˜çš„æ¨¡å‹å«åšTranSparse(share)ï¼Œæ¨¡å‹å‚æ•°sparse degreeï¼Œtheta_rï¼Œæ˜¯ç”±ä¸‹åˆ—å…¬å¼ç¡®å®š:</li>
</ul>
<p><img src="media/TranSparse_equation1.png" alt="alt text"><br>å…¶ä¸­N_ræ˜¯è¯¥å…³ç³»ræ‰€è¿æ¥çš„tripletæ•°ç›®ï¼ŒN_r*æ˜¯æ•°æ®é›†ä¸­æœ€å¤§çš„å…³ç³»tripletæ•°ç›®ã€‚é€šè¿‡è¿™ä¸ªsparse degreeæˆ‘ä»¬å°±å¯ä»¥ç¡®å®šå‚æ•°çŸ©é˜µçš„ç¨€ç–ç¨‹åº¦äº†ã€‚entityçš„å‘é‡é€šè¿‡ä¸‹å¼è¿›è¡Œè½¬æ¢ï¼š<br><img src="media/TranSparse_equation2.png" alt="alt text"></p>
<ul>
<li>é’ˆå¯¹imbalanceé—®é¢˜æå‡ºçš„TranSparse(separate)æ–¹æ³•ä¹Ÿååˆ†ç±»ä¼¼ï¼Œå³åœ¨å…³ç³»çš„headå’Œtailä¸¤ç«¯ä½¿ç”¨ä¸åŒå¤æ‚åº¦çš„matrixã€‚sparse degreeçš„å…¬å¼ä¸ä¸Šé¢TranSparse(share)çš„å‡ ä¹ä¸€æ ·ï¼Œåªä¸è¿‡N_rå’ŒN_r*æ›¿æ¢æˆäº†entityçš„ä¸ªæ•°ã€‚å¦‚æœæŸä¸€ç«¯è¦è¿æ¥æ›´å¤šä¸åŒçš„entityï¼Œé‚£ä¹ˆè¿™ä¸€ç«¯å°±éœ€è¦æ›´å¤æ‚çš„æ¨¡å‹æ¥è¡¨å¾ï¼ˆmatrixæœ‰æ›´å¤šéé›¶å‚æ•°ï¼‰ã€‚</li>
</ul>
<p>ç¡®å®šè¿™ä¸ªsparse degreeä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥åˆå§‹åŒ–å¯¹åº”çš„ç¨€ç–å‚æ•°çŸ©é˜µäº†ï¼ˆåŸæ–‡ä¸­æåˆ°äº†Structuredä¸Unstructuredä¸¤ç§çŸ©é˜µå½¢å¼ï¼‰ã€‚ç›®æ ‡å‡½æ•°ä»¥åŠè®­ç»ƒè¿‡ç¨‹ä¸å…¶ä»–å·¥ä½œä¸€è‡´ï¼Œåªä¸è¿‡åœ¨è¿›è¡Œè®­ç»ƒæ—¶æˆ‘ä»¬åªå¯¹çŸ©é˜µä¸­çš„éé›¶éƒ¨åˆ†è¿›è¡Œæ›´æ–°ã€‚</p>
<p>æœ€åæ¨¡å‹åœ¨tripletåˆ†ç±»å’Œé“¾æ¥é¢„æµ‹ä»»åŠ¡ä¸Šè¿›è¡Œå®éªŒï¼Œç›¸æ¯”äºå…ˆå‰æ¨¡å‹å–å¾—äº†æ›´å¥½çš„æˆç»©ï¼Œä¸è¿‡ç›¸æ¯”äºTranDä¼˜åŠ¿å¹¶ä¸ååˆ†æ˜æ˜¾ã€‚æå‡ºçš„ä¸¤ä¸ªæ¨¡å‹ä¸­TranSparse(separate)çš„è¡¨ç°æ›´å¥½ã€‚</p>
<h2 id="èµ„æº-6"><a href="#èµ„æº-6" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æ•°æ®é›† WordNet    <a href="http://wordnet.princeton.edu/wordnet/download/" target="_blank" rel="external">http://wordnet.princeton.edu/wordnet/download/</a><br>æ•°æ®é›† Freebase   <a href="http://developers.google.com/freebase/" target="_blank" rel="external">http://developers.google.com/freebase/</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-5"><a href="#ç›¸å…³å·¥ä½œ-5" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>ä¸Šé¢çš„ç›¸å…³å·¥ä½œå·²ç»ä»‹ç»å·®ä¸å¤šäº†ï¼Œè¿™é‡Œä¸å†èµ˜è¿°ã€‚</p>
<h2 id="ç®€è¯„-6"><a href="#ç®€è¯„-6" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>TranSparseæ¨¡å‹ä¸»è¦æ˜¯ä¸ºäº†è§£å†³å…³ç³»å’Œå®ä½“çš„å¼‚è´¨æ€§å’Œä¸å¹³è¡¡æ€§è€Œæå‡ºï¼Œé—®é¢˜é’ˆå¯¹æ€§å¼ºã€‚</p>
<h2 id="æ€»ç»“ä¸å±•æœ›"><a href="#æ€»ç»“ä¸å±•æœ›" class="headerlink" title="æ€»ç»“ä¸å±•æœ›"></a>æ€»ç»“ä¸å±•æœ›</h2><p>æœ€è¿‘å‡ å¹´äººä»¬å¯¹çŸ¥è¯†è¡¨ç¤ºæ–¹æ³•çš„æ¢ç©¶ä¸€ç›´éƒ½åœ¨è¿›è¡Œï¼ŒçŸ¥è¯†è¡¨ç¤ºå­¦ä¹ å¯¹äºè®¡ç®—æœºå¦‚ä½•ç†è§£å’Œè®¡ç®—çŸ¥è¯†çš„æ„ä¹‰æ˜¯é‡å¤§çš„ã€‚åœ¨2013å¹´embeddingçš„æ€æƒ³å‡ºç°ä¹‹å‰ï¼Œäººä»¬åŸºæœ¬é‡‡ç”¨one-hotçš„è¡¨ç¤ºæ–¹æ³•æ¥è¡¨ç¤ºå®ä½“ï¼Œè¿‘å‡ å¹´çŸ¥è¯†è¡¨ç¤ºçš„æ ¸å¿ƒæ€æƒ³å°±æ˜¯å¦‚ä½•æ‰¾åˆ°åˆé€‚çš„æ–¹æ³•æ¥å°†çŸ¥è¯†å›¾è°±emmbeddingåˆ°å‘é‡ç©ºé—´ï¼Œä»è€Œåœ¨å‘é‡ç©ºé—´ä¸­è¿›è¡Œè®¡ç®—ï¼Œå¹¶ä¸”ä¹Ÿåœ¨è¿™æ–¹é¢å–å¾—äº†ä¸é”™çš„è¿›å±•ã€‚</p>
<p>ä½†çŸ¥è¯†è¡¨ç¤ºå­¦ä¹ ä»ç„¶é¢ä¸´ç€æŒ‘æˆ˜ï¼Œä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼šï¼ˆ1ï¼‰å¯¹äºå¤šæºçŸ¥è¯†èåˆçš„è¡¨ç¤ºå­¦ä¹ ï¼Œå¦‚ä½•å°†çŸ¥è¯†åº“ä¸­çš„æ–‡æœ¬ç­‰ä¿¡æ¯åŠ å…¥åˆ°å­¦ä¹ ä¸­ã€‚ï¼ˆ2ï¼‰å¦‚ä½•è¿›è¡Œæ›´åŠ å¤æ‚çš„çŸ¥è¯†æ¨ç†ã€‚ï¼ˆ3ï¼‰å¯¹äºçŸ¥è¯†å›¾è°±æ— æ³•è¡¨è¾¾çš„ä¿¡æ¯ï¼Œåº”è¯¥è¿›è¡Œå¦‚ä½•è¡¨ç¤ºå’Œæ¨ç†ã€‚ï¼ˆ4ï¼‰å¦‚ä½•åœ¨çŸ¥è¯†åº“ä¸­èå…¥å¸¸è¯†ä¿¡æ¯ã€‚<br>å‚è€ƒæ–‡çŒ®è¯´æ˜ï¼šæœ¬æ–‡ä¸»è¦å‚è€ƒæ¸…åå¤§å­¦åˆ˜çŸ¥è¿œè€å¸ˆçš„ã€ŠçŸ¥è¯†è¡¨ç¤ºå­¦ä¹ ç ”ç©¶è¿›å±•ã€‹è¿™ç¯‡ç»¼è¿°ã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-10-15T17:39:35.000Z"><a href="/2016/10/15/cs-CL-weekly-2016-10-10-2016-10-14/">2016-10-15</a></time>
      
      
  
    <h1 class="title"><a href="/2016/10/15/cs-CL-weekly-2016-10-10-2016-10-14/">cs.CL weekly 2016.10.10-2016.10.14</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="ä¸€å‘¨å€¼å¾—è¯»"><a href="#ä¸€å‘¨å€¼å¾—è¯»" class="headerlink" title="ä¸€å‘¨å€¼å¾—è¯»"></a>ä¸€å‘¨å€¼å¾—è¯»</h1><h2 id="Personalizing-a-Dialogue-System-with-Transfer-Learning"><a href="#Personalizing-a-Dialogue-System-with-Transfer-Learning" class="headerlink" title="Personalizing a Dialogue System with Transfer Learning"></a><a href="https://arxiv.org/pdf/1610.02891v1.pdf" target="_blank" rel="external">Personalizing a Dialogue System with Transfer Learning</a></h2><p>ã€å¯¹è¯ç³»ç»Ÿã€‘ã€è¿ç§»å­¦ä¹ ã€‘é¢å‘å…·ä½“ä»»åŠ¡çš„å¯¹è¯ç³»ç»Ÿç”±äºæ•°æ®ä¸å……åˆ†ï¼Œé¢ä¸´éš¾ä»¥è®­ç»ƒçš„å°´å°¬å¢ƒåœ°ã€‚è§£å†³è¿™ä¸€é—®é¢˜çš„æ–¹æ³•ä¹‹ä¸€æ˜¯ç”¨è¿ç§»å­¦ä¹ æ¥åšï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºPOMDPçš„è¿ç§»å­¦ä¹ æ¡†æ¶ã€‚å¹¶ä¸”åœ¨è´­ä¹°å’–å•¡çš„å®é™…åœºæ™¯ä¸­å¾—åˆ°äº†åº”ç”¨ï¼Œå–å¾—äº†ä¸é”™çš„æ•ˆæœã€‚æ¸¯ç§‘å¤§æ¨å¼ºè€å¸ˆæ˜¯è¿ç§»å­¦ä¹ é¢†åŸŸçš„ä¸“å®¶ï¼Œè€Œè¿ç§»å­¦ä¹ æ˜¯è§£å†³æœºå™¨å­¦ä¹ ä¸­é¢†åŸŸæ•°æ®è¿‡å°é—®é¢˜çš„ä¸€ç§æœ‰æ•ˆæ–¹æ³•ï¼Œç°æœ‰çš„ç‰¹æœ‰å¯¹è¯ç³»ç»Ÿé¢ä¸´ç€è¿™ä¸ªé—®é¢˜ï¼Œå°¤å…¶æ˜¯è¦æ±‚å¯¹è¯ç³»ç»Ÿå…·æœ‰ä¸ªæ€§åŒ–çš„ç‰¹ç‚¹æ—¶ã€‚æœ¬æ–‡å¯¹äºç ”ç©¶è¯­éŸ³å¯¹è¯ç³»ç»Ÿå’ŒèŠå¤©æœºå™¨äººéƒ½æœ‰ä¸€å®šçš„å¯å‘æ€§ã€‚</p>
<h2 id="Dialogue-Session-Segmentation-by-Embedding-Enhanced-TextTiling"><a href="#Dialogue-Session-Segmentation-by-Embedding-Enhanced-TextTiling" class="headerlink" title="Dialogue Session Segmentation by Embedding-Enhanced TextTiling"></a><a href="https://arxiv.org/pdf/1610.03955v1.pdf" target="_blank" rel="external">Dialogue Session Segmentation by Embedding-Enhanced TextTiling</a></h2><p>ã€chatbotã€‘ã€ä¸Šä¸‹æ–‡å¤„ç†ã€‘æœ¬æ–‡ç ”ç©¶çš„å†…å®¹æ˜¯å¼€æ”¾åŸŸèŠå¤©æœºå™¨äººcontextå¤„ç†çš„é—®é¢˜ï¼Œå½“å‰èŠå¤©çš„å†…å®¹å¾ˆå¤§ç¨‹åº¦ä¸Šéƒ½ä¼šä¸ä¹‹å‰çš„èŠå¤©å†…å®¹æœ‰ç›¸å…³ï¼Œä½†å¹¶ä¸æ˜¯æ¯ä¸€å¥éƒ½ç›¸å…³ï¼Œå› æ­¤ç®—å¥½ç›¸å…³åº¦å¾ˆæœ‰å¿…è¦ã€‚</p>
<h2 id="Exploiting-Sentence-and-Context-Representations-in-Deep-Neural-Models-for-Spoken-Language-Understanding"><a href="#Exploiting-Sentence-and-Context-Representations-in-Deep-Neural-Models-for-Spoken-Language-Understanding" class="headerlink" title="Exploiting Sentence and Context Representations in Deep Neural Models for Spoken Language Understanding"></a><a href="https://arxiv.org/pdf/1610.04120v1.pdf" target="_blank" rel="external">Exploiting Sentence and Context Representations in Deep Neural Models for Spoken Language Understanding</a></h2><p>ã€å¯¹è¯ç³»ç»Ÿã€‘ã€æ·±åº¦å­¦ä¹ ã€‘æœ¬æ–‡æ˜¯steve youngç»„çš„ä¸€ç¯‡æ–°æ–‡ï¼Œæ—¨åœ¨æ¢ç´¢CNNè¡¨ç¤ºå¯¹è¯å¥å­å’ŒLSTMè¡¨ç¤ºä¸Šä¸‹æ–‡ä¿¡æ¯åœ¨å¯¹è¯ç†è§£é—®é¢˜ä¸Šçš„æ•ˆæœï¼Œç›¸æ¯”äºä¼ ç»Ÿæ–¹æ³•ï¼ŒDNNæ–¹æ³•é²æ£’æ€§æ›´å¼ºã€‚</p>
<h2 id="Latent-Sequence-Decompositions"><a href="#Latent-Sequence-Decompositions" class="headerlink" title="Latent Sequence Decompositions"></a><a href="https://arxiv.org/pdf/1610.03035v1.pdf" target="_blank" rel="external">Latent Sequence Decompositions</a></h2><p>ã€seq2seqã€‘æœ¬æ–‡ç ”ç©¶çš„å†…å®¹æ˜¯å¯¹seq2seqæ¡†æ¶ä¸­è¾“å…¥å’Œè¾“å‡ºåºåˆ—è¿›è¡Œæœ‰æ„ä¹‰åˆ†è§£çš„é—®é¢˜ï¼Œè€Œä¸æ˜¯ç®€å•åœ°åˆ†è§£ä¸ºcharï¼Œæå‡ºäº†ä¸€ç§Latent Sequence Decompositionsæ¡†æ¶ï¼Œåœ¨è¯­éŸ³è¯†åˆ«é—®é¢˜ä¸Šå–å¾—äº†ä¸é”™çš„æ•ˆæœã€‚å…¶å®ä¸ä»…ä»…æ˜¯è¯­éŸ³è¯†åˆ«é—®é¢˜ï¼Œåœ¨ç”¨seq2seqæ¡†æ¶æ—¶æ€»ä¼šé‡åˆ°OOVçš„é—®é¢˜ï¼Œcharæ˜¯ä¸€ç§æ–¹æ³•ï¼Œä½†ä¿¡æ¯é‡å¤ªå°‘ï¼Œå¦‚æœèƒ½å¤Ÿå°†word sequenceåˆ†è§£ä¸ºæ›´åŠ æœ‰æ„ä¹‰çš„å­åºåˆ—ï¼Œæ—¢å…¼é¡¾äº†ä¿¡æ¯é‡ï¼Œåˆé™ä½äº†è¯è¡¨ç»´åº¦ã€‚å¯¹è‹±æ–‡ç³»çš„è¯­è¨€æ•ˆæœå¥½ä¸€äº›ï¼Œä¸­æ–‡æ•ˆæœåº”è¯¥ä¸ä¼šé‚£ä¹ˆæ˜æ˜¾ã€‚</p>
<h2 id="Diverse-Beam-Search-Decoding-Diverse-Solutions-from-Neural-Sequence-Models"><a href="#Diverse-Beam-Search-Decoding-Diverse-Solutions-from-Neural-Sequence-Models" class="headerlink" title="Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models"></a><a href="https://arxiv.org/pdf/1610.02424v1.pdf" target="_blank" rel="external">Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models</a></h2><p>ã€seq2seqã€‘seq2seqæ¡†æ¶ä¸­åœ¨è§£ç é˜¶æ®µï¼Œå¸¸å¸¸ä¼šç”¨beam searchæ¥ä»å·¦è‡³å³ã€è´ªå¿ƒåœ°ç”ŸæˆNä¸ªæœ€å¥½çš„è¾“å‡ºï¼Œä¸ä»…ä»…æ•ˆç‡ä½ä¸‹ï¼Œè€Œä¸”åœ¨å¾ˆå¤šå¤æ‚ä»»åŠ¡ä¸­æ•ˆæœä¸å¥½ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æœç´¢ç®—æ³•ã€‚ç®—æ³•ä¼šåœ¨è§£ç©ºé—´å†…explorationå’Œexploitationï¼Œé€šè¿‡è®¾å®šdiverseçš„ç›®æ ‡è¿›è¡Œè®­ç»ƒï¼Œå¾—åˆ°ç»“æœã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæœ¬æ–‡çš„æ–¹æ³•æ›´åŠ é«˜æ•ˆã€‚å¹¶ä¸”åœ¨image  captionã€VQAå’ŒMTç­‰ä»»åŠ¡ä¸­è¿›è¡Œäº†éªŒè¯ã€‚</p>
<h2 id="Gated-End-to-End-Memory-Networks"><a href="#Gated-End-to-End-Memory-Networks" class="headerlink" title="Gated End-to-End Memory Networks"></a><a href="https://arxiv.org/pdf/1610.04211v1.pdf" target="_blank" rel="external">Gated End-to-End Memory Networks</a></h2><p>ã€seq2seqã€‘ã€memory networksã€‘ç«¯åˆ°ç«¯çš„è®°å¿†ç½‘ç»œåœ¨ç®€å•çš„æœºå™¨é˜…è¯»ç†è§£ä»»åŠ¡ä¸Šå–å¾—äº†ä¸é”™çš„æ•ˆæœï¼Œä½†å¤æ‚çš„äº‹å®é—®ç­”å’Œå¯¹è¯ç†è§£ç›¸å…³çš„ä»»åŠ¡å¤„ç†çš„å¹¶ä¸å¥½ï¼ŒåŸå› åœ¨äºè®°å¿†å•å…ƒä¸æ¨¡å‹ä¹‹é—´äº¤äº’å¤æ‚ã€‚æœ¬æ–‡é’ˆå¯¹è¯¥é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§Gatedè®°å¿†ç½‘ç»œï¼Œå–å¾—äº†ä¸é”™çš„æ•ˆæœã€‚æœ¬æ–‡æ¨¡å‹åœ¨æœºå™¨é˜…è¯»ç†è§£bAbI datasetå’Œtask-oriented å¯¹è¯ç³»ç»Ÿä»»åŠ¡DSTC2ä¸­å‡å–å¾—äº†éå¸¸å¥½çš„ç»“æœã€‚</p>
<h2 id="Neural-Paraphrase-Generation-with-Stacked-Residual-LSTM-Networks"><a href="#Neural-Paraphrase-Generation-with-Stacked-Residual-LSTM-Networks" class="headerlink" title="Neural Paraphrase Generation with Stacked Residual LSTM Networks"></a><a href="https://arxiv.org/pdf/1610.03098v3.pdf" target="_blank" rel="external">Neural Paraphrase Generation with Stacked Residual LSTM Networks</a></h2><p>ã€paraphraseã€‘æœ¬æ–‡æå‡ºç”¨å¤šå±‚æ®‹å·®LSTMç½‘ç»œæ¥åšparaphraseçš„ä»»åŠ¡ï¼Œå¾—åˆ°äº†æ¯”ä¹‹å‰seq2seqä»¥åŠseq2seq+attentionæ›´å¥½çš„æ•ˆæœã€‚è½¬è¿°åœ¨æŸä¸ªè§’åº¦ä¸Šå’Œæ ‡é¢˜ç”Ÿæˆï¼ˆå¥å­levelæ‘˜è¦ï¼‰ç±»ä¼¼ï¼Œæ–¹æ³•å¯å€Ÿé‰´ã€‚</p>
<h2 id="SentiHood-Targeted-Aspect-Based-Sentiment-Analysis-Dataset-for-Urban-Neighbourhoods"><a href="#SentiHood-Targeted-Aspect-Based-Sentiment-Analysis-Dataset-for-Urban-Neighbourhoods" class="headerlink" title="SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods"></a><a href="https://arxiv.org/pdf/1610.03771v1.pdf" target="_blank" rel="external">SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods</a></h2><p>ã€è§‚ç‚¹æŒ–æ˜ã€‘ã€æ•°æ®é›†ã€‘æœ¬æ–‡ç»™å‡ºäº†ä¸€ä¸ªè§‚ç‚¹æŒ–æ˜çš„æ•°æ®é›†ï¼Œæ•°æ®æºæ¥è‡ªYahooé—®ç­”ä¸­ä¸Londonç›¸å…³çš„æé—®ã€‚è¿™ä¸ªæ•°æ®é›†é€‚åˆè¿™æ ·çš„åœºæ™¯ï¼Œä¸€æ®µè¯„è®ºä¸­åŒ…å«äº†å¤šä¸ªentityçš„å¤šä¸ªaspectçš„è§‚ç‚¹ï¼Œç›¸äº’ä¹‹é—´æœ‰ä¸€äº›æ¯”è¾ƒã€‚</p>
<h2 id="Domain-specific-Question-Generation-from-a-Knowledge-Base"><a href="#Domain-specific-Question-Generation-from-a-Knowledge-Base" class="headerlink" title="Domain-specific Question Generation from a Knowledge Base"></a><a href="https://arxiv.org/pdf/1610.03807v1.pdf" target="_blank" rel="external">Domain-specific Question Generation from a Knowledge Base</a></h2><p>ã€é—®é¢˜ç”Ÿæˆã€‘é—®ç­”ç³»ç»Ÿæ˜¯ä¸€ä¸ªçƒ­é—¨ç ”ç©¶é¢†åŸŸï¼Œå…¶å…³æ³¨ç‚¹åœ¨äºå¦‚ä½•ç†è§£é—®é¢˜ç„¶åé€‰æ‹©æˆ–è€…ç”Ÿæˆç›¸åº”çš„ç­”æ¡ˆã€‚è€Œæœ¬æ–‡ç ”ç©¶çš„é—®é¢˜æ˜¯å¦‚ä½•æ ¹æ®çŸ¥è¯†å›¾è°±ç”Ÿæˆé«˜è´¨é‡çš„é—®é¢˜ã€‚æå‡ºé«˜è´¨é‡çš„é—®é¢˜éš¾åº¦å¾ˆå¤§ï¼Œä¸”çœ‹æœ¬æ–‡å†…å®¹ã€‚</p>
<h2 id="Compressing-Neural-Language-Models-by-Sparse-Word-Representations"><a href="#Compressing-Neural-Language-Models-by-Sparse-Word-Representations" class="headerlink" title="Compressing Neural Language Models by Sparse Word Representations"></a><a href="https://arxiv.org/pdf/1610.03950v1.pdf" target="_blank" rel="external">Compressing Neural Language Models by Sparse Word Representations</a></h2><p>ã€è¯­è¨€æ¨¡å‹ã€‘ã€æå‡æ•ˆç‡ã€‘æœ¬æ–‡è§£å†³çš„æ˜¯åœ¨å­¦ä¹ è¯­è¨€æ¨¡å‹æ—¶è¾“å‡ºå±‚è¯è¡¨è¿‡å¤§çš„é—®é¢˜ï¼Œè¯è¡¨è¿‡å¤§å¯¼è‡´æ•ˆç‡è¿‡ä½ï¼Œæœ¬æ–‡é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å‹ç¼©æ–¹æ³•ï¼Œå¸¸è§è¯ç”¨denseå‘é‡æ¥è¡¨ç¤ºï¼Œè€Œç½•è§è¯ç”¨å¸¸è§è¯çš„çº¿æ€§ç»„åˆæ¥è¡¨ç¤ºã€‚</p>
<h1 id="ä¸€å‘¨èµ„æº"><a href="#ä¸€å‘¨èµ„æº" class="headerlink" title="ä¸€å‘¨èµ„æº"></a>ä¸€å‘¨èµ„æº</h1><h2 id="CCL-amp-NLP-NABD-2016è®ºæ–‡é›†"><a href="#CCL-amp-NLP-NABD-2016è®ºæ–‡é›†" class="headerlink" title="CCL &amp; NLP-NABD 2016è®ºæ–‡é›†"></a><a href="http://www.cips-cl.org/static/CCL2016/index.html" target="_blank" rel="external">CCL &amp; NLP-NABD 2016è®ºæ–‡é›†</a></h2><p>ç”±Springerå‡ºç‰ˆçš„CCL &amp; NLP-NABD 2016è®ºæ–‡é›†å·²ç»å…¬å¸ƒï¼Œå¹¶åœ¨10æœˆ10æ—¥-11æœˆ10æ—¥æœŸé—´å¯ä»¥å…è´¹ä¸‹è½½ã€‚å…è´¹ä¸‹è½½æ–¹å¼å¦‚ä¸‹ï¼šï¼ˆ1ï¼‰è®¿é—®ä¼šè®®é¦–é¡µï¼›ï¼ˆ2ï¼‰ç‚¹å‡»è¯¥é¡µé¢æœ€æ–°â€œä¼šè®®è®ºæ–‡ä¸‹è½½â€ä¸­çš„é“¾æ¥ï¼›ï¼ˆ3ï¼‰ç‚¹å‡»æ–°é¡µé¢çš„â€œDownload Book (PDF, 35547KB)â€æŒ‰é’®ã€‚</p>
<h2 id="åŒ—äº¬å¤§å­¦ä¸‡å°å†›è€å¸ˆç»„å¼€æºè‡ªåŠ¨æ‘˜è¦å°å·¥å…·PKUSUMSUM"><a href="#åŒ—äº¬å¤§å­¦ä¸‡å°å†›è€å¸ˆç»„å¼€æºè‡ªåŠ¨æ‘˜è¦å°å·¥å…·PKUSUMSUM" class="headerlink" title="åŒ—äº¬å¤§å­¦ä¸‡å°å†›è€å¸ˆç»„å¼€æºè‡ªåŠ¨æ‘˜è¦å°å·¥å…·PKUSUMSUM"></a><a href="http://www.icst.pku.edu.cn/lcwm/wanxj/pkusumsum.htm" target="_blank" rel="external">åŒ—äº¬å¤§å­¦ä¸‡å°å†›è€å¸ˆç»„å¼€æºè‡ªåŠ¨æ‘˜è¦å°å·¥å…·PKUSUMSUM</a></h2><p>æœ¬ç»„æ¨å‡ºæ–‡æ¡£è‡ªåŠ¨æ‘˜è¦å°å·¥å…·PKUSUMSUMï¼Œé›†æˆå¤šç§æ— ç›‘ç£æ‘˜è¦æå–ç®—æ³•ï¼Œæ”¯æŒå¤šç§æ‘˜è¦ä»»åŠ¡ä¸å¤šç§è¯­è¨€ï¼Œé‡‡ç”¨Javaç¼–å†™ï¼Œä»£ç å®Œå…¨å¼€æºï¼Œæ¬¢è¿æ‰¹è¯„æŒ‡æ­£ï¼Œä¹Ÿæ¬¢è¿åŒè¡Œä¸€èµ·å®Œå–„è¯¥å·¥å…·ã€‚</p>
<h2 id="æ–¯å¦ç¦å¤§å­¦NLPç»„2016å¹´ç§‹å­£paperé˜…è¯»å‘¨è®¡åˆ’"><a href="#æ–¯å¦ç¦å¤§å­¦NLPç»„2016å¹´ç§‹å­£paperé˜…è¯»å‘¨è®¡åˆ’" class="headerlink" title="æ–¯å¦ç¦å¤§å­¦NLPç»„2016å¹´ç§‹å­£paperé˜…è¯»å‘¨è®¡åˆ’"></a><a href="http://nlp.stanford.edu/read/" target="_blank" rel="external">æ–¯å¦ç¦å¤§å­¦NLPç»„2016å¹´ç§‹å­£paperé˜…è¯»å‘¨è®¡åˆ’</a></h2><p>æ–¯å¦ç¦å¤§å­¦NLPç»„2016å¹´ç§‹å­£paperé˜…è¯»å‘¨è®¡åˆ’ï¼ŒæŒºå¤šç¯‡éƒ½æ˜¯å¯¹è¯ç³»ç»Ÿç›¸å…³çš„ã€‚ </p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-10-14T04:09:21.000Z"><a href="/2016/10/13/PaperWeekly-ç¬¬ä¹æœŸ/">2016-10-13</a></time>
      
      
  
    <h1 class="title"><a href="/2016/10/13/PaperWeekly-ç¬¬ä¹æœŸ/">PaperWeekly ç¬¬ä¹æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•è¨€"><a href="#å¼•è¨€" class="headerlink" title="å¼•è¨€"></a>å¼•è¨€</h1><p>æ·±åº¦ç”Ÿæˆæ¨¡å‹åŸºæœ¬éƒ½æ˜¯ä»¥æŸç§æ–¹å¼å¯»æ‰¾å¹¶è¡¨è¾¾ï¼ˆå¤šå˜é‡ï¼‰æ•°æ®çš„æ¦‚ç‡åˆ†å¸ƒã€‚æœ‰åŸºäºæ— å‘å›¾æ¨¡å‹ï¼ˆé©¬å°”å¯å¤«æ¨¡å‹ï¼‰çš„è”åˆæ¦‚ç‡åˆ†å¸ƒæ¨¡å‹ï¼Œå¦å¤–å°±æ˜¯åŸºäºæœ‰å‘å›¾æ¨¡å‹ï¼ˆè´å¶æ–¯æ¨¡å‹ï¼‰çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒã€‚å‰è€…çš„æ¨¡å‹æ˜¯æ„å»ºéšå«å±‚(latent)å’Œæ˜¾ç¤ºå±‚ï¼ˆvisible)çš„è”åˆæ¦‚ç‡ï¼Œç„¶åå»é‡‡æ ·ã€‚åŸºäºæœ‰å‘å›¾çš„åˆ™æ˜¯å¯»æ‰¾latentå’Œvisibleä¹‹é—´çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒï¼Œä¹Ÿå°±æ˜¯ç»™å®šä¸€ä¸ªéšæœºé‡‡æ ·çš„éšå«å±‚ï¼Œæ¨¡å‹å¯ä»¥ç”Ÿæˆæ•°æ®ã€‚</p>
<p>ç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒæ˜¯ä¸€ä¸ªéç›‘ç£è¿‡ç¨‹ï¼Œè¾“å…¥åªéœ€è¦æ— æ ‡ç­¾çš„æ•°æ®ã€‚é™¤äº†å¯ä»¥ç”Ÿæˆæ•°æ®ï¼Œè¿˜å¯ä»¥ç”¨äºåŠç›‘ç£çš„å­¦ä¹ ã€‚æ¯”å¦‚ï¼Œå…ˆåˆ©ç”¨å¤§é‡æ— æ ‡ç­¾æ•°æ®è®­ç»ƒå¥½æ¨¡å‹ï¼Œç„¶ååˆ©ç”¨æ¨¡å‹å»æå–æ•°æ®ç‰¹å¾ï¼ˆå³ä»æ•°æ®å±‚åˆ°éšå«å±‚çš„ç¼–ç è¿‡ç¨‹ï¼‰ï¼Œä¹‹åç”¨æ•°æ®ç‰¹å¾ç»“åˆæ ‡ç­¾å»è®­ç»ƒæœ€ç»ˆçš„ç½‘ç»œæ¨¡å‹ã€‚å¦ä¸€ç§æ–¹æ³•æ˜¯åˆ©ç”¨ç”Ÿæˆæ¨¡å‹ç½‘ç»œä¸­çš„å‚æ•°å»åˆå§‹åŒ–ç›‘ç£è®­ç»ƒä¸­çš„ç½‘ç»œæ¨¡å‹ï¼Œå½“ç„¶ï¼Œä¸¤ä¸ªæ¨¡å‹éœ€è¦ç»“æ„ä¸€è‡´ã€‚</p>
<p>ç”±äºå®é™…ä¸­ï¼Œæ›´å¤šçš„æ•°æ®æ˜¯æ— æ ‡ç­¾çš„ï¼Œå› æ­¤éç›‘ç£å’ŒåŠç›‘ç£å­¦ä¹ éå¸¸é‡è¦ï¼Œå› æ­¤ç”Ÿæˆæ¨¡å‹ä¹Ÿéå¸¸é‡è¦ã€‚æœ¬ç¯‡ä¸»è¦ä»‹ç»ä¸€ç§åŸºäºå¯¹æŠ—æ¨¡å¼çš„ç”Ÿæˆæ¨¡å‹ï¼ŒGAN ï¼ ä»ç¬¬ä¸€ç¯‡æå‡ºæ­¤æ¨¡å‹çš„è®ºæ–‡å¼€å§‹ï¼Œä¹‹åç´§æ¥ç€ä¸¤ç¯‡åŸºäºå®ƒçš„å®ç°ä»¥åŠæ”¹è¿›ã€‚ä¸‰ç¯‡æ–‡ç« ä¸€è„‰ç›¸æ‰¿ï¼Œå¯ä»¥çœ‹åˆ°ç»“åˆè¿™ç§æ¨¡å‹çš„ç ”ç©¶è¿›å±•åŠæ–¹å‘ã€‚</p>
<h1 id="Generative-Adversarial-Nets"><a href="#Generative-Adversarial-Nets" class="headerlink" title="Generative Adversarial Nets"></a><a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="external">Generative Adversarial Nets</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Universite of Montreal</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>ç”Ÿæˆæ¨¡å‹ ï¼ˆGenerative modelï¼‰</p>
<h2 id="æ–‡ç« æ¥æº"><a href="#æ–‡ç« æ¥æº" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>NIPS 2014</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>é€šè¿‡æ¨¡æ‹Ÿå¯¹æŠ—è¿‡ç¨‹ï¼Œæå‡ºä¸€ç§æ–°çš„ç”Ÿæˆæ¨¡å‹æ¡†æ¶</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><ul>
<li>å»ºæ¨¡</li>
</ul>
<p>åœ¨å¯¹æŠ—ç”Ÿæˆæ¨¡å‹ä¸­ï¼ŒåŒæ—¶è®­ç»ƒä¸¤ä¸ªç½‘ç»œï¼Œç¬¬ä¸€ä¸ªç½‘ç»œæ˜¯ç”Ÿæˆç½‘ç»œï¼ŒG(z)ï¼Œè¾“å…¥zä¸€èˆ¬æ˜¯æ¥è‡ªå¸¸è§æ¦‚ç‡åˆ†å¸ƒå‡½æ•°çš„æ ·æœ¬å‘é‡ï¼Œç»´åº¦ä¸€èˆ¬æ¯”è¾ƒä½ï¼Œæ¯”å¦‚100ã€‚ç”Ÿæˆç½‘ç»œè¾“å…¥å‘é‡zï¼Œè¾“å‡ºå›¾ç‰‡æ ·ä¾‹ï¼Œå¦‚æœä½¿ç”¨å·æœºç½‘å®ç°çš„è¯ï¼Œæ•´ä¸ªç½‘ç»œå¯ä»¥çœ‹è¿‡ä¸€ä¸ªåå‘çš„CNNï¼Œå…¶ä¸­çš„å·ç§¯å±‚æ›¿æ¢æˆ transposed convolution layerã€‚ç¬¬äºŒä¸ªç½‘ç»œæ˜¯è¯†åˆ«ç½‘ç»œdiscriminator net - D(x)ï¼Œè¾“å…¥ä¸ºä¸€å¼ å›¾ç‰‡xï¼Œè€Œè¾“å‡ºä¸ºä¸€ä¸ªæ ‡é‡ï¼Œç”¨æ¥ä»£è¡¨xæ¥è‡ªçœŸå®å›¾ç‰‡çš„æ¦‚ç‡ã€‚</p>
<ul>
<li>è®­ç»ƒ</li>
</ul>
<p>æ•´ä¸ªç½‘ç»œçš„losså®šä¹‰ä¸º</p>
<p>V = Eâ€™[log D(x)] + Eâ€™â€™[log (1 - D(G(z)) )]<br>Eâ€™ - å½“xæ¥è‡ªçœŸå®æ•°æ®çš„æœŸæœ›<br>Eâ€™â€™ - å½“xæ¥è‡ªç”Ÿæˆç½‘ç»œçš„æœŸæœ›</p>
<p>å¾ˆæ˜¾ç„¶ï¼Œåœ¨å¯¹æŠ—ç½‘ç»œä¸­ï¼Œç”Ÿæˆæ¨¡å‹å¸Œæœ›èƒ½å¤Ÿå¢å¤§D(G(z))ï¼Œå³ï¼Œå¸Œæœ›ç”Ÿæˆçš„å›¾ç‰‡è¶ŠçœŸå®è€Œè®©è¯†åˆ«æ¨¡å‹â€œè¯¯ä»¥ä¸ºâ€æ˜¯æ¥è‡ªçœŸå®çš„å›¾ç‰‡é›†ã€‚</p>
<p>å¦‚æœç”Ÿæˆç½‘ç»œGçš„å‚æ•°ç”¨thetaè¡¨ç¤ºï¼Œè¯†åˆ«æ¨¡å‹çš„å‚æ•°ç”¨theta_dè¡¨ç¤ºï¼Œåœ¨ä½¿ç”¨SGDè®­ç»ƒçš„æ—¶å€™ï¼Œä¸¤ç»„å‚æ•°åˆ†åˆ«è¿›è¡Œè®­ç»ƒï¼Œå¯¹äºDæ¥è¯´ï¼Œéœ€è¦å¯¹ä¸Šé¢çš„å…¬å¼æ±‚Gradientï¼Œä½†æ˜¯åªæ›´æ–°è‡ªå·±çš„å‚æ•°ã€‚å¯¹Gæ¥è¯´ï¼Œåªæœ‰ç¬¬äºŒé¡¹æ˜¯ç›¸å…³çš„ï¼Œè€Œä¸”å¯ä»¥ç­‰æ•ˆçš„è½¬æ¢ä¸ºmaximize log D(G(z))ã€‚ä¸¤ä¸ªç½‘ç»œçš„å‚æ•°æ›´æ–°äº¤æ›¿è¿›è¡Œã€‚</p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>ç½‘ä¸Šæœ‰å¾ˆå¤šå®ç°ï¼Œæ¯”å¦‚:</p>
<p><a href="https://github.com/goodfeli/adversarial" target="_blank" rel="external">goodfeli/adversarial</a>: Theano GAN implementation released by the authors of the GAN paper.<br><a href="https://github.com/Newmu/dcgan_code" target="_blank" rel="external">Newmu/dcgan_code</a>: Theano DCGAN implementation released by the authors of the DCGAN paper.<br><a href="https://github.com/carpedm20/DCGAN-tensorflow" target="_blank" rel="external">carpedm20/DCGAN-tensorflow</a>: Unofficial TensorFlow DCGAN implementation.</p>
<p>è¿™äº›å®ç°ä¸€èˆ¬éƒ½ä¼šåŒ…å«MNISTæµ‹è¯•é›†ã€‚</p>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>å…¶ä»–çš„ç”Ÿæˆæ¨¡å‹åŒ…æ‹¬restricted Boltzmann machine (RBM), deep Boltzmann machine (DBM) ä»¥åŠ variational autoencoder</p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>å…¶ä»–ç”Ÿæˆæ¨¡å‹ä¸­è®­ç»ƒè¿‡ç¨‹æ¶‰åŠintractableçš„è®¡ç®—ï¼Œåœ¨å®é™…å®ç°æ—¶å¾€å¾€é‡‡å–é©¬å°”å¯å¤«é“¾æ¨¡ç‰¹å¡æ´›é‡‡æ ·(MCMC)ã€‚å¯¹æŠ—ç”Ÿæˆæ¨¡å‹(GAN)åˆ™ä¸éœ€è¦ï¼Œæ•´ä¸ªç½‘ç»œçš„è®­ç»ƒå¯ä»¥ä½¿ç”¨backpropagationæ¥å®ç°ã€‚</p>
<p>ç¼ºç‚¹åŒ…æ‹¬è®­ç»ƒä¸ç¨³å®šï¼Œç”Ÿæˆç½‘ç»œä¼šå¡Œé™·åˆ°æŸäº›æ•°æ®ç‚¹ï¼ˆæ¯”å¦‚è¿™äº›æ•°æ®ç‚¹ç›®å‰çœ‹æœ€åƒçœŸå®æ•°æ®ï¼Œç”Ÿæˆç½‘ç»œä¼šä¸åœç”Ÿæˆè¿™äº›æ•°æ®ç‚¹ï¼‰ï¼Œæ¥ä¸‹æ¥çš„å‡ ç¯‡ä¸­å°†æåŠå¦‚ä½•æ”¹è¿›ã€‚</p>
<h1 id="Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks-https-arxiv-org-abs-1511-06434"><a href="#Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks-https-arxiv-org-abs-1511-06434" class="headerlink" title="[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks] (https://arxiv.org/abs/1511.06434)"></a>[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks] (<a href="https://arxiv.org/abs/1511.06434" target="_blank" rel="external">https://arxiv.org/abs/1511.06434</a>)</h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Alec Radford, Luke Metz, Soumith Chintala</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>facebook</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>DCGAN, Representation Learning</p>
<h2 id="æ–‡ç« æ¥æº-1"><a href="#æ–‡ç« æ¥æº-1" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ICLR 2016</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>åŸºäºæ·±åº¦å·ç§¯ç½‘ç»œçš„ç”Ÿæˆå¯¹æŠ—æ¨¡å‹(DCGAN)å®ç°</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>åœ¨GANçš„è®ºæ–‡ä¸­æå‡ºçš„å¯¹æŠ—æ¨¡å‹çš„åŸå‹ï¼Œä½†æ˜¯å¯¹æŠ—æ¨¡å‹æ˜¯ä¸€ä¸ªå¤§çš„æ¡†æ¶ï¼Œå¹¶ä¸å±€é™äºæŸç§ç½‘ç»œå®ç°ã€‚æœ¬æ–‡ç»™å‡ºäº†åŸºäºå·æœºç½‘çš„å®ç°ã€‚</p>
<p>ç”Ÿæˆç½‘ç»œ<br><img src="media/gen-architecture-1.png" alt="gen-architecture"></p>
<p>å…¶ä¸­åå·ç§¯çš„è¿‡ç¨‹æ˜¯</p>
<p><img src="media/padding_strides_transposed-1.gif" alt="padding_strides_transposed"></p>
<p>è¯†åˆ«ç½‘ç»œæ˜¯ä¼ ç»Ÿçš„CNN</p>
<p><img src="media/discrim-architecture.png" alt="discrim-architecture"></p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡ç´§å¯†æ‰¿æ¥ä¸Šç¯‡è®ºæ–‡ï¼Œæè¿°äº†å®ç°è¿‡ç¨‹ä¸­çš„ç»†èŠ‚ï¼Œæ¯”å¦‚å‚æ•°è®¾ç½®ã€‚ä¹Ÿæåˆ°äº†è§£å†³GANä¸­è®­ç»ƒä¸ç¨³å®šçš„æªæ–½ï¼Œä½†æ˜¯å¹¶éå®Œå…¨è§£å†³ã€‚æ–‡ä¸­è¿˜æåˆ°åˆ©ç”¨å¯¹æŠ—ç”Ÿæˆç½‘ç»œæ¥åšåŠç›‘ç£å­¦ä¹ ã€‚åœ¨è®­ç»ƒç»“æŸåï¼Œè¯†åˆ«ç½‘ç»œå¯ä»¥ç”¨æ¥æå–å›¾ç‰‡ç‰¹å¾ï¼Œè¾“å…¥æœ‰æ ‡ç­¾çš„è®­ç»ƒå›¾ç‰‡ï¼Œå¯ä»¥å°†å·åŸºå±‚çš„è¾“å‡ºç‰¹å¾ä½œä¸ºXï¼Œæ ‡ç­¾ä½œä¸ºyåšè®­ç»ƒã€‚</p>
<h1 id="Improved-Techniques-for-Training-GANs"><a href="#Improved-Techniques-for-Training-GANs" class="headerlink" title="Improved Techniques for Training GANs"></a><a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="external">Improved Techniques for Training GANs</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>OpenAI</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>DCGAN</p>
<h2 id="æ–‡ç« æ¥æº-2"><a href="#æ–‡ç« æ¥æº-2" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ICLR 2016</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æå‡ºæ”¹è¿›DCGANçš„æªæ–½</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>è¿™ç¯‡è®ºæ–‡åŒæ ·è·Ÿå‰æ–‡éå¸¸ç´§å¯†ï¼Œå…·ä½“é’ˆå¯¹DCGANä¸­çš„é—®é¢˜ï¼Œæå‡ºäº†æ”¹è¿›æ–¹æ³•ã€‚å…·ä½“æœ‰</p>
<ul>
<li>feature matching è§£å†³è®­ç»ƒä¸ç¨³å®šinstabilityçš„é—®é¢˜</li>
<li>minibatch discrimination è§£å†³ç”Ÿæˆç½‘ç»œç”Ÿæˆå›¾ç‰‡é›†ä¸­çš„é—®é¢˜ï¼ŒåŸç†æ˜¯è®©è¯†åˆ«ç½‘ç»œä¸€æ¬¡çœ‹ä¸€ç»„å›¾ç‰‡ï¼Œè€Œä¸æ˜¯ä¸€å¼ å›¾ç‰‡</li>
<li>å¦‚æœå¯¹å®ç°æ„Ÿå…´è¶£ï¼Œå…¶ä»–æ”¹è¿›ç»†èŠ‚å¯ä»¥å‚è§è®ºæ–‡</li>
</ul>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>å¯¹æŠ—ç”Ÿæˆç½‘ç»œçš„æ¨¡å‹å¾ˆæœ‰æ„æ€ï¼ŒBengio, Hintonç­‰éƒ½è¡¨è¾¾äº†å¾ˆé«˜çš„è¯„ä»·ã€‚ç›¸å¯¹å…¶ä»–ç”Ÿæˆæ¨¡å¼è€Œè¨€ï¼Œå¯¹æŠ—ç”Ÿæˆæ¨¡å¼æ¨¡å‹æ¸…æ™°ç®€å•ï¼Œç›®å‰æ¥çœ‹æ•ˆæœä¹Ÿæ¯”è¾ƒä¸é”™ã€‚ä½†æ˜¯ç›®å‰å¯¹æŠ—ç”Ÿæˆç½‘ç»œä¹Ÿæœ‰å¾ˆå¤šé—®é¢˜ï¼Œæ¯”å¦‚ç”Ÿæˆæ¨¡å‹æ˜¯é€šè¿‡æ¥è‡ªæ¦‚ç‡åˆ†å¸ƒçš„å‘é‡ç”Ÿæˆæ ·æœ¬ï¼Œè€Œä¸æ˜¯ç›´æ¥è¡¨ç¤ºè¾“å…¥çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå› æ­¤ï¼Œç”Ÿæˆçš„å›¾ç‰‡å¯èƒ½ä¸ç¨³å®šä¹‹ç±»ã€‚æ­¤å¤–ï¼Œå¸Œæœ›èƒ½çœ‹åˆ°GANåœ¨è¯­è¨€æ¨¡å‹ä¸­çš„åº”ç”¨ã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>GANè¿™ç§æ¨¡å‹éå¸¸æ–°é¢–ï¼Œä»è®ºæ–‡ä¸­çš„ç»“æœæ¥çœ‹ï¼Œåœ¨å›¾åƒç”Ÿæˆä¸Šå–å¾—äº†ä¸é”™çš„æ•ˆæœï¼Œå¯¹äºMNISTè¿™ç§ç®€å•çš„å›¾å½¢æ•°æ®é›†ï¼Œç”Ÿæˆçš„å›¾ç‰‡å·²ç»å¯ä»¥â€œä»¥å‡ä¹±çœŸâ€ã€‚å¯¹äºå¦å¤–çš„å›¾ç‰‡ï¼Œæ¯”å¦‚åœ¨ç¬¬äºŒç¯‡è®ºæ–‡ä¸­çš„LSUN bedroomå›¾ç‰‡é›†ä»¥åŠäººè„¸å›¾ç‰‡é›†ä¸Šï¼Œç”Ÿæˆçš„å›¾ç‰‡æ•ˆæœä¹Ÿä¸é”™ï¼ˆåˆ†è¾¨ç‡64Ã—64ï¼‰ã€‚<br>GANç›®å‰æ¥çœ‹å·²ç»å·ç§¯ç½‘ç»œå›¾åƒç”Ÿæˆä¸­å–å¾—äº†ä¸é”™çš„æ•ˆæœï¼Œä½†æ˜¯è¿˜æœ‰å¾ˆå¤šé—®é¢˜éœ€è¦ç»§ç»­ç ”ç©¶æ”¹è¿›ï¼Œ æ¯”å¦‚<br>å¦‚ä½•ç”Ÿæˆé«˜åƒç´ é«˜è´¨é‡çš„å›¾ç‰‡ã€‚ç›®å‰ä¸€èˆ¬åƒç´ ä¸è¶…è¿‡64ã€‚<br>å¦‚ä½•æé«˜å¤æ‚å›¾ç‰‡çš„è´¨é‡ã€‚ç›®å‰åœ¨CIFARï¼ŒILSVRCç­‰å›¾ç‰‡é›†ä¸Šè®­ç»ƒç”Ÿæˆçš„å›¾ç‰‡è¿˜æ˜¯å¾ˆç³Ÿç³•ã€‚<br>å¦‚ä½•æé«˜æ•´ä¸ªæ¨¡å‹çš„ç¨³å®šæ€§ã€‚åœ¨å®é™…ä¸­ï¼Œå°¤å…¶å¯¹äºå¤æ‚å›¾å½¢ï¼Œç”Ÿæˆå™¨ç»å¸¸å¾ˆå¿«æ”¶æ•›åˆ°æŸäº›å•ä¸ªæ•°æ®é›†ï¼Œä½¿å¾—æ•´ä¸ªæ¨¡å‹çš„è®­ç»ƒé™·å…¥åƒµå±€ã€‚<br>å¦‚ä½•åœ¨å…¶ä»–é¢†åŸŸï¼Œæ¯”å¦‚NLPä½¿ç”¨GANï¼Œå¦‚ä½•å°†GANå’ŒLSTMç»“åˆçš„ã€‚ç›®å‰æ¥çœ‹ï¼Œè¿˜æ²¡æœ‰æˆåŠŸçš„åº”ç”¨ã€‚åŸæ–‡ä½œè€…åœ¨redditä¸Šå›ç­”å†…å®¹æ¥çœ‹ï¼Œç”±äºGANçš„è¾“å…¥æ˜¯é‡‡æ ·è‡ªè¿ç»­åˆ†å¸ƒï¼Œè€ŒNLPä¸­ï¼Œæ¯ä¸ªå•è¯çš„è¡¨è¾¾å¾€å¾€æ˜¯ç¦»æ•£çš„ï¼Œä½œè€…æåˆ°NLPå¯ä»¥ç”¨å¢å¼ºè®­ç»ƒçš„æ–¹æ³•æ›¿ä»£ã€‚ä½†æ˜¯ä¹Ÿä¸æ’é™¤å¯ä»¥æœ‰å…¶ä»–æ–¹æ³•å°†GANå’ŒLSTMç»“åˆèµ·æ¥çš„ï¼Œè¿™ä¹Ÿæ˜¯ä»¥åçš„ä¸€ä¸ªç ”ç©¶ç‚¹ã€‚</p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-10-08T02:06:28.000Z"><a href="/2016/10/07/cs-CL-weekly-2016-10-03-2016-10-07/">2016-10-07</a></time>
      
      
  
    <h1 class="title"><a href="/2016/10/07/cs-CL-weekly-2016-10-03-2016-10-07/">cs.CL weekly 2016.10.03-2016.10.07</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="ä¸€å‘¨å€¼å¾—è¯»ï¼ˆåå­¦æœ¯ï¼‰"><a href="#ä¸€å‘¨å€¼å¾—è¯»ï¼ˆåå­¦æœ¯ï¼‰" class="headerlink" title="ä¸€å‘¨å€¼å¾—è¯»ï¼ˆåå­¦æœ¯ï¼‰"></a>ä¸€å‘¨å€¼å¾—è¯»ï¼ˆåå­¦æœ¯ï¼‰</h1><h2 id="Controlling-Output-Length-in-Neural-Encoder-Decoders"><a href="#Controlling-Output-Length-in-Neural-Encoder-Decoders" class="headerlink" title="Controlling Output Length in Neural Encoder-Decoders"></a><a href="https://arxiv.org/pdf/1609.09552v1.pdf" target="_blank" rel="external">Controlling Output Length in Neural Encoder-Decoders</a></h2><p>æœ¬æ–‡é’ˆå¯¹encoder-decoderæ¡†æ¶åœ¨åº”ç”¨æ—¶æ— æ³•æ§åˆ¶ç”Ÿæˆåºåˆ—é•¿åº¦ï¼ˆæ¯”å¦‚æ–‡æœ¬æ‘˜è¦ï¼‰çš„é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºå­¦ä¹ çš„æ¨¡å‹æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚encoder-decoderæ¡†æ¶å·²ç»è¢«æˆåŠŸåº”ç”¨äºå„å¤§ä»»åŠ¡ä¸­ï¼ŒåŠ ä¸Šattentionï¼Œä¸åŒå˜ç§çš„attentionï¼Œç ”ç©¶çš„äººå¾ˆå¤šã€‚æœ¬æ–‡ä¹Ÿæ˜¯å±äºå˜ç§ä¹‹ä¸€ï¼Œè€ƒè™‘äº†åœ¨å®é™…åº”ç”¨ä¸­æ–‡æœ¬æ‘˜è¦é•¿åº¦éœ€è¦è¢«æ§åˆ¶çš„é—®é¢˜ï¼Œæå‡ºäº†æœ¬æ–‡çš„æ¨¡å‹ã€‚</p>
<h2 id="Embracing-data-abundance-BookTest-Dataset-for-Reading-Comprehension"><a href="#Embracing-data-abundance-BookTest-Dataset-for-Reading-Comprehension" class="headerlink" title="Embracing data abundance: BookTest Dataset for Reading Comprehension"></a><a href="https://arxiv.org/pdf/1610.00956v1.pdf" target="_blank" rel="external">Embracing data abundance: BookTest Dataset for Reading Comprehension</a></h2><p>ã€æ•°æ®ç¦åˆ©ã€‘æœ¬æ–‡å‘å¸ƒäº†ä¸€ä¸ªæ–°çš„æœºå™¨é˜…è¯»ç†è§£æ•°æ®é›†BookTestï¼Œè¯¥æ•°æ®é›†æœ€å¤§çš„äº®ç‚¹æ˜¯è§„æ¨¡å¤§ï¼Œæ˜¯Facebookå‘å¸ƒçš„Childrenâ€™s Book Testçš„60å€ä¹‹å¤§ã€‚</p>
<h2 id="Visual-Question-Answering-Datasets-Algorithms-and-Future-Challenges"><a href="#Visual-Question-Answering-Datasets-Algorithms-and-Future-Challenges" class="headerlink" title="Visual Question Answering: Datasets, Algorithms, and Future Challenges"></a><a href="https://arxiv.org/pdf/1610.01465v1.pdf" target="_blank" rel="external">Visual Question Answering: Datasets, Algorithms, and Future Challenges</a></h2><p>ã€ç»¼è¿°ã€‘è¿™æ˜¯ä¸€ç¯‡Visual Question Answerä»»åŠ¡çš„ç»¼è¿°æ€§æ–‡ç« ï¼Œç³»ç»Ÿåœ°æ€»ç»“ã€è®¨è®ºå’Œå¯¹æ¯”äº†è¿‘å‡ å¹´è¯¥é¢†åŸŸçš„æ•°æ®é›†å’Œç®—æ³•ï¼Œå¹¶ç»™å‡ºäº†ä¸€äº›è¯¥é¢†åŸŸæœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚</p>
<h2 id="Multi-View-Representation-Learning-A-Survey-from-Shallow-Methods-to-Deep-Methods"><a href="#Multi-View-Representation-Learning-A-Survey-from-Shallow-Methods-to-Deep-Methods" class="headerlink" title="Multi-View Representation Learning: A Survey from Shallow Methods to Deep Methods"></a><a href="https://arxiv.org/pdf/1610.01206v1.pdf" target="_blank" rel="external">Multi-View Representation Learning: A Survey from Shallow Methods to Deep Methods</a></h2><p>ã€ç»¼è¿°ã€‘æœ¬æ–‡æ˜¯ä¸€ç¯‡2015å¹´å‡ºç‰ˆçš„å¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ çš„ç»¼è¿°æ–‡ç« ï¼Œéå¸¸é€‚åˆåˆšåˆšäº†è§£æˆ–è€…å‡†å¤‡è¿›å…¥è¿™ä¸ªé¢†åŸŸçš„ç«¥é‹æ¥è¯»ã€‚ </p>
<h2 id="Neural-based-Noise-Filtering-from-Word-Embeddings"><a href="#Neural-based-Noise-Filtering-from-Word-Embeddings" class="headerlink" title="Neural-based Noise Filtering from Word Embeddings"></a><a href="https://arxiv.org/pdf/1610.01874v1.pdf" target="_blank" rel="external">Neural-based Noise Filtering from Word Embeddings</a></h2><p>è¯å‘é‡å·²ç»æ˜¯NLPä¸­å„ä»»åŠ¡çš„åŸºç¡€éƒ¨ä»¶ï¼Œå¯¹è¯å‘é‡çš„ç ”ç©¶å·¥ä½œä¹Ÿéå¸¸å¤šã€‚æœ¬æ–‡ç ”ç©¶çš„åˆ‡å…¥ç‚¹æ˜¯ä»è¯­æ–™ä¸­çš„å™ªå£°å…¥æ‰‹ï¼Œæå‡ºäº†ä¸¤ç§æ— ç›‘ç£å»å™ªæ¨¡å‹ï¼Œå–å¾—äº†ä¸é”™çš„æ•ˆæœã€‚</p>
<h1 id="ä¸€å‘¨å€¼å¾—è¯»ï¼ˆååº”ç”¨ï¼‰"><a href="#ä¸€å‘¨å€¼å¾—è¯»ï¼ˆååº”ç”¨ï¼‰" class="headerlink" title="ä¸€å‘¨å€¼å¾—è¯»ï¼ˆååº”ç”¨ï¼‰"></a>ä¸€å‘¨å€¼å¾—è¯»ï¼ˆååº”ç”¨ï¼‰</h1><h2 id="Learning-to-Translate-in-Real-time-with-Neural-Machine-Translation"><a href="#Learning-to-Translate-in-Real-time-with-Neural-Machine-Translation" class="headerlink" title="Learning to Translate in Real-time with Neural Machine Translation"></a><a href="https://arxiv.org/pdf/1610.00388v2.pdf" target="_blank" rel="external">Learning to Translate in Real-time with Neural Machine Translation</a></h2><p>æœ¬æ–‡ç ”ç©¶çš„å†…å®¹å®æ—¶æœºå™¨ç¿»è¯‘ï¼Œä¸ä¼ ç»Ÿçš„ç¿»è¯‘é—®é¢˜ä¸åŒï¼Œè¯¥ä»»åŠ¡éœ€è¦åœ¨ç¿»è¯‘è´¨é‡å’Œé€Ÿåº¦ä¸¤ä¸ªæ–¹é¢å¯»æ‰¾ä¸€ä¸ªå¹³è¡¡ç‚¹ï¼ŒNMTå·²ç»è¯æ˜äº†å…¶å¼ºå¤§çš„å®<br>åŠ›ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šç”¨å¢å¼ºå­¦ä¹ åšè®­ç»ƒï¼Œä»¥æ»¡è¶³ä¸¤ä¸ªæ–¹é¢çš„éœ€æ±‚ã€‚</p>
<h2 id="A-Tour-of-TensorFlow"><a href="#A-Tour-of-TensorFlow" class="headerlink" title="A Tour of TensorFlow"></a><a href="https://arxiv.org/pdf/1610.01178v1.pdf" target="_blank" rel="external">A Tour of TensorFlow</a></h2><p>æœ¬æ–‡ç³»ç»Ÿçš„å‰–æäº†TensorFlowçš„è®¡ç®—å›¾æ¶æ„å’Œåˆ†å¸ƒå¼æ‰§è¡Œæ¨¡å‹ï¼Œå¹¶ä¸”ç³»ç»Ÿåœ°å¯¹æ¯”äº†TFå’Œå…¶ä»–æ¡†æ¶çš„æ€§èƒ½ã€‚æœ¬æ–‡çš„ç»“è®ºå¯¹äºæ¡†æ¶é€‰æ‹©å›°éš¾çš„ç«¥é‹æœ‰ä¸€å®šå‚è€ƒæ„ä¹‰ï¼Œå†…å®¹å¯¹äºæœ‰å¿—äºæ·±æŒ–TFåŸç†å’Œæƒ³å¼€å‘æ¡†æ¶çš„ç«¥é‹å…·æœ‰è¾ƒå¼ºçš„æŒ‡å¯¼æ„ä¹‰ã€‚å¯¹äºç«‹å¿—äºæˆä¸ºä¸€åTFBoysï¼ˆTensorFlowï¼‰çš„ç«¥é‹ï¼Œæœ¬æ–‡æ˜¯ä¸€ç¯‡ä¸é”™çš„æ–‡ç« ã€‚</p>
<h1 id="ä¸€å‘¨èµ„æº"><a href="#ä¸€å‘¨èµ„æº" class="headerlink" title="ä¸€å‘¨èµ„æº"></a>ä¸€å‘¨èµ„æº</h1><h2 id="Chatbots-â€“-Conversational-UI-and-the-Future-of-Online-Interaction-Swat-io-Blog"><a href="#Chatbots-â€“-Conversational-UI-and-the-Future-of-Online-Interaction-Swat-io-Blog" class="headerlink" title="Chatbots â€“ Conversational UI and the Future of Online Interaction | Swat.io Blog"></a><a href="https://pan.baidu.com/s/1nuT9qnZ" target="_blank" rel="external">Chatbots â€“ Conversational UI and the Future of Online Interaction | Swat.io Blog</a></h2><p>ç ”ç©¶chatbotçš„ç«¥é‹ï¼Œè¿™æœ¬ç”µå­ä¹¦å€¼å¾—ä¸€çœ‹ï¼Œæˆ–è®¸ä¼šæœ‰ä¸€äº›æ€è€ƒå’Œå¯å‘ï¼ </p>
<h2 id="ç‹å¨å»‰è€å¸ˆå…³äºå¦‚ä½•åšç§‘ç ”çš„å¾®åš"><a href="#ç‹å¨å»‰è€å¸ˆå…³äºå¦‚ä½•åšç§‘ç ”çš„å¾®åš" class="headerlink" title="ç‹å¨å»‰è€å¸ˆå…³äºå¦‚ä½•åšç§‘ç ”çš„å¾®åš"></a><a href="http://weibo.com/1657470871/EbJnqBBJ5?type=comment#_rnd1475892970397" target="_blank" rel="external">ç‹å¨å»‰è€å¸ˆå…³äºå¦‚ä½•åšç§‘ç ”çš„å¾®åš</a></h2><p>â€œä»€ä¹ˆæ˜¯ç ”ç©¶ï¼Ÿæœ¬ç§‘ç”Ÿå¦‚ä½•åšå¥½ç ”ç©¶ï¼Ÿæˆ‘ä»Šå¤©åœ¨ç»„ä¼šä¸Šç®€å•åœ°ç»™ç»„é‡Œçš„æœ¬ç§‘ç”Ÿä»‹ç»äº†ä¸€ç‚¹ä¸ªäººåšç ”ç©¶çš„ç»éªŒï¼Œä¸å¤§å®¶åˆ†äº«ä¸€ä¸‹ã€‚â€</p>
<h2 id="Configuring-Eclipse-with-Torch-â€“-Lighting-Torch"><a href="#Configuring-Eclipse-with-Torch-â€“-Lighting-Torch" class="headerlink" title="Configuring Eclipse with Torch â€“ Lighting Torch"></a><a href="http://www.lighting-torch.com/2015/07/27/configuring-eclipse-with-torch/" target="_blank" rel="external">Configuring Eclipse with Torch â€“ Lighting Torch</a></h2><p>å°†Torché…ç½®åˆ°Eclipseä¸­è¿›è¡Œå¼€å‘å’Œè°ƒè¯•ã€‚</p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-10-07T18:22:30.000Z"><a href="/2016/10/07/PaperWeekly-ç¬¬å…«æœŸ/">2016-10-07</a></time>
      
      
  
    <h1 class="title"><a href="/2016/10/07/PaperWeekly-ç¬¬å…«æœŸ/">PaperWeekly ç¬¬å…«æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•è¨€"><a href="#å¼•è¨€" class="headerlink" title="å¼•è¨€"></a>å¼•è¨€</h1><p>SIGDIALæ˜¯ACLæ‰€å±çš„å…³äºå¯¹è¯ç³»ç»Ÿçš„å…´è¶£å°ç»„ï¼ŒSIGçš„æ–‡ç« é’ˆå¯¹æ€§æ¯”è¾ƒå¼ºï¼Œä½†æ–‡ç« çš„è´¨é‡è‰¯è ä¸é½ï¼Œæœ¬æœŸç»™å¤§å®¶ç²¾å¿ƒæŒ‘é€‰äº†4ç¯‡SIGDIAL 2016çš„æ–‡ç« ï¼Œå¸¦ç€å¤§å®¶ä¸€èµ·æ¥çœ‹çœ‹å¯¹è¯ç³»ç»Ÿæœ€æ–°çš„ç ”ç©¶æˆæœã€‚4ç¯‡æ–‡ç« åˆ†åˆ«æ˜¯ï¼š</p>
<p>1ã€Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks, 2016<br>2ã€Neural Utterance Ranking Model for Conversational Dialogue Systems, 2016<br>3ã€A Context-aware Natural Language Generator for Dialogue Systems, 2016<br>4ã€Task Lineages: Dialog State Tracking for Flexible Interaction, 2016</p>
<h1 id="Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks"><a href="#Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks" class="headerlink" title="Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks"></a><a href="http://arxiv.org/pdf/1609.01462v1.pdf" target="_blank" rel="external">Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Bing Liu, Ian Lane</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Carnegie Mellon University, Electrical and Computer Engineering</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Spoken Language Understanding, RNN</p>
<h2 id="æ–‡ç« æ¥æº"><a href="#æ–‡ç« æ¥æº" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>SIGDIAL 2016</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•å°†è‡ªç„¶è¯­è¨€ç†è§£çš„ä¸¤å¤§é—®é¢˜å’Œè¯­è¨€æ¨¡å‹ç»“åˆåœ¨åŒä¸€ä¸ªæ¨¡å‹ä¸­è¿›è¡Œè®­ç»ƒï¼Œä»¥è¾¾åˆ°å®æ—¶ç†è§£è¯­è¨€çš„ç›®çš„ï¼Ÿ</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>ç‰¹å®šä»»åŠ¡ä¸‹çš„Chatbotåœ¨ç†è§£äººç±»è¯­è¨€æ—¶éœ€è¦é‡ç‚¹è§£å†³å¥½ä¸¤ä¸ªé—®é¢˜ï¼šæ„å›¾è¯†åˆ«(Intent Detection)å’Œæ§½å¡«å……(Slot Filling)ï¼Œæœ¬æ–‡æå‡ºä¸€ç§èåˆIntent Detectionã€Slot Fillingå’ŒLanguage Modelçš„æ¨¡å‹ï¼Œç›¸æ¯”äºä¹‹å‰çš„æ¨¡å‹ï¼Œæœ¬æ–‡æ¨¡å‹çš„ä¸€å¤§ä¼˜åŠ¿åœ¨äºåšè‡ªç„¶è¯­è¨€ç†è§£çš„æ—¶å€™ä¸éœ€è¦ç­‰å¾…æ•´ä¸ªword sequenceå®Œæ•´å±•ç°ï¼Œè€Œæ˜¯å¯ä»¥åœ¨çº¿å¤„ç†æ¯ä¸€ä¸ªarrived wordã€‚å¦‚ä¸‹å›¾ï¼š<br><img src="media/3.png" alt="3"></p>
<p>æ„å›¾è¯†åˆ«æ˜¯ä¸ªå…¸å‹çš„å¤šåˆ†ç±»ä»»åŠ¡ï¼Œè€Œæ§½å¡«å……æ˜¯ä¸ªå…¸å‹çš„åºåˆ—æ ‡æ³¨ä»»åŠ¡ã€‚RNNçš„æ¯ä¸ªstepéƒ½ä»¥å½“å‰wordä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºæ˜¯æ„å›¾classã€è¯¥wordçš„labelå’Œä¸‹ä¸€ä¸ªwordï¼Œæ¯ä¸ªstepçš„éšå±‚éƒ½åŒ…å«äº†ä¹‹å‰æ‰€æœ‰çš„wordã€classã€labelä¿¡æ¯ã€‚æ­¤æ¨¡å‹ä¸ºåŸºæœ¬æ¨¡å‹ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šåšäº†ä¸€äº›å˜å½¢ï¼Œå¾—åˆ°ä¸‹é¢å››ä¸ªå˜ç§ï¼š</p>
<p><img src="media/4.png" alt="4"></p>
<p>æ–‡ç« åœ¨Airline Travel Information Systems(ATIS)æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œåœ¨è¯­è¨€æ¨¡å‹è¯„æµ‹æŒ‡æ ‡å’Œæ„å›¾è¯†åˆ«åˆ†ç±»å‡†ç¡®ç‡ä¸Šç›¸æ¯”ä¹‹å‰çš„æ¨¡å‹éƒ½å¾—åˆ°äº†ä¸€å®šåœ°æå‡ã€‚</p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æœ¬æ–‡Code: <a href="http://speech.sv.cmu.edu/software.html" target="_blank" rel="external">http://speech.sv.cmu.edu/software.html</a><br>ATIS Dataset: <a href="https://github.com/mesnilgr/is13" target="_blank" rel="external">https://github.com/mesnilgr/is13</a></p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºå°†æ„å›¾åˆ†ç±»ã€æ§½å¡«å……å’Œè¯­è¨€æ¨¡å‹ä¸‰è€…åˆä¸€ï¼Œç›¸æ¯”ä¹‹å‰çš„ç‹¬ç«‹æ¨¡å‹æ¥è¯´ï¼Œæ¯ä¸€æ­¥äº§ç”Ÿçš„ä¿¡æ¯æ›´å¤šï¼Œåœ¨é¢„æµ‹ä¸‹ä¸€æ­¥çš„æ—¶å€™contextå†…å®¹æ›´åŠ ä¸°å¯Œï¼Œä»è€Œæé«˜äº†è¯†åˆ«çš„å‡†ç¡®ç‡å’Œé™ä½äº†è¯­è¨€æ¨¡å‹çš„æ··ä¹±åº¦ã€‚</p>
<p>NLPä¸­çš„å¾ˆå¤šä»»åŠ¡éƒ½å¯ä»¥å½’çº³ä¸ºæ ¹æ®contextæ¥é¢„æµ‹æŸä¸€ä¸ªwordã€labelæˆ–è€…classè¿™ç§èŒƒå¼ï¼Œè§£å†³çš„æ€è·¯ä¹Ÿéƒ½åŸºæœ¬ç±»ä¼¼ï¼ŒRNNæˆ–è€…GRUã€LSTMä½œä¸ºencoderå’Œdecoderï¼Œé…ä¸Šattentionæœºåˆ¶æ¥æå‡ç»“æœï¼Œcontextçš„ä¿¡æ¯é‡å’Œè´¨é‡ç›´æ¥å½±å“ç€é¢„æµ‹çš„æ•ˆæœï¼Œuser informationã€user profileç­‰ç­‰éƒ½å¯èƒ½ä½œä¸ºcontextæ¥æ„å»ºæ¨¡å‹ï¼Œå¾—åˆ°æ›´å¥½çš„ç»“æœã€‚</p>
<h1 id="Neural-Utterance-Ranking-Model-for-Conversational-Dialogue-Systems"><a href="#Neural-Utterance-Ranking-Model-for-Conversational-Dialogue-Systems" class="headerlink" title="Neural Utterance Ranking Model for Conversational Dialogue Systems"></a><a href="http://www.sigdial.org/workshops/conference17/proceedings/pdf/SIGDIAL48.pdf" target="_blank" rel="external">Neural Utterance Ranking Model for Conversational Dialogue Systems</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Michimasa Inaba, Kenichi Takahashi</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Hiroshima City University, 3-4-1 Ozukahigashi, Asaminami-ku</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Ranking Model, Utterance Selection</p>
<h2 id="æ–‡ç« æ¥æº-1"><a href="#æ–‡ç« æ¥æº-1" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>SIGDIAL 2016</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>åœ¨åšæ£€ç´¢å¼å¯¹è¯æ—¶ï¼Œå¯¹è¯è¯­å¥è¯¥æ€æ ·è¡¨ç¤ºï¼Œcontextä¿¡æ¯è¯¥æ€æ ·å¼•å…¥åˆ°æ¨¡å‹ä¸­ï¼Ÿ</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æœ¬æ–‡å®ç°çš„æ˜¯ä¸€ä¸ªæ£€ç´¢å¼çš„å¯¹è¯æ¨¡å‹ï¼Œæ¨¡å‹åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œåˆ†åˆ«æ˜¯ï¼š<br>1ã€Utterance Encoding<br>æ£€ç´¢å¼å¯¹è¯ï¼Œå¯¹è¯è¯­å¥çš„encodingæ˜¯å¾ˆé‡è¦çš„ä¸€éƒ¨åˆ†ï¼Œæ–‡ä¸­ä½¿ç”¨äº†RNN encoderæ¨¡å‹æ¥å®ç°å¯¹è¯­å¥çš„encodingã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½œè€…æŠŠencoderç”Ÿæˆçš„å‘é‡ï¼Œåœ¨decodeæˆä¸€ä¸ªç›®æ ‡è¯­å¥ï¼Œå³é€šè¿‡ä¸€ä¸ªå®Œæ•´çš„seq2seqæ¨¡å‹æ¥è®­ç»ƒencoderã€‚<br>2ã€Ranking Candidate Utterances<br>åœ¨å¯¹å€™é€‰è¯­å¥æ’åºæ—¶ï¼Œä½œè€…è€ƒè™‘åˆ°äº†contextçš„é—®é¢˜ï¼Œä»–æŠŠå‰å‡ æ¬¡è¯´çš„è¯­å¥åˆ†åˆ«encodeæˆå‘é‡ï¼Œå¹¶ä¾æ¬¡è¾“å…¥åˆ°LSTMã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p>
<p><img src="media/5.png" alt="5"></p>
<p>å›¾ä¸­u1åˆ°unæ˜¯æ•´ä¸ªå¯¹è¯ä¸­çš„å‰nå¥è¯ï¼Œaiæ˜¯ç¬¬iä¸ªå€™é€‰è¯­å¥ã€‚æ¨¡å‹ä¸­ï¼Œåˆ†åˆ«æŠŠu1â€¦unä»¥åŠaiåˆ†æˆç”¨æˆ·è¯´çš„å’Œç³»ç»Ÿæœ¬èº«è¾“å‡ºçš„ï¼Œåœ¨è¾“å…¥åˆ°å„è‡ªçš„RNN encoderä¸­ï¼Œå¾—åˆ°å‘é‡vu1â€¦vuå’Œvaiã€‚æœ€åå°†å‘é‡ä¾æ¬¡è¾“å…¥åˆ°RNNä¸­ï¼Œå¾—åˆ°yaiä½œä¸ºå€™é€‰è¯­å¥aiåœ¨å½“å‰contextä¸­çš„å¾—åˆ†ã€‚<br>å› ä¸ºæœ¬æ–‡æ˜¯ä¸€ä¸ªranking modelï¼Œæ›´å…³æ³¨çš„æ˜¯å€™é€‰è¯­å¥çš„æ’åºï¼Œæœ€åå€™é€‰é›†åˆ†æ•°åˆ—è¡¨ä¼šè½¬æ¢æˆTOP 1çš„æ¦‚ç‡åˆ†å¸ƒã€‚å¹¶ä½¿ç”¨cross-entropyä½œä¸ºloss functionã€‚</p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡æœ‰ä¸¤ä¸ªåˆ›æ–°ç‚¹ï¼Œé¦–å…ˆé€šè¿‡å•ç‹¬è®­ç»ƒseq2seqæ¨¡å‹ï¼Œæ¥å­¦ä¹ å¯¹è¯è¯­å¥çš„encoderï¼Œä»è€Œé™ä½äº†æ•´ä¸ªæ¨¡å‹çš„å­¦ä¹ æˆæœ¬ï¼Œå‡å°‘äº†éœ€è¦æ ‡æ³¨çš„æ•°æ®é‡ã€‚ç„¶ååœ¨æ’åºæ¨¡å‹ä¸­å°†å¯¹è¯çš„å‰å‡ å¥è¯­å¥æœ‰åºè¾“å…¥åˆ°LSTMï¼Œè¾¾åˆ°èå…¥äº†contextä¿¡æ¯çš„ç›®çš„ã€‚</p>
<h1 id="A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems"><a href="#A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems" class="headerlink" title="A Context-aware Natural Language Generator for Dialogue Systems"></a><a href="https://arxiv.org/pdf/1608.07076" target="_blank" rel="external">A Context-aware Natural Language Generator for Dialogue Systems</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Ondrej Dusek, Filip Jurcicek</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Charles University</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Context-aware, Seq2seq</p>
<h2 id="æ–‡ç« æ¥æº-2"><a href="#æ–‡ç« æ¥æº-2" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>SIGDIAL 2016</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•ä½¿å¾—task-orientedçš„å¯¹è¯ç”Ÿæˆç³»ç»Ÿä¸­ç”Ÿæˆæ›´åŠ è‡ªç„¶çš„å›å¤ï¼Ÿ</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æœ¬æ–‡æ˜¯ACL2016 short paper Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Stringsä¸€æ–‡çš„æ‹“å±•ã€‚åŸæ–‡æå‡ºåŸºäºseq2seqæ¨¡å‹çš„å°†DA(dialogue acts)ç”Ÿæˆresponseçš„æ–¹æ¡ˆï¼Œå…¶ä¸­è¾“å…¥æ˜¯ä¸‰å…ƒç»„(DA type,slot,value)çš„one-hot representationï¼Œè¾“å‡ºæ˜¯å¯¹åº”çš„responseã€‚å¦‚ä¸‹å›¾ï¼š</p>
<p><img src="media/6.png" alt="6"></p>
<p>å»¶ç»­åŸæ–‡çš„å·¥ä½œï¼Œä½œè€…ä¸ºäº†ä½¿å¾—ç”Ÿæˆçš„å›å¤æ›´åŠ è‡ªç„¶ï¼Œå°†å‰é¢ç”¨æˆ·çš„æé—®ä¹Ÿencodeè¿›æ¥ï¼Œå…·ä½“æ˜¯åœ¨åŸæ¥æ¨¡å‹çš„åŸºç¡€ä¸ŠåŠ äº†ä¸¤ä¸ªencodeçš„éƒ¨åˆ†ã€‚Prepending contextæ˜¯æŠŠç”¨æˆ·çš„é—®é¢˜å’ŒDAä¸‰å…ƒç»„å‰åæ‹¼æ¥æˆæ–°çš„è¡¨ç¤ºå†feed into encoderï¼ˆè¿™é‡Œè¦æ³¨æ„é—®é¢˜çš„dictionaryå’ŒDAæ˜¯ä¸ä¸€æ ·çš„ï¼‰ã€‚Context encoderåˆ™æ˜¯æŠŠå•ç‹¬æŠŠé—®é¢˜encodeæˆå’ŒPrepending contextç›¸åŒå¤§å°çš„å‘é‡ï¼Œå†å°†ä¸¤ä¸ªencoderå¾—åˆ°çš„å‘é‡æ‹¼æ¥å°±å¾—åˆ°æœ€åçš„hidden statesã€‚æœ€ådecodeéƒ¨åˆ†ä»ç„¶æ²¿ç”¨lstm+attentionçš„æ–¹æ³•ã€‚å¦‚ä¸‹å›¾ï¼š</p>
<p><img src="media/7.png" alt="7"></p>
<p>æ–‡ç« åœ¨Alex Context NLG Datasetæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œåœ¨BLEU/NIST scoreså’Œäººå·¥è¯„ä»·ä¸¤æ–¹é¢æˆç»©éƒ½å¾—åˆ°äº†ä¸€å®šåœ°æå‡ã€‚</p>
<h2 id="èµ„æº-1"><a href="#èµ„æº-1" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æœ¬æ–‡Code: <a href="https://github.com/UFAL-DSG/tgen" target="_blank" rel="external">https://github.com/UFAL-DSG/tgen</a><br>Alex Context NLG Dataset: <a href="https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1675" target="_blank" rel="external">https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1675</a></p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºå°†ç”¨æˆ·çš„é—®é¢˜ä¹Ÿå°±æ˜¯contextæ˜¾å¼çš„åŠ å…¥åˆ°æ¨¡å‹ä¸­ï¼Œç›¸æ¯”ä¹‹å‰çš„æ¨¡å‹æ¥è¯´ï¼Œç”Ÿæˆçš„å›å¤ä¼šæ›´ç¬¦åˆè¯­å¢ƒã€‚å…ˆå‰çš„å·¥ä½œæ—¨åœ¨å°†rule-basedç¬¦å·å’Œseq2seqæ¨¡å‹ç»“åˆè‡ªåŠ¨ç”Ÿæˆå›å¤ï¼Œæœ¬æ–‡çš„æ”¹è¿›è®©ä¸€éƒ¨åˆ†contextå¾—åˆ°ä¿ç•™ï¼Œä½¿å¾—ç”Ÿæˆçš„å›å¤å†…å®¹æ›´åŠ ä¸°å¯Œï¼Œä»è€Œæ˜¾å¾—è‡ªç„¶ä¸çªå…€ã€‚</p>
<h1 id="Task-Lineages-Dialog-State-Tracking-for-Flexible-Interaction"><a href="#Task-Lineages-Dialog-State-Tracking-for-Flexible-Interaction" class="headerlink" title="Task Lineages: Dialog State Tracking for Flexible Interaction"></a><a href="http://aclweb.org/anthology/W16-3602" target="_blank" rel="external">Task Lineages: Dialog State Tracking for Flexible Interaction</a></h1><h2 id="ä½œè€…-3"><a href="#ä½œè€…-3" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Sungjin Lee, Amanda Stent</p>
<h2 id="å•ä½-3"><a href="#å•ä½-3" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Yahoo Research</p>
<h2 id="æ–‡ç« æ¥æº-3"><a href="#æ–‡ç« æ¥æº-3" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>SIGDIAL 2016</p>
<h2 id="å…³é”®è¯-3"><a href="#å…³é”®è¯-3" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>complex interactions in spoken dialog system, Task Lineage-based Dialog State Tracking</p>
<h2 id="é—®é¢˜-3"><a href="#é—®é¢˜-3" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>â€‹å¦‚ä½•å°†å¤æ‚çš„åˆ¤åˆ«å¼æ¨¡å‹æ¥åšDSTï¼Œå¹¶ä¸”åº”ç”¨äºå¤æ‚åœºæ™¯å¯¹è¯ç³»ç»Ÿï¼Ÿ</p>
<h2 id="æ¨¡å‹-3"><a href="#æ¨¡å‹-3" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æœ¬æ–‡åœ¨ä¹‹å‰Dialog State Trackingæ–¹æ³•çš„åŸºç¡€ä¸Šæå‡ºäº†Task Lineage-based Dialog State Trackingï¼ˆTLâ€”DSTï¼‰ã€‚æœ¬æ¨¡å‹åŒ…æ‹¬ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ï¼š<br>1ã€Task Frame Parsingï¼Œè¿”å›K-best task frame parsesï¼Œ task frame parsesç»“æ„å¦‚ä¸‹å›¾ï¼š</p>
<p><img src="media/1.png" alt="1"></p>
<p>2ã€Context Fetchingï¼Œåœ¨ä¸åŒçš„phenomenaä¸­ï¼Œæ ¹æ®ä¸åŒçš„conversation historyè¿”å›ä¸åŒçš„ç›¸å…³ä¿¡æ¯ã€‚<br>3ã€Task State Updateï¼Œå¯ä»¥é€šè¿‡è°ƒèŠ‚context windowå‚æ•°é€‰æ‹©ä½¿ç”¨ä¸åŒçš„dialog state trackingæ–¹æ³•ã€‚  </p>
<p>æœ¬æ–‡æ¨¡å‹ï¼ˆTL-DSTï¼‰å¤„ç†æµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š<br><img src="media/2.png" alt="2"></p>
<p>åœ¨tè½®ï¼Œç»™å®šå¥å­uï¼Œåˆ©ç”¨task frame parsingç”ŸæˆK-best task frame parses Hï¼Œç»™å®štask frame fï¼Œtask lineage lï¼Œ agent output mï¼Œåˆ©ç”¨context featuresè¿”å›ç›¸å…³ä¿¡æ¯cã€‚</p>
<p>æœ¬æ–‡åœ¨Dialog State Tracking Challenge çš„DSTC2å’ŒDSTC3æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œå‡å–å¾—äº†è¾ƒbaselineå¥½çš„ç»“æœã€‚</p>
<h2 id="èµ„æº-2"><a href="#èµ„æº-2" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>Dialog State Tracking Challengeæ¯”èµ›ä»‹ç»: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" target="_blank" rel="external">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf</a></p>
<h2 id="ç®€è¯„-3"><a href="#ç®€è¯„-3" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡åŸºäºDSTçš„æ–¹æ³•æ¥å¤„ç†å£è¯­å¯¹è¯ç³»ç»Ÿä¸­çš„å¤šä»»åŠ¡ï¼Œè·¨é¢†åŸŸï¼Œå¤æ‚ç›®æ ‡çš„é—®é¢˜ï¼Œç”±äºç¼ºä¹å¤šä»»åŠ¡ï¼Œè·¨é¢†åŸŸï¼Œå¤æ‚ç›®æ ‡çš„å£è¯­å¯¹è¯ç³»ç»Ÿçš„æ•°æ®é›†ï¼Œæœ¬æ–‡å®éªŒåœ¨DSTC2å’ŒDSTC3ä¸Šè¿›è¡Œï¼Œ å¹¶å–å¾—äº†æ¯”baselineå¥½çš„æ•ˆæœã€‚å°†æ¥çš„å·¥ä½œæ˜¯è¦å°†TL-DSTæ–¹æ³•åº”ç”¨äºçœŸå®ç¯å¢ƒä¸­çš„å¤šé¢†åŸŸå¯¹è¯è¯„ä¼°ã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>å¯¹è¯ç³»ç»Ÿ(Dialogue Systems)æ˜¯å½“å‰å·¥ä¸šç•Œæœ€çƒ­é—¨çš„æ–¹å‘ä¹‹ä¸€ï¼Œå»æ‰è¯­éŸ³éƒ¨åˆ†ï¼Œè¯¥é—®é¢˜é€€åŒ–ä¸ºèŠå¤©æœºå™¨äºº(chatbot)é—®é¢˜ï¼Œä¸¤è€…è™½ç„¶åœ¨è¾“å…¥å¤„ç†ä¸­å­˜åœ¨ä¸€å®šçš„å·®å¼‚ï¼Œä½†è‡ªç„¶è¯­è¨€ç†è§£ã€å¯¹è¯ç®¡ç†å’Œè‡ªç„¶è¯­è¨€ç”Ÿæˆç­‰æ ¸å¿ƒéƒ¨ä»¶éƒ½æ˜¯ä¸€æ ·çš„ï¼Œé¢ä¸´çš„å¾ˆå¤šé—®é¢˜éƒ½æ˜¯å…±åŒçš„ï¼Œæ‰€ä»¥ç›¸å…³çš„ç ”ç©¶æˆ–å¤šæˆ–å°‘éƒ½ä¼šæœ‰å‚è€ƒæ„ä¹‰ã€‚ä¸Šä¸‹æ–‡(context)çš„ç†è§£å’Œå¤„ç†æ˜¯ä¸€ä¸ªé‡è¦çš„ç¯èŠ‚ï¼Œç›´æ¥å†³å®šäº†è¯¥botæ˜¯æ™ºèƒ½è¿˜æ˜¯æ™ºéšœï¼ŒæŒºå¤šçš„paperéƒ½æ˜¯é’ˆå¯¹è¿™ä¸€é—®é¢˜è¿›è¡Œç ”ç©¶çš„ï¼Œä½†åœ¨å®é™…åº”ç”¨å½“ä¸­ï¼Œcontextçš„å¤„ç†ä»ç„¶ä¸å°½å¦‚äººæ„ï¼Œè¿‡å¤šä¾èµ–äººå·¥è®¾ç½®ï¼Œæ›´åƒæ˜¯ä¸€ç§è§¦å‘å¼€å…³ï¼Œå­˜åœ¨å¤§é‡çš„ifâ€¦elseâ€¦ã€‚</p>
<p>seq2seqç”Ÿæˆå¼çš„è§£å†³æ–¹æ¡ˆåˆè§æ•ˆæœï¼Œä½†ç¦»çœŸæ­£åº”ç”¨è¿˜æœ‰å¾ˆé•¿çš„è·¯è¦èµ°ï¼Œtemplate-basedå’Œrule-basedä»æ˜¯ä¸»æµè§£å†³æ–¹æ¡ˆï¼Œå°¤å…¶æ˜¯åœ¨é¢å‘å…·ä½“ä»»åŠ¡çš„botæƒ…æ™¯ä¸­ã€‚é‚£ä¹ˆï¼Œç›´æ¥ç”Ÿæˆå›ç­”å¾ˆéš¾çš„è¯ï¼Œé€€ä¸€æ­¥æ¥æƒ³è¿™ä¸ªé—®é¢˜ï¼Œèƒ½å¦å°†seq2seqç”¨åœ¨templateæˆ–è€…ruleçš„è‡ªåŠ¨ç”Ÿæˆä¸Šï¼Ÿèƒ½å¦å°†paperä¸­å¤šä¿¡æ¯èåˆï¼ˆæ¯”å¦‚ï¼šuser profileã€dialogue contextï¼‰çš„æˆæœåº”ç”¨åœ¨å½“å‰botçš„æŸä¸€ä¸ªé˜¶æ®µï¼Ÿèƒ½å¦è®­ç»ƒä¸€ä¸ªbot simulatoræ¥ä¸°å¯Œè®­ç»ƒæ•°æ®ï¼Ÿæ¯ä¸€ç¯‡paperéƒ½ä¼šæœ‰ä¸€äº›åˆ›æ–°ç‚¹ï¼Œå¯èƒ½æœ‰çš„åˆ›æ–°ç‚¹æ˜¯ä¸ºäº†åˆ›æ–°è€Œåˆ›æ–°ï¼Œä½†æ€»å½’ä¼šå¸¦æ¥ä¸€å®šçš„æ€è€ƒå’Œå€Ÿé‰´ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹æŸä¸€ä¸ªç»†èŠ‚é—®é¢˜ï¼Œæˆ‘æƒ³è¿™æ˜¯paperå¯¹äºå·¥ä¸šç•Œçš„å‚è€ƒæ„ä¹‰ï¼Œè€Œä¸æ˜¯è¯´ä»paperä¸­å®Œå…¨æŠ å‡ºä¸€ä¸ªæˆç†Ÿçš„è§£å†³æ–¹æ¡ˆæ¥å¥—ï¼Œç”šè‡³æŠŠdatasetå’Œcodeéƒ½releaseå‡ºæ¥ï¼Œå…¸å‹çš„â€œæ‹¿æ¥ä¸»ä¹‰â€ã€‚</p>
<p>ä»¥ä¸Šä¸ºæœ¬æœŸPaperweeklyçš„ä¸»è¦å†…å®¹ï¼Œæ„Ÿè°¢lshowwayã€zhangjunã€zhangboyuå’Œsuhuiå››ä½åŒå­¦çš„æ•´ç†ã€‚</p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-30T23:11:04.000Z"><a href="/2016/09/30/cs-CL-weekly-2016-09-26-2016-09-30/">2016-09-30</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/30/cs-CL-weekly-2016-09-26-2016-09-30/">cs.CL weekly 2016.09.26-2016.09.30</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="ä¸€å‘¨å€¼å¾—è¯»ï¼ˆåå­¦æœ¯ï¼‰"><a href="#ä¸€å‘¨å€¼å¾—è¯»ï¼ˆåå­¦æœ¯ï¼‰" class="headerlink" title="ä¸€å‘¨å€¼å¾—è¯»ï¼ˆåå­¦æœ¯ï¼‰"></a>ä¸€å‘¨å€¼å¾—è¯»ï¼ˆåå­¦æœ¯ï¼‰</h1><h2 id="HyperNetworks"><a href="#HyperNetworks" class="headerlink" title="HyperNetworks"></a><a href="https://arxiv.org/pdf/1609.09106v1.pdf" target="_blank" rel="external">HyperNetworks</a></h2><p>an approach of using a small network, also known as a hypernetwork, to generate the weights for a larger network. å·¥ä½œæ¥è‡ªGoogle Brainã€‚ä»‹ç»HyperNetworksçš„åšå®¢ï¼š<a href="http://blog.otoro.net/2016/09/28/hyper-networks/" target="_blank" rel="external">http://blog.otoro.net/2016/09/28/hyper-networks/</a></p>
<h2 id="Incorporating-Relation-Paths-in-Neural-Relation-Extraction"><a href="#Incorporating-Relation-Paths-in-Neural-Relation-Extraction" class="headerlink" title="Incorporating Relation Paths in Neural Relation Extraction"></a><a href="https://arxiv.org/pdf/1609.07479v1.pdf" target="_blank" rel="external">Incorporating Relation Paths in Neural Relation Extraction</a></h2><p>æœ¬æ–‡ç ”ç©¶å†…å®¹ä¸ºå®ä½“å…³ç³»æŠ½å–ï¼Œä¼ ç»Ÿæ–¹æ³•å¾€å¾€åªåˆ©ç”¨åŒæ—¶åŒ…å«ä¸¤ä¸ªç›®æ ‡å®ä½“çš„å¥å­ï¼Œè€Œå¿½ç•¥åŒ…å«å•ç›®æ ‡å®ä½“çš„å¥å­ï¼Œæœ¬æ–‡é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œåœ¨ä¿©ç›®æ ‡å®ä½“ä¹‹é—´æ„å»ºäº†ä¸€ä¸ªç”¨äºæ¨ç†çš„ä¸­é—´å®ä½“ï¼Œå¹¶æå‡ºä¸€ç§åŸºäºè·¯å¾„çš„å…³ç³»æŠ½å–æ¨¡å‹ï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥æ¨¡å‹å¾ˆå¥½åœ°åˆ©ç”¨äº†åŒ…å«å•ç›®æ ‡å®ä½“çš„å¥å­ä¿¡æ¯ã€‚æœ¬å·¥ä½œæ¥è‡ªäºåˆ˜çŸ¥è¿œè€å¸ˆç»„é‡Œã€‚</p>
<h2 id="Language-as-a-Latent-Variable-Discrete-Generative-Models-for-Sentence-Compression"><a href="#Language-as-a-Latent-Variable-Discrete-Generative-Models-for-Sentence-Compression" class="headerlink" title="Language as a Latent Variable: Discrete Generative Models for Sentence Compression"></a><a href="https://arxiv.org/pdf/1609.07317v1.pdf" target="_blank" rel="external">Language as a Latent Variable: Discrete Generative Models for Sentence Compression</a></h2><p>æœ¬æ–‡ç ”ç©¶å†…å®¹ä¸ºå¥å­å‹ç¼©ï¼Œä½œè€…æå‡ºäº†ä¸€ç§VAEæ¨¡å‹ï¼Œå…ˆæ ¹æ®èƒŒæ™¯è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸€ä¸ªlatentæ‘˜è¦å¥å­ï¼Œç„¶åæ ¹æ®latentå¥å­ç”Ÿæˆç›®æ ‡å¥å­ã€‚å®éªŒä¸­ç”¨åˆ°äº†æŠ½å–å¼å’Œæ‘˜è¦å¼ä¸¤ç§ç›‘ç£æ–¹æ³•ï¼Œå¹¶åœ¨æœ€åæ¢ç´¢å‡ºåŠç›‘ç£æ–¹æ³•çš„æ•ˆæœå¯èƒ½ä¼šå¥½äºç›‘ç£å­¦ä¹ çš„æ–¹æ³•ã€‚å¥å­å‹ç¼©ä»»åŠ¡å¯ä»¥çœ‹åšæ˜¯sentence-levelçš„æ–‡æœ¬æ‘˜è¦ä»»åŠ¡ï¼Œæœ¬æ–‡çš„æ–¹æ³•åŒæ ·å¯ä»¥å¯å‘æ–‡æœ¬æ‘˜è¦ä»»åŠ¡çš„ç ”ç©¶ã€‚æœ¬æ–‡å·¥ä½œæ¥è‡ªdeepmindï¼Œå¹¶ä¸”æ˜¯EMNLP 2016 Acceptedã€‚</p>
<h2 id="Annotating-Derivations-A-New-Evaluation-Strategy-and-Dataset-for-Algebra-Word-Problems"><a href="#Annotating-Derivations-A-New-Evaluation-Strategy-and-Dataset-for-Algebra-Word-Problems" class="headerlink" title="Annotating Derivations: A New Evaluation Strategy and Dataset for Algebra Word Problems"></a><a href="https://arxiv.org/pdf/1609.07197v1.pdf" target="_blank" rel="external">Annotating Derivations: A New Evaluation Strategy and Dataset for Algebra Word Problems</a></h2><p>æœ¬æ–‡ç ”ç©¶çš„å†…å®¹å¾ˆæœ‰æ„æ€ï¼Œæ˜¯algebra word problemsï¼Œæ˜¯è‡ªåŠ¨æ±‚è§£ä»£æ•°é—®é¢˜çš„åŸºç¡€ï¼Œè¿™ä¸ªé—®é¢˜å¯ä»¥ç­‰åŒä¸ºä¸€ä¸ªsemantic parsingçš„é—®é¢˜ï¼Œæ¨¡å‹é€šè¿‡è¯»å…¥ä¸€æ®µæ–‡æœ¬ï¼Œç†è§£å…¶æ„æ€ï¼Œç„¶åæ„é€ å‡ºä¸€ä¸ªæ–¹ç¨‹ï¼Œæœ€åç»™å‡ºæ–¹ç¨‹çš„è§£ã€‚ä½œè€…è¿˜ç»™å‡ºäº†ä¸€ä¸ªæ–°çš„datasetå’Œè¯„ä»·æ ‡å‡†ï¼Œæœ¬æ–‡å·¥ä½œæ¥è‡ªä¼Šå¤§é¦™æ§Ÿåˆ†æ ¡å’Œå¾®è½¯ç ”ç©¶é™¢ã€‚è¿™ä¸ªtaskæœ¬èº«éå¸¸æœ‰æ„æ€ï¼Œä¹Ÿå¾ˆæœ‰éš¾åº¦ã€‚</p>
<h2 id="Online-Segment-to-Segment-Neural-Transduction"><a href="#Online-Segment-to-Segment-Neural-Transduction" class="headerlink" title="Online Segment to Segment Neural Transduction"></a><a href="https://arxiv.org/pdf/1609.08194v1.pdf" target="_blank" rel="external">Online Segment to Segment Neural Transduction</a></h2><p>æœ¬æ–‡é’ˆå¯¹ä¹‹å‰encoder-decoderæ¨¡å‹é¢ä¸´çš„ä¸€ä¸ªç“¶é¢ˆï¼Œå³å°†è¾“å…¥å…¨éƒ¨è¯»å…¥å¹¶ä¿å­˜ä¸ºä¸€ä¸ªå›ºå®šå¤§å°çš„hidden statesï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„attentionæœºåˆ¶ï¼Œå°†attentionæƒé‡ä½œä¸ºä¸€ç§éšå˜é‡ï¼Œåœ¨å¥å­æ‘˜è¦ä¸Šè¯æ˜äº†æ•ˆæœï¼Œæœ¬æ–‡å·¥ä½œæ¥è‡ªdeepmindã€‚</p>
<h1 id="ä¸€å‘¨å€¼å¾—è¯»ï¼ˆååº”ç”¨ï¼‰"><a href="#ä¸€å‘¨å€¼å¾—è¯»ï¼ˆååº”ç”¨ï¼‰" class="headerlink" title="ä¸€å‘¨å€¼å¾—è¯»ï¼ˆååº”ç”¨ï¼‰"></a>ä¸€å‘¨å€¼å¾—è¯»ï¼ˆååº”ç”¨ï¼‰</h1><h2 id="Googleâ€™s-Neural-Machine-Translation-System-Bridging-the-Gap-between-Human-and-Machine-Translation"><a href="#Googleâ€™s-Neural-Machine-Translation-System-Bridging-the-Gap-between-Human-and-Machine-Translation" class="headerlink" title="Googleâ€™s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"></a><a href="https://arxiv.org/pdf/1609.08144.pdf" target="_blank" rel="external">Googleâ€™s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</a></h2><p>æœ¬å‘¨æœ€å—å…³æ³¨ï¼Œä¹Ÿå¤‡å—äº‰è®®çš„ä¸€ç¯‡paperï¼ŒGoogleæ”¾å‡ºäº†ä»–ä»¬æœ€æ–°ä¸€ä»£çš„æœºå™¨ç¿»è¯‘ç³»ç»Ÿï¼Œä¸€ç§ç¥ç»ç½‘ç»œç¿»è¯‘ç³»ç»Ÿã€‚æŒ‡æ ‡ä¸Šçš„æå‡ï¼Œè¯´æ˜äº†æ•ˆæœç¡®å®æœ‰æå‡ï¼Œä½†ä¸ä»£è¡¨å…·ä½“åˆ°æ¯ä¸€å¥è¯éƒ½èƒ½ä»¤äººæ»¡æ„ã€‚</p>
<h2 id="UbuntuWorld-1-0-LTS-A-Platform-for-Automated-Problem-Solving-amp-Troubleshooting-in-the-Ubuntu-OS"><a href="#UbuntuWorld-1-0-LTS-A-Platform-for-Automated-Problem-Solving-amp-Troubleshooting-in-the-Ubuntu-OS" class="headerlink" title="UbuntuWorld 1.0 LTS - A Platform for Automated Problem Solving &amp; Troubleshooting in the Ubuntu OS"></a><a href="https://arxiv.org/pdf/1609.08524v1.pdf" target="_blank" rel="external">UbuntuWorld 1.0 LTS - A Platform for Automated Problem Solving &amp; Troubleshooting in the Ubuntu OS</a></h2><p>æœ¬æ–‡ç»™å‡ºäº†ä¸€ä¸ªUbuntuç³»ç»Ÿé—®é¢˜å’¨è¯¢å’Œé”™è¯¯æ’æŸ¥çš„botï¼Œå¯ä»¥åœ¨bash terminalä¸­è¿è¡Œï¼Œé€šè¿‡å¢å¼ºå­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œå¯ä»¥å›ç­”ä¸€äº›åŸºæœ¬çš„é—®é¢˜å’Œé”™è¯¯æ’æŸ¥ã€‚demo botè¢«å°è£…æˆä¸€ä¸ªpython packageï¼Œå³æ’å³ç”¨ã€‚å›ç­”é—®é¢˜çš„æ•°æ®æ¥è‡ªäºAsk Ubuntuã€‚æµ‹è¯•äº†DQNåœ¨ç‰¹å®šé¢†åŸŸbotä¸­çš„æ•ˆæœï¼Œå®šä¹‰äº†å‡ ç»„ç®€å•çš„å‘½ä»¤ä½œä¸ºactionï¼Œopen/closeï¼Œinstall/removeç­‰ç­‰ï¼Œtechnical supportæ˜¯å®¢æˆ·æœåŠ¡ä¸­éš¾åº¦éå¸¸å¤§çš„ä¸€ç±»ï¼Œæœ¬æ–‡å°è¯•äº†ç”¨ä¸€ç§å®Œå…¨ç«¯åˆ°ç«¯+å¢å¼ºå­¦ä¹ çš„æ–¹æ¡ˆæ¥æ¢ç´¢è§£å†³æ­¤ç±»é—®é¢˜ã€‚</p>
<h2 id="Character-Sequence-Models-for-ColorfulWords"><a href="#Character-Sequence-Models-for-ColorfulWords" class="headerlink" title="Character Sequence Models for ColorfulWords"></a><a href="https://arxiv.org/pdf/1609.08777v1.pdf" target="_blank" rel="external">Character Sequence Models for ColorfulWords</a></h2><p>æœ¬æ–‡ç ”ç©¶çš„å†…å®¹éå¸¸æœ‰æ„æ€ï¼Œè¾“å…¥ä¸€ä¸ªwordï¼Œè¾“å‡ºè¿™ä¸ªwordå¯¹åº”çš„colorå¹¶ç€è‰²ã€‚ä½œè€…æ„å»ºäº†ä¸€ç»„å¤§å‹çš„color-nameå¯¹æ•°æ®é›†ï¼Œæ¥åšä¸€ä¸ªcolorå›¾çµæµ‹è¯•ã€‚è¯¥ç³»ç»Ÿçš„demoåœ°å€ï¼š<a href="http://colorlab.us./" target="_blank" rel="external">http://colorlab.us./</a></p>
<h2 id="Equation-Parsing-Mapping-Sentences-to-Grounded-Equations"><a href="#Equation-Parsing-Mapping-Sentences-to-Grounded-Equations" class="headerlink" title="Equation Parsing: Mapping Sentences to Grounded Equations"></a><a href="https://arxiv.org/pdf/1609.08824v1.pdf" target="_blank" rel="external">Equation Parsing: Mapping Sentences to Grounded Equations</a></h2><p>æœ¬æ–‡ç ”ç©¶çš„å†…å®¹éå¸¸æœ‰è¶£ä¹Ÿå¾ˆæœ‰å®é™…æ„ä¹‰ï¼Œå³ä»æ–‡æœ¬ä¸­æŠ½å–å‡ºæ•°å­¦å…³ç³»ï¼Œä½œè€…å°†è¯¥ä»»åŠ¡å®šä¹‰å¦‚ä¸‹ï¼šç»™å®šä¸€å¥è¯ï¼ŒæŠ½å–å‡ºå…¶ä¸­çš„å˜é‡å’Œæ•°å­¦å…³ç³»ï¼Œå¹¶ç”¨æ–¹ç¨‹è¡¨ç¤ºã€‚è¿™ä¸ªç ”ç©¶å¯ä»¥è¢«åº”ç”¨åœ¨æ–°é—»æœºå™¨äººä¸Šï¼Œè´¢ç»ã€ä½“è‚²ç­‰ã€‚</p>
<h2 id="Inducing-Multilingual-Text-Analysis-Tools-Using-Bidirectional-Recurrent-Neural-Networks"><a href="#Inducing-Multilingual-Text-Analysis-Tools-Using-Bidirectional-Recurrent-Neural-Networks" class="headerlink" title="Inducing Multilingual Text Analysis Tools Using Bidirectional Recurrent Neural Networks"></a><a href="https://arxiv.org/pdf/1609.09382v1.pdf" target="_blank" rel="external">Inducing Multilingual Text Analysis Tools Using Bidirectional Recurrent Neural Networks</a></h2><p>èµ„æºç¨€ç¼ºè¯­è¨€çš„æ ‡æ³¨é—®é¢˜æ˜¯ä¸€ä¸ªç»å…¸çš„é—®é¢˜ï¼Œä¸€èˆ¬çš„åšæ³•æ˜¯å°†èµ„æºä¸°å¯Œçš„è¯­éŸ³å¯¹é½æ˜ å°„è¿‡å»è¿›è¡Œæ ‡æ³¨ï¼Œè‡ªåŠ¨è¯å¯¹é½çš„é”™è¯¯ä¼šå½±å“æœ€ç»ˆçš„æ•ˆæœã€‚æœ¬æ–‡é’ˆå¯¹è¿™ä¸ªé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§BiRNNæ¨¡å‹ï¼Œå¹¶ä¸”èåˆå¤–éƒ¨ä¿¡æ¯è§£å†³é—®é¢˜ã€‚è¯¥æ¨¡å‹å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š1ã€ä¸éœ€è¦è¯å¯¹é½ä¿¡æ¯ï¼›2ã€ä¸é™å®šè¯­è¨€ï¼Œå¯ç”¨äºå¤šç§èµ„æºå°‘çš„è¯­è¨€ï¼›3ã€æä¾›ä¸€ç§çœŸæ­£çš„å¤šè¯­è¨€taggerã€‚</p>
<h1 id="ä¸€å‘¨èµ„æº"><a href="#ä¸€å‘¨èµ„æº" class="headerlink" title="ä¸€å‘¨èµ„æº"></a>ä¸€å‘¨èµ„æº</h1><h2 id="THULAC"><a href="#THULAC" class="headerlink" title="THULAC"></a><a href="https://github.com/thunlp/THULAC.so" target="_blank" rel="external">THULAC</a></h2><p>THULAC.soï¼šä¸€ä¸ªé«˜æ•ˆçš„ä¸­æ–‡è¯æ³•åˆ†æå·¥å…·åŒ…ï¼Œä¸ºäº†æ»¡è¶³Pythonä¸‹åˆ†è¯å¯¹é€Ÿåº¦çš„è¦æ±‚ï¼Œå‘å¸ƒäº†ä¸€ä¸ªäº§ç”Ÿ.soæ–‡ä»¶çš„THULACç‰ˆæœ¬ï¼Œå¹¶ä¸”æä¾›Pythonè°ƒç”¨çš„ç¤ºä¾‹ä»£ç ã€‚è¿™æ ·THULACåœ¨Pythonä¸‹çš„åˆ†è¯é€Ÿåº¦å¾—åˆ°å¤§å¹…åº¦æé«˜ã€‚</p>
<h2 id="tinyflow"><a href="#tinyflow" class="headerlink" title="tinyflow"></a><a href="https://github.com/tqchen/tinyflow" target="_blank" rel="external">tinyflow</a></h2><p>DMLCé™ˆå¤©å¥‡å¼€æ”¾äº†ä¸€ä¸ªä¸¤åƒè¡Œä»£ç çš„æ ·ä¾‹é¡¹ç›®ï¼Œæ•™ä½ å¦‚ä½•ä»å¤´å¼€å§‹æ‰“é€ ä¸€ä¸ªå’ŒTensorFlowä¸€æ ·APIçš„æ·±åº¦å­¦ä¹ ç³»ç»Ÿã€‚å…¶ä¸­æ¶‰åŠåˆ°ä¸€ä¸ªéå¸¸é‡è¦çš„å¼€æºåº“NNVMï¼Œåœ°å€ï¼š <a href="https://github.com/dmlc/nnvm" target="_blank" rel="external">https://github.com/dmlc/nnvm</a> ã€‚åšå®¢ä»‹ç»ï¼š<a href="http://dmlc.ml/2016/09/30/build-your-own-tensorflow-with-nnvm-and-torch.html" target="_blank" rel="external">http://dmlc.ml/2016/09/30/build-your-own-tensorflow-with-nnvm-and-torch.html</a> ï¼Œä¸­æ–‡ç‰ˆï¼š<a href="http://weibo.com/ttarticle/p/show?id=2309404025388832575825#_0" target="_blank" rel="external">http://weibo.com/ttarticle/p/show?id=2309404025388832575825#_0</a></p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"><br>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/paperweekly" target="_blank" rel="external">http://weibo.com/u/paperweekly</a> ï¼‰<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-30T00:58:47.000Z"><a href="/2016/09/29/PaperWeekly-ç¬¬ä¸ƒæœŸ/">2016-09-29</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/29/PaperWeekly-ç¬¬ä¸ƒæœŸ/">PaperWeekly ç¬¬ä¸ƒæœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•è¨€"><a href="#å¼•è¨€" class="headerlink" title="å¼•è¨€"></a>å¼•è¨€</h1><p>ç¥ç»ç½‘ç»œæœºå™¨ç¿»è¯‘(NMT)æ˜¯seq2seqæ¨¡å‹çš„å…¸å‹åº”ç”¨ï¼Œä»2014å¹´æå‡ºå¼€å§‹ï¼Œå…¶æ€§èƒ½å°±æ¥è¿‘äºä¼ ç»Ÿçš„åŸºäºè¯ç»„çš„æœºå™¨ç¿»è¯‘æ–¹æ³•ï¼Œéšåï¼Œç ”ç©¶äººå‘˜ä¸æ–­æ”¹è¿›seq2seqæ¨¡å‹ï¼ŒåŒ…æ‹¬å¼•å…¥æ³¨æ„åŠ›æ¨¡å‹ã€ä½¿ç”¨å¤–éƒ¨è®°å¿†æœºåˆ¶ã€ä½¿ç”¨åŠç›‘ç£å­¦ä¹ å’Œä¿®æ”¹è®­ç»ƒå‡†åˆ™ç­‰æ–¹æ³•ï¼Œåœ¨çŸ­çŸ­2å¹´æ—¶é—´å†…ä½¿å¾—NMTçš„æ€§èƒ½è¶…è¿‡äº†ä¼ ç»Ÿçš„åŸºäºè¯ç»„çš„æœºå™¨ç¿»è¯‘æ–¹æ³•ã€‚åœ¨27å·è°·æ­Œå®£å¸ƒæ¨å‡ºè°·æ­Œç¥ç»ç½‘ç»œæœºå™¨ç¿»è¯‘ç³»ç»Ÿï¼Œå®ç°äº†NMTçš„é¦–ä¸ªå•†ä¸šåŒ–éƒ¨ç½²ï¼Œä½¿å¾—NMTçœŸæ­£ä»é«˜æ ¡å®éªŒå®¤èµ°å‘äº†å®é™…åº”ç”¨ã€‚æœ¬æœŸPaperweeklyçš„ä¸»é¢˜æ˜¯ç¥ç»ç½‘ç»œæœºå™¨ç¿»è¯‘ä¸‹çš„å­—ç¬¦çº§æ–¹æ³•ï¼Œä¸»è¦ç”¨æ¥è§£å†³NMTä¸­çš„out-of-vocabularyè¯é—®é¢˜ï¼Œåˆ†åˆ«æ˜¯ï¼š</p>
<ol>
<li>A Character-Level Decoder without Explicit Segmentation for Neural Machine Translationï¼Œ2016</li>
<li>Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Modelsï¼Œ2016</li>
<li>Character-based Neural Machine Translationï¼ŒCosta-Jussa, 2016</li>
<li>Character-based Neural Machine Translationï¼ŒLing, 2016</li>
<li>Neural Machine Translation of Rare Words with Subword Unitsï¼Œ2016</li>
</ol>
<h1 id="A-Character-Level-Decoder-without-Explicit-Segmentation-for-Neural-Machine-Translation"><a href="#A-Character-Level-Decoder-without-Explicit-Segmentation-for-Neural-Machine-Translation" class="headerlink" title="A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation"></a><a href="https://arxiv.org/abs/1603.06147" target="_blank" rel="external">A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Junyoung Chung, Kyunghyun Cho, Yoshua Bengio</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Universite de Montreal</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Segmentation, Character-level, Bi-scale recurrent network</p>
<h2 id="æ–‡ç« æ¥æº"><a href="#æ–‡ç« æ¥æº" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ACL 2016</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>èƒ½å¦åœ¨ä¸éœ€è¦åˆ†è¯çš„å‰æä¸‹ç›´æ¥åœ¨å­—ç¬¦çº§è¿›è¡Œç¥ç»æœºå™¨ç¿»è¯‘ã€‚</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>åœ¨è®²æ¨¡å‹ä¹‹å‰ï¼Œæœ¬æ–‡èŠ±äº†å¤§é‡ç¯‡å¹…è®ºè¯ä¸ºä½•éœ€è¦åœ¨ä¸åˆ†è¯çš„å‰æä¸‹è¿›è¡Œå­—ç¬¦çº§ç¿»è¯‘ï¼Œé¦–å…ˆä½œè€…æ€»ç»“äº†è¯çº§ç¿»è¯‘çš„ç¼ºç‚¹ã€‚</p>
<p>è¯çº§ç¿»è¯‘çš„ç¼ºç‚¹åŒ…æ‹¬ï¼š</p>
<ol>
<li>ä»»ä½•ä¸€ä¸ªè¯­è¨€éƒ½æ²¡æœ‰å®Œç¾çš„åˆ†è¯ç®—æ³•ï¼Œå®Œç¾çš„åˆ†è¯ç®—æ³•åº”è¯¥èƒ½å¤Ÿå°†ä»»æ„å¥å­åˆ’åˆ†ä¸ºlexemeså’Œmorphemesç»„æˆçš„åºåˆ—</li>
<li>å¯¼è‡´çš„é—®é¢˜å°±æ˜¯åœ¨è¯å…¸ä¸­ç»å¸¸å……æ–¥ç€è®¸å¤šå…±äº«ä¸€ä¸ªlexemeä½†æœ‰ç€ä¸åŒmorphologyçš„è¯ï¼Œæ¯”å¦‚run,runs,ran,runningå¯èƒ½éƒ½å­˜åœ¨äºè¯å…¸ä¸­ï¼Œæ¯ä¸ªè¯éƒ½å¯¹åº”ä¸€ä¸ªè¯å‘é‡ï¼Œä½†æ˜¯å®ƒä»¬æ˜æ˜¾å…±äº«ç›¸åŒçš„lexemeâ€”â€”run</li>
<li>å­˜åœ¨unknown wordé—®é¢˜å’Œrare wordé—®é¢˜ï¼Œrare wordé—®é¢˜æ˜¯æŒ‡æŸäº›è¯å…¸ä¸­è¯åœ¨è®­ç»ƒé›†ä¸­å‡ºç°æ¬¡æ•°è¿‡å°‘ï¼Œå¯¼è‡´æ— æ³•è®­ç»ƒå¾—åˆ°å¾ˆå¥½çš„è¯å‘é‡ï¼›unknown wordé—®é¢˜æ˜¯æŒ‡ä¸åœ¨è¯å…¸ä¸­çš„è¯è¢«æ ‡è®°ä¸ºUNKï¼ˆOOVè¯ï¼‰</li>
</ol>
<p>æ¥ç€ä½œè€…æŒ‡å‡ºä½¿ç”¨å­—ç¬¦é›†ç¿»è¯‘å¯ä»¥è§£å†³ä¸Šè¿°é—®é¢˜ï¼š</p>
<ol>
<li>ä½¿ç”¨LSTMæˆ–GRUå¯ä»¥è§£å†³é•¿æ—¶ä¾èµ–é—®é¢˜</li>
<li>ä½¿ç”¨å­—ç¬¦çº§å»ºæ¨¡å¯ä»¥é¿å…è®¸å¤šè¯æ€å˜å½¢è¯å‡ºç°åœ¨è¯å…¸ä¸­</li>
</ol>
<p>ç„¶è€Œä¸Šè¿°å­—ç¬¦çº§æ–¹æ³•ä¾ç„¶éœ€è¦è¿›è¡Œåˆ†è¯ï¼Œç„¶åå¯¹æ¯ä¸ªè¯çš„å­—ç¬¦åºåˆ—è¿›è¡Œç¼–ç ï¼Œå› æ­¤å¼•å‡ºäº†æœ¬æ–‡çš„motivationï¼Œå³æ˜¯å¦èƒ½ç›´æ¥åœ¨ä¸åˆ†è¯çš„å­—ç¬¦åºåˆ—ä¸Šè¿›è¡Œç¿»è¯‘ã€‚</p>
<p>æœ¬æ–‡ä½¿ç”¨çš„æ¨¡å‹åŒæ ·æ˜¯ç»å…¸çš„seq2seqæ¨¡å‹ï¼Œå…¶åˆ›æ–°ç‚¹ä¸»è¦åœ¨decoderç«¯ï¼Œå¼•å…¥äº†ä¸€ç§æ–°çš„ç½‘ç»œç»“æ„biscale RNNï¼Œæ¥æ•è·å­—ç¬¦å’Œè¯ä¸¤ä¸ªtimescaleä¸Šçš„ä¿¡æ¯ã€‚å…·ä½“æ¥è¯´ï¼Œä¸»è¦åˆ†ä¸ºfasterå±‚å’Œslowerå±‚ï¼Œfasterå±‚çš„gatedæ¿€æ´»å€¼å–å†³äºä¸Šä¸€æ­¥çš„fasterå’Œslowerå±‚çš„æ¿€æ´»å€¼ï¼Œfasterå±‚è¦æƒ³å½±å“slowerå±‚ï¼Œåˆ™å¿…é¡»è¦æ˜¯fasterå±‚å¤„ç†å®Œå½“å‰æ•°æ®ï¼Œå¹¶ä¸”è¿›è¡Œé‡ç½®ã€‚æ¢å¥è¯è¯´ï¼Œslowerå±‚æ— æ³•æ¥å—fasterå±‚è¾“å…¥ï¼Œç›´åˆ°fasterå±‚å¤„ç†å®Œå…¶æ•°æ®ï¼Œå› æ­¤æ¯”fasterå±‚è¦æ…¢ï¼Œè€Œè¿™æ ·çš„å±‚æ¬¡ç»“æ„ä¹Ÿå¯¹åº”å­—ç¬¦å’Œè¯åœ¨timescaleä¸Šçš„å…³ç³»ã€‚ä¸‹å›¾ä¸ºç½‘ç»œç»“æ„ç¤ºæ„å›¾ã€‚</p>
<p> <img src="media/1-figure1.png" alt="1-figure1"></p>
<p>åœ¨4ç§è¯­è¨€ç¿»è¯‘ä»»åŠ¡ä¸Šçš„å®éªŒæ˜¾ç¤ºå®Œå…¨å¯ä»¥åœ¨ä¸åˆ†è¯çš„æƒ…å†µä¸‹è¿›è¡Œå­—ç¬¦çº§ç¿»è¯‘ï¼Œæ€§èƒ½ä¼˜äºstate-of-the-artçš„éç¥ç»ç¿»è¯‘ç³»ç»Ÿ</p>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>Sennrich ACL2016æå‡ºä½¿ç”¨BPEç®—æ³•å¯¹subwordå»ºæ¨¡ã€‚Kim AAAI2016ä¸­æå‡ºç›´æ¥å¯¹å­—ç¬¦è¿›è¡Œencodeï¼ŒCosta-jussa ICLR2016ä¸­å°†è¯¥æ¨¡å‹ç”¨åœ¨äº†NMTä»»åŠ¡ä¸­ã€‚Ling ICLR2016çš„å·¥ä½œä¸­ä½¿ç”¨Bi-RNNæ¥ç¼–ç å­—ç¬¦åºåˆ—ã€‚ä»¥ä¸Šå·¥ä½œåŸºäºå­—ç¬¦çº§å±•å¼€ï¼Œä½†å®ƒä»¬éƒ½ä¾èµ–äºçŸ¥é“å¦‚ä½•å°†å­—ç¬¦åˆ†ä¸ºè¯ï¼Œå³åˆ†è¯ã€‚æœ¬æ–‡ç ”ç©¶èƒ½å¦åœ¨ä¸åˆ†è¯çš„æƒ…å†µä¸‹è¿›è¡Œå­—ç¬¦çº§ç¿»è¯‘ã€‚</p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡æ˜¯Bengioç»„å·¥ä½œï¼ŒBi-scale RNNå—å¯å‘äºè¯¥ç»„ä¹‹å‰æå‡ºçš„GF-RNNï¼Œæœ¬æ–‡åˆ›æ–°ç‚¹ä¸»è¦æ˜¯æå‡ºäº†ä¸€ç§æ–°çš„RNNç»“æ„ï¼Œå¯ä»¥åœ¨å­—ç¬¦å’Œè¯ä¸¤ä¸ªtimescalesä¸Šè¿›è¡Œå¤„ç†ï¼Œè¾“å‡ºå­—ç¬¦åºåˆ—ä¸éœ€è¦è¿›è¡Œåˆ†è¯ã€‚ä¸è¶³æ˜¯æœªè€ƒè™‘encoderç«¯æ˜¯å¦ä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨æœªåˆ†è¯çš„å­—ç¬¦åºåˆ—ï¼Œè€Œæ˜¯ä»…ä»…ä½¿ç”¨äº†åˆ†è¯åçš„BPEåºåˆ—ã€‚</p>
<h1 id="Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models"><a href="#Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models" class="headerlink" title="Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models"></a><a href="https://arxiv.org/pdf/1604.00788v2.pdf" target="_blank" rel="external">Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Minh-Thang Luong and Christopher D. Manning</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Stanford University</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>OOV, hybrid word-character models, NMT</p>
<h2 id="æ–‡ç« æ¥æº-1"><a href="#æ–‡ç« æ¥æº-1" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ACL 2016</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æœºå™¨ç¿»è¯‘é‡Œé¢çš„OOVé—®é¢˜, å¦‚ä½•å¤„ç†UNK</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æå‡ºäº†ä¸€ç§æ··åˆword-characterçš„NMTæ¨¡å‹.åœ¨è®­ç»ƒéš¾åº¦å’Œå¤æ‚åº¦ä¸æ˜¯å¾ˆé«˜çš„æƒ…å†µä¸‹,åŒæ—¶è§£å†³æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€çš„OOVé—®é¢˜.<br><img src="media/2-1.png" alt="2-1"></p>
<p>è¿™ä¸ªå›¾è¡¨è¾¾äº†æ¨¡å‹çš„æ•´ä½“æ€è·¯. å¤§å¤šæ•°æƒ…å†µä¸‹,æ¨¡å‹åœ¨word-levelè¿›è¡Œtranslation. å½“å‡ºç°unkçš„æ—¶å€™,åˆ™ä¼šå¯ç”¨character-levelçš„æ¨¡å‹. å¯¹source unk, ç”±character-levelæ¨¡å‹æ¥å¾—åˆ°å®ƒçš„representation; å¯¹target unk, ç”¨character-levelæ¨¡å‹æ¥äº§ç”Ÿword.</p>
<ol>
<li>æ•´ä½“ä¸Šé‡‡ç”¨ä»–ä»¬ç»„ä»¥å‰æå‡ºçš„åŸºäºglobal attentionçš„encoder-decoderæ¨¡å‹. RNNé‡‡ç”¨çš„æ˜¯deep LSTM. </li>
<li>æºè¯­è¨€ç«¯å’Œç›®æ ‡è¯­è¨€ç«¯çš„character-levelæ¨¡å‹éƒ½æ˜¯åŸºäºcharacterçš„deep LSTM. å¯¹æºè¯­è¨€ç«¯æ¥è¯´, å®ƒçš„character-levelæ¨¡å‹æ˜¯context independentçš„. éšå±‚çŠ¶æ€å…¨éƒ¨åˆå§‹åŒ–ä¸º0, å› æ­¤åœ¨è®­ç»ƒæ—¶å¯ä»¥é¢„å…ˆè®¡ç®—mini-batché‡Œçš„æ¯ä¸€ä¸ªrare wordçš„representation. è€Œå¯¹äºç›®æ ‡è¯­è¨€ç«¯æ¥è¯´, å®ƒçš„character-levelæ¨¡å‹æ˜¯context dependentçš„.å®ƒçš„ç¬¬ä¸€å±‚çš„hidden stateè¦æ ¹æ®å½“å‰contextæ¥åˆå§‹åŒ–, å…¶å®ƒéƒ¨åˆ†éƒ½åˆå§‹åŒ–ä¸º0.è®­ç»ƒæ—¶, åœ¨ç›®æ ‡è¯­è¨€çš„decoderé˜¶æ®µ, é¦–å…ˆç”¨word-levelçš„decoderäº§ç”Ÿå¥å­, è¿™æ—¶å¥å­é‡ŒåŒ…å«äº†ä¸€äº›unk. æ¥ç€å¯¹è¿™äº›unk, ç”¨character-levelæ¨¡å‹ä»¥batch modeæ¥äº§ç”Ÿrare word.</li>
<li>å¯¹äºç›®æ ‡è¯­è¨€ç«¯character-levelæ¨¡å‹çš„åˆå§‹åŒ–é—®é¢˜, ä½œè€…æå‡ºäº†ä¸¤ç§æ–¹æ³•æ¥è¡¨ç¤ºå½“å‰çš„context. ä¸€ç§å«åšsame-path, ç”¨é¢„æµ‹<unk>çš„softmaxå±‚ä¹‹å‰çš„htæ¥è¡¨è¾¾. ä½†æ˜¯å› ä¸ºhtæ˜¯ç”¨æ¥é¢„æµ‹<unk>çš„, æ‰€ä»¥æ‰€æœ‰htçš„å€¼éƒ½ä¼šæ¯”è¾ƒç›¸ä¼¼,è¿™æ ·å¾ˆéš¾ç”¨æ¥äº§ç”Ÿä¸åŒçš„ç›®æ ‡rare word. å› æ­¤ä½œè€…æå‡ºäº†ç¬¬äºŒç§è¡¨è¾¾å«åšseparate-path, ç”¨htâ€™æ¥è¡¨è¾¾context. htâ€™ä¸ç”¨é¢„æµ‹unk, æ˜¯ä¸“é—¨ä½œä¸ºcontextåœ¨character-levelçš„è¾“å…¥çš„. å®ƒçš„è®¡ç®—æ–¹æ³•å’Œhtâ€™ç›¸åŒ,åªæ˜¯ç”¨äº†ä¸€ä¸ªä¸ä¸€æ ·çš„çŸ©é˜µ.</unk></unk></li>
<li>æ¨¡å‹è®­ç»ƒçš„ç›®æ ‡å‡½æ•°æ˜¯cross-entropy loss, åŒæ—¶è€ƒè™‘äº†word levelå’Œcharacter levelçš„loss. </li>
</ol>
<h2 id="ç›¸å…³å·¥ä½œ-1"><a href="#ç›¸å…³å·¥ä½œ-1" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>NMTçš„æ¨¡å‹åˆ†ä¸ºword-levelå’Œcharacter-levelçš„. å¯¹äºword-levelæ¨¡å‹,è¦è§£å†³OOVé—®é¢˜, ä¹‹å‰çš„å·¥ä½œæå‡ºäº†unk replacement(Luong et al. 2015b), ä½¿ç”¨å¤§å­—å…¸å¹¶åœ¨softmaxæ—¶è¿›è¡Œé‡‡æ ·(Jean et al. 2015), å¯¹unkè¿›è¡ŒHuffmanç¼–ç (Chitnis et al. 2015)ç­‰æ–¹æ³•. è€Œå¯¹äºcharacter-levelçš„æ¨¡å‹, æœ¬èº«å¯ä»¥å¤„ç†OOVè¯, ä½†æ˜¯è®­ç»ƒéš¾åº¦å’Œå¤æ‚åº¦ä¼šå¢åŠ .</p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡çš„åˆ›æ–°ä¹‹å¤„åœ¨äºæå‡ºäº†æ··åˆword-character modelçš„NMTæ¨¡å‹. è¿™ä¸ªæ··åˆæ¨¡å‹ç»“åˆäº†äºŒè€…çš„ä¼˜ç‚¹, åœ¨ä¿è¯æ¨¡å‹å¤æ‚åº¦è¾ƒä½çš„åŒæ—¶,å®ç°äº†å¾ˆå¥½çš„æ•ˆæœ.å› ä¸ºåŠ å…¥äº†character, ç‰¹åˆ«é€‚åˆå•è¯æœ‰ä¸°å¯Œå˜å½¢çš„è¯­è¨€. </p>
<h1 id="Character-based-Neural-Machine-Translation"><a href="#Character-based-Neural-Machine-Translation" class="headerlink" title="Character-based Neural Machine Translation"></a><a href="http://arxiv.org/abs/1511.04586" target="_blank" rel="external">Character-based Neural Machine Translation</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Marta R. Costa-jussa and Jose A. R. Fonollosa </p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>TALP Research Center<br>Universitat Politecnica de Catalunya, Barcelona</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>NMTï¼Œcharacter-based word embeddingsï¼ŒCNN</p>
<h2 id="æ–‡ç« æ¥æº-2"><a href="#æ–‡ç« æ¥æº-2" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ICLR2016</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æœ¬æ–‡æå‡ºä½¿ç”¨character-based word embeddingsçš„NMTï¼Œå¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šå…‹æœæœºå™¨ç¿»è¯‘ä¸­OOVé—®é¢˜ã€‚</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p><img src="media/3-encoder_decoder.png" alt="3-encoder_decode"></p>
<p>å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œè¿™ç¯‡è®ºæ–‡ä½¿ç”¨çš„åŸºæœ¬æ¨¡å‹æ¶æ„æ˜¯ä¸€ä¸ªå¸¦attentionæœºåˆ¶çš„seq2seqçš„encoder-decoderçš„æ¶æ„ï¼Œä½¿ç”¨çš„ç¥ç»ç½‘ç»œå•å…ƒæ˜¯GRUã€‚encoderæŠŠæºå¥å­è½¬åŒ–æˆä¸€ä¸ªå‘é‡ï¼ˆåŒå‘ï¼‰ï¼Œä½¿ç”¨attentionçš„æœºåˆ¶æ¥æ•è·contextä¿¡æ¯ï¼ŒdecoderæŠŠcontextè§£ç æˆç›®æ ‡å¥å­ã€‚ç½‘ç»œçš„è¾“å…¥ä»ç„¶ä½¿ç”¨word embeddingï¼Œä½†æ˜¯ä½œè€…åœ¨è·å–word embeddingçš„æ—¶å€™ä½¿ç”¨çš„æ–¹æ³•ä¸åŒã€‚æœ¬æ–‡æ˜¯åŸºäºè¯ä¸­çš„characteræ¥ç”Ÿæˆword embeddingçš„ï¼Œå…·ä½“æ–¹æ³•å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚<br><img src="media/3-embedding.png" alt="3-embedding"></p>
<p>ä¸Šå›¾ä¸­ï¼Œæœ€åº•å±‚æ˜¯ä¸€ä¸ªcharacter-based embeddingç»„æˆçš„åºåˆ—ï¼Œå¯¹åº”çš„æ˜¯æ¯ä¸ªè¯ä¸­çš„å­—æ¯ã€‚ç„¶åè¿™ä¸ªåºåˆ—è¢«é€å…¥ä¸€ä¸ªç”±ä¸åŒé•¿åº¦çš„ä¸€ç»´å·ç§¯è¿‡æ»¤å™¨ç»„æˆçš„é›†åˆä¸­è¿›è¡Œå¤„ç†ï¼Œä¸åŒçš„é•¿åº¦å¯¹åº”å•è¯ä¸­ä¸åŒæ•°é‡çš„å­—æ¯ï¼ˆä»1åˆ°7ï¼‰ã€‚å¯¹äºæ¯ä¸ªå·ç§¯è¿‡æ»¤å™¨ï¼Œåªå–æœ€å¤§çš„å€¼ä½œä¸ºè¾“å‡ºã€‚ç„¶åæŠŠæ¯ä¸ªå·ç§¯è¿‡æ»¤å™¨è¾“å‡ºçš„æœ€å¤§å€¼è¿æ¥èµ·æ¥ç»„æˆä¸€ä¸ªå‘é‡ã€‚æœ€åè¿™ä¸ªå‘é‡å†é€šè¿‡ä¸¤å±‚Highway layerçš„å¤„ç†ä½œä¸ºæœ€ç»ˆçš„word embeddingsã€‚è¿™ä¸ªæ–¹æ³•çš„è¯¦ç»†ä¿¡æ¯å¯ä»¥å‚è€ƒKimçš„è®ºæ–‡<a href="http://arxiv.org/abs/1508.06615" target="_blank" rel="external">Character-Aware Neural Language Models</a>(2016)ã€‚</p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><ol>
<li>æœ¬æ–‡æ•°æ®é›†[German-English WMT data] (<a href="http://www.statmt.org/wmt15/translation-task.html" target="_blank" rel="external">http://www.statmt.org/wmt15/translation-task.html</a>) <br></li>
<li>å»ºç«‹å¯¹æ¯”æ¨¡å‹ä½¿ç”¨çš„è½¯ä»¶åŒ…<a href="http://dl4mt.computing.dcu.ie/" target="_blank" rel="external">DL4MT</a> </li>
</ol>
<h2 id="ç›¸å…³å·¥ä½œ-2"><a href="#ç›¸å…³å·¥ä½œ-2" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>ï¼ˆ1ï¼‰2003å¹´ï¼ŒåŸºäºçŸ­è¯­çš„ç»Ÿè®¡æœºå™¨ç¿»è¯‘æ¨¡å‹ã€‚Statistical Phrase-Based Translation <br><br>ï¼ˆ2ï¼‰2013å¹´ï¼ŒåŸºäºç¥ç»ç½‘ç»œçš„æœºå™¨ç¿»è¯‘æ¨¡å‹ã€‚Recurrent continuous translation models <br><br>ï¼ˆ3ï¼‰2014å¹´ï¼Œseq2seqçš„ç¥ç»ç½‘ç»œæ¨¡å‹ç”¨äºæœºå™¨ç¿»è¯‘ã€‚Sequence to sequence learning with neural networks </p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡ä½œè€…å°†åŸºäºcharacteræ¥äº§ç”Ÿword embeddingçš„æ–¹æ³•åº”ç”¨äºæœºå™¨ç¿»è¯‘ï¼Œå¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šå…‹æœOOVçš„é—®é¢˜ã€‚åŒæ—¶ï¼Œç”±äºåˆ©ç”¨äº†å•è¯å†…éƒ¨çš„ä¿¡æ¯ï¼Œè¿™ç¯‡è®ºæ–‡æå‡ºçš„æ–¹æ³•å¯¹äºè¯å½¢å˜åŒ–ä¸°å¯Œçš„è¯­è¨€çš„ç¿»è¯‘ä¹Ÿäº§ç”Ÿäº†æ›´å¥½çš„æ•ˆæœã€‚ä½†æ˜¯ï¼Œä½œè€…åªæ˜¯åœ¨source sideä½¿ç”¨äº†ä¸Šè¿°æ–¹æ³•ï¼Œå¯¹äºtarget sideï¼Œä»ç„¶é¢ä¸´è¯å…¸å¤§å°çš„é™åˆ¶ã€‚</p>
<h1 id="CHARACTER-BASED-NEURAL-MACHINE-TRANSLATION"><a href="#CHARACTER-BASED-NEURAL-MACHINE-TRANSLATION" class="headerlink" title="CHARACTER-BASED NEURAL MACHINE TRANSLATION"></a><a href="http://arxiv.org/abs/1511.04586" target="_blank" rel="external">CHARACTER-BASED NEURAL MACHINE TRANSLATION</a></h1><h2 id="ä½œè€…-3"><a href="#ä½œè€…-3" class="headerlink" title="ä½œè€…:"></a>ä½œè€…:</h2><p>Wang Ling, Isabel Trancoso, Chris Dyer, Alan W Black</p>
<h2 id="å•ä½-3"><a href="#å•ä½-3" class="headerlink" title="å•ä½"></a>å•ä½</h2><ol>
<li>LF Spoken Systems Lab,Instituto Superior Tecnico Lisbon, Portugal</li>
<li>Language Technologies Institute, Carnegie Mellon University Pittsburga, PA 15213, USA</li>
</ol>
<h2 id="å…³é”®è¯-3"><a href="#å…³é”®è¯-3" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>NMT, Character-Based</p>
<h2 id="æ–‡ç« æ¥æº-3"><a href="#æ–‡ç« æ¥æº-3" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ICLR 2016</p>
<h2 id="é—®é¢˜-3"><a href="#é—®é¢˜-3" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å°è¯•åœ¨å­—ç¬¦çº§åˆ«ä¸Šåº”ç”¨ç¥ç»æœºå™¨å­¦ä¹ æ–¹æ³•</p>
<h2 id="æ¨¡å‹-3"><a href="#æ¨¡å‹-3" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>åœ¨å¸¦æ³¨æ„åŠ›æœºåˆ¶çš„ç¥ç»æœºå™¨å­¦ä¹ æ¨¡å‹çš„å‰åç«¯å¢åŠ å­—ç¬¦åˆ°è¯ï¼ˆC2W)å’Œè¯å‘é‡åˆ°å­—ç¬¦ï¼ˆV2Cï¼‰çš„æ¨¡å—ã€‚</p>
<p><img src="media/4-C2W.png" alt="4-C2"></p>
<p>å›¾ä¸­ï¼Œå°çŸ©å½¢æ˜¯ä¸€ä¸ªåŒå‘LSTMï¼ŒåŒå‘LSTMçš„å‰å‘å’Œåå‘çš„æœ€ç»ˆçŠ¶æ€ä»¥åŠbiasä¹‹å’Œä¸ºè¯çš„å‘é‡è¡¨ç¤ºã€‚</p>
<p><img src="media/4-V2C-1.png" alt="4-V2"></p>
<p>è¿™ä¸ªæ¨¡å—ä¸»è¦ç”±ä¸‰ä¸ªæ­¥éª¤ç»„æˆï¼š</p>
<ol>
<li>å°†å­—ç¬¦è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºã€‚</li>
<li>å°†å­—ç¬¦å‘é‡å’Œä¹‹å‰æ¨¡å‹äº§ç”Ÿæ³¨æ„åŠ›å‘é‡çš„aå’Œç›®æ ‡è¯åœ¨å‰å‘LSTMä¸­äº§ç”Ÿçš„å‘é‡è¡¨ç¤ºåšæ‹¼æ¥å¹¶è¾“å…¥åˆ°LSTMã€‚</li>
<li>å°†å¾—åˆ°çš„å‘é‡è¾“å…¥åˆ°softmaxå±‚å¾—åˆ°ç»“æœã€‚</li>
</ol>
<h2 id="ç›¸å…³å·¥ä½œ-3"><a href="#ç›¸å…³å·¥ä½œ-3" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><ol>
<li>Neural machine translation by jointly learning to align and translate. </li>
</ol>
<h2 id="ç®€è¯„-3"><a href="#ç®€è¯„-3" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¿™ç¯‡æ–‡ç« åœ¨åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„æœºå™¨ç¿»è¯‘æ¨¡å‹ä¸Šå¢åŠ äº†ä¸¤ä¸ªæ¨¡å—ã€‚ç”±äºæ˜¯åŸºäºå­—ç¬¦é›†åˆ«çš„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹è‡ªç„¶å¯ä»¥å­¦å¾—ä¸€äº›è¯­è¨€ä¸­çš„å‰åç¼€åœ¨ç¿»è¯‘ä¸­çš„å…³ç³»ã€‚æ­¤å¤–ï¼ŒåŸºäºå­—ç¬¦çº§åˆ«çš„æ¨¡å‹åœ¨ç¿»è¯‘æœªçŸ¥è¯æ—¶æœ‰çµæ´»æ€§ã€‚å¯æ˜¯ï¼Œæ–‡ä¸­ä¹Ÿæåˆ°ï¼Œè¯¥æ¨¡å‹ä¸ºèƒ½å¤Ÿå‡†ç¡®çš„ç¿»è¯‘æœªçŸ¥è¯ã€‚å¹¶ä¸”è¯¥æ–‡ä¹Ÿæ²¡æœ‰æ˜ç¡®è¡¨æ˜è¯¥æ¨¡å‹å’Œå…¶ä»–æ¨¡å‹ç›¸æ¯”å…·æœ‰å“ªäº›æ˜æ˜¾çš„ä¼˜åŠ¿ã€‚ä»å®é™…ä¸Šæ¥è¯´ï¼Œè¯¥æ¨¡å‹åœ¨V2Céƒ¨åˆ†çš„è®­ç»ƒé€Ÿåº¦æ…¢æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„å¼±ç‚¹ï¼Œå› æ­¤è‹¥ä»…æ ¹æ®æ–‡ç« çš„è¡¨è¿°ï¼Œè¯¥æ¨¡å‹çš„å®é™…åº”ç”¨ä»·å€¼åº”è¯¥æœ‰é™ã€‚</p>
<h1 id="Neural-Machine-Translation-of-Rare-Words-with-Subword-Units"><a href="#Neural-Machine-Translation-of-Rare-Words-with-Subword-Units" class="headerlink" title="Neural Machine Translation of Rare Words with Subword Units"></a><a href="https://arxiv.org/abs/1508.07909" target="_blank" rel="external">Neural Machine Translation of Rare Words with Subword Units</a></h1><h2 id="ä½œè€…-4"><a href="#ä½œè€…-4" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Rico Sennrich and Barry Haddow and Alexandra Birch</p>
<h2 id="å•ä½-4"><a href="#å•ä½-4" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>School of Informatics, University of Edinburgh</p>
<h2 id="å…³é”®è¯-4"><a href="#å…³é”®è¯-4" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>NMT;Rare Words;Subword Units;BPE</p>
<h2 id="æ–‡ç« æ¥æº-4"><a href="#æ–‡ç« æ¥æº-4" class="headerlink" title="æ–‡ç« æ¥æº"></a>æ–‡ç« æ¥æº</h2><p>ACL 2016</p>
<h2 id="é—®é¢˜-4"><a href="#é—®é¢˜-4" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>NMTä¸­çš„OOVï¼ˆé›†å¤–è¯ï¼‰å’Œç½•è§è¯ï¼ˆRare Wordsï¼‰é—®é¢˜é€šå¸¸ç”¨back-off è¯å…¸çš„æ–¹å¼æ¥è§£å†³ï¼Œæœ¬æ–‡å°è¯•ç”¨ä¸€ç§æ›´ç®€å•æœ‰æ•ˆçš„æ–¹å¼ï¼ˆSubword Unitsï¼‰æ¥è¡¨ç¤ºå¼€æ”¾è¯è¡¨ã€‚</p>
<h2 id="æ¨¡å‹-4"><a href="#æ¨¡å‹-4" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æœ¬æ–‡ä»å‘½åå®ä½“ã€åŒæ ¹è¯ã€å¤–æ¥è¯­ã€ç»„åˆè¯ï¼ˆç½•è§è¯æœ‰ç›¸å½“å¤§æ¯”ä¾‹æ˜¯ä¸Šè¿°å‡ ç§ï¼‰çš„ç¿»è¯‘ç­–ç•¥ä¸­å¾—åˆ°å¯å‘ï¼Œè®¤ä¸ºæŠŠè¿™äº›ç½•è§è¯æ‹†åˆ†ä¸ºâ€œå­è¯å•å…ƒâ€(subword units)çš„ç»„åˆï¼Œå¯ä»¥æœ‰æ•ˆçš„ç¼“è§£NMTçš„OOVå’Œç½•è§è¯ç¿»è¯‘çš„é—®é¢˜ã€‚<br>å­è¯å•å…ƒçš„æ‹†åˆ†ç­–ç•¥ï¼Œåˆ™æ˜¯å€Ÿé‰´äº†ä¸€ç§æ•°æ®å‹ç¼©ç®—æ³•ï¼šByte Pair Encoding(BPE)(Gage,1994)ç®—æ³•ã€‚è¯¥ç®—æ³•çš„æ“ä½œè¿‡ç¨‹å’Œç¤ºä¾‹å¦‚Figure1æ‰€ç¤ºã€‚<br><img src="media/5-Fig1.jpg" alt="5-Fig1"></p>
<p>ä¸åŒäº(Chitnis and DeNero,2015)æå‡ºçš„éœå¤«æ›¼ç¼–ç ï¼Œè¿™é‡Œçš„å‹ç¼©ç®—æ³•ä¸æ˜¯é’ˆå¯¹äºè¯åšå˜é•¿ç¼–ç ï¼Œè€Œæ˜¯å¯¹äºå­è¯æ¥æ“ä½œã€‚è¿™æ ·ï¼Œå³ä½¿æ˜¯è®­ç»ƒè¯­æ–™é‡Œæœªè§è¿‡çš„æ–°è¯ï¼Œä¹Ÿå¯ä»¥é€šè¿‡å­è¯çš„æ‹¼æ¥æ¥ç”Ÿæˆç¿»è¯‘ã€‚<br>æœ¬æ–‡è¿˜æ¢è®¨äº†BPEçš„ä¸¤ç§ç¼–ç æ–¹å¼ï¼šä¸€ç§æ˜¯æºè¯­è¨€è¯æ±‡å’Œç›®æ ‡è¯­è¨€è¯æ±‡åˆ†åˆ«ç¼–ç ï¼Œå¦ä¸€ç§æ˜¯åŒè¯­è¯æ±‡è”åˆç¼–ç ã€‚å‰è€…çš„ä¼˜åŠ¿æ˜¯è®©è¯è¡¨å’Œæ–‡æœ¬çš„è¡¨ç¤ºæ›´ç´§å‡‘ï¼Œåè€…åˆ™å¯ä»¥å°½å¯èƒ½ä¿è¯åŸæ–‡å’Œè¯‘æ–‡çš„å­è¯åˆ‡åˆ†æ–¹å¼ç»Ÿä¸€ã€‚ä»å®éªŒç»“æœæ¥çœ‹ï¼Œåœ¨éŸ³è¯‘æˆ–ç®€å•å¤åˆ¶è¾ƒå¤šçš„æƒ…å½¢ä¸‹ï¼ˆæ¯”å¦‚è‹±å¾·ï¼‰ç¿»è¯‘ï¼Œè”åˆç¼–ç çš„æ•ˆæœæ›´ä½³ã€‚<br>å®éªŒç»“æœåˆ†åˆ«åœ¨WMT15è‹±å¾·å’Œè‹±ä¿„çš„ä»»åŠ¡ä¸Šå¾—åˆ°1.1å’Œ1.3ä¸ªBLEUå€¼çš„æå‡ã€‚</p>
<h2 id="èµ„æº-1"><a href="#èµ„æº-1" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æœ¬æ–‡æå‡ºçš„å­è¯æ‹†åˆ†ç®—æ³•ä»£ç åœ¨ <a href="https://github.com/rsennrich/subword-nmt" target="_blank" rel="external">https://github.com/rsennrich/subword-nmt</a><br>å®éªŒæ‰€ç”¨çš„NMTç³»ç»Ÿä¸ºGroundhog: github.com/sebastien-j/LV_groundhog<br>å®éªŒæ•°æ®æ¥è‡ªWMT 2015</p>
<h2 id="ç›¸å…³å·¥ä½œ-4"><a href="#ç›¸å…³å·¥ä½œ-4" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>OOVçš„å¤„ç†ä¸€ç›´æ˜¯æœºå™¨ç¿»è¯‘ç ”ç©¶çš„é‡ç‚¹ã€‚<br>åŸºäºå­—ç¬¦çš„ç¿»è¯‘åœ¨çŸ­è¯­SMTæ¨¡å‹ä¸­å°±å·²è¢«æå‡ºï¼Œå¹¶åœ¨ç´§å¯†ç›¸å…³çš„è¯­ç§å¯¹ä¸ŠéªŒè¯æ˜¯æˆåŠŸçš„(Vilar et al., 2007; Tiedemann,2009; Neubig et al., 2012)ã€‚  æ­¤å¤–è¿˜æœ‰å„ç§å½¢æ€ç´ åˆ‡åˆ†æ–¹æ³•åº”ç”¨äºçŸ­è¯­æ¨¡å‹ï¼Œ(NieÃŸen and Ney,2000; Koehn and Knight, 2003; Virpioja et al.,2007; Stallard et al., 2012)ã€‚<br>å¯¹äºNMTï¼Œä¹Ÿæœ‰å¾ˆå¤šåŸºäºå­—ç¬¦æˆ–å½¢æ€ç´ çš„æ–¹æ³•ç”¨äºç”Ÿæˆå®šé•¿è¿ç»­è¯å‘é‡(Luong et al., 2013; Botha and Blunsom, 2014; Ling et al., 2015a; Kim et al., 2015)ã€‚ä¸æœ¬æ–‡ç±»ä¼¼çš„ä¸€é¡¹å·¥ä½œ (Ling et al., 2015b)å‘ç°åœ¨åŸºäºè¯çš„æ–¹æ³•ä¸Šæ²¡æœ‰æ˜æ˜¾æå‡ã€‚å…¶ä¸æœ¬æ–‡çš„ä¸€ä¸ªåŒºåˆ«åœ¨äºï¼Œattentionæœºåˆ¶ä»ç„¶åœ¨è¯å±‚çº§è¿›è¡Œæ“ä½œï¼Œè€Œæœ¬æ–‡åœ¨å­è¯å±‚çº§ä¸Šã€‚</p>
<h2 id="ç®€è¯„-4"><a href="#ç®€è¯„-4" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¿™ç¯‡æ–‡ç« çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§ä»‹ä¹å­—ç¬¦å’Œå•è¯ä¹‹é—´ï¼Œä¹Ÿä¸åŒäºå­—ç¬¦n-gramçš„æ–‡æœ¬è¡¨ç¤ºå•å…ƒï¼Œå¹¶å€Ÿé‰´BPEå‹ç¼©ç®—æ³•ï¼Œåœ¨è¯è¡¨å¤§å°å’Œæ–‡æœ¬é•¿åº¦ä¸¤ä¸ªæ–¹é¢å–å¾—ä¸€ä¸ªè¾ƒä¸ºå¹³è¡¡çš„çŠ¶æ€ã€‚åº”ç”¨åœ¨éåŒæº/è¿‘æºçš„è¯­è¨€å¯¹ï¼ˆå¦‚è‹±æ±‰ï¼‰æ˜¯å¦å¯ä»¥æœ‰ç±»ä¼¼çš„æ•ˆæœï¼Œå°šå¾…ç ”ç©¶ã€‚åœ¨NMTæ¨¡å‹çš„ä¼˜åŒ–ä¸Šï¼Œä¹Ÿè¿˜æœ‰æ¢è®¨çš„ç©ºé—´ã€‚<br>æœ¬æ–‡çš„å®éªŒè¯„ä»·æ–¹æ³•å€¼å¾—å­¦ä¹ ï¼Œå•çœ‹BLEUå€¼å¹¶ä¸è§‰å¾—æœ‰æƒŠè‰³ä¹‹å¤„ï¼Œä½†åŠ ä¸ŠCHR F3å’Œ(å¯¹æ‰€æœ‰è¯ã€ç½•è§è¯å’Œé›†å¤–è¯åˆ†åˆ«ç»Ÿè®¡çš„)unigram F1è¿™ä¸¤ä¸ªè¯„ä»·æŒ‡æ ‡ï¼Œå°¤å…¶æ˜¯Figure2å’Œ3ç”»å‡ºæ¥çš„æ•ˆæœï¼Œè¿˜æ˜¯è®©äººæ¯”è¾ƒä¿¡æœçš„ã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>OOVè¯å¯¹äºç¿»è¯‘æ€§èƒ½å’Œå®ç”¨æ€§çš„å½±å“éå¸¸å·¨å¤§ï¼Œå¦‚ä½•å¤„ç†OOVè¯å¹¶è¾¾åˆ°open vocabularyä¸€ç›´æ˜¯NMTçš„ä¸»è¦ç ”ç©¶æ–¹å‘ã€‚ä¼ ç»Ÿæ–¹æ³•åŸºäºå•è¯çº§åˆ«æ¥å¤„ç†è¯¥é—®é¢˜ï¼Œæ¯”å¦‚ä½¿ç”¨UNKæ›¿æ¢ã€æ‰©å¤§è¯å…¸è§„æ¨¡ç­‰æ–¹æ³•ï¼Œå¾€å¾€æ²»æ ‡ä¸æ²»æœ¬ã€‚å› æ­¤æœ€è¿‘ä¸€äº›ç ”ç©¶è€…æå‡ºåŸºäºå­—ç¬¦çš„NMTæ¨¡å‹ï¼Œå–å¾—äº†ä¸é”™çš„æˆç»©ï¼Œå­—ç¬¦çº§æ–¹æ³•çš„ä¸»è¦ä¼˜åŠ¿åŒ…æ‹¬ä¸å—è¯­è¨€çš„å½¢æ€å˜åŒ–ã€èƒ½é¢„æµ‹å‡ºè¯å…¸ä¸­æœªå‡ºç°çš„å•è¯å¹¶é™ä½è¯å…¸å¤§å°ç­‰ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼ŒåŸºäºå­—ç¬¦çš„æ¨¡å‹ä¸ä»…å±€é™äºNMTä¸Šï¼Œä»»ä½•ç”Ÿæˆæ¨¡å‹éƒ½é¢ä¸´OOVè¯é—®é¢˜ï¼Œå› æ­¤æ˜¯å¦èƒ½å¤Ÿå°†å­—ç¬¦çº§æ–¹æ³•ç”¨åœ¨å…¶ä»–NLPä»»åŠ¡ï¼Œæ¯”å¦‚é˜…è¯»ç†è§£æˆ–æ–‡æœ¬æ‘˜è¦ä¸Šï¼Œè®©æˆ‘ä»¬æ‹­ç›®ä»¥å¾…ã€‚</p>
<p>ä»¥ä¸Šä¸ºæœ¬æœŸPaperweeklyçš„ä¸»è¦å†…å®¹ï¼Œæ„Ÿè°¢EdwardHuxã€Mygod9ã€Jaylee1992ã€Susieå’ŒAllenCaiäº”ä½åŒå­¦çš„æ•´ç†ã€‚</p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"><br>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-24T16:57:50.000Z"><a href="/2016/09/24/cs-CL-weekly-2016-09-19-2016-09-23/">2016-09-24</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/24/cs-CL-weekly-2016-09-19-2016-09-23/">cs.CL weekly 2016.09.19-2016.09.23</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="ä¸€å‘¨å€¼å¾—è¯»"><a href="#ä¸€å‘¨å€¼å¾—è¯»" class="headerlink" title="ä¸€å‘¨å€¼å¾—è¯»"></a>ä¸€å‘¨å€¼å¾—è¯»</h1><h2 id="Long-Term-Trends-in-the-Public-Perception-of-Artificial-Intelligence"><a href="#Long-Term-Trends-in-the-Public-Perception-of-Artificial-Intelligence" class="headerlink" title="Long-Term Trends in the Public Perception of Artificial Intelligence"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.04904v1.pdf" target="_blank" rel="external">Long-Term Trends in the Public Perception of Artificial Intelligence</a></h2><p>æœ¬æ–‡ç ”ç©¶äº†30å¹´æ¥çº½çº¦æ—¶æŠ¥å¯¹AIçš„æŠ¥é“ï¼Œç ”ç©¶äº†äººä»¬è¿™30å¹´æ¥å¯¹AIçš„å…´è¶£ã€å…³æ³¨åº¦å’Œå„ç§å„æ ·çš„è®¨è®ºã€‚æ˜¯ä¸€ç¯‡å¾ˆæœ‰æ„æ€çš„æ–‡ç« ï¼Œæ˜¯ä¸€ç§é•¿æ—¶é—´æ®µå†…çš„èˆ†æƒ…ç›‘æµ‹å’Œåˆ†æã€‚</p>
<h2 id="Distant-Supervision-for-Relation-Extraction-beyond-the-Sentence-Boundary"><a href="#Distant-Supervision-for-Relation-Extraction-beyond-the-Sentence-Boundary" class="headerlink" title="Distant Supervision for Relation Extraction beyond the Sentence Boundary"></a><a href="http://120.52.73.77/arxiv.org/pdf/1609.04873v1.pdf" target="_blank" rel="external">Distant Supervision for Relation Extraction beyond the Sentence Boundary</a></h2><p>æœ¬æ–‡ç ”ç©¶çš„é—®é¢˜æ˜¯éç»“æ„åŒ–æ–‡æœ¬ä¸­çš„å…³ç³»æŠ½å–é—®é¢˜ï¼Œé’ˆå¯¹ä¼ ç»Ÿæ–¹æ³•åœ¨æŠ½å–å…³ç³»æ—¶ä»…é™äºå•ä¸ªå¥å­ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œä»å¤šä¸ªå¥å­ä¸­è¿›è¡Œå…³ç³»æŠ½å–ã€‚</p>
<h2 id="What-You-Get-Is-What-You-See-A-Visual-Markup-Decompiler"><a href="#What-You-Get-Is-What-You-See-A-Visual-Markup-Decompiler" class="headerlink" title="What You Get Is What You See: A Visual Markup Decompiler"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.04938v1.pdf" target="_blank" rel="external">What You Get Is What You See: A Visual Markup Decompiler</a></h2><p>ã€è½¬å‘è¾ƒå¤šã€‘æœ¬æ–‡ç ”ç©¶çš„é—®é¢˜æ˜¯å¦‚ä½•ä»webé¡µé¢ä¸­ç”Ÿæˆhtmlä»£ç ï¼Œä»¥åŠå¦‚ä½•ä»å…¬å¼å›¾ç‰‡ä¸­ç”Ÿæˆlatexä»£ç ï¼Œä¸ºæ­¤ä½œè€…æ„é€ äº†ä¸¤ä¸ªç›¸å…³çš„å¤§å‹æ•°æ®é›†ï¼Œç”¨äº†å®Œå…¨æ•°æ®é©±åŠ¨çš„ç«¯åˆ°ç«¯è®­ç»ƒæ–¹æ³•å¾—åˆ°äº†ä¸é”™çš„æ•ˆæœã€‚æœ¬æ–‡å·¥ä½œæ¥è‡ªHarvardã€‚</p>
<p>Demo|Dataset|Code: <a href="http://lstm.seas.harvard.edu/latex/" target="_blank" rel="external">http://lstm.seas.harvard.edu/latex/</a></p>
<h2 id="Select-Additive-Learning-Improving-Cross-individual-Generalization-in-Multimodal-Sentiment-Analysis"><a href="#Select-Additive-Learning-Improving-Cross-individual-Generalization-in-Multimodal-Sentiment-Analysis" class="headerlink" title="Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.05244v1.pdf" target="_blank" rel="external">Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis</a></h2><p>æœ¬æ–‡ç ”ç©¶çš„å†…å®¹æ˜¯å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æï¼Œé’ˆå¯¹å½“å‰ç›¸å…³é«˜è´¨é‡æ•°æ®é›†è§„æ¨¡å¤ªå°é€ æˆçš„æƒ…æ„Ÿä¾èµ–äºä¸ªä½“ç‰¹å¾çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§Select-Additiveå­¦ä¹ æ–¹æ³•æé«˜é€šç”¨æ€§ã€‚ </p>
<h2 id="Interactive-Spoken-Content-Retrieval-by-Deep-Reinforcement-Learning"><a href="#Interactive-Spoken-Content-Retrieval-by-Deep-Reinforcement-Learning" class="headerlink" title="Interactive Spoken Content Retrieval by Deep Reinforcement Learning"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.05234v1.pdf" target="_blank" rel="external">Interactive Spoken Content Retrieval by Deep Reinforcement Learning</a></h2><p>æœ¬æ–‡ç ”ç©¶çš„å†…å®¹æ˜¯DQNç®—æ³•æ¥åšè¯­éŸ³å†…å®¹æ£€ç´¢ï¼Œé€šè¿‡äººæœºäº¤äº’æ¥å®Œæˆå†…å®¹æ£€ç´¢ã€‚DQNç›¸æ¯”ä¼ ç»Ÿçš„RLæ¨¡å‹æ˜æ˜¾çš„ä¼˜åŠ¿åœ¨äºä¸ä¾èµ–hand-crafted featuresã€‚æœ¬æ–‡è¢«Interspeech 2016å½•ç”¨ã€‚</p>
<h2 id="Graph-Structured-Representations-for-Visual-Question-Answering"><a href="#Graph-Structured-Representations-for-Visual-Question-Answering" class="headerlink" title="Graph-Structured Representations for Visual Question Answering"></a><a href="http://arxiv.org/pdf/1609.05600v1.pdf" target="_blank" rel="external">Graph-Structured Representations for Visual Question Answering</a></h2><p>æœ¬æ–‡ç ”ç©¶å†…å®¹ä¸ºVQAï¼ŒVQAçš„ä¸»è¦æŒ‘æˆ˜åœ¨äºå¯¹visualå’Œtextä¸¤ä¸ªé¢†åŸŸéƒ½éœ€è¦ç†è§£ã€‚ä¼ ç»Ÿçš„æ¨¡å‹ä¸­å¸¸å¸¸å¿½ç•¥åœºæ™¯ä¸­çš„ç»“æ„å’Œé—®é¢˜ä¸­çš„è¯­è¨€ç»“æ„ï¼Œæœ¬æ–‡é’ˆå¯¹è¿™ä¸¤ä¸ªé—®é¢˜æå‡ºäº†ä¸€ç§å›¾æ¨¡å‹ï¼Œå–å¾—äº†ä¸é”™çš„æ•ˆæœã€‚</p>
<h2 id="Context-aware-Sequential-Recommendation"><a href="#Context-aware-Sequential-Recommendation" class="headerlink" title="Context-aware Sequential Recommendation"></a><a href="http://arxiv.org/pdf/1609.05787v1.pdf" target="_blank" rel="external">Context-aware Sequential Recommendation</a></h2><p>ç”¨æˆ·è¡Œä¸ºå»ºæ¨¡æ˜¯æ¨èç³»ç»Ÿä¸­çš„ä¸€ä¸ªå…³é”®éƒ¨ä»¶ï¼Œè¡Œä¸ºæ•°æ®æ˜¯åºåˆ—æ•°æ®ï¼Œå¤©ç„¶é€‚åˆç”¨RNNæ¥å»ºæ¨¡ã€‚ä½†å®é™…åº”ç”¨ä¸­contextä¿¡æ¯(time,location,weahter)ä¹Ÿå¾ˆé‡è¦ï¼Œæœ¬æ–‡é’ˆå¯¹è¿™ä¸ªé—®é¢˜æå‡ºäº†ä¸€ç§CA-RNNæ¨¡å‹å°†contextè€ƒè™‘åœ¨å†…ï¼Œå–å¾—äº†ä¸é”™æ•ˆæœã€‚</p>
<h2 id="ReasoNet-Learning-to-Stop-Reading-in-Machine-Comprehension"><a href="#ReasoNet-Learning-to-Stop-Reading-in-Machine-Comprehension" class="headerlink" title="ReasoNet: Learning to Stop Reading in Machine Comprehension"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.05284v1.pdf" target="_blank" rel="external">ReasoNet: Learning to Stop Reading in Machine Comprehension</a></h2><p>æœ¬æ–‡ç ”ç©¶å†…å®¹ä¸ºæœºå™¨é˜…è¯»ç†è§£ï¼Œä¹‹å‰æ•ˆæœä¸é”™çš„æ–¹æ³•å¤§å¤šæ•°åœç•™åœ¨æœ‰é™çš„å‡ è½®reasoningï¼Œæœ¬æ–‡ç”¨å¢å¼ºå­¦ä¹ æ¥åŠ¨æ€åœ°å†³å®šæ˜¯å¦ç»§ç»­è¯»ä¸‹å»æˆ–è€…åœä¸‹æ¥è¿›è¡Œç­”æ¡ˆé€‰æ‹©ã€‚æœ¬æ–‡å·¥ä½œæ¥è‡ªå¾®è½¯ç ”ç©¶é™¢ã€‚</p>
<h2 id="Enhancing-and-Combining-Sequential-and-Tree-LSTM-for-Natural-Language-Inference"><a href="#Enhancing-and-Combining-Sequential-and-Tree-LSTM-for-Natural-Language-Inference" class="headerlink" title="Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.06038v1.pdf" target="_blank" rel="external">Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference</a></h2><p>æœ¬æ–‡ç ”ç©¶å†…å®¹ä¸ºè‡ªç„¶è¯­è¨€æ¨ç†ï¼Œä½œè€…è®¤ä¸ºLSTMç±»çš„æ¨¡å‹æ½œåŠ›å¹¶æ²¡æœ‰è¢«å……åˆ†æŒ–æ˜ï¼ŒåŸºäºæ­¤ï¼Œæœ¬æ–‡åœ¨ä¼ ç»ŸLSTMæ¨¡å‹çš„åŸºç¡€ä¸Šå¢åŠ äº†syntactic parseä¿¡æ¯ï¼Œå¾—åˆ°äº†æ›´å¥½çš„æ•ˆæœã€‚</p>
<h2 id="A-framework-for-mining-process-models-from-emails-logs"><a href="#A-framework-for-mining-process-models-from-emails-logs" class="headerlink" title="A framework for mining process models from emails logs"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.06127v1.pdf" target="_blank" rel="external">A framework for mining process models from emails logs</a></h2><p>æœ¬æ–‡ç ”ç©¶çš„å†…å®¹æ˜¯é‚®ä»¶æ—¥å¿—çš„æŒ–æ˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ— ç›‘ç£çš„æŒ–æ˜æ–¹æ³•ï¼Œå¹¶ä¸”æå‡ºäº†ä¸€ç§åŠè‡ªåŠ¨åŒ–çš„é‚®ä»¶æ ‡æ³¨æ–¹æ³•ã€‚</p>
<h2 id="Character-level-and-Multi-channel-Convolutional-Neural-Networks-for-Large-scale-Authorship-Attribution"><a href="#Character-level-and-Multi-channel-Convolutional-Neural-Networks-for-Large-scale-Authorship-Attribution" class="headerlink" title="Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.06686v1.pdf" target="_blank" rel="external">Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution</a></h2><p>æœ¬æ–‡ç ”ç©¶å†…å®¹ä¸ºauthorship attributionï¼Œæ˜¯ä¸€ä¸ªå…¸å‹çš„å¤šåˆ†ç±»ä»»åŠ¡ã€‚ä½œè€…åˆ©ç”¨å­—ç¬¦çº§åˆ«çš„å¤šé€šé“CNNæ¨¡å‹å¯¹å¤§è§„æ¨¡datasetè¿›è¡Œäº†å»ºæ¨¡ï¼Œå–å¾—äº†ä¸é”™çš„ç»“æœã€‚ä½œè€…ä¹‹ä¸€æ¥è‡ªaylien.com å…¬å¸ï¼Œä¸€å®¶éå¸¸å‡ºè‰²çš„NLP SaaS å…¬å¸ã€‚</p>
<h2 id="Minimally-Supervised-Written-to-Spoken-Text-Normalization"><a href="#Minimally-Supervised-Written-to-Spoken-Text-Normalization" class="headerlink" title="Minimally Supervised Written-to-Spoken Text Normalization"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.06649v1.pdf" target="_blank" rel="external">Minimally Supervised Written-to-Spoken Text Normalization</a></h2><p>æœ¬æ–‡ç ”ç©¶çš„å†…å®¹æ˜¯ç‰¹å®šè¯­è¨€é¢†åŸŸçŸ¥è¯†åœ¨æ„å»ºtext normalization systemçš„æ—¶å€™åº”è¯¥å¦‚ä½•åštrade-offï¼Œæœ¬æ–‡ä½œè€…æ¥è‡ªGoogleã€‚</p>
<h2 id="Recognizing-Implicit-Discourse-Relations-via-Repeated-Reading-Neural-Networks-with-Multi-Level-Attention"><a href="#Recognizing-Implicit-Discourse-Relations-via-Repeated-Reading-Neural-Networks-with-Multi-Level-Attention" class="headerlink" title="Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.06380v1.pdf" target="_blank" rel="external">Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention</a></h2><p>æœ¬æ–‡ç ”ç©¶å†…å®¹æ˜¯å¦‚ä½•è¯†åˆ«éšå¼çš„discourseå…³ç³»ï¼Œä½œè€…æå‡ºäº†ä¸€ç§å¤šå±‚æ³¨æ„åŠ›æ¨¡å‹ï¼Œè”åˆæ³¨æ„åŠ›æœºåˆ¶å’Œå¤–éƒ¨memoryæ¥åšå…³ç³»è¯†åˆ«ã€‚æœ¬æ–‡æ˜¯EMNLP2016çš„é•¿æ–‡ã€‚</p>
<h2 id="SoftTarget-Regularization-An-Effective-Technique-to-Reduce-Over-Fitting-in-Neural-Networks"><a href="#SoftTarget-Regularization-An-Effective-Technique-to-Reduce-Over-Fitting-in-Neural-Networks" class="headerlink" title="SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.06693v2.pdf" target="_blank" rel="external">SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks</a></h2><p>ã€è½¬å‘è¾ƒå¤šã€‘æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ­£åˆ™åŒ–æ–¹æ³•ï¼Œé€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è°ƒæ•´labelæ¥å®ç°ï¼Œè¾¾åˆ°äº†å’ŒDropoutæ¥è¿‘çš„æ•ˆæœã€‚</p>
<h2 id="The-Color-of-the-Cat-is-Gray-1-Million-Full-Sentences-Visual-Question-Answering-FSVQA"><a href="#The-Color-of-the-Cat-is-Gray-1-Million-Full-Sentences-Visual-Question-Answering-FSVQA" class="headerlink" title="The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA)"></a><a href="http://120.52.73.77/arxiv.org/pdf/1609.06657v1.pdf" target="_blank" rel="external">The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA)</a></h2><p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ª1 millionçš„Visual Question Answer Datasetï¼Œæ•°æ®åœ°å€ï¼š<a href="http://www.mi.t.u-tokyo.ac.jp/static/projects/fsvqa/" target="_blank" rel="external">http://www.mi.t.u-tokyo.ac.jp/static/projects/fsvqa/</a></p>
<h2 id="Knowledge-Representation-via-Joint-Learning-of-Sequential-Text-and-Knowledge-Graphs"><a href="#Knowledge-Representation-via-Joint-Learning-of-Sequential-Text-and-Knowledge-Graphs" class="headerlink" title="Knowledge Representation via Joint Learning of Sequential Text and Knowledge Graphs"></a><a href="http://arxiv.org/pdf/1609.07075v1.pdf" target="_blank" rel="external">Knowledge Representation via Joint Learning of Sequential Text and Knowledge Graphs</a></h2><p>ã€è½¬å‘è¾ƒå¤šã€‘å½“å‰çŸ¥è¯†è¡¨ç¤ºå­˜åœ¨ä¸¤ä¸ªæŒ‘æˆ˜ï¼š1ã€å¦‚ä½•æ›´å¥½åœ°åˆ©ç”¨entityçš„contextï¼›2ã€å¦‚ä½•å‘ç°ä¸entityç›¸å…³çš„å¥å­ï¼›é’ˆå¯¹è¿™ä¸¤ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ä»å¤šä¸ªå¥å­ä¸­å­¦ä¹ è¡¨ç¤ºçš„æ¨¡å‹ã€‚ç»™å®šæ¯ä¸ªentityçš„å‚è€ƒå¥å­ï¼Œé¦–å…ˆç”¨å¸¦æ± åŒ–çš„RNNæˆ–LSTMæ¥encodeä¸è¯¥entityç›¸å…³çš„å¥å­ï¼Œç„¶åç”¨attentionæ¨¡å‹æ¥è¡¡é‡æ¯ä¸ªå¥å­çš„ä¿¡æ¯é‡ï¼Œæœ€åå¾—åˆ°entityçš„è¡¨ç¤ºã€‚æ¨¡å‹åœ¨triple classificationå’Œlink predictionä¸¤ä¸ªä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æ»¡æ„çš„ç»“æœã€‚æœ¬æ–‡å·¥ä½œæ¥è‡ª@åˆ˜çŸ¥è¿œTHUç»„ã€‚</p>
<p>åˆ˜çŸ¥è¿œï¼šæˆ‘è§‰å¾—è¿™ä¸ªå·¥ä½œçš„æœ€æœ‰æ„æ€çš„åœ°æ–¹æ˜¯ï¼Œèƒ½å¤Ÿä¸ºå®ä½“æ‰¾åˆ°æœ€æœ‰ä¿¡æ¯é‡çš„å¥å­ï¼Œè¿™äº›å¥å­å¾€å¾€æ˜¯è¯¥å®ä½“çš„å®šä¹‰æˆ–æè¿°ã€‚è¿™æ ·ï¼Œåœ¨æ„å»ºçŸ¥è¯†å›¾è°±æ—¶ï¼Œæˆ‘ä»¬å°±å¯ä»¥è‡ªåŠ¨ä¸ºæ–°å¢çš„å®ä½“æ„å»ºå¯¹åº”çš„æ–‡æœ¬æè¿°ä¿¡æ¯äº†ã€‚</p>
<h2 id="Semantic-Tagging-with-Deep-Residual-Networks"><a href="#Semantic-Tagging-with-Deep-Residual-Networks" class="headerlink" title="Semantic Tagging with Deep Residual Networks"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.07053v1.pdf" target="_blank" rel="external">Semantic Tagging with Deep Residual Networks</a></h2><p>æœ¬æ–‡æå‡ºä¸€ç§å¤šè¯­è¨€æ™ºèƒ½taggerï¼Œæ¨¡å‹é‡‡ç”¨äº†char-levelå’Œword-levelçš„æ·±åº¦æ®‹å·®ç½‘ç»œï¼Œåœ¨è¯æ€§æ ‡æ³¨ä»»åŠ¡ä¸­å–å¾—äº†ä¸é”™çš„æ•ˆæœï¼Œæœ¬æ–‡COLING 2016åœ¨å®¡ã€‚</p>
<h2 id="Image-embodied-Knowledge-Representation-Learning"><a href="#Image-embodied-Knowledge-Representation-Learning" class="headerlink" title="Image-embodied Knowledge Representation Learning"></a><a href="http://arxiv.org/pdf/1609.07028v1.pdf" target="_blank" rel="external">Image-embodied Knowledge Representation Learning</a></h2><p>ã€è½¬å‘è¾ƒå¤šã€‘entityå›¾åƒä¸­åŒ…å«ä¸°å¯Œçš„ä¿¡æ¯ï¼Œå¤§å¤šæ•°ä¼ ç»Ÿæ–¹æ³•å¹¶æ²¡æœ‰åˆ©ç”¨è¿™ä¸€ç‚¹ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§çŸ¥è¯†è¡¨ç¤ºæ¨¡å‹ï¼Œåˆ©ç”¨äº†tripleså’Œimageä¿¡æ¯ï¼Œå¹¶åœ¨çŸ¥è¯†å›¾è°±è¡¥å…¨å’Œtripleåˆ†ç±»ä¸¤ä¸ªä»»åŠ¡ä¸­å–å¾—äº†ä¸é”™çš„æ•ˆæœã€‚æœ¬æ–‡æ˜¯ä¸€ç¯‡å…¸å‹çš„å¤šä¿¡æ¯èåˆçš„æ–‡ç« ï¼Œéå¸¸å€¼å¾—æ€è€ƒï¼å·¥ä½œåŒæ ·æ¥è‡ª@åˆ˜çŸ¥è¿œTHUè€å¸ˆç»„ã€‚</p>
<h2 id="Twitter-Network-Topic-Model-A-Full-Bayesian-Treatment-for-Social-Network-and-Text-Modeling"><a href="#Twitter-Network-Topic-Model-A-Full-Bayesian-Treatment-for-Social-Network-and-Text-Modeling" class="headerlink" title="Twitter-Network Topic Model: A Full Bayesian Treatment for Social Network and Text Modeling"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.06791v1.pdf" target="_blank" rel="external">Twitter-Network Topic Model: A Full Bayesian Treatment for Social Network and Text Modeling</a></h2><p>æ¨ç‰¹ä¸Šçš„æ¨å¯¹äºtopicå»ºæ¨¡æœ‰ä»¥ä¸‹ç¼ºç‚¹ï¼š1ã€çŸ­ï¼›2ã€éç»“æ„åŒ–ï¼›3ã€å£è¯­åŒ–ï¼›ä¹Ÿæœ‰ä¼˜ç‚¹ï¼š1ã€ä½œè€…ï¼›2ã€hashtagsï¼›3ã€ç²‰ä¸ç½‘ç»œã€‚æœ¬æ–‡ç»“åˆæ¨ç‰¹ä¿¡æ¯çš„ä¼˜ç‚¹æå‡ºäº†ä¸€ç§æ–°æ¨¡å‹ã€‚topic modelæ˜¯ä¸ªè€è¯é¢˜äº†ï¼Œå¤šæºä¿¡æ¯çš„èåˆæ˜¯çªç ´ç ”ç©¶ç“¶é¢ˆä¸€ä¸ªä¸é”™çš„æ–¹å‘ï¼Œæœ¬æ–‡çš„æ–¹æ³•åŒæ ·å¯å€Ÿé‰´äºå¾®åšå’Œå…¶ä»–ç¤¾äº¤ç½‘ç»œã€‚</p>
<h2 id="Joint-CTC-Attention-based-End-to-End-Speech-Recognition-using-Multi-task-Learning"><a href="#Joint-CTC-Attention-based-End-to-End-Speech-Recognition-using-Multi-task-Learning" class="headerlink" title="Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.06773v1.pdf" target="_blank" rel="external">Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning</a></h2><p>ã€è½¬å‘è¾ƒå¤šã€‘Attentionç±»æ¨¡å‹åœ¨ç«¯åˆ°ç«¯è¯­éŸ³è¯†åˆ«é¢†åŸŸå–å¾—äº†ä¸é”™çš„æ•ˆæœï¼Œä½†å½“è¾“å…¥å™ªå£°éå¸¸å¤§çš„çš„æ—¶å€™ï¼Œè¯†åˆ«é•¿å¥å­æ•ˆæœä¸æ˜¯å¾ˆå¥½ã€‚CTCæ˜¯å¦å¤–ä¸€ç§ä¸é”™çš„ç«¯åˆ°ç«¯æ¨¡å‹ï¼Œæœ¬æ–‡ç»“åˆä¸¤è€…çš„ä¼˜åŠ¿æ„å»ºæ¨¡å‹ã€‚æ„å»ºäº†è”åˆæ¨¡å‹ä¹‹åï¼Œå…‹æœäº†ä¹‹å‰çš„é—®é¢˜ã€‚å¤§å®¶éƒ½åœ¨ç”¨Attentionï¼Œéƒ½è¯´Attentionå¥½ï¼Œä½†ç»ˆç©¶è¿˜æ˜¯æœ‰äº›æƒ…å¢ƒä¸‹attentionå¹¶ä¸èƒ½å¦‚äººæ„ã€‚é‚£ä¹ˆé—®é¢˜æ¥äº†ï¼Œåˆ°åº•å“ªäº›åœºæ™¯ä¸‹attentionè¡¨ç°ä¸å¥½ï¼ŒåŸå› æ˜¯ä»€ä¹ˆï¼Ÿæƒ³æ¸…æ¥šè¿™ä¸ªåˆ°åº•ä¹‹åï¼Œæ”¹è¿›çš„æ–¹æ³•å¤§æ¦‚ä¹Ÿå°±åœ¨è·¯ä¸Šäº†ã€‚#Attention Modelçš„ç¼ºç‚¹#</p>
<h1 id="èµ„æºåˆ†äº«"><a href="#èµ„æºåˆ†äº«" class="headerlink" title="èµ„æºåˆ†äº«"></a>èµ„æºåˆ†äº«</h1><h2 id="Bots-Product-Hunt"><a href="#Bots-Product-Hunt" class="headerlink" title="Bots - Product Hunt"></a><a href="https://www.producthunt.com/topics/bots" target="_blank" rel="external">Bots - Product Hunt</a></h2><p>ä¸€ä¸ªåˆ†äº«å’Œç‚¹è¯„å„ç§å¥½ç©productçš„ç«™ç‚¹ï¼Œå…¶ä¸­ä¸€ä¸ªæ ç›®æœ‰å„ç§å„æ ·çš„botã€‚</p>
<h2 id="Gorgonia-is-a-library-that-helps-facilitate-machine-learning-in-Go"><a href="#Gorgonia-is-a-library-that-helps-facilitate-machine-learning-in-Go" class="headerlink" title="Gorgonia is a library that helps facilitate machine learning in Go"></a><a href="https://github.com/chewxy/gorgonia" target="_blank" rel="external">Gorgonia is a library that helps facilitate machine learning in Go</a></h2><p>ç”¨Goå†™çš„æœºå™¨å­¦ä¹ å¼€æºæ¡†æ¶ã€‚</p>
<h2 id="A-Thorough-Examination-of-the-CNN-Daily-Mail-Reading-Comprehension-Task"><a href="#A-Thorough-Examination-of-the-CNN-Daily-Mail-Reading-Comprehension-Task" class="headerlink" title="A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task"></a><a href="https://github.com/danqi/rc-cnn-dailymail" target="_blank" rel="external">A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task</a></h2><p>è¿™ç¯‡paperçš„ä»£ç æ”¾å‡ºæ¥äº†ï¼ŒåŒæ—¶åŒ…æ‹¬CNNå’ŒDaily Mailçš„æ•°æ®é›†ã€‚æ¥è‡ªæ–¯å¦ç¦Danqi Chençš„å·¥ä½œã€‚</p>
<h1 id="ä¸šç•Œæ–°é—»"><a href="#ä¸šç•Œæ–°é—»" class="headerlink" title="ä¸šç•Œæ–°é—»"></a>ä¸šç•Œæ–°é—»</h1><h2 id="API-AI-is-joining-Google"><a href="#API-AI-is-joining-Google" class="headerlink" title="API.AI is joining Google!"></a><a href="https://api.ai/blog/2016/09/19/api-ai-joining-google/" target="_blank" rel="external">API.AI is joining Google!</a></h2><p>chatbotæ„å»ºå¹³å°api.aiè¢«Googleæ”¶è´­äº†</p>
<h2 id="Angel-ai-a-company-that-builds-chat-bots-acqui-hired-by-Amazon-TechCrunch"><a href="#Angel-ai-a-company-that-builds-chat-bots-acqui-hired-by-Amazon-TechCrunch" class="headerlink" title="Angel.ai, a company that builds chat bots, acqui-hired by Amazon | TechCrunch "></a><a href="https://techcrunch.com/2016/09/20/angel-ai-a-company-that-builds-chat-bots-acqui-hired-by-amazon/" target="_blank" rel="external">Angel.ai, a company that builds chat bots, acqui-hired by Amazon | TechCrunch </a></h2><p>TechCrunchæŠ¥é“ç§°ï¼Œç»§api.aiè¢«googleæ”¶è´­ä¹‹åï¼Œä¸€å®¶åšè‡ªç„¶è¯­è¨€ç†è§£çš„å…¬å¸angel.aiä¹Ÿå‡ ä¹è¢«Amazonæ”¶è´­ã€‚</p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰æ¯å¤©éƒ½ä¼šåˆ†äº«å½“å¤©arXiv cs.CLæ¿å—åˆ·æ–°çš„é«˜è´¨é‡paper<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-23T03:51:47.000Z"><a href="/2016/09/22/PaperWeekly-ç¬¬å…­æœŸ/">2016-09-22</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/22/PaperWeekly-ç¬¬å…­æœŸ/">PaperWeekly ç¬¬å…­æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•"><a href="#å¼•" class="headerlink" title="å¼•"></a>å¼•</h1><p>æœ¬æœŸpaperweeklyçš„ä¸»é¢˜æ˜¯Question Answering Modelsï¼Œè§£å†³è¿™ä¸€ç±»é—®é¢˜å¯ä»¥å¾ˆå¥½åœ°å±•ç°AIç†è§£äººç±»è‡ªç„¶è¯­è¨€çš„èƒ½åŠ›ï¼Œé€šè¿‡è§£å†³æ­¤ç±»datasetå¯ä»¥ç»™AIç†è§£äººç±»è¯­è¨€å¾ˆå¥½çš„insightsã€‚é—®é¢˜çš„å®šä¹‰å¤§è‡´æ˜¯ï¼Œç»™å®šè¾ƒé•¿ä¸€æ®µè¯çš„contextå’Œä¸€ä¸ªè¾ƒçŸ­çš„é—®é¢˜ï¼Œä»¥åŠä¸€äº›candidate answersï¼Œè®­ç»ƒä¸€äº›å¯ä»¥å‡†ç¡®é¢„æµ‹æ­£ç¡®ç­”æ¡ˆçš„æ¨¡å‹ã€‚</p>
<p>æ­¤é—®é¢˜ä¹Ÿå­˜åœ¨ä¸€äº›å˜ç§ï¼Œä¾‹å¦‚contextå¯ä»¥æ˜¯éå¸¸å¤§å—çš„knowledge baseï¼Œå¯ä»¥ä¸æä¾›candidate answersè€Œæ˜¯åœ¨æ‰€æœ‰çš„vocabularyä¸­æœç´¢ç­”æ¡ˆï¼Œæˆ–è€…æ˜¯åœ¨contextä¸­æå–ç­”æ¡ˆã€‚</p>
<p>åŸºäº(Recurrent) Neural Networkçš„ä¸€äº›æ¨¡å‹åœ¨è¿™ä¸€ç±»é—®é¢˜ä¸Šç»™å‡ºäº†state of the art modelsï¼Œæœ¬æœŸpaperweeklyå°±å¸¦é¢†å¤§å®¶æ¬£èµè¿™ä¸€é¢†åŸŸæœ‰è¶£çš„å·¥ä½œã€‚</p>
<h1 id="Attention-over-Attention-Neural-Networks-for-Reading-Comprehension"><a href="#Attention-over-Attention-Neural-Networks-for-Reading-Comprehension" class="headerlink" title="Attention-over-Attention Neural Networks for Reading Comprehension"></a><a href="https://arxiv.org/abs/1607.04423" target="_blank" rel="external">Attention-over-Attention Neural Networks for Reading Comprehension</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Yiming Cui, Zhipeng Chen, Si Wei, Shijin Wang, Ting Liu and Guoping Hu</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>iFLYTEK Research, China<br>Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Question Answering, Attentive Readers</p>
<h2 id="æ¥æº"><a href="#æ¥æº" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>arXiv, 201608</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æœ¬æ–‡ä¼˜åŒ–äº†attentionæœºåˆ¶ï¼ŒåŒæ—¶apply question-to-document and document-to-question attentionï¼Œæå‡äº†å·²æœ‰æ¨¡å‹åœ¨Cloze-Style Question Answering Taskä¸Šçš„å‡†ç¡®ç‡ã€‚</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æœ¬æ–‡è§£å†³çš„æ˜¯Cloze-style question answeringçš„é—®é¢˜ï¼Œç»™å®šä¸€ä¸ªDocumentå’Œä¸€ä¸ªQueryï¼Œä»¥åŠä¸€ä¸ªlistçš„candidate answersï¼Œæ¨¡å‹éœ€è¦ç»™å‡ºä¸€ä¸ªæ­£ç¡®ç­”æ¡ˆã€‚</p>
<p>å·²æœ‰çš„æ¨¡å‹å¤§éƒ½é€šè¿‡æ¯”è¾ƒæ¯ä¸€ä¸ªQuery + candidate answerå’Œcontext documentçš„ç›¸ä¼¼æ€§æ¥æ‰¾å‡ºæ­£ç¡®ç­”æ¡ˆï¼Œè¿™ç§ç›¸ä¼¼æ€§measureå¤§éƒ½é€šè¿‡æŠŠquery æŠ•å°„åˆ°context documentæ¯ä¸ªå•è¯åŠæ‰€åœ¨contextçš„ç›¸ä¼¼æ€§æ¥è·å¾—ã€‚æœ¬æ–‡çš„ä¸åŒä¹‹å¤„åœ¨äºæ¨¡å‹è¿˜è®¡ç®—äº†contextæŠ•å°„åˆ°æ¯ä¸ªqueryå•è¯çš„ç›¸ä¼¼åº¦ï¼Œè¿›ä¸€æ­¥ä¸°å¯Œäº†contextå’Œqueryç›¸ä¼¼åº¦çš„è®¡ç®—ã€‚</p>
<p><img src="media/model_image.png" alt="model_image"></p>
<p>é¦–å…ˆï¼Œdocumentå’Œqueryéƒ½ä¼šè¢«modelæˆbiGRUã€‚<br><img src="media/embedding_and_encoding.png" alt="embedding_and_encoding"></p>
<p>ç„¶åä½¿ç”¨document biGRUå’Œquery biGRUçš„æ¯ä¸€ä¸ªpositionåšinner productè®¡ç®—ï¼Œå¯ä»¥å¾—åˆ°ä¸€ä¸ªsimilarity matrixã€‚<br><img src="media/similarity_matrix.png" alt="similarity_matrix"></p>
<p>å¯¹è¿™ä¸ªmatrixåšä¸€ä¸ªcolumn-wise softmaxï¼Œå¯ä»¥å¾—åˆ°æ¯ä¸ªqueryå•è¯åœ¨æ¯ä¸ªdocumentå•è¯ä¸Šçš„similarityã€‚<br><img src="media/column_softmax.png" alt="column_softmax"></p>
<p>similarlyï¼Œå¯¹è¿™ä¸ªmatrixåšä¸€ä¸ªrow-wise softmaxï¼Œå¯ä»¥å¾—åˆ°æ¯ä¸ªdocumentå•è¯åœ¨æ¯ä¸ªqueryå•è¯ä¸Šçš„similarityã€‚<br><img src="media/row_softmax.png" alt="row_softmax"></p>
<p>å–ä¸ªå¹³å‡å°±å¾—åˆ°äº†æ¯ä¸ªqueryå•è¯åœ¨æ•´ä¸ªcontext documentä¸Šçš„similarityã€‚<br><img src="media/average.png" alt="average"></p>
<p>ç„¶åæŠŠalphaå’Œbetaåšä¸ªinner productå°±å¾—åˆ°äº†æ¯ä¸ªcontext document wordçš„probabilityã€‚<br><img src="media/context_word_probability.png" alt="context_word_probability"></p>
<p>æ¯ä¸ªcandidate answerçš„probabilityå°±æ˜¯å®ƒå‡ºç°åœ¨ä¸Šè¿°sä¸­çš„probabilityä¹‹å’Œã€‚<br><img src="media/attention_sum.png" alt="attention_su"></p>
<p>Loss Functionå¯ä»¥å®šä¹‰ä¸ºæ­£ç¡®ç­”æ¡ˆçš„log probabilityä¹‹å’Œã€‚<br><img src="media/loss_function.png" alt="loss_function"></p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><ul>
<li><a href="https://github.com/deepmind/rc-data" target="_blank" rel="external">cnnå’Œdaily mail datasets</a></li>
<li><a href="https://research.facebook.com/research/babi/" target="_blank" rel="external">Childrenâ€™s book test</a></li>
</ul>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>åˆ©ç”¨attentive readersè§£å†³question answeringé—®é¢˜æœ€æ—©å‡ºè‡ªdeep mind: teaching machines to read and comprehendã€‚åæ¥åˆæœ‰Bhuwan Dhingra: Gated-Attention Readers for Text Comprehensionå’ŒDanqi Chen: A Thorough Examination of the CNN/Daily Mail Reading Comprehension Taskï¼Œä»¥åŠå…¶ä»–ç›¸å…³å·¥ä½œï¼Œåœ¨æ­¤ä¸ä¸€ä¸€èµ˜è¿°ã€‚</p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡å¾ˆå¥½åœ°å®Œå–„äº†attentive readerçš„å·¥ä½œï¼ŒåŒæ—¶è€ƒè™‘äº†query to document and document to query attentionsï¼Œåœ¨å‡ ä¸ªdata setä¸Šéƒ½å–å¾—äº†state of the artæ•ˆæœï¼Œæ€è·¯éå¸¸æ¸…æ™°ï¼Œåœ¨question answeringé—®é¢˜ä¸Šå¾ˆæœ‰å‚è€ƒä»·å€¼ã€‚</p>
<h1 id="MACHINE-COMPREHENSION-USING-MATCH-LSTM-AND-ANSWER-POINTER"><a href="#MACHINE-COMPREHENSION-USING-MATCH-LSTM-AND-ANSWER-POINTER" class="headerlink" title="MACHINE COMPREHENSION USING MATCH-LSTM AND ANSWER POINTER"></a><a href="http://120.52.73.76/arxiv.org/pdf/1608.07905v1.pdf" target="_blank" rel="external">MACHINE COMPREHENSION USING MATCH-LSTM AND ANSWER POINTER</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Shuohang Wang, Jing Jiang</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Singapore Management University</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Machine comprehension, Match-LSTM, Pointer Net</p>
<h2 id="æ¥æº-1"><a href="#æ¥æº-1" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>arXivï¼Œ201608</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æå‡ºä¸€ç§ç»“åˆmatch-LSTMå’ŒPointer Netçš„ç«¯åˆ°ç«¯ç¥ç»ç½‘ç»œç»“æ„ï¼Œæ¥è§£å†³SQuADæ•°æ®é›†è¿™ç±»æ²¡æœ‰å€™é€‰é¡¹ä¸”ç­”æ¡ˆå¯èƒ½æ˜¯å¤šä¸ªè¯çš„machine comprehensioné—®é¢˜ã€‚</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æœ¬æ–‡æå‡ºçš„æ¨¡å‹ç»“åˆäº†match-LSTM(mLSTM)å’ŒPointer Net(Ptr-Net)ä¸¤ç§ç½‘ç»œç»“æ„ã€‚</p>
<p>1ã€match-LSTM</p>
<p>mLSTMæ˜¯ç”±Wangå’ŒJiangæå‡ºçš„ä¸€ç§è§£å†³æ–‡æœ¬è•´å«è¯†åˆ«ï¼ˆRTEï¼‰é—®é¢˜çš„ä¸€ç§ç¥ç»ç½‘ç»œç»“æ„ã€‚æ¨¡å‹ç»“æ„è§ä¸‹å›¾ï¼Œè¯¥æ¨¡å‹é¦–å…ˆå°†premiseå’Œhypothesisä¸¤å¥è¯åˆ†åˆ«è¾“å…¥åˆ°ä¸¤ä¸ªLSTMä¸­ï¼Œç”¨å¯¹åº”LSTMçš„éšå±‚è¾“å‡ºä½œä¸ºpremiseå’Œhypothesisä¸­æ¯ä¸ªä½ç½®å¯¹åº”ä¸Šä¸‹æ–‡ä¿¡æ¯çš„ä¸€ç§è¡¨ç¤ºï¼ˆåˆ†åˆ«å¯¹åº”å›¾ä¸­çš„Hså’ŒHtï¼‰ã€‚å¯¹äºhypothesisä¸­çš„æŸä¸ªè¯çš„è¡¨ç¤ºht_iï¼Œä¸premiseä¸­çš„æ¯ä¸ªè¯çš„è¡¨ç¤ºHsè®¡ç®—å¾—åˆ°ä¸€ä¸ªæƒé‡å‘é‡ï¼Œç„¶åå†å¯¹premiseä¸­çš„è¯è¡¨ç¤ºè¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°htiå¯¹åº”çš„ä¸Šä¸‹æ–‡å‘é‡a_iï¼ˆattentionè¿‡ç¨‹ï¼‰ã€‚æœ€åæŠŠhypothesisä¸­è¯¥è¯çš„è¡¨ç¤ºht_iå’Œå…¶å¯¹åº”çš„contextå‘é‡a_iæ‹¼æ¥åœ¨ä¸€èµ·ï¼Œè¾“å…¥åˆ°ä¸€ä¸ªæ–°çš„LSTMä¸­ã€‚è¯¥æ¨¡å‹å°†ä¸¤ä¸ªå¥å­çš„æ–‡æœ¬è•´å«ä»»åŠ¡æ‹†åˆ†æˆè¯å’ŒçŸ­è¯­çº§åˆ«çš„è•´å«è¯†åˆ«ï¼Œå› æ­¤å¯ä»¥æ›´å¥½åœ°è¯†åˆ«è¯ä¹‹é—´çš„åŒ¹é…å…³ç³»ã€‚<br><img src="media/mLSTM.png" alt="mLST"></p>
<p>2ã€ Pointer networks</p>
<p>è¯¥æ¨¡å‹ä¸åŸºäºattentionçš„ç”Ÿæˆæ¨¡å‹ç±»ä¼¼ã€‚åŒºåˆ«ä¹‹å¤„åœ¨äºï¼Œpointer networksç”Ÿæˆçš„ç»“æœéƒ½åœ¨è¾“å…¥åºåˆ—ä¸­ï¼Œå› æ­¤pointer networkså¯ä»¥ç›´æ¥å°†attentionå¾—åˆ°çš„alignå‘é‡ä¸­çš„æ¯ä¸ªæƒé‡ç›´æ¥ä½œä¸ºé¢„æµ‹ä¸‹ä¸€ä¸ªè¯å¯¹åº”çš„æ¦‚ç‡å€¼ã€‚</p>
<p>3ã€ Sequence Model &amp; Boundary Model</p>
<p>æœ¬æ–‡æå‡ºçš„æ¨¡å‹ç»“æ„è§ä¸‹å›¾ï¼Œå…·ä½“åˆ°æœ¬æ–‡çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œå¯ä»¥ç®€å•åˆ†ä¸ºä¸‹é¢ä¸¤éƒ¨åˆ†ï¼š<br><img src="media/Seq_Bound.png" alt="Seq_Bound"><br>ï¼ˆ1ï¼‰Match-LSTMå±‚ï¼šè¯¥éƒ¨åˆ†å°†machine comprehensionä»»åŠ¡ä¸­çš„questionä½œä¸ºpremiseï¼Œè€Œpassageä½œä¸ºhypothesisã€‚ç›´æ¥å¥—ç”¨ä¸Šè¿°çš„mLSTMæ¨¡å‹å¾—åˆ°å…³äºpassageæ¯ä¸ªä½ç½®çš„ä¸€ç§è¡¨ç¤ºã€‚ä¸ºäº†å°†å‰åæ–¹å‘çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å…¨éƒ¨ç¼–ç è¿›æ¥ï¼Œè¿˜ç”¨ç›¸åŒçš„æ–¹æ³•å¾—åˆ°ä¸€ä¸ªåå‘mLSTMè¡¨ç¤ºï¼Œå°†ä¸¤ä¸ªæ­£åæ–¹å‘çš„è¡¨ç¤ºæ‹¼æ¥åœ¨ä¸€èµ·ä½œä¸ºæœ€ç»ˆpassageçš„è¡¨ç¤ºã€‚</p>
<p>ï¼ˆ2ï¼‰ç”Ÿæˆç­”æ¡ˆåºåˆ—éƒ¨åˆ†ï¼Œè®ºæ–‡ä¸­æå‡ºäº†ä¸¤ç§ç”Ÿæˆæ–¹æ³•ï¼š</p>
<ul>
<li><p>Sequenceæ–¹æ³•ä¸Pointer Netç›¸åŒï¼Œå³æ ¹æ®æ¯ä¸€ä¸ªæ—¶åˆ»attentionçš„alignå‘é‡ç”Ÿæˆä¸€ä¸ªè¯ä½ç½®ï¼Œç›´åˆ°ç”Ÿæˆç»ˆæ­¢ç¬¦ä¸ºæ­¢ã€‚</p>
</li>
<li><p>Boundaryæ–¹æ³•åˆ™æ˜¯åˆ©ç”¨SQuADæ•°æ®é›†çš„ç­”æ¡ˆå‡æ˜¯å‡ºç°åœ¨passageä¸­è¿ç»­çš„åºåˆ—è¿™ä¸€ç‰¹ç‚¹ï¼Œè¯¥æ–¹æ³•ä»…ç”Ÿæˆé¦–å°¾ä¸¤ä¸ªä½ç½®ï¼Œä¾æ®èµ·å§‹ä½ç½®å’Œç»ˆæ­¢ä½ç½®æ¥æˆªå–passageçš„ä¸€éƒ¨åˆ†ä½œä¸ºæœ€ç»ˆçš„ç­”æ¡ˆã€‚</p>
</li>
</ul>
<p>æœ¬æ–‡åœ¨SQuADæ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒï¼Œä¸¤ç§æ–¹æ³•å®éªŒç»“æœè¾ƒä¹‹ä¼ ç»ŸLRæ–¹æ³•å‡æœ‰å¤§å¹…åº¦æå‡ã€‚å…¶ä¸­Boundaryæ–¹æ³•æ¯”Sequenceæ–¹æ³•æ•ˆæœæ›´å¥½ã€‚</p>
<h2 id="èµ„æº-1"><a href="#èµ„æº-1" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><ul>
<li><a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank" rel="external">SQuAD</a></li>
</ul>
<h2 id="ç›¸å…³å·¥ä½œ-1"><a href="#ç›¸å…³å·¥ä½œ-1" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>æ•°æ®é›†ç›¸å…³è®ºæ–‡<br>SQuAD: 100,000+ Questions for Machine Comprehension of Text<br>æ¨¡å‹ç›¸å…³è®ºæ–‡<br>Learning Natural Language Inference with LSTM<br>Pointer networks</p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬ç¯‡è®ºæ–‡æå‡ºçš„æ¨¡å‹æ˜¯ç¬¬ä¸€ä¸ªåœ¨SQuADè¯­æ–™ä¸Šåº”ç”¨ç«¯åˆ°ç«¯ç¥ç»ç½‘ç»œçš„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å°†Match-LSTMå’ŒPointer Networksç»“åˆåœ¨ä¸€èµ·ï¼Œåˆ©ç”¨äº†æ–‡æœ¬ä¹‹é—´çš„è•´å«å…³ç³»æ›´å¥½åœ°é¢„æµ‹ç­”æ¡ˆã€‚<br>æœ¬æ–‡æå‡ºäº†ä¸¤ç§æ–¹æ³•æ¥ç”Ÿæˆç­”æ¡ˆï¼Œå…¶ä¸­Boundaryæ–¹æ³•å·§å¦™åœ°åˆ©ç”¨SQuADæ•°æ®é›†çš„ç­”æ¡ˆå‡æ˜¯æ–‡æœ¬ä¸­å‡ºç°è¿‡çš„è¿ç»­åºåˆ—è¿™ä¸€ç‰¹ç‚¹ï¼Œåªç”Ÿæˆç­”æ¡ˆçš„èµ·å§‹å’Œç»ˆæ­¢ä½ç½®ï¼Œæœ‰æ•ˆåœ°æå‡äº†æ¨¡å‹çš„æ•ˆæœã€‚</p>
<h1 id="Dataset-and-Neural-Recurrent-Sequence-Labeling-Model-for-Open-Domain-Factoid-Question-Answering"><a href="#Dataset-and-Neural-Recurrent-Sequence-Labeling-Model-for-Open-Domain-Factoid-Question-Answering" class="headerlink" title="Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering"></a><a href="https://arxiv.org/pdf/1607.06275v2.pdf" target="_blank" rel="external">Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Peng Li, Wei Li, Zhengyan He, Xuguang Wang, Ying Cao, Jie Zhou, Wei Xu</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Baidu IDL</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Question Answering, Sequence Labeling, CRF</p>
<h2 id="æ¥æº-2"><a href="#æ¥æº-2" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>arXiv, 201609</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>ä½œè€…ç»™å‡ºäº†ä¸€ä¸ªæ–°çš„ä¸­æ–‡çš„QAæ•°æ®é›†, å¹¶ä¸”æå‡ºäº†ä¸€ä¸ªéå¸¸æœ‰æ„æ€çš„baseline model.</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>1ã€WebQA Dataset</p>
<p>ä½œè€…æ¥è‡ªç™¾åº¦IDL, ä»–ä»¬åˆ©ç”¨ç™¾åº¦çŸ¥é“å’Œä¸€äº›å…¶ä»–çš„èµ„æº, æ„å»ºäº†è¿™ä¸ªä¸­æ–‡çš„QAæ•°æ®é›†. è¿™ä¸ªæ•°æ®é›†é‡Œæ‰€æœ‰çš„é—®é¢˜éƒ½æ˜¯factoidç±»å‹çš„é—®é¢˜, å¹¶ä¸”é—®é¢˜çš„ç­”æ¡ˆéƒ½åªåŒ…å«ä¸€ä¸ªentity (ä½†æ˜¯ä¸€ä¸ªentityå¯èƒ½ä¼šåŒ…å«å¤šä¸ªå•è¯). å¯¹äºæ¯ä¸ªé—®é¢˜, æ•°æ®é›†æä¾›äº†è‹¥å¹²ä¸ªâ€™evidenceâ€™, è¿™äº›evidenceæ˜¯åˆ©ç”¨æœç´¢å¼•æ“åœ¨ç½‘ç»œä¸­æ£€ç´¢çš„.</p>
<p>2ã€Recurrent Sequence Labeling Model</p>
<p>ä½œè€…æŠŠQAç±»å‹çš„é—®é¢˜çœ‹åšsequence labelingé—®é¢˜, ç»™å‡ºçš„æ¨¡å‹å¤§æ¦‚åˆ†ä¸‰éƒ¨åˆ†:<br><img src="media/ericyuan_graph.png" alt="ericyuan_graph"></p>
<p>ï¼ˆ1ï¼‰Question LSTM<br>è¿™éƒ¨åˆ†å¾ˆç®€å•, å°±æ˜¯æ™®é€šçš„å•å‘LSTM, å¯¹æ•´ä¸ªQuestion sequenceè¿›è¡Œencoding, ä¹‹åè®¡ç®—self-attention, å¹¶ç”¨attentionå¯¹question encodingæ±‚åŠ æƒå¹³å‡ä½œä¸ºé—®é¢˜çš„representation.</p>
<p>ï¼ˆ2ï¼‰Evidence LSTMs<br>è¿™éƒ¨åˆ†æ¯”è¾ƒæœ‰æ„æ€, é¦–å…ˆ, ä½œè€…ä»æ•°æ®ä¸­æå–å‡ºä¸¤ç§feature: æ¯ä¸ªè¯æ˜¯å¦åœ¨questionå’Œevidenceä¸­å…±åŒå‡ºç°, ä»¥åŠæ¯ä¸ªè¯æ˜¯å¦åŒæ—¶åœ¨å¤šä¸ªevidenceä¸­å‡ºç°. ä¹‹å, æ¨¡å‹ç”¨ä¸€ä¸ªä¸‰å±‚çš„å•å‘LSTMå¯¹evidence/quesiton/featureè¿›è¡Œç¼–ç . </p>
<ul>
<li>ç¬¬ä¸€å±‚: å°†evidence/question representation/featureè¿›è¡Œè¿æ¥, æ”¾è¿›ä¸€ä¸ªæ­£å‘LSTM.</li>
<li>ç¬¬äºŒå±‚: å°†ç¬¬ä¸€å±‚çš„ç»“æœæ”¾å…¥ä¸€ä¸ªåå‘LSTM.</li>
<li>ç¬¬ä¸‰å±‚: å°†ç¬¬ä¸€å±‚å’Œç¬¬äºŒå±‚çš„ç»“æœè¿›è¡Œè¿æ¥, æ”¾è¿›ä¸€ä¸ªæ­£å‘LSTM.</li>
</ul>
<p>ï¼ˆ3ï¼‰CRF<br>ç»è¿‡evidence LSTMs, questionå’Œevidenceçš„representationå·²ç»æ‰åœ¨ä¸€èµ·, æ‰€ä»¥å¹¶ä¸éœ€è¦å…¶ä»–QAæ¨¡å‹(ä¸»è¦æ˜¯Attention Sum Reader)å¹¿æ³›ç”¨çš„, ç”¨question representationå’Œstory representationè¿›è¡Œdot product, æ±‚cosine similarity. è¿™æ—¶å€™åªéœ€è¦å¯¹evidence representationçš„æ¯ä¸€ä¸ªtime stepè¿›è¡Œåˆ†ç±»å°±å¯ä»¥äº†, è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆä½œè€…å°†æ•°æ®æ ‡æ³¨æˆIOB taggingçš„æ ¼å¼, æˆ‘ä»¬å¯ä»¥ç›´æ¥ç”¨ä¸€ä¸ªCRFå±‚å¯¹æ•°æ®è¿›è¡Œé¢„æµ‹. åœ¨ä¸€äº›å®éªŒä¸­, ä½œè€…å°†ç­”æ¡ˆä¹‹å‰çš„è¯ç”¨O1, ç­”æ¡ˆä¹‹åçš„è¯ç”¨O2è¿›è¡Œæ ‡æ³¨, è¿™åˆç»™äº†æ¨¡å‹å…³äºéç­”æ¡ˆè¯çš„ä½ç½®ä¿¡æ¯(æ­£ç¡®ç­”æ¡ˆæ˜¯åœ¨è¿™ä¸ªè¯çš„å‰é¢è¿˜æ˜¯åé¢). </p>
<h2 id="èµ„æº-2"><a href="#èµ„æº-2" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><ul>
<li><a href="http://idl.baidu.com/webqa.html" target="_blank" rel="external">WebQA dataset</a></li>
<li><a href="https://github.com/baidu/Paddle" target="_blank" rel="external">Baidu Paddle</a></li>
</ul>
<h2 id="ç›¸å…³å·¥ä½œ-2"><a href="#ç›¸å…³å·¥ä½œ-2" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><ul>
<li>å…³äºCRFè¿›è¡Œåºåˆ—æ ‡æ³¨çš„é—®é¢˜, å¯ä»¥å‚è€ƒè¿™ç¯‡æ–‡ç« .<br>Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF models for sequence tagging. arXiv:1508.01991v1.</li>
<li>å…³äºmulti-wordç­”æ¡ˆé€‰æ‹©åœ¨SQuAD datasetä¸Šçš„æ¨¡å‹, å¯ä»¥å‚è€ƒè¿™ç¯‡.<br>Shuohang Wang, Jing Jiang. 2016. Machine Comprehension Using Match_LSTM and Answer Pointer. arXiv: 1608.07905v1.</li>
</ul>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>é¦–å…ˆå¯¹æ‰€æœ‰releaseæ•°æ®é›†çš„äººè¡¨ç¤ºæ„Ÿè°¢.<br>å…³äºdatasetéƒ¨åˆ†, ç™¾åº¦åˆ©ç”¨äº†è‡ªå·±åºå¤§çš„èµ„æºæ”¶é›†æ•°æ®. ç¬¬ä¸€, ç™¾åº¦çŸ¥é“é‡Œçš„é—®é¢˜éƒ½æ˜¯äººç±»é—®çš„é—®é¢˜, è¿™ä¸€ç‚¹ç›¸æ¯”äºä»Šå¹´å‰åŠå¹´æ¯”è¾ƒæµè¡Œçš„CNN/CBTç­‰ç­‰cloze styleçš„é—®é¢˜, è¦å¼ºå¾ˆå¤š. ç¬¬äºŒ, æ•°æ®é›†ä¸­åŒ…å«äº†å¾ˆå¤šç”±å¤šä¸ªè¯ç»„æˆçš„ç­”æ¡ˆ, è¿™ä¹Ÿä½¿æ•°æ®é›†çš„éš¾åº¦å¤§äºCNN/CBTè¿™ç§å•ä¸ªè¯ä½œä¸ºç­”æ¡ˆçš„æ•°æ®. ç¬¬ä¸‰, å¯¹äºæ¯ä¸ªé—®é¢˜, å¹¶æ²¡æœ‰ç»™å‡ºå¤‡é€‰ç­”æ¡ˆ, è¿™ä½¿å¾—å¯¹äºç­”æ¡ˆçš„æœç´¢ç©ºé—´å˜å¤§(å¯ä»¥æŠŠæ•´ä¸ªevidenceçœ‹åšæ˜¯å¤‡é€‰ç­”æ¡ˆ). ç¬¬å››, å¯¹äºæ¯ä¸€ä¸ªé—®é¢˜, datasetä¸­å¯èƒ½æœ‰å¤šä¸ªsupporting evidence, è¿™ä¹Ÿè¿åˆäº†æœ€è¿‘multi-supporting storyçš„è¶‹åŠ¿, å› ä¸ºå¯¹äºæœ‰äº›é—®é¢˜, ç­”æ¡ˆå¹¶ä¸åªåœ¨æŸä¸€ä¸ªå•ä¸€çš„æ–‡ç« ä¸­(å¯¹äºç™¾åº¦æ¥è¯´, å¦‚æœæœç´¢ä¸€ä¸ªé—®é¢˜, é‚£ä¹ˆç­”æ¡ˆå¹¶ä¸ä¸€å®šåœ¨å•ä¸€çš„æœç´¢ç»“æœç½‘é¡µä¸­), é‚£ä¹ˆä¸€ä¸ªå¥½çš„modeléœ€è¦åœ¨æœ‰é™çš„æ—¶é—´å†…å¯¹å°½å¯èƒ½å¤šçš„æœç´¢ç»“æœè¿›è¡Œæ£€ç´¢. </p>
<p>å…³äºmodeléƒ¨åˆ†, æœ¬æ–‡å°è¯•å°†QAé—®é¢˜çœ‹åšæ˜¯åºåˆ—æ ‡æ³¨é—®é¢˜, æŸç§æ„ä¹‰ä¸Šè§£å†³äº†multiword answerçš„éš¾ç‚¹. ç†Ÿæ‚‰å‰åŠå¹´QA paperçš„äººéƒ½ä¼šå¯¹Attention Sum Readerä»¥åŠå»¶ä¼¸å‡ºæ¥çš„è¯¸å¤šæ¨¡å‹æ¯”è¾ƒç†Ÿæ‚‰, ç”±äºç”¨äº†ç±»ä¼¼Pointer Networkçš„æœºåˆ¶, ä¸€èˆ¬çš„æ¨¡å‹åªèƒ½ä»æ–‡ä¸­é€‰æ‹©storyå’Œquestionçš„cosine similarityæœ€é«˜çš„è¯ä½œä¸ºç­”æ¡ˆ, è¿™ä½¿å¾—multiple word answerå¾ˆéš¾å¤„ç†, å°¤å…¶æ˜¯å½“multiple answer wordä¸è¿ç»­çš„æ—¶å€™, æ›´éš¾å¤„ç†. è€ŒCRFæ˜¯å¤§å®¶éƒ½ç†ŸçŸ¥çš„ç®€å•é«˜æ•ˆçš„åºåˆ—æ ‡æ³¨å·¥å…·, æŠŠå®ƒåšæˆå¯è®­ç»ƒçš„, å¹¶ä¸”æ”¾åœ¨end to endæ¨¡å‹ä¸­, çœ‹èµ·æ¥æ˜¯éå¸¸å®ç”¨çš„. åœ¨Evidence LSTMçš„éƒ¨åˆ†, åŠ å…¥çš„ä¸¤ä¸ªfeatureæ®ä½œè€…è¯´éå¸¸æœ‰å¸®åŠ©, çœ‹èµ·æ¥åœ¨deep learning æ¨¡å‹ä¸­åŠ å…¥ä¸€äº›ç²¾å¿ƒè®¾è®¡çš„feature, æˆ–è€…IRçš„è¦ç´ , æœ‰å¯èƒ½èƒ½å¤Ÿå¯¹æ¨¡å‹çš„performanceç»™äºˆä¸€å®šçš„æå‡. åœ¨entropyçš„è§’åº¦, è™½ç„¶ä¸ä¸€å®šæ˜¯entropy reduction, å› ä¸ºè¿™äº›ä¿¡æ¯å…¶å®æœ¬æ¥å·²ç»åŒ…å«åœ¨question/evidenceä¸­äº†, ä½†æ˜¯æœ‰å¯èƒ½å› ä¸ºä½ æä¾›ç»™æ¨¡å‹è¿™äº›ä¿¡æ¯, å®ƒå°±å¯ä»¥æŠŠæ›´å¤šç²¾åŠ›ç”¨åœ¨ä¸€äº›å…¶ä»–çš„ç‰¹å¾ä¸Š?</p>
<p>å¦å¤–å€¼å¾—ä¸€æçš„æ˜¯, æœ€è¿‘Singapore Management Universityçš„Wang and Jiangä¹Ÿæœ‰æ‰€çªç ´, åœ¨SQuAD dataset(ä¹Ÿæ˜¯multiple word answer)ä¸Šä¸€åº¦å–å¾—äº†state of the artçš„ç»“æœ, ä»–ä»¬ç”¨çš„mLSTMæ¨¡å‹ä¹Ÿååˆ†æœ‰è¶£. </p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>è¿™ä¸€ç±»modeléƒ½å¤§é‡ä½¿ç”¨äº†Recurrent Neural Network(LSTMæˆ–è€…GRU)å¯¹textè¿›è¡Œencodingï¼Œå¾—åˆ°ä¸€ä¸ªsequenceçš„hidden state vectorã€‚ç„¶åé€šè¿‡inner productæˆ–è€…bilinear termæ¯”è¾ƒä¸åŒä½ç½®hidden state vectorä¹‹é—´çš„similarityæ¥è®¡ç®—å®ƒä»¬æ˜¯æ­£ç¡®ç­”æ¡ˆçš„å¯èƒ½æ€§ã€‚å¯è§Recurrent Neural Networkä»¥åŠå¯¹äºSimilarityçš„å®šä¹‰ä¾æ—§æ˜¯è§£å†³æ­¤ç±»é—®é¢˜çš„å…³é”®æ‰€åœ¨ï¼Œæ›´å¥½åœ°æ”¹è‰¯è¿™ä¸€ç±»æ¨¡å‹ä¹Ÿæ˜¯æå‡å‡†ç¡®ç‡çš„ä¸»æµæ–¹æ³•ã€‚ç¬”è€…è®¤ä¸ºï¼Œsimilarityçš„è®¡ç®—ç»™äº†æ¨¡å‹ä»åŸæ–‡ä¸­æœç´¢ç­”æ¡ˆçš„èƒ½åŠ›ï¼Œç„¶è€Œæ¨¡å‹éå¸¸ç¼ºä¹çš„æ˜¯æ¨ç†å’Œæ€è€ƒçš„èƒ½åŠ›ï¼ˆå…¶å®ä¹Ÿæœ‰ç›¸å…³å·¥ä½œ<a href="http://arxiv.org/abs/1508.05508" target="_blank" rel="external">Towards Neural Network-based Reasoning</a>ï¼‰ï¼Œå¦‚æœæ¨¡å‹èƒ½å¤Ÿé…å¤‡é€»è¾‘æ€è€ƒèƒ½åŠ›ï¼Œé‚£ä¹ˆè§£å†³é—®é¢˜çš„èƒ½åŠ›ä¼šå¤§å¤§å¢å¼ºã€‚éå¸¸æœŸå¾…æœ‰æ–°çš„æ€è·¯èƒ½å¤Ÿå‡ºç°åœ¨è¿™ä¸€é¢†åŸŸä¸­ï¼Œä»¤AIèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£äººç±»è¯­è¨€ã€‚</p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-18T05:05:11.000Z"><a href="/2016/09/17/paperweeklyç”¨æˆ·æŠ•ç¥¨æ€»ç»“/">2016-09-17</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/17/paperweeklyç”¨æˆ·æŠ•ç¥¨æ€»ç»“/">paperweeklyç”¨æˆ·æŠ•ç¥¨æ€»ç»“</a></h1>
  

    </header>
    <div class="entry">
      
        <p>å‚ä¸æŠ•ç¥¨131äººï¼Œè¿œè¶…æˆ‘ä¸ªäººçš„é¢„æœŸï¼Œè¯æ˜äº†å‘çº¢åŒ…æ˜¯ä¸€ä¸ªéå¸¸æœ‰æ•ˆçš„æ‰‹æ®µï¼Œæ„Ÿè°¢å„ä½çš„å‚ä¸ã€‚</p>
<p><img src="media/1.png" alt="1"></p>
<p>ä»ç¬¬ä¸€ä¸ªé—®é¢˜çš„å›ç­”æ¥çœ‹ï¼Œç¾¤é‡Œçš„ç«¥é‹åŸºæœ¬ä¸Šéƒ½å–œæ¬¢è¯»paperï¼Œå¹¶ä¸”å¤§å¤šæ•°ä¸€å‘¨å†…å¯ä»¥è¯»1-3ç¯‡ï¼Œæ›´æœ‰ç”šè€…å¯ä»¥è¯»åˆ°6ç¯‡ä»¥ä¸Šã€‚å…³äºè¯»paperï¼Œä»¥åŠä»æœ€å¼€å§‹åšpaperweeklyï¼Œä¹Ÿæ˜¯å—äº†Ngä¸€æ¬¡é‡‡è®¿å†…å®¹çš„å¯å‘ï¼Œä»–å¤§æ¦‚çš„æ„æ€æ˜¯è¯´ï¼Œæ¯å¤©åšæŒè¯»ç¯‡paperæ˜¯ä¸€ç§é•¿æœŸæŠ•èµ„ï¼ŒåšæŒåšä¸€å¹´ã€ä¸¤å¹´ä¹‹åä¼šæœ‰æ˜¾è‘—åœ°æé«˜ã€‚ï¼ˆè™½ç„¶ä¸ç¡®å®šè¿™è¯æ˜¯ä¸æ˜¯Ngæœ¬äººè¯´çš„ï¼Œä½†æˆ‘æ¯”è¾ƒè®¤åŒè¿™ä¸ªè§‚ç‚¹ï¼‰</p>
<p><img src="media/2.png" alt="2"></p>
<p>ç¬¬äºŒä¸ªé—®é¢˜æ˜¯å…³äºpaperç±»å‹çš„ï¼Œæ˜¯ä¸€ä¸ªå¤šé€‰é¢˜ã€‚ç¾¤é‡Œçš„ç«¥é‹æœ‰çš„æ˜¯å­¦ç”Ÿï¼Œæœ‰çš„æ˜¯å·¥ä¸šç•Œçš„æœ‹å‹ï¼Œæœ‰çš„å¤§å‚çš„å·¥ç¨‹å¸ˆï¼Œæœ‰çš„æ˜¯åˆ›ä¸šå…¬å¸çš„å¤§æ‹¿ï¼Œä¸åŒçš„èƒŒæ™¯å†³å®šäº†å¯¼å‘ä¸åŒã€‚ä»ç»“æœåˆ†å¸ƒæ¥çœ‹ï¼Œå·¥ç¨‹æ€§å¼ºã€çƒ­é—¨çš„paperæ›´å—æ¬¢è¿ï¼Œè¿™ä¸ªç»“æœå¯ä»¥ä¹Ÿæ¯”è¾ƒå¥½ç†è§£ï¼Œæ¯•ç«Ÿå¤§ä¼—åŒ–çš„ä¸œè¥¿æ˜¯æ›´å—å¤§å®¶æ¬¢è¿ï¼Œå·¥ç¨‹æ€§å¼ºçš„æ–‡ç« ä¸€èˆ¬æ¥è¯´å¯æ“ä½œæ€§éƒ½æ¯”è¾ƒå¼ºï¼Œé€‚åˆå¤ç°ï¼Œå¹¶ä¸”å¯ä»¥æœ‰é€‰æ‹©åœ°åº”ç”¨åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼›çƒ­é—¨çš„æ–‡ç« æ˜¯å¤§å®¶çƒ­è®®çš„è¯é¢˜ï¼ŒAlphaGoçƒ­ç‚’é‚£ä¼šï¼Œå‡ºé—¨ä¸èŠå‡ å¥å¢å¼ºå­¦ä¹ éƒ½ä¸å¥½æ„æ€å’Œäººæ‰“æ‹›å‘¼ï¼Œç”šè‡³è¿™ä¸ªPRè¡Œä¸ºå¸¦åŠ¨äº†ä¸€å¤§æ‰¹äººå¼€å§‹å­¦ä¹ ä¸‹å›´æ£‹ï¼Œçƒ­é—¨ã€è¯é¢˜æ€§æ˜¯æ˜¯åª’ä½“æ„Ÿå…´è¶£çš„ï¼Œä¹Ÿæ˜¯å¤§ä¼—å–œæ¬¢æ´¥æ´¥ä¹é“çš„ï¼›ç†è®ºæ€§å¼ºçš„paperé€šå¸¸æ¥è¯´ä¸å¥½è¯»ï¼Œå› ä¸ºå¾ˆéš¾ï¼Œéœ€è¦å¾ˆæ·±çš„åŸºç¡€åœ¨é‚£å„¿ï¼Œä¸æ˜¯ä¸€å¥ã€ä¸¤å¥è¯´å¾—æ¸…çš„ï¼Œä½†æ­£æ˜¯è¿™äº›ç†è®ºæ€§å¼ºçš„paperçœŸæ­£åœ°æ¨åŠ¨ç€AIåœ¨å¾€å‰èµ°ï¼›æ¯ä¸ªäººçš„å…´è¶£ç‚¹å¯èƒ½éƒ½ä¸æ˜¯å¾ˆç›¸åŒï¼Œæ‰€ä»¥æœ‰28ä¸ªç«¥é‹é€‰æ‹©äº†æœ€åä¸€ä¸ªé€‰é¡¹ï¼Œä¹Ÿç¬¦åˆå°ä¼—è¿™ä¸ªè¯çš„ç‰¹ç‚¹ã€‚</p>
<p>chatbotæ˜¯å½“ä¸‹å¯èƒ½æœ€ç«çš„æ–¹å‘ä¹‹ä¸€ï¼Œä½†è¯´å¥å®è¯ï¼Œ10å¹´å‰paperæå‡ºçš„æ–¹æ³•å¯èƒ½åœ¨ç°åœ¨çš„ç³»ç»Ÿä¸­ä»ç„¶æ˜¯éå¸¸å¥½ç”¨çš„ï¼Œè®°å¾—å¾®åšä¸Šçœ‹åˆ°è¿‡ä¸€ä¸ªäººè¯´ç”¨æ­£åˆ™å¯ä»¥è§£å†³å¤§å¤šæ•°çš„é—®é¢˜ï¼Œä»”ç»†æƒ³æƒ³rule-basedæ˜¯ä¸€ä¸ªå¤šä¹ˆç¥é€šå¹¿å¤§çš„äº‹æƒ…å•Šã€‚æ—¢ç„¶rule-basedè¿™ä¹ˆå¥½ï¼Œå¹²å˜›è¿˜ç ”ç©¶é‚£ä¹ˆå¤šæ–°ä¸œè¥¿ã€æ–°æ¦‚å¿µå‘¢ï¼Ÿä¸å°±æ˜¯å› ä¸ºäººå·¥æ™ºèƒ½å¤ªåé‡äºäººå·¥ä¸€è¯ï¼Œç¦»æ™ºèƒ½å¤ªè¿œï¼Œç¦»æ™ºéšœå¤ªè¿‘å˜›ã€‚æˆ‘ä¸€ç›´æ˜¯è¿™ä¹ˆçœ‹å¾…paperè¿™ä¸ªäº‹å„¿çš„ï¼Œpaperé’ˆå¯¹çš„å¯èƒ½ä¸æ˜¯å½“ä¸‹çš„é—®é¢˜ï¼Œè€Œæ˜¯æœªæ¥çš„é—®é¢˜ï¼Œä½†ä¸æ„å‘³ç€å½“ä¸‹çš„paperå¯¹äºå½“ä¸‹çš„é—®é¢˜æ²¡æœ‰å‚è€ƒå’Œå€Ÿé‰´çš„æ„ä¹‰ã€‚paperweeklyçš„ä¸€ä¸ªåˆè¡·æ˜¯å¸Œæœ›å¤§å®¶å¯ä»¥é€šè¿‡ç®€å•ã€æ¸…æ™°åœ°æè¿°æ¥çœ‹çœ‹æŸä¸€ç¯‡æˆ–è€…æŸå‡ ç¯‡paperåˆ°åº•è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Œç”¨äº†ä»€ä¹ˆæ–¹æ³•ï¼Œç»“æœå¦‚ä½•ï¼Œå½“ç„¶ç»“æœçš„å¯ä¿¡åº¦æ˜¯å¦å¤–ä¸€å›äº‹ï¼Œä½†ç»ˆç©¶æ˜¯ä¼šæœ‰å¯å‘çš„ã€‚</p>
<p><img src="media/3.png" alt="3"></p>
<p>è¿™ä¸ªé—®é¢˜å°‘æ‰“ä¸¤ä¸ªå­—ï¼Œä½†æ˜¯æ„Ÿè§‰æ ¹æ®ä¸Šä¸‹æ–‡å¤§å®¶åº”è¯¥æ˜¯ç†è§£äº†æˆ‘æçš„é—®é¢˜ã€‚æˆ‘æƒ³äº†è§£ï¼Œåˆ°åº•paperweeklyå†™çš„æ–‡ç« æœ‰æ²¡æœ‰çœŸæ­£åœ°è§£å†³äº†ä¸€ç‚¹ç‚¹éœ€æ±‚ï¼Œæˆ–è€…ç»™å¤§å®¶å¸¦æ¥é‚£ä¹ˆä¸€ç‚¹ç‚¹å¯å‘ã€‚ç­”æ¡ˆå‘Šè¯‰äº†æˆ‘ï¼Œç¡®å®æœ‰ï¼ŒæŸäº›ç»†èŠ‚æˆ–è€…æ€è·¯ç¡®å®å¾ˆæœ‰å€Ÿé‰´æ„ä¹‰ï¼Œè¿™ä»¶äº‹æƒ…å€¼å¾—åšã€‚è°¢è°¢ã€‚</p>
<p><img src="media/4.png" alt="4"></p>
<p>è¿™æ˜¯ä¸€ä¸ªå¤šé€‰é¢˜ï¼Œåˆè¡·æ˜¯æƒ³äº†è§£ä¸‹å“ªç§æ–¹å¼æˆ–è€…å“ªå‡ ç§æ–¹å¼å¯ä»¥è®©äº¤æµå˜å¾—æ›´åŠ é«˜æ•ˆç‡ã€‚æ¯«æ— ç–‘é—®ï¼Œå¾®ä¿¡ç¾¤æ˜¯æœ€å¤šçš„ç­”æ¡ˆï¼Œè¯´å¥å®è¯ï¼Œå¾®ä¿¡ç¾¤æ’ç¬¬ä¸€æ˜¯å› ä¸ºå¤§å®¶å¯¹å¾®ä¿¡çš„ä¾èµ–å¼ºï¼Œé»æ€§å¤§ï¼Œbbsæ’ç¬¬äºŒï¼Œå…¶å®bbsæ˜¯æ›´åŠ å¥½çš„è®¨è®ºæ–¹å¼ï¼Œä½†æ˜¯é»æ€§å¾ˆå·®ï¼Œè®¨è®ºèµ·æ¥æ“ä½œä¼šéº»çƒ¦ä¸€äº›ï¼Œæ‰€ä»¥æˆ‘è¿™è¾¹æœ‰ä¸ªéå¸¸naiveçš„æƒ³æ³•ï¼Œå°±æ˜¯æƒ³å°†bbså’Œå¾®ä¿¡ç¾¤æ‰“é€šï¼Œç¾¤é‡Œæœ‰å‡ ä¸ªæŠ€æœ¯å¤§ç‰›ä¹Ÿæ„¿æ„ä¸€èµ·æ¥åšè¿™ä»¶äº‹æƒ…ï¼Œå¸Œæœ›å¯ä»¥æœ‰ä¸€ä¸ªæ–¹ä¾¿å¤§å®¶çš„ä¸œè¥¿å‡ºæ¥ã€‚</p>
<p><img src="media/5.png" alt="5"></p>
<p>å¤ç°åˆ«äººpaperè¿™ä¸ªäº‹å„¿ï¼Œæˆ‘ä¸ªäººä¼šé€‰ä¸€èˆ¬æœ‰ã€‚åŸå› å¦‚ä¸‹ï¼š1ã€é¦–å…ˆpaperçš„ç»“æœå¯èƒ½æ²¡æœ‰é‚£ä¹ˆåœ°å¥½ï¼Œåªæ˜¯è¯´å†™çš„æˆ–è€…é€‰çš„æ¯”è¾ƒå¥½è€Œå·²ï¼›2ã€paperé‡Œçš„ç®—æ³•ä¸è§å¾—é€‚åˆä½ çš„é—®é¢˜ï¼›3ã€paperä¸­çš„å®éªŒåœ¨å®ç°è¿‡ç¨‹ä¸­å¯èƒ½æœ‰å¾ˆå¤šçš„trickï¼Œå¹¶æ²¡æœ‰å†™æ˜åœ¨paperä¸­ï¼Œè¿™éƒ½æ˜¯ä¸€ä¸ªåˆä¸€ä¸ªçš„å‘å•Šï¼›4ã€æœ‰äº›paperæœ‰å¼€æºçš„codeï¼Œå¯ä»¥æ‹¿æ¥è·‘ä¸€è·‘çœ‹çœ‹æ•ˆæœå†è¯´ã€‚</p>
<p><img src="media/6.png" alt="6"></p>
<p>è¿™ä¸ªç­”æ¡ˆä¹Ÿæ˜¯æˆ‘é¢„æƒ³ä¹‹ä¸­çš„ï¼Œæ‘˜è¦å°±æ˜¯ä¸ºäº†è§£å†³ä¿¡æ¯è¿‡è½½é—®é¢˜çš„ã€‚ç¾¤é‡Œæ¯å¤©ä¼šäº§ç”Ÿä¸€å®šæ•°é‡çš„æ¶ˆæ¯ï¼ˆä¸æ˜¯å¾ˆå¤šå…¶å®ï¼‰ï¼Œä½†æ²¡æœ‰èµ¶ä¸Šå®æ—¶èŠå¤©çš„è¯ï¼Œå¾ˆå®¹æ˜“é”™è¿‡ä¸€äº›ç²¾å½©çš„å¯¹è¯æˆ–è€…å¹²è´§åˆ†äº«ã€‚ä»è¿™ä¸ªè§’åº¦æ¥çœ‹ï¼Œåšdigestè¿™ä»¶äº‹æƒ…å°±æ˜¾å¾—å¾ˆæœ‰æ„ä¹‰äº†ã€‚å…³äºå¦‚ä½•åšï¼Œç¾¤é‡Œä¹‹å‰ä¹Ÿæœ‰è¿‡ä¸é”™çš„è®¨è®ºï¼Œæˆ‘ä¹Ÿå°è¯•æ ‡æ³¨äº†ä¸‹æ•°æ®ï¼Œæ„Ÿè§‰éš¾åº¦ä¸å°ï¼Œç°åœ¨çš„æƒ³æ³•æ˜¯ï¼Œæˆ‘æ¯å¤©æ™šä¸ŠèŠ±ç‚¹æ—¶é—´æ‰‹å·¥æ‘˜è¦å‡ºæ¥ï¼Œåˆ†äº«åœ¨bbså’Œç¾¤é‡Œã€‚ï¼ˆæ—¥åæœ‰æœºä¼šå¯ä»¥å°†è¿™ä¸ªäº‹æƒ…è‡ªåŠ¨åŒ–ï¼‰</p>
<p><img src="media/7.png" alt="7"></p>
<p>è¿™ä¸ªé—®é¢˜çš„ç»“æœåŸºæœ¬ä¸Šå’Œæˆ‘ä¸Šé¢çš„æƒ³æ³•å»åˆäº†ã€‚</p>
<p><img src="media/8.png" alt="8"></p>
<p>ç›®å‰paperweeklyè¿è¥å›¢é˜Ÿé‡Œæœ‰å››ä¸ªæ´»è·ƒçš„å°ç»„ï¼Œåˆ†åˆ«æ˜¯chatbotã€NMTã€QAå’Œrepresentationï¼Œæ¯ä¸ªç»„æ¯å‘¨è´Ÿè´£å‡ºä¸€æœŸæ–‡ç« ï¼ŒåŒ…æ‹¬3-5ç¯‡paperï¼ŒKGè¿™ä¸ªç»„å»ºç«‹äº†ï¼Œä½†æ˜¯ä¸€ç›´ä¸å¤Ÿæ´»è·ƒï¼Œéœ€è¦å¤§ç‰›çš„åŠ å…¥ï¼Œæ¥å†™KGæ–¹é¢çš„æ–‡ç« ã€‚</p>
<p>æŠ•ç¥¨çš„ç»“æœå’Œæ€»ç»“åŸºæœ¬æ˜¯è¿™æ ·çš„æƒ…å†µï¼ŒæŠ•ç¥¨å¯èƒ½è®¾è®¡çš„ä¸ç§‘å­¦ä¹Ÿæœ‰äº›ä»“ä¿ƒï¼Œä½†åŸºæœ¬è¾¾åˆ°äº†é¢„æœŸçš„ç›®çš„ï¼Œå¾—åˆ°äº†å……åˆ†çš„åé¦ˆï¼Œè¿™é‡Œæ„Ÿè°¢å„ä½çš„æ”¯æŒã€‚è°¢è°¢å¤§å®¶ï¼</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-17T04:34:58.000Z"><a href="/2016/09/16/cs-CL-weekly-2016-09-12-2016-09-16/">2016-09-16</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/16/cs-CL-weekly-2016-09-12-2016-09-16/">cs.CL weekly 2016.09.12-2016.09.16</a></h1>
  

    </header>
    <div class="entry">
      
        <p>æœ¬å‘¨ï¼ˆ2016.09.12-2016.09.16ï¼‰è´¨é‡è¾ƒé«˜çš„arXiv cs.CLçš„paperå¦‚ä¸‹ï¼š<br>ï¼ˆç‚¹å‡»æ ‡é¢˜å¯çœ‹åŸæ–‡ï¼‰</p>
<h1 id="Dialogue-manager-domain-adaptation-using-Gaussian-process-reinforcement-learning"><a href="#Dialogue-manager-domain-adaptation-using-Gaussian-process-reinforcement-learning" class="headerlink" title="Dialogue manager domain adaptation using Gaussian process reinforcement learning"></a><a href="http://120.52.73.75/arxiv.org/pdf/1609.02846v1.pdf" target="_blank" rel="external">Dialogue manager domain adaptation using Gaussian process reinforcement learning</a></h1><p>æœ¬æ–‡æ˜¯Steve Youngç»„çš„ä¸€ç¯‡å¤§ä½œï¼Œæ–‡ä¸­è¯¦ç»†ä»‹ç»äº†Gaussian process reinforcement learningæ¡†æ¶çš„æ€è·¯å’Œä¼˜åŠ¿ï¼Œå¹¶ä¸”åœ¨å¤šä¸ªå¯¹è¯é¢†åŸŸä¸­è¿›è¡Œäº†å®éªŒå¹¶å¾—åˆ°æ›´å¥½çš„ç»“æœã€‚</p>
<h1 id="A-Hierarchical-Model-of-Reviews-for-Aspect-based-Sentiment-Analysis"><a href="#A-Hierarchical-Model-of-Reviews-for-Aspect-based-Sentiment-Analysis" class="headerlink" title="A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.02745v1.pdf" target="_blank" rel="external">A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis</a></h1><p>æœ¬æ–‡æå‡ºç”¨åˆ†å±‚åŒå‘LSTMæ¨¡å‹å¯¹ç½‘ç«™è¯„è®ºæ•°æ®è¿›è¡Œè§‚ç‚¹æŒ–æ˜ï¼Œå‘è¡¨åœ¨EMNLP 2016ã€‚è¯¥ä½œè€…ä»Šå¤©åœ¨arxivä¸Šæäº¤äº†ä¸‰ç¯‡åŒç±»é—®é¢˜ä¸åŒè§£å†³æ–¹æ¡ˆçš„paperï¼Œå¯¹è¯„è®ºè§‚ç‚¹å’Œæƒ…æ„ŸæŒ–æ˜çš„ç«¥é‹å¯ä½œå‚è€ƒã€‚</p>
<h1 id="Knowledge-as-a-Teacher-Knowledge-Guided-Structural-Attention-Networks"><a href="#Knowledge-as-a-Teacher-Knowledge-Guided-Structural-Attention-Networks" class="headerlink" title="Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.03286v1.pdf" target="_blank" rel="external">Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks</a></h1><p>æœ¬æ–‡æå‡ºäº†ç”¨å…ˆéªŒçŸ¥è¯†+attention networkçš„æ¨¡å‹ï¼Œç”¨æ¥è§£å†³äº†è‡ªç„¶è¯­è¨€ç†è§£å­˜åœ¨é—®é¢˜ï¼šé€šè¿‡ä»å°‘é‡è®­ç»ƒæ•°æ®ä¸­æ•è·é‡è¦å­ç»“æ„ï¼Œæ¥ç¼“è§£æµ‹è¯•é›†ä¸­çš„unseen dataé—®é¢˜ï¼ŒåŒæ—¶æé«˜ç†è§£èƒ½åŠ›ã€‚</p>
<h1 id="Wav2Letter-an-End-to-End-ConvNet-based-Speech-Recognition-System"><a href="#Wav2Letter-an-End-to-End-ConvNet-based-Speech-Recognition-System" class="headerlink" title="Wav2Letter: an End-to-End ConvNet-based Speech Recognition System"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.03193v2.pdf" target="_blank" rel="external">Wav2Letter: an End-to-End ConvNet-based Speech Recognition System</a></h1><p>æœ¬æ–‡æå‡ºäº†ä¸€ç§è¯­éŸ³è¯†åˆ«çš„ç«¯åˆ°ç«¯æ¨¡å‹ï¼ŒåŸºäºCNNå’Œgraph decodingï¼Œåœ¨ä¸ä¾èµ–å› ç´ å¯¹é½çš„å‰æä¸‹ï¼Œè¾“å‡ºlettersã€‚æœ¬æ–‡å·¥ä½œæ¥è‡ªFacebook AIã€‚</p>
<h1 id="Multimodal-Attention-for-Neural-Machine-Translation"><a href="#Multimodal-Attention-for-Neural-Machine-Translation" class="headerlink" title="Multimodal Attention for Neural Machine Translation "></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.03976v1.pdf" target="_blank" rel="external">Multimodal Attention for Neural Machine Translation </a></h1><p>æœ¬æ–‡é€šè¿‡åˆ©ç”¨image captionçš„å¤šæ¨¡æ€ã€å¤šè¯­è¨€æ•°æ®æ„å»ºäº†ä¸€ä¸ªNMTæ¨¡å‹ï¼Œæ¨¡å‹çš„è¾“å…¥ä¸ä»…æ˜¯source languageï¼Œè¿˜æœ‰æ‰€æè¿°çš„å›¾åƒï¼Œè¾“å‡ºæ˜¯target languageã€‚é€šè¿‡è¾“å…¥æ›´å¤šçš„ä¿¡æ¯ï¼Œå¾—åˆ°äº†æ›´å¥½çš„æ•ˆæœã€‚</p>
<h1 id="Joint-Extraction-of-Events-and-Entities-within-a-Document-Context"><a href="#Joint-Extraction-of-Events-and-Entities-within-a-Document-Context" class="headerlink" title="Joint Extraction of Events and Entities within a Document Context"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.03632v1.pdf" target="_blank" rel="external">Joint Extraction of Events and Entities within a Document Context</a></h1><p>æœ¬æ–‡é’ˆå¯¹ä¼ ç»Ÿä¿¡æ¯æŠ½å–æ–¹æ³•å°†eventå’Œentityåˆ†å¼€è€ƒè™‘çš„é—®é¢˜ï¼Œæå‡ºäº†åœ¨docuemnt-level contextä¸‹è€ƒè™‘eventå’Œentityä¹‹é—´å…³ç³»è¿›è¡Œä¿¡æ¯æŠ½å–çš„æ–°æ–¹æ³•ï¼Œå–å¾—äº†éå¸¸å¥½çš„ç»“æœã€‚æœ¬æ–‡å‘è¡¨åœ¨NAACL2016.</p>
<h1 id="Character-Level-Language-Modeling-with-Hierarchical-Recurrent-Neural-Networks"><a href="#Character-Level-Language-Modeling-with-Hierarchical-Recurrent-Neural-Networks" class="headerlink" title="Character-Level Language Modeling with Hierarchical Recurrent Neural Networks"></a><a href="http://120.52.73.75/arxiv.org/pdf/1609.03777v1.pdf" target="_blank" rel="external">Character-Level Language Modeling with Hierarchical Recurrent Neural Networks</a></h1><p>è¯­è¨€æ¨¡å‹é—®é¢˜ä¸Šï¼Œchar-levelå¯ä»¥å¾ˆå¥½åœ°è§£å†³OOVçš„é—®é¢˜ï¼Œä½†æ•ˆæœä¸å¦‚word-levelï¼Œæœ¬æ–‡é’ˆå¯¹è¯¥é—®é¢˜æå‡ºäº†ä¸€ç§åˆ†å±‚æ¨¡å‹ï¼ŒåŒæ—¶å…¼é¡¾word-levelå’Œchar-levelçš„ä¼˜åŠ¿ã€‚æœ¬æ–‡å‘è¡¨åœ¨nips2016ã€‚</p>
<h1 id="Neural-Machine-Translation-with-Supervised-Attention"><a href="#Neural-Machine-Translation-with-Supervised-Attention" class="headerlink" title="Neural Machine Translation with Supervised Attention"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.04186v1.pdf" target="_blank" rel="external">Neural Machine Translation with Supervised Attention</a></h1><p>attentionæœºåˆ¶å¯ä»¥åŠ¨æ€åœ°å¯¹é½sourceå’Œtarget wordsï¼Œä½†å‡†ç¡®ç‡ä¸å¦‚ä¼ ç»Ÿæ–¹æ³•ã€‚æœ¬æ–‡æå‡ºäº†ç”¨ä¼ ç»Ÿæ–¹æ³•ä½œä¸ºteacherï¼Œæ¥â€œæ•™â€modelå­¦ä¹ alignmentï¼Œæ¨¡å‹ç§°ä¸ºsupervised attentionã€‚æœ¬æ–‡å·²æŠ•ç¨¿COLING2016ï¼Œåœ¨å®¡ã€‚</p>
<h1 id="Efficient-softmax-approximation-for-GPUs"><a href="#Efficient-softmax-approximation-for-GPUs" class="headerlink" title="Efficient softmax approximation for GPUs"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.04309v1.pdf" target="_blank" rel="external">Efficient softmax approximation for GPUs</a></h1><p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„softmaxè¿‘ä¼¼æ–¹æ³•ï¼Œå¹¶ä¸”å¯ä»¥æ–¹ä¾¿åœ°è¿›è¡Œå¹¶è¡Œè®¡ç®—ã€‚æœ¬æ–‡ç§°ä¹‹ä¸ºadaptive softmaxï¼Œæ ¹æ®è¯åˆ†å¸ƒè¿›è¡Œèšç±»ï¼Œæå¤§åœ°æé«˜äº†è®¡ç®—æ•ˆç‡å¹¶ä¿è¯äº†ä¸é”™çš„å‡†ç¡®ç‡ã€‚æœ¬æ–‡å·¥ä½œæ¥è‡ªFacebook AI Researchã€‚</p>
<p>åœ¨è‡ªç„¶è¯­è¨€ç”Ÿæˆä»»åŠ¡ä¸­å¸¸å¸¸é¢ä¸´word vocabulary sizeå¤ªå¤§çš„å›°å¢ƒï¼Œsoftmaxçš„æ•ˆç‡éå¸¸ä½ï¼Œæœ¬æ–‡ç»™å‡ºäº†ä¸€ç§å¿«é€Ÿè®¡ç®—çš„æ–¹æ³•ã€‚Tomas Mikolovä¹‹å‰ä¹Ÿæåˆ°è¿‡ç±»ä¼¼çš„æ€è·¯ã€‚</p>
<h1 id="Characterizing-the-Language-of-Online-Communities-and-its-Relation-to-Community-Reception"><a href="#Characterizing-the-Language-of-Online-Communities-and-its-Relation-to-Community-Reception" class="headerlink" title="Characterizing the Language of Online Communities and its Relation to Community Reception"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.04779v1.pdf" target="_blank" rel="external">Characterizing the Language of Online Communities and its Relation to Community Reception</a></h1><p>æœ¬æ–‡ç ”ç©¶äº†åœ¨çº¿ç¤¾åŒºè¯­è¨€çš„styleå’Œtopicå“ªä¸ªæ›´å…·ä»£è¡¨æ€§ï¼Œè¿™é‡Œstyleç”¨å¤åˆè¯­è¨€æ¨¡å‹æ¥è¡¨ç¤ºï¼Œtopicç”¨LDAæ¥è¡¨ç¤ºï¼Œé€šè¿‡Reddit Forumå®éªŒå¾—åˆ°styleæ¯”topicæ›´æœ‰ä»£è¡¨æ€§ã€‚</p>
<h1 id="Factored-Neural-Machine-Translation"><a href="#Factored-Neural-Machine-Translation" class="headerlink" title="Factored Neural Machine Translation"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.04621v1.pdf" target="_blank" rel="external">Factored Neural Machine Translation</a></h1><p>é’ˆå¯¹æœºå™¨ç¿»è¯‘é¢†åŸŸä¸­ä¸¤ä¸ªå¸¸è§çš„é—®é¢˜ï¼š1ã€ç›®æ ‡è¯­è¨€è¯æ±‡è¡¨è¿‡å¤§ï¼›2ã€OOVé—®é¢˜ï¼›åˆ©ç”¨äº†å•è¯çš„è¯å½¢å’Œè¯­æ³•åˆ†è§£ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„NMTæ¨¡å‹ï¼Œå¹¶å–å¾—äº†æ»¡æ„çš„æ•ˆæœã€‚</p>
<h1 id="Context-Aware-Nonnegative-Matrix-Factorization-Clustering"><a href="#Context-Aware-Nonnegative-Matrix-Factorization-Clustering" class="headerlink" title="Context Aware Nonnegative Matrix Factorization Clustering"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.04628v1.pdf" target="_blank" rel="external">Context Aware Nonnegative Matrix Factorization Clustering</a></h1><p>å¤§å¤šæ•°paperéƒ½åœ¨ç ”ç©¶NMFåœ¨èšç±»ä¸­çš„åˆå§‹åŒ–å’Œä¼˜åŒ–éƒ¨åˆ†ï¼Œè€Œæœ¬æ–‡å…³æ³¨çš„ç‚¹åœ¨äºæœ€åçš„èšç±»åˆ†é…ä¸Šã€‚æœ¬æ–‡è¢« ICPR 2016å…¨æ–‡æ”¶å½•ã€‚</p>
<p>ä»¥ä¸‹å†…å®¹ä¸ºarXivå¤–çš„ä¼˜è´¨å†…å®¹ï¼š</p>
<h1 id="SIGDIAL-2016-Accepted-Paper"><a href="#SIGDIAL-2016-Accepted-Paper" class="headerlink" title="SIGDIAL 2016 Accepted Paper"></a><a href="http://www.sigdial.org/workshops/conference17/proceedings/SIGDIAL-2016.pdf" target="_blank" rel="external">SIGDIAL 2016 Accepted Paper</a></h1><p>SIGdialæ˜¯ACLä¸‹é¢çš„ä¸€ä¸ªå…³äºå¯¹è¯ç³»ç»Ÿåœ°ç‰¹åˆ«å…´è¶£å°ç»„ï¼Œæ¯å¹´å¼€ä¸€æ¬¡ä¼šã€‚ä»Šå¹´çš„ä¼šè®®æœ€è¿‘æ­£åœ¨å¼€ï¼Œä¼šè®®å½•ç”¨çš„æ‰€æœ‰paperéƒ½å·²ç»æ”¾å‡ºã€‚</p>
<h1 id="CMU-SPEECH-Team-Homepage"><a href="#CMU-SPEECH-Team-Homepage" class="headerlink" title="CMU SPEECH Team Homepage"></a><a href="http://speech.sv.cmu.edu/software.html" target="_blank" rel="external">CMU SPEECH Team Homepage</a></h1><p>CMU SPEECH Teamçš„ä¸»é¡µï¼ŒåŒ…æ‹¬ä»–ä»¬çš„å¼€æºè½¯ä»¶Yodaå’ŒpublicationåŠå…¶å¼€æºå®ç°ã€‚</p>
<h1 id="Machine-Learning-WAYR-What-Are-You-Reading"><a href="#Machine-Learning-WAYR-What-Are-You-Reading" class="headerlink" title="Machine Learning - WAYR (What Are You Reading)"></a><a href="https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/?st=ISZ6YT6D&amp;sh=02bd0722" target="_blank" rel="external">Machine Learning - WAYR (What Are You Reading)</a></h1><p>redditä¸Šçš„è¿™ä¸ªå¸–å­å¾ˆæœ‰æ„æ€ï¼Œå’Œpaperweeklyæƒ³åšçš„ä¸€ä¸ªäº‹æƒ…éå¸¸åƒï¼Œå°±æ˜¯å¯ä»¥è®©è¯»ç±»ä¼¼æˆ–è€…åŒä¸€ç¯‡paperçš„ç«¥é‹å¾—åˆ°å……åˆ†äº¤æµã€‚</p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"><br>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰æ¯å¤©éƒ½ä¼šåˆ†äº«å½“å¤©arXiv cs.CLæ¿å—åˆ·æ–°çš„é«˜è´¨é‡paper<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-16T18:14:40.000Z"><a href="/2016/09/16/PaperWeekly-ç¬¬äº”æœŸ/">2016-09-16</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/16/PaperWeekly-ç¬¬äº”æœŸ/">PaperWeekly ç¬¬äº”æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•"><a href="#å¼•" class="headerlink" title="å¼•"></a>å¼•</h1><p>Word2Vecä»æå‡ºè‡³ä»Šï¼Œå·²ç»æˆä¸ºäº†æ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åŸºç¡€éƒ¨ä»¶ï¼Œå¤§å¤§å°å°ã€å½¢å½¢è‰²è‰²çš„DLæ¨¡å‹åœ¨è¡¨ç¤ºè¯ã€çŸ­è¯­ã€å¥å­ã€æ®µè½ç­‰æ–‡æœ¬è¦ç´ æ—¶éƒ½éœ€è¦ç”¨word2vecæ¥åšword-levelçš„embeddingã€‚Word2Vecçš„ä½œè€…Tomas Mikolovæ˜¯ä¸€ä½äº§å‡ºå¤šç¯‡é«˜è´¨é‡paperçš„å­¦è€…ï¼Œä»RNNLMã€Word2Vecå†åˆ°æœ€è¿‘æµè¡Œçš„FastTextéƒ½ä¸ä»–æ¯æ¯ç›¸å…³ã€‚ä¸€ä¸ªäººå¯¹åŒä¸€ä¸ªé—®é¢˜çš„ç ”ç©¶å¯èƒ½ä¼šæŒç»­å¾ˆå¤šå¹´ï¼Œè€Œæ¯ä¸€å¹´çš„ç ”ç©¶æˆæœéƒ½å¯èƒ½ä¼šç»™åŒè¡Œå¸¦æ¥æ–°çš„å¯å‘ï¼Œæœ¬æœŸçš„PaperWeeklyå°†ä¼šåˆ†äº«å…¶ä¸­ä¸‰ç¯‡ä»£è¡¨ä½œï¼Œåˆ†åˆ«æ˜¯ï¼š</p>
<p>1ã€Efficient Estimation of Word Representation in Vector Space, 2013<br>2ã€Distributed Representations of Sentences and Documents, 2014<br>3ã€Enriching Word Vectors with Subword Information, 2016</p>
<h1 id="Efficient-Estimation-of-Word-Representation-in-Vector-Space"><a href="#Efficient-Estimation-of-Word-Representation-in-Vector-Space" class="headerlink" title="Efficient Estimation of Word Representation in Vector Space"></a><a href="https://arxiv.org/pdf/1301.3781.pdf" target="_blank" rel="external">Efficient Estimation of Word Representation in Vector Space</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Google Inc., Mountain View, CA</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Word Representation, Word Embedding, Neural Network, Syntactic Similarity, and Semantic Similarity</p>
<h2 id="æ¥æº"><a href="#æ¥æº" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>arXiv, 201309</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•åœ¨ä¸€ä¸ªå¤§å‹æ•°æ®é›†ä¸Šå¿«é€Ÿã€å‡†ç¡®åœ°å­¦ä¹ å‡ºè¯è¡¨ç¤ºï¼Ÿ</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>ä¼ ç»Ÿçš„NNLMæ¨¡å‹åŒ…å«å››å±‚ï¼Œå³è¾“å…¥å±‚ã€æ˜ å°„å±‚ã€éšå«å±‚å’Œè¾“å‡ºå±‚ï¼Œè®¡ç®—å¤æ‚åº¦å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºæ˜ å°„å±‚åˆ°éšå«å±‚ä¹‹é—´çš„è®¡ç®—ï¼Œè€Œä¸”éœ€è¦æŒ‡å®šä¸Šä¸‹æ–‡çš„é•¿åº¦ã€‚RNNLMæ¨¡å‹è¢«æå‡ºç”¨æ¥æ”¹è¿›NNLMæ¨¡å‹ï¼Œå»æ‰äº†æ˜ å°„å±‚ï¼Œåªæœ‰è¾“å…¥å±‚ã€éšå«å±‚å’Œè¾“å‡ºå±‚ï¼Œè®¡ç®—å¤æ‚åº¦æ¥æºäºä¸Šä¸€å±‚çš„éšå«å±‚åˆ°ä¸‹ä¸€å±‚éšå«å±‚ä¹‹é—´çš„è®¡ç®—ã€‚</p>
<p>æœ¬æ–‡æå‡ºçš„ä¸¤ä¸ªæ¨¡å‹CBOW (Continuous Bag-of-Words Model)å’ŒSkip-gram (Continuous Skip-gram Model)ç»“åˆäº†ä¸Šé¢ä¸¤ä¸ªæ¨¡å‹çš„ç‰¹ç‚¹ï¼Œéƒ½æ˜¯åªæœ‰ä¸‰å±‚ï¼Œå³è¾“å…¥å±‚ã€æ˜ å°„å±‚å’Œè¾“å‡ºå±‚ã€‚CBOWæ¨¡å‹ä¸NNLMæ¨¡å‹ç±»ä¼¼ï¼Œç”¨ä¸Šä¸‹æ–‡çš„è¯å‘é‡ä½œä¸ºè¾“å…¥ï¼Œæ˜ å°„å±‚åœ¨æ‰€æœ‰çš„è¯é—´å…±äº«ï¼Œè¾“å‡ºå±‚ä¸ºä¸€ä¸ªåˆ†ç±»å™¨ï¼Œç›®æ ‡æ˜¯ä½¿å½“å‰è¯çš„æ¦‚ç‡æœ€å¤§ã€‚Skip-gramæ¨¡å‹ä¸CBOWçš„è¾“å…¥è·Ÿè¾“å‡ºæ°å¥½ç›¸åï¼Œè¾“å…¥å±‚ä¸ºå½“å‰è¯å‘é‡ï¼Œè¾“å‡ºå±‚æ˜¯ä½¿å¾—ä¸Šä¸‹æ–‡çš„é¢„æµ‹æ¦‚ç‡æœ€å¤§ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚è®­ç»ƒé‡‡ç”¨SGDã€‚<br><img src="media/14740499814306.jpg" alt=""></p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>Code: <a href="https://code.google.com/archive/p/word2vec/" target="_blank" rel="external">C++ä»£ç </a><br>Dataset: <a href="https://sites.google.com/site/semeval2012task2/" target="_blank" rel="external">SemEval-2012</a>,ç”¨æ¥è¯„ä¼°è¯­ä¹‰ç›¸å…³æ€§ã€‚</p>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>Bengio[1]åœ¨2003å¹´å°±æå‡ºäº†language modelçš„æ€è·¯ï¼ŒåŒæ ·æ˜¯ä¸‰å±‚ï¼ˆè¾“å…¥å±‚ï¼Œéšå«å±‚å’Œè¾“å‡ºå±‚ï¼‰ç”¨ä¸Šä¸‹æ–‡çš„è¯å‘é‡æ¥é¢„æµ‹ä¸­é—´è¯ï¼Œä½†æ˜¯è®¡ç®—å¤æ‚åº¦è¾ƒé«˜ï¼Œå¯¹äºè¾ƒå¤§çš„æ•°æ®é›†è¿è¡Œæ•ˆç‡ä½ï¼›å®éªŒä¸­ä¹Ÿå‘ç°å°†ä¸Šä¸‹æ–‡çš„n-gramå‡ºç°çš„é¢‘ç‡ç»“åˆè¿›å»ä¼šæé«˜æ€§èƒ½ï¼Œè¿™ä¸ªä¼˜ç‚¹ä½“ç°åœ¨CBOWå’ŒSkip-gramæ¨¡å‹çš„è¾“å‡ºå±‚ä¸­ï¼Œç”¨hierarchical softmaxï¼ˆwith huffman treesï¼‰æ¥è®¡ç®—è¯æ¦‚ç‡ã€‚</p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡çš„å®éªŒç»“æœæ˜¾ç¤ºCBOWæ¯”NNLMåœ¨syntacticå’Œsemanticä¸Šçš„é¢„æµ‹éƒ½è¦å¥½ï¼Œè€ŒSkip-gramåœ¨semanticä¸Šçš„æ€§èƒ½è¦ä¼˜äºCBOWï¼Œä½†æ˜¯å…¶è®¡ç®—é€Ÿåº¦è¦ä½äºCBOWã€‚ç»“æœæ˜¾ç¤ºç”¨è¾ƒå¤§çš„æ•°æ®é›†å’Œè¾ƒå°‘çš„epochï¼Œå¯ä»¥å–å¾—è¾ƒå¥½çš„æ•ˆæœï¼Œå¹¶ä¸”åœ¨é€Ÿåº¦ä¸Šæœ‰æ‰€æå‡ã€‚ä¸LSIå’ŒLDAç›¸æ¯”ï¼Œword2vecåˆ©ç”¨äº†è¯çš„ä¸Šä¸‹æ–‡ï¼Œè¯­ä¹‰ä¿¡æ¯æ›´åŠ ä¸°å¯Œã€‚åŸºäºword2vecï¼Œå‡ºç°äº†phrase2vec, sentence2vecå’Œdoc2vecï¼Œä»¿ä½›ä¸€ä¸‹å­è¿›å…¥äº†embeddingçš„ä¸–ç•Œã€‚NLPçš„è¿™äº›æ€æƒ³ä¹Ÿåœ¨ç”¨äºrecommendationç­‰æ–¹é¢ï¼Œå¹¶ä¸”ä¸imageç»“åˆï¼Œå°†imageè·Ÿtextä¹‹é—´è¿›è¡Œè½¬æ¢ã€‚</p>
<h1 id="Distributed-Representations-of-Sentences-and-Documents"><a href="#Distributed-Representations-of-Sentences-and-Documents" class="headerlink" title="Distributed Representations of Sentences and Documents"></a><a href="http://120.52.73.76/arxiv.org/pdf/1405.4053v2.pdf" target="_blank" rel="external">Distributed Representations of Sentences and Documents</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Quoc V. Le, Tomas Mikolov</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Google Inc, Mountain View, CA</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>sentence representation</p>
<h2 id="æ¥æº-1"><a href="#æ¥æº-1" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>ICML 2014</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>åŸºäºword2vecçš„æ€è·¯ï¼Œå¦‚ä½•è¡¨ç¤ºsentenceå’Œdocumentï¼Ÿ</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p><img src="media/14740512129190.jpg" alt=""><br>åˆ©ç”¨one-hotçš„è¡¨ç¤ºæ–¹æ³•ä½œä¸ºç½‘ç»œçš„è¾“å…¥ï¼Œä¹˜ä»¥è¯çŸ©é˜µWï¼Œç„¶åå°†å¾—åˆ°çš„æ¯ä¸ªå‘é‡é€šè¿‡å¹³å‡æˆ–è€…æ‹¼æ¥çš„æ–¹æ³•å¾—åˆ°æ•´ä¸ªå¥å­çš„è¡¨ç¤ºï¼Œæœ€åæ ¹æ®ä»»åŠ¡è¦æ±‚åšä¸€åˆ†ç±»ï¼Œè€Œè¿™è¿‡ç¨‹ä¸­å¾—åˆ°çš„Wå°±æ˜¯è¯å‘é‡çŸ©é˜µï¼ŒåŸºæœ¬ä¸Šè¿˜æ˜¯word2vecçš„æ€è·¯ã€‚</p>
<p>æ¥ä¸‹æ¥æ˜¯æ®µè½çš„å‘é‡è¡¨ç¤ºæ–¹æ³•ï¼š<br><img src="media/14740512491434.jpg" alt=""><br>ä¾æ—§æ˜¯ç›¸åŒçš„æ–¹æ³•ï¼Œåªæ˜¯åœ¨è¿™é‡ŒåŠ ä¸Šäº†ä¸€ä¸ªæ®µè½çŸ©é˜µï¼Œç”¨ä»¥è¡¨ç¤ºæ¯ä¸ªæ®µè½ï¼Œå½“è¿™äº›è¯è¾“å…¥ç¬¬iä¸ªæ®µè½æ—¶ï¼Œé€šè¿‡æ®µè½idå°±å¯ä»¥ä»è¿™ä¸ªçŸ©é˜µä¸­å¾—åˆ°ç›¸å¯¹åº”çš„æ®µè½è¡¨ç¤ºæ–¹æ³•ã€‚éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œåœ¨ç›¸åŒçš„æ®µè½ä¸­ï¼Œæ®µè½çš„è¡¨ç¤ºæ˜¯ç›¸åŒçš„ã€‚æ–‡ä¸­è¿™æ ·è¡¨ç¤ºçš„åŠ¨æœºå°±æ˜¯æ®µè½çŸ©é˜µDå¯ä»¥ä½œä¸ºä¸€ä¸ªmemoryè®°ä½åœ¨è¯çš„contextä¸­é—å¤±çš„ä¸œè¥¿ï¼Œç›¸å½“äºå¢åŠ äº†ä¸€ä¸ªé¢å¤–çš„ä¿¡æ¯ã€‚è¿™æ ·ç»è¿‡è®­ç»ƒä¹‹åï¼Œæˆ‘ä»¬çš„å°±å¾—åˆ°äº†æ®µè½è¡¨ç¤ºDï¼Œå½“ç„¶è¿™ä¸ªæ®µè½å°±å¯ä»¥æ˜¯ä¸€æ®µæˆ–è€…ä¸€ç¯‡æ–‡ç« ã€‚</p>
<p>æœ€åä¸€ç§å°±æ˜¯æ²¡æœ‰è¯åºçš„æ®µè½å‘é‡è¡¨ç¤ºæ–¹æ³•ï¼š<br><img src="media/14740512902836.jpg" alt=""><br>ä»å›¾ä¸­å°±å¯ä»¥æ„Ÿè§‰åˆ°è¿™ä¸ªæ–¹æ³•æ˜æ˜¾å’Œskip-graméå¸¸ç›¸ä¼¼ï¼Œè¿™é‡Œåªæ˜¯æŠŠé‡ç‚¹æ”¾åœ¨äº†æ®µè½çš„è¡¨ç¤ºä¸­ï¼Œé€šè¿‡æ®µè½çš„è¡¨ç¤ºï¼Œæ¥é¢„æµ‹ç›¸åº”çš„context è¯çš„è¡¨ç¤ºã€‚æœ€åæˆ‘ä»¬ä¾ç„¶å¯ä»¥å¾—åˆ°æ®µè½çŸ©é˜µDï¼Œè¿™æ ·å°±å¯ä»¥å¯¹æ®µè½è¿›è¡Œå‘é‡åŒ–è¡¨ç¤ºäº†ã€‚ä½†æ˜¯è¾“å…¥èµ·ç æ˜¯å¥å­çº§åˆ«çš„è¡¨ç¤ºï¼Œè€Œè¾“å‡ºåˆ™æ˜¯è¯çš„å‘é‡è¡¨ç¤ºï¼Œå› æ­¤ä¸ªäººæ¯”è¾ƒæ€€ç–‘è¿™ç§æ–¹æ³•çš„åˆç†æ€§ã€‚</p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¿™ç¯‡æ–‡ç« æ˜¯word2vecçš„æ–¹æ³•æå‡ºä¸€å¹´åæå‡ºçš„æ–¹æ³•ï¼Œå› æ­¤æœ¬æ–‡å¹¶æ²¡æœ‰ä½¿ç”¨ç›®å‰éå¸¸æµè¡Œçš„word2vecçš„è®­ç»ƒæ–¹æ³•æ¥è®­ç»ƒè¯å‘é‡ï¼Œè€Œæ˜¯åˆ©ç”¨word2vecçš„æ€è·¯ï¼Œæå‡ºäº†ä¸€ç§æ›´åŠ ç®€å•çš„ç½‘ç»œç»“æ„æ¥è®­ç»ƒä»»æ„é•¿åº¦çš„æ–‡æœ¬è¡¨ç¤ºæ–¹æ³•ã€‚è¿™æ ·ä¸€æ–¹é¢å¥½è®­ç»ƒï¼Œå¦ä¸€æ–¹é¢å‡å°‘äº†å‚æ•°ï¼Œé¿å…æ¨¡å‹è¿‡æ‹Ÿåˆã€‚ä¼˜ç‚¹å°±æ˜¯åœ¨è®­ç»ƒparagraph vectorçš„æ—¶å€™åŠ å…¥äº†ä¸€ä¸ªparagraph matrixï¼Œè¿™æ ·åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿ç•™äº†ä¸€éƒ¨åˆ†æ®µè½æˆ–è€…æ–‡æ¡£ä¿¡æ¯ã€‚è¿™ç‚¹åœ¨ç›®å‰çœ‹æ¥ä¹Ÿæ˜¯æœ‰ä¸€å®šä¼˜åŠ¿çš„ã€‚ä½†æ˜¯ç›®å‰æ·±åº¦å­¦ä¹ å‘å±•è¿…é€Ÿï¼Œå¯ä»¥å¤„ç†éå¸¸å¤§çš„è®¡ç®—é‡ï¼ŒåŒæ—¶word2vecä»¥åŠå…¶å˜ç§è¢«åº”ç”¨å¾—éå¸¸æ™®éï¼Œå› æ­¤è¯¥æ–‡ç« æå‡ºçš„æ–¹æ³•æ€è·¯å¤§äºæ¨¡å‹ï¼Œæ€è·¯æˆ‘ä»¬å¯ä»¥å€Ÿé‰´ï¼Œæ¨¡å‹å°±ä¸å…·æœ‰ä¼˜åŠ¿äº†ã€‚</p>
<h1 id="Enriching-Word-Vectors-with-Subword-Information"><a href="#Enriching-Word-Vectors-with-Subword-Information" class="headerlink" title="Enriching Word Vectors with Subword Information"></a><a href="http://120.52.73.80/arxiv.org/pdf/1607.04606v1.pdf" target="_blank" rel="external">Enriching Word Vectors with Subword Information</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>Facebook AI Research</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Word embedding, morphological, character n-gram</p>
<h2 id="æ¥æº-2"><a href="#æ¥æº-2" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>arXiv, 201607</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•è§£å†³word2vecæ–¹æ³•ä¸­ç½•è§è¯æ•ˆæœä¸ä½³çš„é—®é¢˜ï¼Œä»¥åŠå¦‚ä½•æå‡è¯å½¢æ€ä¸°å¯Œè¯­è¨€çš„æ€§èƒ½ï¼Ÿ</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>word2vecåœ¨è¯æ±‡å»ºæ¨¡æ–¹é¢äº§ç”Ÿäº†å·¨å¤§çš„è´¡çŒ®ï¼Œç„¶è€Œå…¶ä¾èµ–äºå¤§é‡çš„æ–‡æœ¬æ•°æ®è¿›è¡Œå­¦ä¹ ï¼Œå¦‚æœä¸€ä¸ªwordå‡ºç°æ¬¡æ•°è¾ƒå°‘é‚£ä¹ˆå­¦åˆ°çš„vectorè´¨é‡ä¹Ÿä¸ç†æƒ³ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ä½œè€…æå‡ºä½¿ç”¨subwordä¿¡æ¯æ¥å¼¥è¡¥è¿™ä¸€é—®é¢˜ï¼Œç®€å•æ¥è¯´å°±æ˜¯é€šè¿‡è¯ç¼€çš„vectoræ¥è¡¨ç¤ºè¯ã€‚æ¯”å¦‚unofficialæ˜¯ä¸ªä½é¢‘è¯ï¼Œå…¶æ•°æ®é‡ä¸è¶³ä»¥è®­ç»ƒå‡ºé«˜è´¨é‡çš„vectorï¼Œä½†æ˜¯å¯ä»¥é€šè¿‡un+officialè¿™ä¸¤ä¸ªé«˜é¢‘çš„è¯ç¼€å­¦ä¹ åˆ°ä¸é”™çš„vectorã€‚</p>
<p>æ–¹æ³•ä¸Šï¼Œæœ¬æ–‡æ²¿ç”¨äº†word2vecçš„skip-gramæ¨¡å‹ï¼Œä¸»è¦åŒºåˆ«ä½“ç°åœ¨ç‰¹å¾ä¸Šã€‚word2vecä½¿ç”¨wordä½œä¸ºæœ€åŸºæœ¬çš„å•ä½ï¼Œå³é€šè¿‡ä¸­å¿ƒè¯é¢„æµ‹å…¶ä¸Šä¸‹æ–‡ä¸­çš„å…¶ä»–è¯æ±‡ã€‚è€Œsubword modelä½¿ç”¨å­—æ¯n-gramä½œä¸ºå•ä½ï¼Œæœ¬æ–‡nå–å€¼ä¸º3~6ã€‚è¿™æ ·æ¯ä¸ªè¯æ±‡å°±å¯ä»¥è¡¨ç¤ºæˆä¸€ä¸²å­—æ¯n-gramï¼Œä¸€ä¸ªè¯çš„embeddingè¡¨ç¤ºä¸ºå…¶æ‰€æœ‰n-gramçš„å’Œã€‚è¿™æ ·æˆ‘ä»¬è®­ç»ƒä¹Ÿä»ç”¨ä¸­å¿ƒè¯çš„embeddingé¢„æµ‹ç›®æ ‡è¯ï¼Œè½¬å˜æˆç”¨ä¸­å¿ƒè¯çš„n-gram embeddingé¢„æµ‹ç›®æ ‡è¯ã€‚</p>
<p>å®éªŒåˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼Œåˆ†åˆ«æ˜¯ï¼ˆ1ï¼‰è®¡ç®—ä¸¤ä¸ªè¯ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œä¸äººç±»æ ‡æ³¨çš„ç›¸ä¼¼åº¦è¿›è¡Œç›¸å…³æ€§æ¯”è¾ƒï¼›ï¼ˆ2ï¼‰ä¸word2vecä¸€æ ·çš„è¯ç±»æ¯”å®éªŒï¼›ï¼ˆ3ï¼‰ä¸å…¶ä»–è€ƒè™‘morphologyçš„æ–¹æ³•æ¯”è¾ƒã€‚ç»“æœæ˜¯æœ¬æ–‡æ–¹æ³•åœ¨è¯­è¨€å½¢æ€ä¸°å¯Œçš„è¯­è¨€ï¼ˆåœŸè€³å…¶è¯­ï¼Œæ³•è¯­ç­‰ï¼‰åŠå°æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¸é¢„æœŸä¸€è‡´ã€‚</p>
<h2 id="èµ„æº-1"><a href="#èµ„æº-1" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æºç å…¬å¸ƒåœ¨Facebookçš„fastTexté¡¹ç›®ä¸­ï¼š <a href="https://github.com/facebookresearch/fastText" target="_blank" rel="external">https://github.com/facebookresearch/fastText</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-1"><a href="#ç›¸å…³å·¥ä½œ-1" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>åˆ©ç”¨è¯­è¨€å½¢æ€å­¦æ¥æ”¹è¿›nlpçš„ç ”ç©¶æºè¿œæµé•¿ï¼Œæœ¬æ–‡æåŠçš„è®¸å¤šå…³äºcharacter-levelå’Œmorphologyçš„æœ‰è¶£å·¥ä½œå€¼å¾—å‚è€ƒã€‚</p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æ–‡ç« ä¸­æå‡ºçš„æ€è·¯å¯¹äºmorphologically rich languagesï¼ˆä¾‹å¦‚åœŸè€³å…¶è¯­ï¼Œè¯ç¼€çš„ä½¿ç”¨æä¸ºæ™®éè€Œæœ‰è¶£ï¼‰æ¥è¯´ååˆ†æœ‰æ„ä¹‰ã€‚è¯ç¼€ä½œä¸ºå­—æ¯ä¸å•è¯ä¹‹é—´çš„ä¸­å±‚å•ä½ï¼Œæœ¬èº«å…·æœ‰ä¸€å®šçš„è¯­ä¹‰ä¿¡æ¯ã€‚é€šè¿‡å……åˆ†åˆ©ç”¨è¿™ç§ä¸­å±‚è¯­ä¹‰æ¥è¡¨å¾ç½•è§è¯æ±‡ï¼Œç›´è§‚ä¸Šè®²æ€è·¯ååˆ†åˆç†ï¼Œä¹Ÿæ˜¯åº”ç”¨äº†compositionalityçš„æ€æƒ³ã€‚</p>
<p>åˆ©ç”¨å½¢æ€å­¦æ”¹è¿›word embeddingçš„å·¥ä½œååˆ†ä¸°å¯Œï¼Œä½†ä¸­æ–‡NLPä¼¼ä¹å¾ˆéš¾åˆ©ç”¨è¿™ä¸€æ€è·¯ã€‚å…¶å®ä¸ªäººæ„Ÿè§‰ä¸­æ–‡ä¸­ä¹Ÿæœ‰ç±»ä¼¼äºè¯ç¼€çš„å•ä½ï¼Œæ¯”å¦‚åæ—éƒ¨é¦–ç­‰ç­‰ï¼Œåªä¸è¿‡ä¸åƒä½¿ç”¨å­—æ¯ç³»ç»Ÿçš„è¯­è¨€é‚£æ ·å®¹æ˜“å¤„ç†ã€‚æœŸå¾…ä»Šåä¹Ÿæœ‰é—ªå…‰çš„å·¥ä½œå‡ºç°åœ¨ä¸­æ–‡ç¯å¢ƒä¸­ã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>ä»Word2Vecåˆ°FastTextï¼Œä»word representationåˆ°sentence classificationï¼ŒTomas Mikolovçš„å·¥ä½œå½±å“äº†å¾ˆå¤šäººã€‚è™½ç„¶æœ‰ä¸ªåˆ«æ¨¡å‹å’Œå®éªŒç»“æœæ›¾é­å—è´¨ç–‘ï¼Œä½†ç»ˆç©¶ç‘•ä¸æ©ç‘œã€‚word2vecå¯¹NLPçš„ç ”ç©¶èµ·åˆ°äº†æå¤§åœ°æ¨åŠ¨ä½œç”¨ï¼Œå…¶å®ä¸ä»…ä»…æ˜¯åœ¨NLPé¢†åŸŸä¸­ï¼Œåœ¨å…¶ä»–å¾ˆå¤šé¢†åŸŸä¸­éƒ½å¯ä»¥çœ‹åˆ°word2vecçš„æ€æƒ³å’Œä½œç”¨ï¼Œä¹Ÿæ­£æ˜¯ä»word2vecå¼€å§‹ï¼Œè¿™ä¸ªä¸–ç•Œå˜å¾—éƒ½è¢«vectoråŒ–äº†ï¼Œperson2vecï¼Œsentence2vecï¼Œparagraph2vecï¼Œanything2vecï¼Œworld2vecã€‚</p>
<p>ä»¥ä¸Šä¸ºæœ¬æœŸPaperweeklyçš„ä¸»è¦å†…å®¹ï¼Œæ„Ÿè°¢memrayã€zhkunã€gcyydxfã€jellå››ä½åŒå­¦çš„æ•´ç†ã€‚</p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"><br>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-10T19:38:13.000Z"><a href="/2016/09/10/cs-CL-weekly-2016-09-05-2016-09-09/">2016-09-10</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/10/cs-CL-weekly-2016-09-05-2016-09-09/">cs.CL weekly 2016.09.05-2016.09.09</a></h1>
  

    </header>
    <div class="entry">
      
        <p>æœ¬å‘¨ï¼ˆ2016.09.05-2016.09.09ï¼‰è´¨é‡è¾ƒé«˜çš„arXiv cs.CLçš„paperå¦‚ä¸‹ï¼š<br>ï¼ˆç‚¹å‡»æ ‡é¢˜å¯çœ‹åŸæ–‡ï¼‰</p>
<h1 id="Convolutional-Neural-Networks-for-Text-Categorization-Shallow-Word-level-vs-Deep-Character-level"><a href="#Convolutional-Neural-Networks-for-Text-Categorization-Shallow-Word-level-vs-Deep-Character-level" class="headerlink" title="Convolutional Neural Networks for Text Categorization: Shallow Word-level vs. Deep Character-level"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.00718v1.pdf" target="_blank" rel="external">Convolutional Neural Networks for Text Categorization: Shallow Word-level vs. Deep Character-level</a></h1><p>å¼ æ½¼è€å¸ˆçš„æ–‡ç« ï¼Œé€šè¿‡å®éªŒå¯¹æ¯”äº†shallow word-level CNNï¼ˆæœ¬æ–‡å·¥ä½œï¼‰å’Œdeep char-level CNNæ¨¡å‹åœ¨è€Œæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œç»“è®ºæ˜¯æœ¬æ–‡å·¥ä½œåˆå¿«åˆå‡†ã€‚</p>
<p>ï¼ˆè¿™ç¯‡æ–‡ç« å¯¹äºé€‰æ‹©char-levelè¿˜æ˜¯word-levelåšæ–‡æœ¬åˆ†ç±»éå¸¸æœ‰æŒ‡å¯¼æ„ä¹‰ï¼‰</p>
<h1 id="Skipping-Word-A-Character-Sequential-Representation-based-Framework-for-Question-Answering"><a href="#Skipping-Word-A-Character-Sequential-Representation-based-Framework-for-Question-Answering" class="headerlink" title="Skipping Word: A Character-Sequential Representation based Framework for Question Answering"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.00565v1.pdf" target="_blank" rel="external">Skipping Word: A Character-Sequential Representation based Framework for Question Answering</a></h1><p>æœ¬æ–‡ç”¨char-level CNNæ¨¡å‹æ¥åšå¥å­è¡¨ç¤ºï¼Œç„¶åè¿›è¡Œquestionå’Œanswerä¹‹é—´çš„ç›¸å…³åŒ¹é…å­¦ä¹ ï¼ŒCIKM2016 short paper acceptedã€‚</p>
<h1 id="End-to-End-Reinforcement-Learning-of-Dialogue-Agents-for-Information-Access"><a href="#End-to-End-Reinforcement-Learning-of-Dialogue-Agents-for-Information-Access" class="headerlink" title="End-to-End Reinforcement Learning of Dialogue Agents for Information Access"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.00777v1.pdf" target="_blank" rel="external">End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a></h1><p>æœ¬æ–‡æ˜¯å¾®è½¯ç ”ç©¶è½¯é‚“åŠ›è€å¸ˆçš„æ–‡ç« ï¼Œæ„å»ºäº†ä¸€ç§ä»çŸ¥è¯†å›¾è°±ä¸­å½¢æˆresponseçš„èŠå¤©æœºå™¨äººKB-InfoBotï¼Œå¹¶ä¸”æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„å¢å¼ºå­¦ä¹ è®­ç»ƒæ–¹æ¡ˆã€‚</p>
<p>ï¼ˆæœ¬æ–‡å¯¹äºæ„å»ºä¸€ä¸ªç«¯åˆ°ç«¯çš„KB + task-oriented chatbotéå¸¸æœ‰å¯å‘å’ŒæŒ‡å¯¼æ„ä¹‰ï¼‰</p>
<h1 id="Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks"><a href="#Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks" class="headerlink" title="Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.01462v1.pdf" target="_blank" rel="external">Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks</a></h1><p>æœ¬æ–‡æå‡ºä¸€ç§æ¨¡å‹ï¼Œå°†intent detectionã€slot fillingå’Œlanguage modelingèåˆåœ¨ä¸€èµ·è¿›è¡Œå­¦ä¹ ï¼Œç”¨äºè§£å†³å¯¹è¯ç³»ç»Ÿä¸­çš„SLU taskã€‚æœ¬æ–‡æ˜¯SIGDIAL 2016 paperã€‚</p>
<p>ç”¨åˆ°çš„æ•°æ®é›†åœ¨Dropboxæœ‰ä¸€ä»½<a href="http://t.cn/Rcbcpfl" target="_blank" rel="external">copy</a></p>
<h1 id="Attention-Based-Recurrent-Neural-Network-Models-for-Joint-Intent-Detection-and-Slot-Filling"><a href="#Attention-Based-Recurrent-Neural-Network-Models-for-Joint-Intent-Detection-and-Slot-Filling" class="headerlink" title="Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.01454v1.pdf" target="_blank" rel="external">Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling</a></h1><p>å’Œä¸Šä¸€ç¯‡paperæ˜¯åŒä¸€ä¸ªä½œè€…ï¼Œè§£å†³çš„æ˜¯åŒä¸€ä¸ªé—®é¢˜ã€‚å°†RNNæ¢æˆäº†attention-based RNNï¼Œè¢«å¦å¤–ä¸€ä¸ªä¼šè®®å½•å–ã€‚(æœ‰ç‚¹çŒæ°´çš„æ„æ€)</p>
<h1 id="Ask-the-GRU-Multi-task-Learning-for-Deep-Text-Recommendations"><a href="#Ask-the-GRU-Multi-task-Learning-for-Deep-Text-Recommendations" class="headerlink" title="Ask the GRU: Multi-task Learning for Deep Text Recommendations"></a><a href="http://120.52.73.77/arxiv.org/pdf/1609.02116v1.pdf" target="_blank" rel="external">Ask the GRU: Multi-task Learning for Deep Text Recommendations</a></h1><p>æœ¬æ–‡æå‡ºäº†ç”¨ç«¯åˆ°ç«¯çš„è§£å†³æ–¹æ¡ˆæ¥åšpaperçš„æ¨èä»»åŠ¡ï¼Œç”¨GRUå°†æ–‡æœ¬åºåˆ—ï¼ˆæ ‡é¢˜ã€æ‘˜è¦ç­‰ï¼‰encodeåˆ°ä¸€ä¸ªlatent vectorä¸­ã€‚å¹¶ä¸”é€šè¿‡å¤šä»»åŠ¡å­¦ä¹ æ¥å®Œæˆå†…å®¹æ¨èå’Œæ¡ç›®é¢„æµ‹ä¸¤ä¸ªtaskï¼Œå–å¾—äº†ä¸é”™çš„æ•ˆæœã€‚</p>
<p>ä»¥ä¸‹å†…å®¹ä¸ºarXivå¤–çš„<b>ä¼˜è´¨å†…å®¹</b>ï¼š</p>
<h1 id="Discriminative-Methods-for-Statistical-Spoken-Dialogue-Systems"><a href="#Discriminative-Methods-for-Statistical-Spoken-Dialogue-Systems" class="headerlink" title="Discriminative Methods for Statistical Spoken Dialogue Systems"></a><a href="http://www.matthen.com/research/papers/Discriminative_Methods_for_Statistical_Spoken_Dialogue_Systems_Matthew_Henderson_PhD_Thesis.pdf" target="_blank" rel="external">Discriminative Methods for Statistical Spoken Dialogue Systems</a></h1><p>å‰‘æ¡¥å¤§å­¦Spoken Dialogue Systemç»„æ¯•ä¸šçš„Matthew Hendersonåšå£«ï¼Œå¸ˆä»äºSteve Youngæ•™æˆï¼Œç ”ç©¶é¢†åŸŸæ˜¯å¯¹è¯ç³»ç»Ÿä¸­çš„Dialogue State Trackingï¼Œä¸»è¦ç‰¹è‰²æ˜¯ç”¨transfer learningæ¥è§£å†³discriminative modelçš„æ‰©å±•æ€§å’Œé€šç”¨æ€§ã€‚</p>
<p>å¦‚æœä½ å¯¹chatbotæ„Ÿå…´è¶£ï¼Œå¼ºçƒˆå»ºè®®å¥½å¥½ç ”è¯»ä¸€ä¸‹è¿™ç¯‡åšå£«è®ºæ–‡ã€‚</p>
<h1 id="CONNECTING-IMAGES-AND-NATURAL-LANGUAGE"><a href="#CONNECTING-IMAGES-AND-NATURAL-LANGUAGE" class="headerlink" title="CONNECTING IMAGES AND NATURAL LANGUAGE"></a><a href="http://cs.stanford.edu/people/karpathy/main.pdf" target="_blank" rel="external">CONNECTING IMAGES AND NATURAL LANGUAGE</a></h1><p>æ–¯å¦ç¦å¤§å­¦Feifei Liçš„åšå£«ç”ŸAndrej Karpathyçš„PhD thesisï¼ŒKarpathyç»´æŠ¤ç€å‡ ä¸ªéå¸¸æµè¡Œçš„å¼€æºä»£ç åº“ï¼Œå¹¶ä¸”æœ‰ç€ä¸€ä¸ªå½±å“åŠ›éå¸¸å¤§çš„åšå®¢ã€‚åå¸ˆå‡ºé«˜å¾’ï¼Œè¿™ç¯‡åšå£«åšå£«è®ºæ–‡å€¼å¾—ä¸€çœ‹ï¼</p>
<p>æœ€è¿‘ï¼Œä»–æ›´æ–°äº†ä¸€ç¯‡åšå®¢ï¼Œè°ˆè®ºäº†ä¸€äº›è‡ªå·±å¯¹è¯»åšçš„æ€è€ƒå’Œå»ºè®®ã€‚ <a href="http://karpathy.github.io/2016/09/07/phd/" target="_blank" rel="external">A Survival Guide to a PhD</a></p>
<h1 id="Mendeley-Docs"><a href="#Mendeley-Docs" class="headerlink" title="Mendeley Docs"></a><a href="https://pan.baidu.com/share/link?shareid=317480&amp;uk=1594817379" target="_blank" rel="external">Mendeley Docs</a></h1><p>paperè¶Šçœ‹è¶Šå¤šï¼Œä¸€ä¸ªä¼˜ç§€çš„paperç®¡ç†å·¥å…·å°±å˜å¾—éå¸¸å¿…è¦äº†ï¼ŒMendeleyæ˜¯å…¶ä¸­æœ€ä¼˜ç§€çš„ä»£è¡¨ä¹‹ä¸€ã€‚</p>
<p>Easily organize your papers, read &amp; annotate your PDFs, collaborate in private or open groups, and securely access your research from everywhere.</p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly</p>
<p><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-09T19:48:42.000Z"><a href="/2016/09/09/PaperWeeklyç¬¬å››æœŸ/">2016-09-09</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/09/PaperWeeklyç¬¬å››æœŸ/">PaperWeeklyç¬¬å››æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•"><a href="#å¼•" class="headerlink" title="å¼•"></a>å¼•</h1><p>2013å¹´ä»¥æ¥Deep mindå›¢é˜Ÿç›¸ç»§åœ¨NIPSå’ŒNaturesä¸Šå‘è¡¨äº†ç”¨æ·±åº¦å¢å¼ºï¼ˆå¼ºåŒ–ï¼‰å­¦ä¹ ç©Atariæ¸¸æˆï¼Œå¹¶å–å¾—è‰¯å¥½çš„æ•ˆæœï¼ŒéšåAlpha goä¸æä¸–ä¹­çš„ä¸€æˆ˜æ›´ä½¿å¾—æ·±åº¦å¢å¼ºå­¦ä¹ å®¶å–»æˆ·æ™“ã€‚åœ¨æ¸¸æˆä¸Šå–å¾—äº†ä¸é”™çš„æˆæœåï¼Œæ·±åº¦å¢å¼ºå­¦ä¹ ä¹Ÿé€æ¸è¢«å¼•å…¥NLPé¢†åŸŸã€‚æœ¬æœŸä»‹ç»ç›®å‰NLPé¢†åŸŸè¾ƒä¸ºçƒ­ç‚¹çš„ç ”ç©¶æ–¹å‘ï¼ŒåŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–‡æœ¬ç”ŸæˆæŠ€æœ¯ï¼ˆNLGï¼‰ï¼Œå…±é€‰æ‹©äº†ä¸‰ç¯‡æ–‡ç« ï¼Œåˆ†åˆ«ä¸ºï¼š</p>
<p>(1)ã€ŠGenerating Text with Deep Reinforcement Learningã€‹<br>åº”ç”¨Deep Q-Networkä½œä¸ºç”Ÿæˆæ¨¡å‹ç”¨äºæ”¹å–„seq2seqæ¨¡å‹</p>
<p>(2)    ã€ŠDeep Reinforcement Learning for Dialogue Generationã€‹<br>åº”ç”¨å¼ºåŒ–å­¦ä¹ è¿›è¡Œå¼€æ”¾é¢†åŸŸçš„æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼Œå¹¶å¯¹æ¯”äº†æœ‰ç›‘ç£çš„seq2seqåŠ attentionæ¨¡å‹å’ŒåŸºäºæœ€å¤§äº’ä¿¡æ¯çš„æ¨¡å‹</p>
<p>(3)ã€ŠHierarchical Reinforcement Learning for Adaptive Text Generation_lshowwayã€‹<br>ä»¥ä»»åŠ¡ä¸ºå¯¼å‘çš„æˆ·å†…å¯¼èˆªå¯¹è¯ç³»ç»Ÿç”¨åˆ†å±‚å¼ºåŒ–å­¦ä¹ è¿›è¡Œæ–‡æœ¬ç”Ÿæˆ</p>
<p>ä»¥ä¸‹ä¸ºä¸‰ç¯‡æ–‡ç« çš„ä¸»è¦ä¿¡æ¯ï¼š</p>
<h1 id="Generating-Text-with-Deep-Reinforcement-Learning"><a href="#Generating-Text-with-Deep-Reinforcement-Learning" class="headerlink" title="Generating Text with Deep Reinforcement Learning"></a><a href="http://120.52.73.76/arxiv.org/pdf/1510.09202v1.pdf" target="_blank" rel="external">Generating Text with Deep Reinforcement Learning</a></h1><h2 id="ä½œè€…"><a href="#ä½œè€…" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Hongyu Guo</p>
<h2 id="å•ä½"><a href="#å•ä½" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>National Research Council Canada</p>
<h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Reinforcement Learningã€Seq2Seqã€Text Generation</p>
<h2 id="æ¥æº"><a href="#æ¥æº" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>NIPS2015 Workshop (2015.10.30)</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æœ¬æ–‡æå‡ºå°†Deep Q-Networkä½œä¸ºç”Ÿæˆæ¨¡å‹ç”¨äºæ”¹å–„seq2seqæ¨¡å‹ï¼Œå°†decodingä¿®æ”¹ä¸ºè¿­ä»£å¼çš„è¿‡ç¨‹ï¼Œå®éªŒè¡¨æ˜æœ¬æ¨¡å‹å…·æœ‰æ›´å¥½çš„æ³›åŒ–æ€§ã€‚</p>
<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>å¯¹seq2seqæ¨¡å‹æ”¹è¿›çš„è®ºæ–‡å±‚å‡ºä¸ç©·ï¼Œæœ¬æ–‡ç‡å…ˆå¼•å…¥æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„æ€æƒ³ï¼Œå°†DQNç”¨äºæ–‡æœ¬ç”Ÿæˆã€‚å¯¹DQNè¿˜ä¸äº†è§£çš„åŒå­¦å¯ä»¥å…ˆé˜…è¯»DeepMindçš„è®ºæ–‡Playing Atari with Deep Reinforcement Learningã€‚æœ¬æ–‡çš„æ¨¡å‹å¦‚ä¸‹ï¼š</p>
<p><img src="media/14734508069657.jpg" alt=""></p>
<p>å¦‚åŒä¸€èˆ¬çš„ç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æŠŠDQNå½“åšä¸€ä¸ªé»‘ç›’æ¥ä½¿ç”¨ã€‚åªéœ€è¦å‡†å¤‡å¥½DQNéœ€è¦çš„å››ä¸ªå…ƒç´ s(i),a(i),r(i),s(i+1)ï¼Œåˆ†åˆ«ä»£è¡¨iæ—¶åˆ»ä¸‹state,action,rewordå’Œi+1æ—¶åˆ»çš„stateã€‚</p>
<p>å¯¹ç…§ä¸Šå›¾æˆ‘ä»¬æŠŠç®—æ³•è§£å‰–åˆ†ä¸º4ä¸ªæ­¥éª¤ï¼š</p>
<p>Step 1: å…ˆæ˜¯ä¼ ç»Ÿçš„seq2seqæ¨¡å‹ã€‚é€šè¿‡LSTMå…ˆæŠŠè¾“å…¥åºåˆ—encodeä¸ºä¸€ä¸ªå®šé•¿å‘é‡EnSen(i)ï¼Œç„¶åä½œä¸ºdecodeé˜¶æ®µçš„åˆå§‹çŠ¶æ€ä¾æ¬¡ç”Ÿæˆæ–°çš„åºåˆ—DeSen(i)ï¼ˆdecoding searchä½¿ç”¨beam searchç®—æ³•æ¥ expand next wordsï¼‰ã€‚ç»è¿‡ç¬¬ä¸€æ­¥æˆ‘ä»¬å¾—åˆ°åˆå§‹stateï¼š(EnSen(i), DeSen(i))å’Œactioné›†åˆï¼šæ¯ä¸ªä½ç½®çš„hypothesesã€‚</p>
<p>Step 2: æ¥ä¸‹æ¥ä»hypothesesï¼ˆactionsï¼‰ä¸­é€‰æ‹©ä¸€ä¸ªå¯ä»¥è·å¾—æœ€å¤§rewardçš„å•è¯ï¼ˆactionï¼‰ä½œä¸ºè¯¥ä½ç½®æ–°ç”Ÿæˆçš„è¯ï¼Œç”¨æ–°å•è¯æ¥ä»£æ›¿ä¹‹å‰çš„æ—§è¯ï¼Œäºæ˜¯ç”Ÿæˆæ–°çš„stateï¼š(EnSen(i), DeSen(i+1))ã€‚</p>
<p>Step 3: æ¥ç€å°±æ˜¯æ ‡å‡†çš„DQNçš„éƒ¨åˆ†ï¼Œè®¡ç®—Losså‡½æ•°å¹¶å¯¹å…¶åº”ç”¨æ¢¯åº¦ä¸‹é™ã€‚</p>
<p>Step 4: å›åˆ°Step 2ï¼Œå¯¹å¾—åˆ°çš„stateç»§ç»­è¿­ä»£ï¼Œæ¯ä¸€æ¬¡è¿­ä»£éƒ½åªç”Ÿæˆä¸€ä¸ªæ–°è¯æ¥ä»£æ›¿æ—§è¯ï¼Œç›´åˆ°è¿­ä»£æ¬¡æ•°è¾¾åˆ°è®¾å¥½çš„å€¼ï¼ˆä½œè€…å°†æ¬¡æ•°å®šä¸ºå¥å­é•¿åº¦çš„ä¸¤å€ï¼ŒåŒå­¦ä»¬å¯ä»¥æ€è€ƒä¸€ä¸‹ç†ç”±ï¼‰ã€‚</p>
<p>æ€»ç»“DQNæ‰€éœ€çš„å››ä¸ªå…ƒç´ å¯¹åº”å¦‚ä¸‹ï¼š<br>(1) iæ—¶åˆ»ä¸‹çš„stateï¼š(EnSen(i), DeSen(i))ï¼›<br>(2) iæ—¶åˆ»ä¸‹çš„actionï¼šbeam searchå¾—åˆ°çš„æ¯ä¸ªä½ç½®çš„hypothesesï¼›<br>(3) iæ—¶åˆ»ä¸‹çš„rewordï¼štarget sentenceå’ŒDeSen(i+1)çš„ç›¸ä¼¼åº¦ï¼ˆBLEU scoreï¼‰ï¼›<br>(4) i+1æ—¶åˆ»ä¸‹çš„stateï¼š(EnSen(i), DeSen(i+1))ï¼›</p>
<p>ä¸ºäº†æ›´å¥½çš„æå–å¥å­çš„ç‰¹å¾ï¼Œä½œè€…åœ¨decodeé˜¶æ®µä½¿ç”¨äº†åŒå‘LSTMã€‚åŒæ—¶è¿˜åœ¨reinforcement learningä¸­åŠ å…¥attentionæœºåˆ¶ï¼Œå¯ä»¥è¾¾åˆ°å…ˆdecodeæ¯”è¾ƒç®€å•çš„éƒ¨åˆ†å†å¤„ç†å›°éš¾éƒ¨åˆ†çš„æ•ˆæœã€‚æœ€ååœ¨ç”Ÿæˆç›¸ä¼¼å¥å­çš„å®éªŒä¸­å¾—åˆ°äº†æ¯”åªç”¨LSTM decoderæ•ˆæœæ›´å¥½çš„ç»“è®ºï¼š</p>
<p><img src="media/14734509263452.jpg" alt=""></p>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p><img src="media/14734510298695.jpg" alt=""></p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡çš„æ€æƒ³å…¶å®éå¸¸ç¬¦åˆå†™ä½œçš„ä¸€ç§æƒ…å†µï¼Œå°±åƒè´¾å²›æ¨æ•²çš„æ•…äº‹ï¼Œå›æƒ³å°æ—¶å€™åˆšå­¦ä¹ å†™å¥å­æ—¶ï¼Œä¹Ÿä¸èƒ½ä¸€æ¬¡å†™å¥½ï¼Œæ€»ä¼šä¸æ–­å¯¹ä¸€äº›è¯è¯­è¿›è¡Œä¿®æ”¹ã€‚Google DeepMindçš„æ–‡ç« ã€ŠDRAWï¼šA Recurrent Neural Network For Imageã€‹ä¹Ÿå’Œæœ¬æ–‡å¼‚æ›²åŒå·¥ï¼šç”»ç”»ä¹Ÿä¸æ˜¯ä¸€æ¬¡ç”»å¥½ï¼Œä¹Ÿè¦ä¸æ–­çš„å®Œå–„ã€‚ä¸åŒä¹‹å¤„åœ¨äºæœ¬æ–‡ç‡å…ˆå¼•å…¥DQNåšæ–‡æœ¬ç”Ÿæˆã€‚åœ¨æœºå™¨å­¦ä¹ å„ä¸ªåˆ†æ”¯ä¸‹ï¼Œå¼ºåŒ–å­¦ä¹ å’Œäººç±»ä¸ç¯å¢ƒçš„äº¤äº’æ–¹å¼éå¸¸ç›¸ä¼¼ï¼Œåœ¨è®¸å¤šé¢†åŸŸå¼€å§‹åˆéœ²å¤´è§’ï¼ŒæœŸå¾…çœ‹åˆ°æ›´å¤šå°†å¼ºåŒ–å­¦ä¹ ç»“åˆè¯­è¨€æ¨¡å‹çš„åº”ç”¨ã€‚</p>
<h1 id="Deep-Reinforcement-Learning-for-Dialogue-Generation"><a href="#Deep-Reinforcement-Learning-for-Dialogue-Generation" class="headerlink" title="Deep Reinforcement Learning for Dialogue Generation"></a><a href="http://120.52.73.76/arxiv.org/pdf/1606.01541v3.pdf" target="_blank" rel="external">Deep Reinforcement Learning for Dialogue Generation</a></h1><h2 id="ä½œè€…-1"><a href="#ä½œè€…-1" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Jiwei Li, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, Dan Jurafsky</p>
<h2 id="å•ä½-1"><a href="#å•ä½-1" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>(1) Stanford University, Stanford, CA, USA<br>(2) Microsoft Research, Redmond, WA, USA<br>(3) Ohio State University, OH, USA</p>
<h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Reinforcement Learningã€Seq2Seqã€Text Generation</p>
<h2 id="æ¥æº-1"><a href="#æ¥æº-1" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>arXiv.org(2016.06.25)</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æœ¬æ–‡æå‡ºåˆ©ç”¨å¼ºåŒ–å­¦ä¹ è¿›è¡Œå¼€æ”¾é¢†åŸŸçš„æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼Œå¹¶å¯¹æ¯”äº†æœ‰ç›‘ç£çš„seq2seqåŠ attentionæ¨¡å‹å’ŒåŸºäºæœ€å¤§äº’ä¿¡æ¯çš„æ¨¡å‹</p>
<h2 id="æ¨¡å‹-1"><a href="#æ¨¡å‹-1" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>å¼ºåŒ–å­¦ä¹ ä¸­çš„reward</p>
<p><img src="media/14734512073402.jpg" alt=""></p>
<p>æ˜“è¢«å“åº”ï¼ˆEase of answeringï¼‰ï¼Œä¸å®¹æ˜“å‡ºç°å¯¹è¯åƒµå±€ï¼Œå…¶ä¸­ S æ˜¯æ— æ„ä¹‰å›ç­”åˆé›†ï¼Œsæ˜¯æŸä¸€æ—¶åˆ»çš„å“åº”</p>
<p><img src="media/14734512278456.jpg" alt=""></p>
<p>ä¿¡æ¯æµï¼Œè‹¥å¼€è¾Ÿæ–°çš„è¯é¢˜ï¼Œæœ‰åˆ©äºå¯¹è¯çš„ç»§ç»­å‘å±•ï¼Œéšå±‚è¡¨ç¤º hpi å’Œ hpi+1 çš„å¤¹è§’ä½™å¼¦</p>
<p><img src="media/14734512443645.jpg" alt=""></p>
<p>è¯­ä¹‰è¿è´¯æ€§ï¼Œå‡å°‘ä¸å¯¹è¯æ— å…³é—®é¢˜çš„å½±å“ï¼Œå…¶ä¸­ï¼Œpseq2seq(a|pi,qi) æ˜¯ç”±ä¸Šä¸€è½®çŠ¶æ€å¾—åˆ°å“åº”çš„æ¦‚ç‡ï¼Œåä¸€é¡¹æ˜¯ç”±å½“å‰äº§ç”Ÿå“åº”é€šè¿‡ç½‘ç»œç”Ÿæˆä¹‹å‰çš„ qi çš„æ¦‚ç‡ã€‚</p>
<p><img src="media/14734512828474.jpg" alt=""></p>
<p>æœ€ç»ˆçš„rewardæ˜¯å¯¹ä¸‰è€…åŠ æƒæ±‚å’Œï¼Œç³»æ•°åˆ†åˆ«ä¸ºï¼š0.25ã€0.25ã€0.5.</p>
<p>å¯¹æ¯”è¯•éªŒï¼š<br>(1) å¯¹è¯åˆå§‹çŠ¶æ€ä¸ºä¸€ä¸ªSEQ2SEQåŠ attentionçš„æ¨¡å‹ä½œä¸ºå¼ºåŒ–å­¦ä¹ çš„åˆå§‹çŠ¶æ€ã€‚</p>
<p>(2) åœ¨å‰é¢çš„åŸºç¡€ä¸Šå°†æœ€å¤§äº’ä¿¡æ¯åŠ å…¥å…¶ä¸­ä½œä¸ºrewardï¼Œå¯¹äºä¸€ä¸ªç»™å®šçš„è¾“å…¥[pi,qi]ï¼Œå¯ä»¥æ ¹æ®æ¨¡å‹ç”Ÿæˆä¸€ä¸ªå€™é€‰å›ç­”é›†åˆAã€‚å¯¹äºAä¸­çš„æ¯ä¸€ä¸ªå›ç­”a,ä»é¢„è®­ç»ƒæ¨¡å‹ä¸­å¾—åˆ°çš„æ¦‚ç‡åˆ†å¸ƒä¸Šå¯ä»¥è®¡ç®—å‡ºäº’ä¿¡æ¯çš„å€¼ m(a,[pi,qi])ã€‚</p>
<p>(3) å°†äº’ä¿¡æ¯è®­ç»ƒè¿‡çš„æ¨¡å‹ä½œä¸ºåˆå§‹æ¨¡å‹ï¼Œç”¨ç­–ç•¥æ¢¯åº¦æ›´æ–°å‚æ•°å¹¶åŠ å…¥è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œæœ€ç»ˆæœ€å¤šé™å®šäº”è½®å¯¹è¯ã€‚</p>
<p><img src="media/14734513584870.jpg" alt=""></p>
<h2 id="ç›¸å…³å·¥ä½œ-1"><a href="#ç›¸å…³å·¥ä½œ-1" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p><img src="media/14734513827800.jpg" alt=""></p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡ä½œè€…æå‡ºäº†ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ¨¡æ‹Ÿä¸¤ä¸ªagentè®©å…¶è‡ªåŠ¨å¯¹è¯è®­ç»ƒç¥ç»ç½‘ç»œSEQ2SEQæ¨¡å‹ï¼Œå°†Encoder-Decoderæ¨¡å‹å’Œå¼ºåŒ–å­¦ä¹ æ•´åˆï¼Œä»è€Œèƒ½ä¿è¯ä½¿å¯¹è¯è½®æ•°å¢åŠ ã€‚æ–‡ä¸­ä½¿ç”¨çš„æ¨¡å‹éå¸¸ç®€æ´ï¼Œrewardå‡½æ•°å®šä¹‰æ¸…æ™°ï¼Œè¯„ä»·æŒ‡æ ‡ä¹Ÿè¾ƒä¸ºç§‘å­¦ï¼Œå¯ä»¥ç”Ÿæˆä¿¡æ¯æ›´ä¸ºä¸°å¯Œã€æ˜“äºå“åº”çš„å¯¹è¯ç³»ç»Ÿã€‚</p>
<h1 id="Hierarchical-Reinforcement-Learning-for-Adaptive-Text-Generation"><a href="#Hierarchical-Reinforcement-Learning-for-Adaptive-Text-Generation" class="headerlink" title="Hierarchical Reinforcement Learning for Adaptive Text Generation"></a><a href="http://www.aclweb.org/anthology/W10-4204" target="_blank" rel="external">Hierarchical Reinforcement Learning for Adaptive Text Generation</a></h1><h2 id="ä½œè€…-2"><a href="#ä½œè€…-2" class="headerlink" title="ä½œè€…"></a>ä½œè€…</h2><p>Nina Dethlefs, Heriberto CuayÂ´ahuitl</p>
<h2 id="å•ä½-2"><a href="#å•ä½-2" class="headerlink" title="å•ä½"></a>å•ä½</h2><p>University of Bremen, Germany</p>
<h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>NLG, åˆ†å±‚å¼ºåŒ–å­¦ä¹ , æ–‡æœ¬ç”Ÿæˆ, wayfinding</p>
<h2 id="æ¥æº-2"><a href="#æ¥æº-2" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>å›½é™…è‡ªç„¶è¯­è¨€ç”Ÿæˆä¼šè®®INLG(2010)</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>åœ¨wayfindingï¼ˆæˆ·å†…å¯¼èˆªå¯¹è¯ç³»ç»Ÿï¼‰é¢†åŸŸåˆ©ç”¨åˆ†å±‚å¼ºåŒ–å­¦ä¹ è¿›è¡Œæ–‡æœ¬ç”Ÿæˆã€‚è¯¥æ–¹æ³•çš„ç›®æ ‡æ˜¯å¯¹wayfindingçš„NLGä»»åŠ¡æ•´åˆè¿›è¡Œä¼˜åŒ–ï¼Œå¹¶åœ¨æ¨¡æ‹Ÿç³»ç»Ÿä¸­éªŒè¯è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
<h2 id="æ¨¡å‹-2"><a href="#æ¨¡å‹-2" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>æœ¬æ–‡ä»»åŠ¡åœ¨wayfindingä¸­çš„NLGä»»åŠ¡æœ‰å¤šä¸ªï¼Œä¸”å„ä¸ªä»»åŠ¡ä¹‹é—´å¹¶éç‹¬ç«‹ã€‚ä»è€Œæå‡ºåº”è¯¥æ ¹æ®ç”¨æˆ·ç±»å‹ï¼Œå¯¼èˆªè·ç¦»ï¼Œ ç¯å¢ƒæ¡ä»¶ç­‰ä½œå‡ºä¸åŒçš„å¯¼èˆªç­–ç•¥ï¼Œä»‹ç»äº†åˆ†å±‚å¼ºåŒ–å­¦ä¹ ã€‚</p>
<p>æ–‡ç« å°†æˆ·å†…å¯¼èˆªå¯¹è¯ç³»ç»Ÿçš„æ–‡æœ¬ç”Ÿæˆé—®é¢˜åˆ†ä¸ºå››å—ï¼š</p>
<p>(1) Content Selectionï¼šç»™ä¸ç†Ÿæ‚‰ç¯å¢ƒçš„ç”¨æˆ·çš„å¯¼èˆªè¦æ¯”ç†Ÿæ‚‰ç¯å¢ƒçš„ç”¨æˆ·çš„å¯¼èˆªæ›´ç»†è‡´<br>(2) Text Structureï¼šæ ¹æ®å¯¼èˆªè·ç¦»ä»¥åŠç”¨æˆ·ç†Ÿæ‚‰ç¯å¢ƒç¨‹åº¦ç»™äºˆä¸åŒç±»å‹çš„å¯¼èˆªï¼Œå¦‚å¤§ç™½è¯çš„ï¼Œä»¥fisrtï¼Œ secondâ€¦è¡¨è¾¾æˆ–è€…ç¤ºæ„æ€§çš„ã€‚<br>(3) Referring Expression Generationï¼šä¸€é—´æˆ¿é—´å¯ä»¥å«â€œA203â€ï¼Œä¹Ÿå¯ä»¥å«â€œåŠå…¬å®¤â€æˆ–è€…â€œå°ç™½æ¥¼â€<br>(4) Surface Realisationï¼šå¾€å‰èµ°å¯ä»¥ç”¨â€œgoâ€ä¹Ÿå¯ä»¥ç”¨â€œwalkâ€ç­‰ã€‚</p>
<p>å¼ºåŒ–å­¦ä¹ ç¤ºæ„å›¾å¦‚ä¸‹ï¼Œåˆ†å±‚å¼ºåŒ–å­¦ä¹ çš„æ€æƒ³ä¸å¼ºåŒ–å­¦ä¹ ç±»ä¼¼ï¼Œä½†åœ¨å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€ä¸ŠåŠ ä¸Šå±‚æ¬¡ï¼Œä¸åŒå±‚æ¬¡çš„æ¨¡å‹å¤„ç†ä¸åŒå±‚æ¬¡çš„é—®é¢˜ã€‚<br><img src="media/14734516131737.jpg" alt=""></p>
<p>agentæ ¹æ®å½“å‰çŠ¶æ€ï¼Œæ‰§è¡ŒåŠ¨ä½œaä¸ç¯å¢ƒäº¤äº’ï¼Œä¹‹åç¯å¢ƒäº§ç”Ÿä¸€ä¸ªæ–°çš„çŠ¶æ€så¹¶è¿”å›ç»™agentä¸€ä¸ªå¥–èµrï¼ˆå¯æ­£å¯è´Ÿï¼‰ï¼Œå¼ºåŒ–å­¦ä¹ çš„ç›®æ ‡å‡½æ•°ä¾¿æ˜¯ä½¿agentè·å¾—å¥–èµræœ€å¤§ã€‚</p>
<p>åˆ†å±‚å¢å¼ºå­¦ä¹ åŒ…å«Lä¸ªå±‚ï¼Œæ¯å±‚Nä¸ªæ¨¡å‹ï¼Œå¦‚Figure 1æ˜¯æœ‰15ä¸ªagentsçš„hierarchyï¼Œå…¶ä¸­ä¸åŒçš„agentè´Ÿè´£ä¸åŒçš„å±‚æ¬¡ã€‚</p>
<p><img src="media/14734516802648.jpg" alt=""></p>
<p>æ¯ä¸ªagentå®šä¹‰ä¸ºåŠé©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹ï¼Œå¯ä»¥è¡¨ç¤ºæˆä¸€ä¸ªå››å…ƒç»„</p>
<p><img src="media/14734517382304.jpg" alt=""></p>
<p>åˆ†åˆ«ä¸ºçŠ¶æ€é›†ï¼ŒåŠ¨ä½œé›†ï¼Œè½¬æ¢å‡½æ•°ï¼Œå¥–åŠ±å‡½æ•°ã€‚</p>
<p>å¥–åŠ±å‡½æ•°è¡¨ç¤ºagentåœ¨æ—¶é—´tçŠ¶æ€sæ˜¯æ‰§è¡ŒåŠ¨ä½œaè½¬æ¢åˆ°æ–°çš„çŠ¶æ€sâ€™æ‰€è·å¾—çš„å¥–åŠ±ã€‚åŠé©¬å°”ç§‘å¤«çš„ç›®æ ‡æ˜¯æ‰¾åˆ°policy Ï€*ï¼Œ</p>
<p><img src="media/14734524023811.jpg" alt=""></p>
<p>ä½¿å¾—åœ¨ä»å½“å‰çŠ¶æ€è½¬æ¢åˆ°æ–°çš„çŠ¶æ€è·å¾—çš„ç´¯è®¡å¥–åŠ±æœ€å¤šã€‚</p>
<p>æœ¬æ–‡ä½¿ç”¨ä¸¤ç§å¥–åŠ±å‡½æ•°ï¼Œä¸€ç§ç€é‡åœ¨ interaction lengthï¼Œ å¦ä¸€ç§ç€é‡åœ¨alignment and variationä¹‹é—´çš„å¹³è¡¡ï¼ˆå…·ä½“å…¬å¼å¯è§è®ºæ–‡ï¼‰ã€‚</p>
<p>æœ¬æ–‡æ˜¯åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è¿›è¡Œè¯•éªŒï¼Œå…¶ä¸­æ¨¡æ‹Ÿç¯å¢ƒåŒ…æ‹¬user typeï¼ˆç†Ÿæ‚‰ç¯å¢ƒï¼Œä¸ç†Ÿæ‚‰ç¯å¢ƒï¼‰ï¼Œ information needï¼ˆé«˜ï¼Œä½ï¼‰ï¼Œlength of the current routeï¼ˆçŸ­ï¼Œä¸­é•¿ï¼Œé•¿ï¼‰ï¼Œnext action to performï¼ˆè½¬ï¼Œç›´èµ°ï¼‰ï¼Œcurrent focus of attentionï¼ˆç»§ç»­èµ°ï¼Œå…³æ³¨æ ‡è¯†ï¼‰ã€‚baselineä¸ºä¸ºéƒ¨åˆ†agentéšæœºé€‰æ‹©actionï¼Œå³ä¸è€ƒè™‘ç”¨æˆ·ç±»å‹ï¼Œå¯¼èˆªè·ç¦»ç­‰å› ç´ ã€‚ç»ä¸baselineæ¯”è¾ƒï¼Œæ•ˆæœè¾ƒå¥½ã€‚</p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>è¯æ€§æ ‡æ³¨å·¥å…·ï¼š<a href="http://nlp.stanford.edu/software/tagger.shtml" target="_blank" rel="external">http://nlp.stanford.edu/software/tagger.shtml</a></p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>å°†æ¥çš„å·¥ä½œï¼šå°†åˆ†å±‚å¼ºåŒ–å­¦ä¹ åº”ç”¨äºå…¶ä»–NLGä»»åŠ¡<br>ä¸è¶³ä¹‹å¤„ï¼šå®éªŒæ˜¯åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸‹è¿›è¡Œçš„ï¼Œæœªæ¥åº”è¯¥åœ¨çœŸå®ç¯å¢ƒè¿›è¡Œè¯„ä¼°ã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>è¿™ä¸‰ç¯‡æ–‡ç« çš†æ˜¯å¼ºåŒ–å­¦ä¹ åœ¨NLPé¢†åŸŸçš„åº”ç”¨ï¼Œç¬¬ä¸€ç¯‡ä¸»è¦ä¾§é‡ç‚¹åœ¨äºåº”ç”¨DQNè¿›è¡Œæ–‡æœ¬ç”Ÿæˆï¼Œå¹¶ç”¨BLUEæŒ‡æ ‡è¿›è¡Œè¯„ä»·ï¼Œå¯¹æ¯”ä¼ ç»Ÿçš„LSTM-decoderå’ŒåŠ å…¥DQNä¹‹åçš„ç»“æœï¼›ç¬¬äºŒç¯‡æ–‡ç« ä¾§é‡ç‚¹åœ¨äºè™šæ‹Ÿä¸¤ä¸ªAgentï¼Œåœ¨ä¼ ç»ŸSeq2Seqçš„åŸºç¡€ä¸ŠåŠ å…¥å¼ºåŒ–å­¦ä¹ ä»è€Œä½¿å¾—èŠå¤©èƒ½å¤ŸæŒç»­ä¸‹å»ï¼›ç¬¬ä¸‰ç¯‡æ–‡ç« ä¾§é‡ç‚¹åœ¨äºä»»åŠ¡é©±åŠ¨çš„å¯¹è¯ç³»ç»Ÿåº”ç”¨åˆ†å±‚å¼ºåŒ–å­¦ä¹ ï¼Œé’ˆå¯¹ä¸åŒæƒ…å†µè¿›è¡Œåˆ†å±‚å¤„ç†ã€‚</p>
<p>ä»¥ä¸Šä¸ºæœ¬æœŸPaperweeklyçš„ä¸»è¦å†…å®¹ï¼Œæ„Ÿè°¢lshowwayã€ç¾å¥½æ—¶å…‰æµ·è‹”ã€Tonyaä¸‰ä½åŒå­¦çš„æ•´ç†ã€‚</p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-03T17:02:40.000Z"><a href="/2016/09/03/cs-CL-weekly-2016-08-29-2016-09-02/">2016-09-03</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/03/cs-CL-weekly-2016-08-29-2016-09-02/">cs.CL weekly 2016.08.29-2016.09.02</a></h1>
  

    </header>
    <div class="entry">
      
        <p>æœ¬å‘¨ï¼ˆ2016.08.29-2016.09.02ï¼‰è´¨é‡è¾ƒé«˜çš„arXiv cs.CLçš„paperå¦‚ä¸‹ï¼š<br>ï¼ˆç‚¹å‡»æ ‡é¢˜å¯çœ‹åŸæ–‡ï¼‰</p>
<h1 id="Abstractive-Text-Summarization-Using-Sequence-to-Sequence-RNNs-and-Beyond"><a href="#Abstractive-Text-Summarization-Using-Sequence-to-Sequence-RNNs-and-Beyond" class="headerlink" title="Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond"></a><a href="http://120.52.73.75/arxiv.org/pdf/1602.06023v5.pdf" target="_blank" rel="external">Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond</a></h1><p>ä¸€ç¯‡è€æ–‡çš„updateï¼Œseq2seq+attentionçš„æœºåˆ¶æ¥è§£å†³abstractive text summarizationï¼Œé’ˆå¯¹æ–‡æœ¬æ‘˜è¦çš„å…³é”®é—®é¢˜åœ¨åŸºç¡€æ¨¡å‹ä¸­å¢åŠ äº†å¯¹å…³é”®è¯ã€è¯å¥å±‚æ¬¡æ€§å’Œä½é¢‘è¯çš„å¤„ç†ã€‚</p>
<h1 id="Machine-Comprehension-Using-Match-LSTM-and-Answer-Pointer"><a href="#Machine-Comprehension-Using-Match-LSTM-and-Answer-Pointer" class="headerlink" title="Machine Comprehension Using Match-LSTM and Answer Pointer"></a><a href="http://120.52.73.76/arxiv.org/pdf/1608.07905v1.pdf" target="_blank" rel="external">Machine Comprehension Using Match-LSTM and Answer Pointer</a></h1><p>æœ¬æ–‡åŸºäºMatch-LSTMå’ŒAnswer Pointerä¸¤ä¸ªæ¨¡å‹åœ¨Stanford Question Answering Dataset (SQuAD)ä¸Šå¾—åˆ°äº†state-of-the-artçš„ç»“æœã€‚ </p>
<h1 id="Measuring-Machine-Intelligence-Through-Visual-Question-Answering"><a href="#Measuring-Machine-Intelligence-Through-Visual-Question-Answering" class="headerlink" title="Measuring Machine Intelligence Through Visual Question Answering"></a><a href="http://120.52.73.75/arxiv.org/pdf/1608.08716v1.pdf" target="_blank" rel="external">Measuring Machine Intelligence Through Visual Question Answering</a></h1><p>æœ¬æ–‡æŒ‡å‡ºäº†image captionä½œä¸ºè¯„æµ‹AIæ•ˆæœçš„ä»»åŠ¡å­˜åœ¨çš„ç¼ºé™·ï¼ŒåŒæ—¶æå‡ºç”¨visual QAä½œä¸ºè¯„æµ‹ä»»åŠ¡æ›´åŠ æœ‰æ•ˆï¼Œå¹¶ä¸”ç»™å‡ºäº†ä¸€ä¸ªå¤§å‹Visual QAçš„æ•°æ®é›†ã€‚æ•°æ®é›†åœ°å€ï¼šwww.visualqa.org.</p>
<h1 id="How-Much-is-131-Million-Dollars-Putting-Numbers-in-Perspective-with-Compositional-Descriptions"><a href="#How-Much-is-131-Million-Dollars-Putting-Numbers-in-Perspective-with-Compositional-Descriptions" class="headerlink" title="How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.00070v1.pdf" target="_blank" rel="external">How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions</a></h1><p>æ–‡ç« æå‡ºäº†ä¸€ä¸ªå¥½ç©çš„ä»»åŠ¡ï¼Œä»¥ä¸€ä¸ªç»Ÿè®¡æ•°å­—ä½œä¸ºä¸Šä¸‹æ–‡æ¥ç”Ÿæˆä¸€æ®µç®€çŸ­çš„æè¿°ï¼Œæè¿°çš„å†…å®¹æ˜¯ä¸€ç§å¸¦æœ‰è¿™ä¸ªæ•°å­—çš„è§‚ç‚¹ã€‚æ•´ä¸ªè¿‡ç¨‹åˆ†ä¸ºä¸¤æ­¥ï¼šå…¬å¼çš„æ„å»ºå’Œè§‚ç‚¹çš„ç”Ÿæˆã€‚</p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-1-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -1-"></p>
<p>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰ï¼Œæ¯å¤©ä¼šå‘å¸ƒarXiv cs.CLé«˜è´¨é‡paperå’Œç®€è¯„ã€‚<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-01T21:58:14.000Z"><a href="/2016/09/01/PaperWeekly-ç¬¬ä¸‰æœŸ/">2016-09-01</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/01/PaperWeekly-ç¬¬ä¸‰æœŸ/">PaperWeekly ç¬¬ä¸‰æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•"><a href="#å¼•" class="headerlink" title="å¼•"></a>å¼•</h1><p>å†ç»åŠä¸ªæœˆæ—¶é—´ç»ˆäºå‘å¸ƒäº†æ–°ä¸€æœŸPaperWeeklyï¼Œå¤§å®¶ä¹…ç­‰äº†ã€‚åœ¨è¿™ä¸ªåŠä¸ªæœˆé‡Œï¼ŒPaperWeeklyå‘ç”Ÿäº†ä¸€äº›æ˜æ˜¾çš„å˜åŒ–ã€‚ç»´æŠ¤å’Œè¿è¥ä»æˆ‘ä¸€ä¸ªäººå˜æˆäº†ä¸€ä¸ªåäººå·¦å³çš„å›¢é˜Ÿæ¥ä¸€èµ·åšï¼Œå°ä¼™ä¼´ä»¬æ¥è‡ªå…¨çƒå„åœ°ï¼Œé¢ å€’ç€é»‘å¤œå’Œç™½å¤©è¿›è¡Œæ²Ÿé€šã€‚å›¢é˜Ÿä¸­çš„æ¯ä¸ªäººéƒ½æœ‰ä¸€é¢—çƒ­çˆ±çŸ¥è¯†å’Œåˆ†äº«çŸ¥è¯†çš„å¿ƒï¼Œéƒ½è®¤ä¸ºåˆ†äº«æ˜¯ä¸€ç§ç¾å¾·ï¼Œæ˜¯ä¸€ç§ä»˜å‡ºï¼Œæ›´æ˜¯ä¸€ç§å›æŠ¥ã€‚å¯èƒ½æˆ‘ä»¬ä¸å®Œç¾ï¼Œä½†æˆ‘ä»¬ç›¸ä¿¡æˆ‘ä»¬æ­£åœ¨è¿½æ±‚å®Œç¾çš„è·¯ä¸Šåšå®šåœ°èµ°ç€ã€‚</p>
<p>æœ‰äº†æ›´å¤šçš„åŒå­¦åŠ å…¥ï¼ŒPaperWeeklyä¼šæ›´åŠ å¤šå…ƒåŒ–ï¼Œä¸å†å—é™äºæˆ‘ä¸ªäººæ„Ÿå…´è¶£çš„æ–¹å‘å’Œé˜…è¯»ã€å†™ä½œä¹ æƒ¯ã€‚PaperWeeklyä¼šåšæŒæ¯å‘¨å‘å¸ƒä¸€æœŸæ–‡ç« ï¼Œæ¯ä¸€æœŸçš„æ–‡ç« å°½é‡å›´ç»•åŒä¸€ä¸ªtopicå±•å¼€ï¼Œåœ¨å¾®ä¿¡å…¬ä¼—å·ã€å®˜æ–¹å¾®åšå’ŒçŸ¥ä¹ä¸“æ ä¼šåŒæ­¥æ›´æ–°ï¼Œé™¤äº†è¿™ä¸€ç¯‡æ–‡ç« ï¼Œæˆ‘ä»¬è¿˜ä¼šåšæŒåœ¨å¾®åšä¸Šæä¾›ä¸€ä¸ªæ–°çš„æœåŠ¡ï¼Œcs.CL dailyï¼Œå¸®åŠ©å¤§å®¶è¿‡æ»¤æ‰arXiv cs.CLä¸Šæ¯”è¾ƒæ°´çš„paperï¼Œç•™ä¸‹è´¨é‡é«˜çš„paperï¼Œå¹¶ä¸”ç”¨ç®€è¯„çš„æ–¹å¼åˆ†äº«åœ¨å¾®åšä¸Šï¼Œæ¯å‘¨æœ«ä¼šæ›´æ–°ä¸€ç¯‡cs.CL weeklyå‡ºæ¥ï¼Œå°†ä¸€å‘¨å€¼å¾—è¯»çš„cs.CL paperæ±‡æ€»å‘å¸ƒã€‚</p>
<p>PaperWeeklyç»„ç»‡äº†ä¸€ä¸ªé«˜è´¨é‡çš„NLPè®¨è®ºç¾¤ï¼Œåªè¦æœ‰ä½ ç›¸å…³çš„é—®é¢˜ï¼Œç¾¤é‡Œçš„é«˜æ‰‹ä¼šç¬¬ä¸€æ—¶é—´ç«™å‡ºæ¥è§£ç­”æˆ–è€…è®¨è®ºä½ çš„é—®é¢˜ï¼Œæœ‰çš„æ—¶å€™ä¼šç»™å‡ºä¸€äº›å¼€æºcodeå’Œç›¸å…³çš„paperï¼Œæé—®è€…ã€è®¨è®ºè€…å’Œæ½œæ°´è€…éƒ½ä¼šæœ‰å¾ˆå¤§çš„æ”¶è·ã€‚åˆ†äº«paperå¯¼è¯»çš„æ„ä¹‰åœ¨äºè®¨è®ºï¼Œå¤§å®¶ä¸€èµ·æ¥è®¨è®ºï¼Œæ‰èƒ½æ›´åŠ å……åˆ†åœ°å¸æ”¶paperé‡Œçš„è¥å…»ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ä¸ºä»€ä¹ˆç»„ç»‡ä¸€ä¸ªè®¨è®ºç¾¤çš„åŸå› ã€‚</p>
<p>å¯’æš„çš„è¯å°±è¯´åˆ°è¿™é‡Œï¼Œæœ¬æœŸåˆ†äº«çš„topicæ˜¯ACL 2016ï¼Œä¸€å…±10ç¯‡æ–‡ç« ï¼Œæ¶‰åŠçš„å†…å®¹åŒ…æ‹¬ï¼šLogic Formã€NMTã€Summarizationã€QAã€Chatbotç­‰ã€‚</p>
<h1 id="Sentence-Rewriting-for-Semantic-Parsing"><a href="#Sentence-Rewriting-for-Semantic-Parsing" class="headerlink" title="Sentence Rewriting for Semantic Parsing"></a><a href="http://aclweb.org/anthology/P/P16/P16-1073.pdf" target="_blank" rel="external">Sentence Rewriting for Semantic Parsing</a></h1><h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Semantic Parsingã€Sentence Rewriting</p>
<h2 id="æ¥æº"><a href="#æ¥æº" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>ACL 2016</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>è¯­ä¹‰åˆ†æçš„è¡¨ç°å½¢å¼æ˜¯å°†è‡ªç„¶è¯­è¨€ï¼ˆnatural languageï¼‰è½¬åŒ–æˆé€»è¾‘å½¢å¼ï¼ˆlogic formï¼‰ã€‚å› è¯­è¨€è¡¨è¾¾å¤šæ ·æ€§çš„é—®é¢˜å¯¼è‡´ä¸¤è€…é—´å­˜åœ¨mismatch problemã€‚</p>
<h2 id="æ–‡ç« æ€è·¯"><a href="#æ–‡ç« æ€è·¯" class="headerlink" title="æ–‡ç« æ€è·¯"></a>æ–‡ç« æ€è·¯</h2><p>å…ˆç»™å‡ºä¸€ä¸ªè¯­ä¹‰åˆ†æçš„ä¾‹å­ï¼š</p>
<p><img src="media/14727920453411.jpg" alt=""></p>
<p>ç»™å¥å­æ¢ä¸ªè¡¨è¾¾ï¼ˆHow many people live in Berlin?ï¼‰ï¼Œå¯¹åº”çš„é€»è¾‘å½¢å¼å°±å˜å¾—å¤æ‚å¾ˆå¤š(count(Î»x.person(x)âˆ§live(x,Berlin)))ã€‚</p>
<p>ä½œè€…è®¤ä¸ºï¼ŒåŸå¥å­å’Œé€»è¾‘å½¢å¼ä¹‹é—´å­˜åœ¨çš„ç»“æ„ä¸åŒ¹é…å¯¼è‡´äº†è¯­ä¹‰åˆ†æçš„å›°éš¾ï¼Œè€Œç»“æ„ä¸åŒ¹é…çš„æ ¸å¿ƒæ˜¯è¯æ±‡çš„ä¸åŒ¹é…ã€‚ä½œè€…ç‡å…ˆæå‡ºå…ˆæŠŠå¥å­é‡å†™å†è½¬æˆç›®æ ‡é€»è¾‘å½¢å¼çš„è¯­ä¹‰åˆ†ææ–¹æ¡ˆï¼Œå¦‚ä¸‹å›¾ï¼š</p>
<p><img src="media/14727921250895.jpg" alt=""></p>
<p>é’ˆå¯¹è¯æ±‡ä¸åŒ¹é…é—®é¢˜çš„ä¸¤ç§æƒ…å†µåˆ†åˆ«ç»™å‡ºåŸºäºå­—å…¸å’ŒåŸºäºæ¨¡æ¿ä¸¤ç§æ–¹æ³•ã€‚</p>
<p>1ï¼‰é—®é¢˜ä¸€ï¼š1-N mismatch<br>æ˜¯æŒ‡ä¸€ä¸ªå•è¯ï¼ˆwordï¼‰å¯¹åº”ä¸€ä¸ªå¤åˆçš„é€»è¾‘å½¢å¼ï¼ˆcompound formulaï¼‰ã€‚</p>
<p>ä¾‹å¦‚daughterå¯¹åº” child âˆ© femaleã€‚ä½†åœ¨å¼€æ”¾åŸŸçš„çŸ¥è¯†ä½“ç³»ä¸‹ï¼Œåˆ¶å®šè¿™äº›è§„åˆ™ååˆ†å›°éš¾ã€‚äºæ˜¯ä½œè€…æå‡ºå°†å¥å­ä¸­çš„å¸¸ç”¨åè¯æ›¿æ¢ä¸ºå­—å…¸ï¼ˆWiktionaryï¼‰ä¸­çš„è§£é‡Šï¼Œæ¯”å¦‚å…ˆæŠŠåˆšæ‰çš„daughterè½¬æ¢ä¸ºfemale childï¼Œæ¥ç€å†è½¬æ¢ä¸ºé€»è¾‘å½¢å¼child âˆ© femaleå°±ååˆ†è‡ªç„¶äº†ã€‚</p>
<p>2ï¼‰é—®é¢˜äºŒï¼šN-1 mismatch<br>æ˜¯æŒ‡å°†å¤æ‚çš„è‡ªç„¶è¯­è¨€è¡¨è¾¾å¯¹åº”ä¸ºå•ä¸ªé€»è¾‘è¡¨è¾¾ã€‚</p>
<p>ä¾‹å¦‚å°†How many people live in Berlin?è½¬åŒ–ä¸ºÎ»x.population(Berlin,x)çš„åˆ†æè¿‡ç¨‹ä¸­ï¼ŒHow many people live inè¢«å¯¹åº”ä¸ºé€»è¾‘å¼å¸¸é‡populationã€‚å¦‚åŒé—®é¢˜ä¸€ï¼Œè¿™æ ·çš„è§„åˆ™å®åœ¨è¿‡å¤šï¼Œä½œè€…çš„æ€è·¯æ˜¯å°†å¤æ‚çš„è¡¨è¾¾å¼è½¬åŒ–ä¸ºç®€å•çš„å½¢å¼ã€‚</p>
<p>æ²¿ç”¨ä¹‹å‰çš„å¥å­æ¥äº†è§£ç®—æ³•æµç¨‹ã€‚</p>
<p><img src="media/14727921375652.jpg" alt=""></p>
<p>Step 1 æ›¿æ¢å®ä½“ç”Ÿæˆå€™é€‰templateï¼Œä¾‹å¦‚å¾—åˆ°æ¨¡æ¿how many people live in #yã€‚<br>Step 2 æ£€ç´¢template pairsæ¥æ›¿æ¢æ¨¡æ¿ï¼Œä¾‹å¦‚æ‰¾åˆ°(aï¼šhow many people live in #y, bï¼šwhat is the population of #y)çš„æ¨¡æ¿å¯¹ï¼Œäºæ˜¯å°†bä½œä¸ºæ–°æ¨¡æ¿ï¼Œ<br>Step 3 æŠŠå®ä½“æ›¿æ¢å›å»å¾—åˆ°å®¹æ˜“ç”Ÿæˆé€»è¾‘å½¢å¼çš„what is the population of Berlinã€‚ </p>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p><img src="media/14727925154995.jpg" alt=""></p>
<h2 id="ç®€è¯„"><a href="#ç®€è¯„" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>å¦‚ä»Šæ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå¤§çº¢å¤§ç´«ï¼Œä¹Ÿç»™è¯­ä¹‰åˆ†æçš„æ–¹æ³•å¸¦æ¥æ›´å¤šçš„æ€è€ƒã€‚æ¯”å¦‚ACL2016å¦å¤–ä¸€ç¯‡æ–‡ç« Language to Logical Form with Neural Attentionï¼Œå°±æŠŠè¯­ä¹‰åˆ†æè½¬æ¢ä¸ºseq2seqé—®é¢˜ï¼Œè¿›è€Œä½¿ç”¨æ·±åº¦å­¦ä¹ çš„æ–¹æ³•æ¥è§£å†³ã€‚å¦‚æœæˆ‘ä»¬æŠŠè¯å‘é‡è¿™æ ·çš„è¡¨ç¤ºå½¢å¼æ¯”å–»ä¸ºç²—ç³™çš„è¿ç»“ä¸»ä¹‰ï¼Œé‚£ä¹ˆé€»è¾‘è¡¨è¾¾å°±å¥½æ¯”ç²¾ç»†çš„å½¢å¼ä¸»ä¹‰ã€‚ä¸¤è€…å„æœ‰ä¼˜åŠ¿ï¼Œå¸Œæœ›ä»¥åä¼šæœ‰æ›´å¤šç»“åˆä¸¤ç§æ€æƒ³çš„å·¥ä½œå‡ºç°ã€‚</p>
<h1 id="Language-to-Logical-Form-with-Neural-Attention"><a href="#Language-to-Logical-Form-with-Neural-Attention" class="headerlink" title="Language to Logical Form with Neural Attention"></a><a href="http://aclweb.org/anthology/P/P16/P16-1004.pdf" target="_blank" rel="external">Language to Logical Form with Neural Attention</a></h1><h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Logical Forms, Sequence to Sequence</p>
<h2 id="æ¥æº-1"><a href="#æ¥æº-1" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>ACL 2016</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•æŠŠè‡ªç„¶è¯­è¨€è½¬åŒ–æˆStructured Logical Formsï¼Ÿ</p>
<h2 id="æ–‡ç« æ€è·¯-1"><a href="#æ–‡ç« æ€è·¯-1" class="headerlink" title="æ–‡ç« æ€è·¯"></a>æ–‡ç« æ€è·¯</h2><p><img src="media/14727925632141.jpg" alt=""></p>
<p>æ¨¡å‹æ€»ä½“æ˜¯ä¸€ä¸ªencoder-decoderæ¶æ„ï¼Œinput sequenceé¦–å…ˆé€šè¿‡LSTM encoderè½¬åŒ–æˆä¸€ä¸ªvectorï¼Œç„¶åè¿™ä¸ªvectoré€šè¿‡LSTM decoderè¢«è½¬åŒ–æˆLogical Formsã€‚åœ¨decodeè¿‡ç¨‹ä¸­ç”¨åˆ°äº†ä¸€ä¸ªattention layerå»è·å–contextä¿¡æ¯ã€‚</p>
<p><img src="media/14727705332596.jpg" alt=""></p>
<p>å’Œencoder-decoderæ¨¡å‹ç±»ä¼¼ï¼Œä½œè€…æå‡ºäº†ä¸€ç§hierarchical decoderã€‚ä¸æ™®é€šçš„decoderä¸åŒï¼Œé¦–å…ˆï¼Œdecodeä¹‹åçš„sequenceä¸­å­˜åœ¨ä¸€ä¸ªç‰¹æ®Šå­—ç¬¦<n>ä»£è¡¨nonterminalã€‚åœ¨nonterminalçš„åŸºç¡€ä¸Šï¼Œdecoderå¯ä»¥ç»§ç»­è¿›è¡Œä¸‹ä¸€ä¸ªlayerçš„decodingã€‚æ¯ä¸€æ¬¡decodingçš„è¾“å…¥ä¸ä»…åŒ…å«current hidden state,è¿˜åŒ…å«è¿™ä¸€ä¸ªparent nonterminalçš„hidden stateã€‚</n></p>
<p><img src="media/14727925854664.jpg" alt=""></p>
<p>ä½œè€…è¿˜ä½¿ç”¨äº†ä¸€ç§attentionæœºåˆ¶ï¼Œåœ¨æ„å»ºcurrent hidden stateçš„æ—¶å€™å°†hidden stateä¸æ‰€æœ‰encoderä¸­çš„hidden stateè¿›è¡Œå¯¹æ¯”ï¼Œç»™æ¯ä¸€ä¸ªencoder hidden stateä¸€ä¸ªweightã€‚</p>
<h2 id="èµ„æº"><a href="#èµ„æº" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>ä»£ç ï¼š<a href="https://github.com/donglixp/lang2logic" target="_blank" rel="external">https://github.com/donglixp/lang2logic</a><br>Jobså’ŒGEOæ•°æ®é›†ï¼š<a href="http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf" target="_blank" rel="external">http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-1"><a href="#ç›¸å…³å·¥ä½œ-1" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>ä¹‹å‰çš„å¤§éƒ¨åˆ†å·¥ä½œéƒ½é‡‡ç”¨ä¸€äº›parsing modelsï¼Œstring-to-tree transformation rulesï¼Œæ–‡ä¸­æ²¡æœ‰æåˆ°ä¹‹å‰æœ‰äººé‡‡ç”¨seq2seq/deep learningçš„æ–¹æ³•ã€‚æœ¬æ–‡ä¸­ä½¿ç”¨çš„seq2seqæ–¹æ³•ä¸»è¦æ¥è‡ªKalchbrenner, Blunsom, Cho, Sutskever åœ¨machine translationä¸­æå‡ºçš„æ¨¡å‹ã€‚</p>
<h2 id="ç®€è¯„-1"><a href="#ç®€è¯„-1" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡è§£å†³çš„æ˜¯ä¸€ä¸ªéå¸¸æœ‰è¶£çš„é—®é¢˜ï¼Œå°†è‡ªç„¶è¯­è¨€è½¬æ¢æˆç»“æ„åŒ–çš„Logical Formsã€‚è¯•æƒ³å¦‚æœæ­¤æ¨¡å‹èƒ½å¤Ÿå¾ˆå¥½çš„è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œé‚£ä¹ˆå°†æ¥çš„å„ç§query languageç”šè‡³programming languageséƒ½å¯ä»¥ç”±è‡ªç„¶è¯­è¨€è½¬æ¢è€Œæˆã€‚</p>
<h1 id="Neural-Summarization-by-Extracting-Sentences-and-Words"><a href="#Neural-Summarization-by-Extracting-Sentences-and-Words" class="headerlink" title="Neural Summarization by Extracting Sentences and Words"></a><a href="http://aclweb.org/anthology/P/P16/P16-1046.pdf" target="_blank" rel="external">Neural Summarization by Extracting Sentences and Words</a></h1><h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Summarizationã€Hierarchical Document Encoderã€Attention-based Extractor</p>
<h2 id="æ¥æº-2"><a href="#æ¥æº-2" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>ACL 2016</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•ä½¿ç”¨æ•°æ®é©±åŠ¨çš„æ–¹æ³•æ¥åšæå–å¼æ‘˜è¦ï¼Ÿ</p>
<h2 id="æ–‡ç« æ€è·¯-2"><a href="#æ–‡ç« æ€è·¯-2" class="headerlink" title="æ–‡ç« æ€è·¯"></a>æ–‡ç« æ€è·¯</h2><p>æœ¬æ–‡é’ˆå¯¹çš„ä»»åŠ¡åˆ†ä¸ºsentenceå’Œwordä¸¤ä¸ªlevelçš„summarizationã€‚sentence levelæ˜¯ä¸€ä¸ªåºåˆ—æ ‡ç­¾é—®é¢˜ï¼Œæ¯ä¸ªå¥å­æœ‰0æˆ–1ä¸¤ä¸ªæ ‡ç­¾ï¼Œä¸º1è¡¨ç¤ºéœ€è¦æå–è¯¥å¥ä½œä¸ºæ€»ç»“ã€‚è€Œword levelåˆ™æ˜¯ä¸€ä¸ªé™å®šè¯å…¸è§„æ¨¡ä¸‹çš„ç”Ÿæˆé—®é¢˜ï¼Œè¯å…¸è§„æ¨¡é™å®šä¸ºåŸæ–‡æ¡£ä¸­æ‰€æœ‰å‡ºç°çš„è¯ã€‚</p>
<p>ä½¿ç”¨çš„æ¨¡å‹ä¹Ÿæ¯”è¾ƒæœ‰ç‰¹ç‚¹ï¼Œé¦–å…ˆåœ¨encoderç«¯å°†documentåˆ†ä¸ºwordå’Œsentenceæ¥encodeï¼Œwordä½¿ç”¨CNN encodeå¾—åˆ°å¥å­è¡¨ç¤ºï¼Œæ¥ç€å°†å¥å­è¡¨ç¤ºè¾“å…¥RNNå¾—åˆ°encoderç«¯éšè—å±‚çŠ¶æ€ã€‚ä»wordåˆ°sentenceçš„encodeä½“ç°äº†æœ¬æ–‡çš„hierarchical document encoderçš„æ¦‚å¿µã€‚</p>
<p><img src="media/14727709292807.jpg" alt=""></p>
<p>åœ¨decoderç«¯æ ¹æ®ä»»åŠ¡çš„ä¸åŒä½¿ç”¨ä¸åŒç½‘ç»œç»“æ„ï¼Œsentenceä»»åŠ¡å°±æ˜¯ä¸€ä¸ªç®€å•çš„æœ‰ç›‘ç£ä¸‹äºŒåˆ†ç±»é—®é¢˜ï¼Œä½¿ç”¨RNNç½‘ç»œç»“æ„æ›´æ–°decoderç«¯éšè—å±‚çŠ¶æ€ï¼Œ decoderç«¯éšè—å±‚çŠ¶æ€ä¸²è”encoderç«¯éšè—å±‚çŠ¶æ€åæ¥å…¥ä¸€ä¸ªMLPå±‚å†æ¥sigmoidæ¿€æ´»å‡½æ•°å¾—åˆ°å¥å­æ˜¯å¦è¢«extractçš„æ¦‚ç‡ã€‚</p>
<p>wordä»»åŠ¡åˆ™æ˜¯ä½¿ç”¨ä¼ ç»Ÿçš„attention-basedçš„æ–¹æ³•æ¥è®¡ç®—æ¯ä¸ªè¯çš„æ¦‚ç‡ã€‚ä½†è¦æ³¨æ„æœ¬æ–‡çš„è®¡ç®—çš„attentionä¸æ˜¯word-level attentionï¼Œè€Œæ˜¯encoderç«¯sentence-level attentionã€‚</p>
<p><img src="media/14727709957739.jpg" alt=""></p>
<h2 id="èµ„æº-1"><a href="#èµ„æº-1" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æ•°æ®é›†ï¼š<a href="http://homepages.inf.ed.ac.uk/s1537177/resources.html" target="_blank" rel="external">http://homepages.inf.ed.ac.uk/s1537177/resources.html</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-2"><a href="#ç›¸å…³å·¥ä½œ-2" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>ä¹‹å‰å¤§å¤šæ•°extractive methodséƒ½åŸºäºhuman-engineeredç‰¹å¾æ¥ç»™å¥å­å»ºæ¨¡ï¼Œé€šå¸¸ä¼šå¯¹æ¯ä¸ªå¥å­è®¡ç®—ä¸€ä¸ªåˆ†æ•°ï¼Œç„¶åå†ä½¿ç”¨è¯¸å¦‚binary classifiersï¼Œhidden Markovæ¨¡å‹ï¼Œgraph-basedç®—æ³•æˆ–integer linear programmingç­‰æ–¹æ³•æ¥é€‰æ‹©å¥å­æ„æˆæ€»ç»“ã€‚</p>
<h2 id="ç®€è¯„-2"><a href="#ç®€è¯„-2" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>ä¹‹å‰åŸºäºdata-drivençš„seq2seqæ¨¡å‹åœ¨abstractive summarizationä»»åŠ¡ä¸Šå¤§æ”¾å¼‚å½©ï¼Œæœ¬æ–‡æå‡ºäº†ä½¿ç”¨ç±»ä¼¼çš„æ¨¡å‹æ¥è§£å†³extractive summarizationä»»åŠ¡ã€‚ä¸è¿‡é’ˆå¯¹çš„ä¾æ—§æ˜¯single-document summarizationä»»åŠ¡ï¼Œæœªæ¥éœ€è¦å°†å·¥ä½œæ‹“å±•è‡³multi-document summarizationä»»åŠ¡ä¸Šã€‚</p>
<h1 id="Sequence-to-Sequence-Generation-for-Spoken-Dialogue-via-Deep-Syntax-Trees-and-Strings"><a href="#Sequence-to-Sequence-Generation-for-Spoken-Dialogue-via-Deep-Syntax-Trees-and-Strings" class="headerlink" title="Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings"></a><a href="http://aclweb.org/anthology/P/P16/P16-2008.pdf" target="_blank" rel="external">Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings</a></h1><h2 id="å…³é”®è¯-3"><a href="#å…³é”®è¯-3" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Sequence to Sequenceã€Natural Language Generationã€Chatbot</p>
<h2 id="æ¥æº-3"><a href="#æ¥æº-3" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>ACL 2016</p>
<h2 id="é—®é¢˜-3"><a href="#é—®é¢˜-3" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•é€šè¿‡å°è§„æ¨¡ã€æœªå¯¹é½è¯­æ–™ç”Ÿæˆå¯¹è¯è¯­å¥ï¼Ÿ</p>
<h2 id="æ–‡ç« æ€è·¯-3"><a href="#æ–‡ç« æ€è·¯-3" class="headerlink" title="æ–‡ç« æ€è·¯"></a>æ–‡ç« æ€è·¯</h2><p>ä½œè€…ä»‹ç»äº†ä¸¤ä¸ªæ¨¡å‹:</p>
<p>1ã€é€šè¿‡DA(diglogue acts)ç”Ÿæˆå¥æ³•ä¾èµ–æ ‘ï¼Œå†åˆ©ç”¨external surface realizerï¼Œç”Ÿæˆè¯­å¥ã€‚ï¼ˆå¦‚ä¸‹å›¾ï¼‰</p>
<p><img src="media/14727713613292.jpg" alt=""></p>
<p>2ã€å°†ä¸¤éƒ¨åˆ†ç»“åˆèµ·æ¥ï¼Œç›´æ¥ç”Ÿæˆè¯­å¥ã€‚æ­¥éª¤å¦‚ä¸‹ï¼š</p>
<p>Step 1 å°†DA(dialogue acts)ä¸­çš„æ¯ä¸ªslot(è¡¨ç¤ºç‰¹å®šä¿¡æ¯)è¡¨ç¤ºæˆä¸‰å…ƒç»„(DA type,slot,value)å¹¶ç»“åˆ(ä¸‹å›¾å·¦)</p>
<p><img src="media/14727714252636.jpg" alt=""></p>
<p>Step 2 åŸºäºseq2seq generation techniqueç”Ÿå‡ºè¯­å¥æˆ–å¥æ³•ä¾èµ–æ ‘ã€‚<br>Step 3 ç»“åˆbeam searchå’Œn-beståˆ—è¡¨é‡æ’åºï¼ˆlist rerankerï¼‰ä»¥å‡å°‘è¾“å‡ºä¸­çš„ä¸ç›¸å…³ä¿¡æ¯ã€‚</p>
<h2 id="èµ„æº-2"><a href="#èµ„æº-2" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>ä»£ç : <a href="https://github.com/UFAL-DSG/tgen" target="_blank" rel="external">https://github.com/UFAL-DSG/tgen</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-3"><a href="#ç›¸å…³å·¥ä½œ-3" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p><img src="media/14727926849132.jpg" alt=""></p>
<h2 id="ç®€è¯„-3"><a href="#ç®€è¯„-3" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>è¯¥æ–¹æ³•åŸºäºå¹¿æ³›ä½¿ç”¨çš„seq2seqæ¨¡å‹ï¼Œå¯ä»¥ç”¨æœªå¯¹é½çš„MRå¯¹(pair of  meaning representation)å’Œå¥å­è¿›è¡Œè®­ç»ƒï¼Œä¸”åªè¦å°è§„æ¨¡çš„è¯­æ–™å°±å¯ä»¥æœ‰å¾ˆå¥½çš„æ•ˆæœã€‚ç”Ÿæˆå™¨å¯ä»¥ä»æ•°æ®ä¸­å­¦ä¼šslotçš„å¯¹é½å’Œå€¼ï¼Œç”Ÿæˆæµåˆ©çš„domain style)è¯­å¥ï¼Œè™½ç„¶è¯­ä¹‰é”™è¯¯è¿˜æ˜¯å¾ˆé¢‘ç¹ï¼Œä½†è¿˜æ˜¯å–å¾—äº†ä¸é”™çš„æˆç»©ã€‚</p>
<h1 id="On-line-Active-Reward-Learning-for-Policy-Optimisation-in-Spoken-Dialogue-Systems"><a href="#On-line-Active-Reward-Learning-for-Policy-Optimisation-in-Spoken-Dialogue-Systems" class="headerlink" title="On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems"></a><a href="http://aclweb.org/anthology/P/P16/P16-1230.pdf" target="_blank" rel="external">On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems</a></h1><h2 id="å…³é”®è¯-4"><a href="#å…³é”®è¯-4" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Dialogue Systemã€Reinforcement Learningã€Online Active Reward Learning</p>
<h2 id="æ¥æº-4"><a href="#æ¥æº-4" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>ACL 2016</p>
<h2 id="é—®é¢˜-4"><a href="#é—®é¢˜-4" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æ–‡ç« æå‡ºä¸€ç§åœ¨çº¿å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡é«˜æ–¯è¿‡ç¨‹åˆ†ç±»æ¨¡å‹è¿›è¡Œä¸»åŠ¨å­¦ä¹ ï¼Œè®­ç»ƒå¯¹è¯ç­–ç•¥å’Œå¥–åŠ±æ¨¡å‹ï¼Œå‡å°‘æ•°æ®æ ‡æ³¨çš„èŠ±è´¹å’Œç”¨æˆ·åé¦ˆä¸­çš„å™ªå£°ã€‚</p>
<h2 id="æ–‡ç« æ€è·¯-4"><a href="#æ–‡ç« æ€è·¯-4" class="headerlink" title="æ–‡ç« æ€è·¯"></a>æ–‡ç« æ€è·¯</h2><p><img src="media/14727785168705.jpg" alt=""></p>
<p>æ¡†æ¶åˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼šå¯¹è¯ç­–ç•¥ã€å¯¹è¯åµŒå…¥å‡½æ•°ã€ç”¨æˆ·åé¦ˆä¸»åŠ¨å¥–åŠ±æ¨¡å‹ã€‚</p>
<p>æ— ç›‘ç£å­¦ä¹ è¾“å…¥ä¸ºåŒå‘LSTMï¼Œé€šè¿‡Encoder-Decoderæ¨¡å‹è¡¨å¾ç”¨æˆ·æ„å›¾ï¼Œå°†å¯¹è¯çš„æˆåŠŸä¸å¦çœ‹åšé«˜æ–¯è¿‡ç¨‹çš„ä¸€ä¸ªäºŒå…ƒåˆ†ç±»é—®é¢˜ï¼Œå½“æ¨¡å‹å¯¹å½“å‰ç»“æœä¸èƒ½è¯„åˆ¤æ—¶ï¼Œä¸»åŠ¨å­¦ä¹ ï¼Œé€šè¿‡rewardæ¨¡å‹å†³å®šæ˜¯å¦è¯¢é—®ç”¨æˆ·åé¦ˆï¼Œå½“æ¨¡å‹ä¸ç¡®å®šæ—¶ï¼Œç”Ÿæˆå¢å¼ºä¿¡å·æ¥è®­ç»ƒç­–ç•¥ã€‚</p>
<h2 id="èµ„æº-3"><a href="#èµ„æº-3" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æ•°æ®é›†ï¼š<a href="http://camdial.org/~mh521/dstc/" target="_blank" rel="external">http://camdial.org/~mh521/dstc/</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-4"><a href="#ç›¸å…³å·¥ä½œ-4" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>1ã€ä¹‹å‰çš„å·¥ä½œæœ‰ç”¨ä»»åŠ¡å®Œæˆåº¦å’Œå¯¹è¯æŒç»­æƒ…å†µåšRewardï¼Œä½†ä»»åŠ¡å®Œæˆåº¦ä¸å¥½è¡¡é‡<br>2ã€ç”¨ååŒè¿‡æ»¤è¡¨å¾ç”¨æˆ·åå¥½<br>3ã€ç”¨é€†å¼ºåŒ–å­¦ä¹ ä»è¡Œä¸ºä¸­æ¨å‡ºreward</p>
<h2 id="ç®€è¯„-4"><a href="#ç®€è¯„-4" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>ç”¨lSTM Encoder-Decoderè¡¨å¾ç”¨æˆ·æ„å›¾ï¼Œæ— éœ€å¤§è§„æ¨¡æ ‡æ³¨è¯­æ–™å’Œæ„å»ºç”¨æˆ·æ¨¡æ‹Ÿå™¨æ¥è¿›è¡Œè®­ç»ƒï¼Œåœ¨è¾ƒå°çš„è®­ç»ƒè¯­æ–™ä¸­å–å¾—äº†ä¸é”™çš„æ•ˆæœï¼Œç‡å…ˆå®ç°äº†åœ¨çœŸå®åœºæ™¯ä¸­çš„åº”ç”¨ã€‚ä½†Rewardå‡½æ•°åªå…³å¿ƒå¯¹è¯ä»»åŠ¡æ˜¯å¦æˆåŠŸï¼Œæ¨¡å‹è¿‡äºç®€å•ã€‚</p>
<h1 id="Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models"><a href="#Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models" class="headerlink" title="Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models"></a><a href="http://aclweb.org/anthology/P/P16/P16-1100.pdf" target="_blank" rel="external">Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models</a></h1><h2 id="å…³é”®è¯-5"><a href="#å…³é”®è¯-5" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Neural Machine Translationã€UNK Words</p>
<h2 id="æ¥æº-5"><a href="#æ¥æº-5" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>ACL 2016</p>
<h2 id="é—®é¢˜-5"><a href="#é—®é¢˜-5" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•è§£å†³æœºå™¨ç¿»è¯‘ä¸­çš„æœªç™»å½•è¯é—®é¢˜ï¼Ÿ</p>
<h2 id="æ–‡ç« æ€è·¯-5"><a href="#æ–‡ç« æ€è·¯-5" class="headerlink" title="æ–‡ç« æ€è·¯"></a>æ–‡ç« æ€è·¯</h2><p>æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ··åˆï¼ˆå±‚æ¬¡ï¼‰æ¨¡å‹ã€‚è¯¥æ¨¡å‹ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼Œåˆ†åˆ«ä¸ºï¼š<br>a. ä¼ ç»Ÿçš„åŸºäºè¯ï¼ˆword levelï¼‰çš„seq2seqæ¨¡å‹ï¼›<br>b. åŸºäºå­—æ¯çº§åˆ«ï¼ˆcharacter levelï¼‰çš„LSTMæ¨¡å‹ï¼Œç”±ä¸€ä¸ªå°†å­—æ¯encodeæˆå•è¯çš„encoderå’Œä¸€ä¸ªæ ¹æ®çŠ¶æ€ç”Ÿæˆä½é¢‘è¯çš„decoderç»„æˆã€‚å…¶ä¸­aéƒ¨åˆ†è´Ÿè´£è¿›è¡Œç¿»è¯‘ï¼Œbéƒ¨åˆ†è´Ÿè´£å¤„ç†ä½é¢‘è¯ï¼ˆunkï¼‰ã€‚</p>
<p><img src="media/14727723863213.jpg" alt=""></p>
<p>å…·ä½“åœ°ï¼Œaéƒ¨åˆ†çš„encoderé‡åˆ°unkæ—¶ï¼Œä¼šä½¿ç”¨character levelå¯¹è¯¥ä½é¢‘è¯è¿›è¡Œencodeï¼Œå¹¶ä½¿ç”¨encodeå‡ºçš„representationä½œä¸ºè¾“å…¥ã€‚è€Œdecoderé‡åˆ°unkæ—¶ï¼Œä¼šåˆ©ç”¨attentionæœºåˆ¶å°†å½“å‰ä¸Šä¸‹æ–‡å’ŒLSTMçŠ¶æ€åˆå§‹åŒ–character level decoderã€‚æ­¤å¤„çš„åˆå§‹åŒ–é‡‡ç”¨çš„æ˜¯æ–‡ç« æå‡ºçš„separate pathæ¨¡å¼ï¼Œå³åˆ©ç”¨ä¸€ä¸ªMLPä½œä¸ºcharacter level decoderçš„åˆå§‹åŒ–ç½‘ç»œã€‚å€¼å¾—æ³¨æ„çš„æ˜¯æ­¤å¤„word level decoderä»ä¼šé€‰æ‹©ç”¨<unk>ä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥ã€‚</unk></p>
<h2 id="ç›¸å…³å·¥ä½œ-5"><a href="#ç›¸å…³å·¥ä½œ-5" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>Unké—®é¢˜å±äºNMTä¸­é•¿æœŸå­˜åœ¨é—®é¢˜ã€‚ç›®å‰å¤šæ˜¯é‡‡å–åå¤„ç†çš„æ–¹æ³•ã€‚ä»Šå¹´ACLæœ‰ä¸¤ç¯‡paperï¼Œåˆ†åˆ«æ˜¯æèˆªè€å¸ˆå®éªŒå®¤çš„copynetå’ŒBengioå®éªŒå®¤çš„pointing the unknown wordsï¼Œä½†å¯¹æœºå™¨ç¿»è¯‘ä»»åŠ¡å‚è€ƒæ„ä¹‰æœ‰é™ã€‚<br>å¦å¤–ä¸€ç§æ€è·¯åˆ™æ˜¯åŠ å¤§è¯å…¸ï¼Œæ¯”è¾ƒçŸ¥åå·¥ä½œæœ‰On Using Very Large Target Vocabulary for Neural Machine Translationã€‚æ­¤å¤–è¯¥å·¥ä½œè¿˜å€Ÿé‰´äº†Jiwei Liçš„hierarchical auto encoderã€‚</p>
<h2 id="ç®€è¯„-5"><a href="#ç®€è¯„-5" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æ–‡ç« æ€è·¯æ–°é¢–ä¸”ç®€å•æ˜äº†ã€‚å› ä¸ºNMTä¸­å­˜åœ¨unkçš„é—®é¢˜ï¼Œä½œè€…ç›´æ¥åˆ©ç”¨character level RNNæ¥ç”Ÿæˆä¸€ä¸ªè¯æ›¿ä»£unkã€‚è¯¥å·¥ä½œå¯¹æ‹¼éŸ³æ–‡å­—æœ‰ä¸€å®šæ„ä¹‰ï¼Œå¯¹ä¸­æ—¥éŸ©æ–‡çš„å‚è€ƒæ„ä¹‰æœ‰é™ã€‚</p>
<h1 id="Pointing-the-Unknown-Words"><a href="#Pointing-the-Unknown-Words" class="headerlink" title="Pointing the Unknown Words"></a><a href="http://aclweb.org/anthology/P/P16/P16-1014.pdf" target="_blank" rel="external">Pointing the Unknown Words</a></h1><h2 id="å…³é”®è¯-6"><a href="#å…³é”®è¯-6" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Neural Machine Translationã€UNK Words</p>
<h2 id="æ¥æº-6"><a href="#æ¥æº-6" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>ACL 2016</p>
<h2 id="é—®é¢˜-6"><a href="#é—®é¢˜-6" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•è§£å†³æœºå™¨ç¿»è¯‘ä¸­çš„æœªç™»å½•è¯é—®é¢˜ï¼Ÿ</p>
<h2 id="æ–‡ç« æ€è·¯-6"><a href="#æ–‡ç« æ€è·¯-6" class="headerlink" title="æ–‡ç« æ€è·¯"></a>æ–‡ç« æ€è·¯</h2><p>ä½œè€…åœ¨æœ‰æ³¨æ„åŠ›çš„æœºå™¨ç¿»è¯‘æ¨¡å‹ä¸Šå¢åŠ äº†ä¸€ä¸ªå¼€å…³æ¥åˆ¤æ–­å’Œæ˜¯å¦å¤åˆ¶åŸæ–‡ã€‚</p>
<p>1ã€Attention-basedæœºå™¨ç¿»è¯‘æ¨¡å‹<br><img src="media/14727726836085.jpg" alt=""><br>ç»å…¸çš„attention modelè¿™é‡Œä¸å†èµ˜è¿°ã€‚</p>
<p>2ã€Pointer Softmaxæ¨¡å‹<br><img src="media/14727727829495.jpg" alt=""></p>
<p>ä¸¤ä¸ªé—®é¢˜æœ‰å¾…è§£å†³è§£å†³ï¼š<br>a. æ˜¯å¦è¿›è¡Œcopyï¼Ÿ<br>b. copyçš„ä½ç½®åœ¨å“ªï¼Ÿ</p>
<p>å…ˆè¯´ç¬¬äºŒä¸ªé—®é¢˜ï¼Œä½œè€…å…ˆå¼•å…¥shortlist softmaxå’Œlocation softmaxã€‚å‰è€…æ¥ç¡®å®šè¦ä»shortlistä¸­é€‰å–å“ªä¸€ä¸ªå•è¯ä½œä¸ºè¾“å‡ºï¼Œåè€…ç¡®å®šåœ¨å“ªä¸ªä½ç½®è¦è¿›è¡Œcopyæ“ä½œã€‚</p>
<p>å†çœ‹ç¬¬ä¸€ä¸ªé—®é¢˜ï¼Œä½œè€…å¼•å…¥ä¸€ä¸ªäºŒå€¼å˜é‡ï¼ˆå¯ä»¥æƒ³è±¡ä¸ºä¸€ä¸ªå¼€å…³ï¼‰æ¥é€‰æ‹©ä½¿ç”¨shortlist softmaxè¿˜æ˜¯location softmaxã€‚å½“å€¼ä¸º1çš„æ—¶å€™ä¸è¿›è¡Œcopyæ“ä½œï¼Œä½¿ç”¨shortlist softmaxæ¥ä»shortlistä¸­é€‰ä¸€ä¸ªè¯ä½œä¸ºè¾“å‡ºã€‚å½“å€¼ä¸º0çš„æ—¶å€™è¿›è¡Œcopyæ“ä½œï¼Œä½¿ç”¨location softmaxï¼Œå°†åŸæ–‡çš„è¯ç›´æ¥copyåˆ°æŒ‡å®šä½ç½®ã€‚</p>
<h2 id="èµ„æº-4"><a href="#èµ„æº-4" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>ä»£ç ï¼š<a href="https://github.com/caglar/pointer_softmax" target="_blank" rel="external">https://github.com/caglar/pointer_softmax</a></p>
<h2 id="ç®€è¯„-6"><a href="#ç®€è¯„-6" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>æœ¬æ–‡çš„æƒ³æ³•å¾ˆæœ‰è¶£ï¼Œç›´æ¥ä»åŸæ–‡ç…§æŠ„ç½•è§è¯å’ŒæœªçŸ¥è¯å¾ˆç¬¦åˆæ—¥å¸¸ç”Ÿæ´»ä¸­äººç±»çš„å¤„ç†æ–¹æ³•ã€‚ä»æ–‡ä¸­å®éªŒç»“æœæ¥çœ‹ï¼Œè¯¥æ¨¡å‹æœ‰ä¸€å®šçš„æå‡æ•ˆæœã€‚æ³¨æ„åŠ›æ¨¡å‹çš„æå‡ºä¸å¯¹äººç±»è¡Œä¸ºçš„è§‚å¯Ÿå¯†ä¸å¯åˆ†ï¼Œè€Œcopyæœºåˆ¶ä¹Ÿæ˜¯ä»ç”Ÿæ´»ä¸­æç‚¼å‡ºæ¥çš„ä¸€ç§æœ‰æ•ˆæ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥å€Ÿé‰´çš„æ˜¯ä»äººç±»è§£å†³é—®é¢˜çš„å…·ä½“æ–¹å¼ä¸­è¿›è¡Œæ€»ç»“å’Œå½’çº³ä¸å¤±ä¸ºä¸€ç§æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</p>
<h1 id="Harnessing-Deep-Neural-Networks-with-Logic-Rules"><a href="#Harnessing-Deep-Neural-Networks-with-Logic-Rules" class="headerlink" title="Harnessing Deep Neural Networks with Logic Rules"></a><a href="http://aclweb.org/anthology/P/P16/P16-1228.pdf" target="_blank" rel="external">Harnessing Deep Neural Networks with Logic Rules</a></h1><h2 id="å…³é”®è¯-7"><a href="#å…³é”®è¯-7" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>CNNã€RNNã€First-order Logic, Iterative Distillation Method</p>
<h2 id="æ¥æº-7"><a href="#æ¥æº-7" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>ACL 2016</p>
<h2 id="é—®é¢˜-7"><a href="#é—®é¢˜-7" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•å°†æ·±åº¦å­¦ä¹ ä¸é€»è¾‘è§„åˆ™ç»“åˆä½¿ç”¨ï¼Ÿ</p>
<h2 id="æ–‡ç« æ€è·¯-7"><a href="#æ–‡ç« æ€è·¯-7" class="headerlink" title="æ–‡ç« æ€è·¯"></a>æ–‡ç« æ€è·¯</h2><p><img src="media/14727734980533.png" alt=""></p>
<p>ç³»ç»Ÿåœ¨æ„å»ºæ­£å¸¸ç¥ç»ç½‘ç»œ(student)çš„åŒæ—¶ï¼Œæ„å»ºäº†ä¸€ä¸ªåŸºäºé€»è¾‘è§„åˆ™çš„è®­ç»ƒç½‘ç»œ(teacher)ã€‚æ•´ä¸ªç½‘ç»œçš„ç›®æ ‡è¿˜æ˜¯ä¼˜åŒ–ç¥ç»ç½‘ç»œçš„å‚æ•°å˜é‡ Î¸ï¼Œå› ä¸ºæ–°çš„ç›®æ ‡æŸå¤±å‡½æ•°ç»“åˆäº†äºŒè€…çš„æŸå¤±ï¼Œé€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ•™å¸ˆç½‘ç»œçš„é€»è¾‘ä¿¡æ¯å°±èƒ½å¤Ÿè¢«è½¬ç§»åˆ°ç¥ç»ç½‘ç»œçš„Î¸ä¸Šï¼Œä»è€ŒåŠ å¼ºç¥ç»ç½‘ç»œçš„æ€§èƒ½ã€‚ åœ¨è¿™ç§ç»“æ„é‡Œé€»è¾‘è§„åˆ™æ˜¯ç”¨äºè¾…åŠ©çš„å¯é€‰é¡¹ï¼Œé€šè¿‡è°ƒæ•´æƒé‡ï¼Œç³»ç»Ÿå¯ä»¥åå‘æŸä¸ªç½‘ç»œã€‚è¿™ç§æ¨¡å‹å¯ä»¥å°†ç›‘ç£å­¦ä¹ æ‰©å±•åˆ°æ— ç›‘ç£å­¦ä¹ ï¼Œæ¯”å¦‚å›¾ç¤ºä¸­ï¼Œæ— æ ‡è®°çš„æ•°æ®é€šè¿‡æ•™å¸ˆå­ç½‘ä¹‹åæå–æœ‰ç”¨ä¿¡æ¯ï¼Œä¹Ÿå¯ä»¥ç”¨æ¥è®­ç»ƒç›‘ç£å­¦ä¹ çš„ç¥ç»ç½‘ç»œã€‚</p>
<p>1ã€è®­ç»ƒè¿‡ç¨‹</p>
<p>å‡è®¾è¾“å…¥æ•°æ®ä¸ºx, yã€‚studentç¥ç»ç½‘ç»œçš„å‚æ•°å˜é‡æ˜¯Î¸, è¾“å‡ºå±‚æ˜¯softmaxï¼Œå¯¹è¾“å…¥xnï¼Œè¾“å‡ºé¢„æµ‹æ¦‚ç‡åˆ†å¸ƒÏƒ(xn)ã€‚å¯¹teacherç½‘ç»œï¼Œåœ¨ç¬¬ï½”æ¬¡è¿­ä»£ä¸­åŸºäºé€»è¾‘è§„åˆ™çš„é¢„æµ‹ç»“æœè¡¨ç¤ºä¸ºsn(t)ï¼Œé‚£ä¹ˆæ–°çš„ä¼˜åŒ–ç›®æ ‡å˜æˆäº†</p>
<p><img src="media/14727735567000.png" alt=""></p>
<p>å¯ä»¥çœ‹å‡ºæ¥è‡ªæ•™å¸ˆç½‘ç»œçš„åé¦ˆä½œä¸ºregularizationåŠ åˆ°äº†ç›®æ ‡å‡½æ•°é‡Œï¼Œé€šè¿‡è¿™ç§æ–¹å¼ä¸¤ä¸ªç½‘ç»œçš„ä¿¡æ¯å°±ç»“åˆåœ¨äº†ä¸€èµ·ã€‚æ³¨æ„æ•™å¸ˆç½‘ç»œåœ¨æ¯æ¬¡è®­ç»ƒè¿­ä»£ä¸­éƒ½è¦æ„å»ºï¼Œå› æ­¤æ•´ä¸ªè¿‡ç¨‹è¢«ç§°ä¹‹ä¸ºiterative knowledge distillation.</p>
<p>2ã€æ•™å¸ˆç½‘ç»œ</p>
<p>æ•™å¸ˆç½‘ç»œä½¿ç”¨è½¯é€»è¾‘(soft logic)æ¥ç¼–ç first-order logicçš„ä¿¡æ¯ã€‚soft logicåœ¨[0,1]ä¹‹é—´çš„è¿ç»­å–å€¼ï¼Œè€Œä¸æ˜¯äºŒå…ƒå€¼{0, 1}ã€‚é€»è¾‘è¿ç®—ä¹Ÿç”¨max, min, sumä»£æ›¿åŸæ¥çš„ä¸æˆ–éã€‚</p>
<p>ç¥ç»ç½‘ç»œæ•°å­¦æ¨¡å‹ä¸ºpÎ¸(y|x) æ•™å¸ˆç½‘ç»œæ•°å­¦æ¨¡å‹å‡è®¾ä¸ºq(y|x)ã€‚æˆ‘ä»¬å®é™…ä¸Šæ˜¯ç”¨åŸºäºé€»è¾‘è§„åˆ™çš„æ•™å¸ˆç½‘ç»œæ¥æ¨¡æ‹Ÿç¥ç»ç½‘ç»œè¾“å‡ºï¼Œå› æ­¤æˆ‘ä»¬å¸Œæœ›èƒ½æ‰¾åˆ°ä¸€ä¸ªæœ€ä¼˜çš„qï¼Œä½¿å¾—è¾“å…¥å°½å¯èƒ½æ»¡è¶³é€»è¾‘è§„åˆ™çš„è¦æ±‚ï¼ŒåŒæ—¶qè¦å°½å¯èƒ½æ¥è¿‘pÎ¸ã€‚è¯¦ç»†æ¨å¯¼å¯ä»¥å‚è§åŸæ–‡ï¼Œæœ€åçš„ä¼˜åŒ–ç»“æœå°±æ˜¯</p>
<p><img src="media/14727736225787.png" alt=""></p>
<p>Î»l æ˜¯æ¯ä¸ªè§„åˆ™çš„è‡ªä¿¡åº¦(confidence)ï¼Œè€Œrl,â€†gl æ˜¯æŸä¸ªè§„åˆ™åº”ç”¨äºæŸä¸€è¾“å…¥æ—¶çš„é€»è¾‘ç»“æœï¼Œä»‹äº0,1ä¹‹é—´ã€‚å¯ä»¥çœ‹åˆ°è‡ªä¿¡åº¦æ¯”è¾ƒé«˜çš„è§„åˆ™å¯ä»¥ä½¿è¾“å…¥æ›´å®¹æ˜“é€šè¿‡è§„åˆ™ã€‚</p>
<p>3ã€åº”ç”¨</p>
<p>a. åŸºäºCNNçš„æƒ…æ„Ÿåˆ†æ<br>b. åŸºäºBLSTM-CNNçš„NERä»»åŠ¡</p>
<h2 id="ç›¸å…³å·¥ä½œ-6"><a href="#ç›¸å…³å·¥ä½œ-6" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>1ã€Neural-symbolic systems (Garcez et al., 2012) ä»ç»™å®šçš„è§„åˆ™æ„å»ºæ¨ç†ç½‘ç»œ<br>2ã€(Collobert 2011)ï¼Œ åˆ©ç”¨é¢†åŸŸçŸ¥è¯†domain knowledgeæå–é¢å¤–ç‰¹å¾ï¼Œå¢å¼ºåŸå§‹æ•°æ®<br>3ã€Knowledge distillation (Hinton et al., 2015) (Bucilu et al. 2006)<br>4ã€Posterior regularization (PR) method (Ganchev et al., 2010)</p>
<h2 id="ç®€è¯„-7"><a href="#ç®€è¯„-7" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>åˆ›æ–°ç‚¹åœ¨äºå°†é€»è¾‘è§„åˆ™ä¸ç¥ç»ç½‘ç»œç»“åˆï¼Œå¯ä»¥åˆ©ç”¨äººå·²çŸ¥çš„çŸ¥è¯†å»å¼•å¯¼æœºå™¨å­¦ä¹ ã€‚å½“æ•°æ®é‡ä¸è¶³çš„ï¼Œæˆ–è€…å¯¹æ•°æ®è¿›è¡Œè¡¥å……æ—¶ï¼Œå¯ä»¥å°†äººç±»çš„çŸ¥è¯†ç”¨é€»è¾‘è¯­è¨€è¡¨è¾¾å‡ºæ¥ï¼Œç„¶åé€šè¿‡æœ¬æ–‡æå‡ºçš„æ¡†æ¶è¿›è¡Œå¢å¼ºè®­ç»ƒã€‚æœ¬æ–‡çš„ä¸¤ä¸ªä¾‹å­ä¸­éƒ½æåˆ°åªç”¨äº†å°‘é‡è§„åˆ™ï¼Œä¼˜åŒ–çš„ç»“æœè™½ç„¶æ˜¾ç¤ºè¦æ¯”å½“å‰å…¶ä»–æ¨¡å‹å¥½ï¼Œä½†æ˜¯æ²¡æœ‰å¤§å¹…åº¦çš„æé«˜ã€‚éœ€è¦è¿›ä¸€æ­¥éªŒè¯å¦‚æœä½¿ç”¨æ›´å¤šçš„è§„åˆ™ï¼Œèƒ½ä¸èƒ½å¤§å¹…åº¦æé«˜å‡†ç¡®ç‡ã€‚</p>
<h1 id="Easy-Questions-First-A-Case-Study-on-Curriculum-Learning-for-Question-Answering"><a href="#Easy-Questions-First-A-Case-Study-on-Curriculum-Learning-for-Question-Answering" class="headerlink" title="Easy Questions First? A Case Study on Curriculum Learning for Question Answering"></a><a href="http://aclweb.org/anthology/P/P16/P16-1043.pdf" target="_blank" rel="external">Easy Questions First? A Case Study on Curriculum Learning for Question Answering</a></h1><h2 id="å…³é”®è¯-8"><a href="#å…³é”®è¯-8" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Curriculum Learningã€Self-paced Learningã€Question Answering</p>
<h2 id="æ¥æº-8"><a href="#æ¥æº-8" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>ACL2016</p>
<h2 id="é—®é¢˜-8"><a href="#é—®é¢˜-8" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æ–‡ç« è®¨è®ºäº†Curriculum Learningåœ¨NLPé¢†åŸŸ, å°¤å…¶æ˜¯åœ¨QA taské‡Œåº”ç”¨çš„å¯è¡Œæ€§ã€‚</p>
<h2 id="æ–‡ç« æ€è·¯-8"><a href="#æ–‡ç« æ€è·¯-8" class="headerlink" title="æ–‡ç« æ€è·¯"></a>æ–‡ç« æ€è·¯</h2><p>æ–‡ç« é¦–å…ˆå¯¹QAç±»å‹çš„taskç»™å‡ºäº†æ¯”è¾ƒgeneralçš„å®šä¹‰: æˆ‘ä»¬å¯ä»¥æŠŠQAé—®é¢˜çœ‹åšæ˜¯ä¸€ä¸ªç»éªŒé£é™©æœ€å°åŒ–(ERM)é—®é¢˜, æˆ‘ä»¬éœ€è¦æœ€å°åŒ–:</p>
<p><img src="media/14727739856834.jpg" alt=""></p>
<p>å…¶ä¸­æ˜¯aæ­£ç¡®ç­”æ¡ˆ, fæ˜¯ç»™å®šèƒŒæ™¯çŸ¥è¯†ä»¥åŠé—®é¢˜, æ¨¡å‹é€‰æ‹©å‡ºçš„æœ€ä½³ç­”æ¡ˆ,Î©æ˜¯regularizer. </p>
<p>ä¹‹å, ä½œè€…å¯¹äºCurriculum Learning, å°¤å…¶æ˜¯Self-paced Learningåšäº†ä»‹ç», å¹¶ä¸”å°†å…¶å¼•å…¥QA task, è¿›è€Œå°†ä¹‹å‰çš„ERMé—®é¢˜å˜ä¸º:</p>
<p><img src="media/14727740344982.jpg" alt=""></p>
<p>å…¶ä¸­væ˜¯å¯¹é—®é¢˜è¿›è¡Œé‡‡æ ·æ—¶å€™çš„æƒå€¼, gæ˜¯self-paced regularizer, å…¶ä¸­Î»ä»£è¡¨â€™ageâ€™, æˆ–è€…è¯´â€™paceâ€™. è®­ç»ƒåˆæœŸ, æ¨¡å‹è¶‹å‘äºå¯¹ç®€å•çš„é—®é¢˜è¿›è¡Œè®­ç»ƒ, è€Œéšç€â€™ageâ€™çš„å¢åŠ , æ¨¡å‹è¶Šæ¥è¶Šå¤šåœ°åŠ å…¥æ›´å¤æ‚çš„é—®é¢˜ä¸€èµ·è®­ç»ƒã€‚</p>
<p>æ–‡ç« ç»™å‡ºå¹¶åˆ†æäº†å››ç§æµè¡Œçš„self-paced regularizerå¦‚Table 1:</p>
<p><img src="media/14727745747996.jpg" alt=""></p>
<p>ä¹‹åæå‡ºäº†7ç§æ–°çš„heuristics:</p>
<p>1)    Greedy Optimal (GO): å°†å·²æœ‰çš„Qå’Œä¸€ç³»åˆ—æ–°çš„Qä¸€èµ·è®­ç»ƒ, é€‰å›ç­”æ­£ç¡®å¹¶ä¸”lossæœ€ä½çš„ã€‚<br>2)    Change in Objective (CiO): å°†å·²æœ‰çš„Qå’Œä¸€ç³»åˆ—æ–°çš„Qä¸€èµ·è®­ç»ƒ, é€‰æ‹©ä»¤lossæ”¹å˜æœ€å°çš„ã€‚<br>3)    Mini-max (M2 ): å½“æŸä¸ªæ–°çš„Qä¸å…¶lossæœ€å¤§çš„ä¸€ä¸ªcandidate answeré…å¯¹æ—¶, lossæœ€å°çš„. (é€šä¿—åœ°è®², å°±æ˜¯æœ€å·®æƒ…å†µéƒ½æ²¡æœ‰é‚£ä¹ˆç³Ÿç³•çš„ä¸€ä¸ª)ã€‚<br>4)    Expected Change in Objective (ECiO): åªæ‹¿æ–°çš„Qè®­ç»ƒ, å’Œä¹‹å‰çš„lossæ”¹å˜æœ€å°çš„. (ç›¸æ¯”äºç¬¬äºŒç§çš„å°†å·²æœ‰çš„Qå’Œæ–°Qä¸€èµ·è®­ç»ƒ)ã€‚<br>5)    Change in Objective-Expected Change in Objective (CiO - ECiO): 2)å’Œ4)çš„å€¼æœ€æ¥è¿‘çš„, æŒ‰ç…§ä½œè€…çš„æ„æ€, è¿™ä¸ªå€¼ååº”äº†modelè§åˆ°æŸä¸ªæ–°Qæ—¶surpriseçš„ç¨‹åº¦ã€‚<br>6)    Correctly Answered (CA): å°†ä¸€ç³»åˆ—æ–°Qåœ¨å½“å‰modelä¸Šæµ‹è¯•, é€‰æ‹©ç”¨æœ€å°çš„lossæ­£ç¡®å›ç­”çš„ã€‚<br>7)    Farthest from Decision Boundary (FfDB): åªç”¨åœ¨latent structural SVMsä¸Š, é€‰æ‹©ç­”æ¡ˆä¸decision boundaryæœ€è¿œçš„ä¸€ä¸ªæ–°Qã€‚</p>
<h2 id="èµ„æº-5"><a href="#èµ„æº-5" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>MCTest: <a href="http://research.microsoft.com/en-us/um/redmond/projects/mctest/" target="_blank" rel="external">http://research.microsoft.com/en-us/um/redmond/projects/mctest/</a><br>Science Textbook: <a href="http://http://www.ck12.org/" target="_blank" rel="external">http://http://www.ck12.org/</a><br>Science question answering: <a href="http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip" target="_blank" rel="external">http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip</a><br>Simple English Wikipedia: <a href="https://dumps.wikimedia.org/simplewiki/20151102/" target="_blank" rel="external">https://dumps.wikimedia.org/simplewiki/20151102/</a><br>QANTA: <a href="https://cs.umd.edu/~miyyer/qblearn/" target="_blank" rel="external">https://cs.umd.edu/~miyyer/qblearn/</a></p>
<h2 id="ç›¸å…³å·¥ä½œ-7"><a href="#ç›¸å…³å·¥ä½œ-7" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p>1ã€Curriculum Learning: </p>
<p>æ—©åœ¨1958å¹´[1], å°±æœ‰è®¤çŸ¥ç§‘å­¦çš„ç›¸å…³å­¦è€…æ„è¯†åˆ°, å¯¹äºäººç±»å­¦ä¹ è¿‡ç¨‹, ç›¸å¯¹äºæä¾›éšæœºçš„çŸ¥è¯†,ç”±æµ…åŠæ·±çš„åœ°ç»™äºˆæœ‰è®¡åˆ’çš„è®­ç»ƒæ ·æœ¬, å¯ä»¥å¾—åˆ°æ›´å¥½çš„æ•ˆæœ. ä¹‹åè¿™ä¸€Curriculum Learningçš„æƒ³æ³•ä¹Ÿè¢«å¼•å…¥åˆ°æœºå™¨å­¦ä¹ ä¸­[2], å…¶ä¸­Self-paced learning (SPL)[3][4][5]æ˜¯æ¯”è¾ƒå¸¸ç”¨çš„æ–¹æ³•ã€‚ </p>
<p>2ã€QA:</p>
<p>Jurafskyå’ŒMartin[6]å¯¹äºQAç³»åˆ—é—®é¢˜æœ‰ä¸€ä¸ªéå¸¸å¥½çš„å™è¿°, è€Œè¿™ç¯‡æ–‡ç« çªå‡ºè®¨è®ºCurriculum Learningåœ¨non-convexçš„QAæ¨¡å‹ä¸Šçš„åº”ç”¨, ç€é‡ä»‹ç»äº†åŸºäºé…å¯¹çš„æ¨¡å‹[7][8][9]å’ŒåŸºäºæ·±åº¦å­¦ä¹ çš„æ¨¡å‹[10][11].<br>åŸºäºé…å¯¹çš„æ¨¡å‹å°†æ¯ä¸€ä¸ªé—®é¢˜å’Œé—®é¢˜é™„å¸¦çš„å¤šä¸ªå¤‡é€‰ç­”æ¡ˆç»„æˆè‹¥å¹²ä¸ªQAå¯¹, æˆ‘ä»¬ç§°ä¹‹ä¸ºå‡è®¾, ç„¶ååœ¨ç»™å®šç›¸å…³æ–‡ç« çš„æƒ…å†µä¸‹, å¯»æ‰¾æœ‰æœ€å¯èƒ½æ˜¯æ­£ç¡®çš„ä¸€ä¸ªå‡è®¾ä½œä¸ºç­”æ¡ˆ. åŸºäºæ·±åº¦å­¦ä¹ çš„æ¨¡å‹å¯ä»¥ä½¿ç”¨ä¾èµ–å…³ç³»æ ‘ç»“æ„çš„é€’å½’ç¥ç»ç½‘ç»œ, å¯¹å¥å­levelçš„QAæ¨¡å‹çš„ç»“æœå–å¹³å‡[10]; ä¹Ÿå¯ä»¥ç”¨RNNæ„å»ºâ€é•¿æœŸâ€å­˜å‚¨å™¨, é€šè¿‡å­¦ä¹ å¯¹å­˜å‚¨å™¨è¿›è¡Œè¯»/å†™æ“ä½œ, æ¨¡æ‹Ÿä¸€ä¸ªåŠ¨æ€çš„çŸ¥è¯†æ„å»ºè¿‡ç¨‹[11]ã€‚</p>
<h2 id="ç®€è¯„-8"><a href="#ç®€è¯„-8" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>åœ¨QA taskä¸­å¼•å…¥Curriculum Learningæ—¨åœ¨åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­, å¯å‘å¼åœ°å¯¹äºæä¾›ç»™æ¨¡å‹çš„æ•°æ®å‡ºç°çš„é¡ºåºè¿›è¡Œä¸€äº›è°ƒæ•´, ä»è€Œè®©æ¨¡å‹ä»ç®€å•çš„, æ˜“äºå­¦ä¹ çš„æ ·æœ¬å¼€å§‹, éšç€æ¨¡å‹å¯¹æ•°æ®çš„è¡¨è¿°æ„ˆåŠ æˆç†Ÿ, é€æ¸åŠ å…¥æ›´å¤æ‚çš„æ ·æœ¬. ç†æƒ³çŠ¶å†µä¸‹è¿™ä¼šæŒ‡å¯¼æ¨¡å‹ä»å¾—åˆ°ä¸€ä¸ªæ™®é€šçš„local minima, å˜æˆå¾—åˆ°ä¸€ä¸ªâ€æ›´â€å¥½çš„local minima, è¿›è€Œåˆ©ç”¨å…¨éƒ¨æ•°æ®å¾—åˆ°ä¸€ä¸ªâ€æ›´æ›´â€å¥½çš„local minimaã€‚</p>
<p>é€šå¸¸æ¥è¯´, æˆ‘ä»¬ç»™äºˆæ¨¡å‹çš„heuristicå¹¶ä¸ä¸€å®šèƒ½å¤ŸçœŸæ­£å¸®åŠ©æ¨¡å‹, å› ä¸ºé€šå¸¸æˆ‘ä»¬éƒ½åœ¨çŒœæµ‹æ•°æ®ä»¥åŠæ¨¡å‹çš„latent representationæ˜¯ä»€ä¹ˆ, ä½†æ˜¯è¿™ç¯‡æ–‡ç« é€šè¿‡äº†ä¸€ç³»åˆ—çš„å®éªŒéªŒè¯, æœ¬æ–‡é˜è¿°çš„heuristicç¡®å®å¯ä»¥å¸®åŠ©QA modelè·å¾—æ›´å¥½çš„å‡†ç¡®ç‡. è¿™è¯æ˜äº†å¼•å¯¼æ¨¡å‹ç”±æµ…åŠæ·±çš„è¿™ç§æ€è·¯æ˜¯å¯è¡Œçš„, æˆ‘ä»¬ä¹Ÿè®¸å¯ä»¥æ€è€ƒä¸€äº›æ›´å¤æ‚çš„heuristic, æˆ–è€…å°†å…¶åº”ç”¨åˆ°å…¶ä»–çš„ä¸€äº›NLP tasksã€‚</p>
<p>ç„¶è€Œæœ¬æ–‡ç»™å‡ºçš„å¤§éƒ¨åˆ†heuristicåœ¨æ–°é—®é¢˜çš„é€‰æ‹©ä¸Šéƒ½éœ€è¦æ¯”è¾ƒå¤§çš„æ—¶é—´å¤æ‚åº¦, å¯¹äºç±»ä¼¼MCTestè¿™ç§æ€»å…±åªæœ‰660ä¸ªæ–‡ç« çš„å°å‹æ•°æ®é›†æ¥è¯´è¿˜ç®—æ¯”è¾ƒç°å®, ä½†æ˜¯å¯¹äºæ›´å¤§æ›´é•¿çš„æ•°æ®é›†(æ¯”å¦‚CNNæ•°æ®é›†, 38ä¸‡ä¸ªæ–‡ç« , å¾ˆå¤šæ–‡ç« éƒ½è¶…è¿‡äº†ä¸€åƒäº”ç™¾ä¸ªå•è¯, è€Œä¸”å¤‡é€‰ç­”æ¡ˆæ•°é‡ä¹Ÿè¿œè¶…MCTestçš„å››ä¸ª)æ—¶, å°±æ˜¾å¾—ä¸é‚£ä¹ˆè½»æ¾äº†. æœ€ç®€å•çš„Attention Sum Reader[1] åœ¨CNNæ•°æ®é›†ä¸Š, æ¯ä¸ªepochéƒ½éœ€è¦10ä¸ªå¤šå°æ—¶, å°±æ›´åˆ«è¯´å…¶ä»–åŸºäºAS Readerçš„æ¨¡å‹äº†ã€‚</p>
<p>æ€»ä½“æ¥è¯´, ç›¸å¯¹äºå®ç”¨æ€§, è¿™ç¯‡æ–‡ç« æ›´å¤šåœ¨äºæä¾›äº†ä¸€ç§æ–°çš„æ€è·¯, ä¹Ÿå°±æ˜¯æŠŠCurriculum Learningç›¸å…³çš„æ¦‚å¿µåº”ç”¨åˆ°QAä¹ƒè‡³äºå…¶ä»–NLP taskä¸­, éå¸¸å€¼å¾—æ€è€ƒ, å› æ­¤æ˜¯ä¸€ç¯‡éå¸¸å€¼å¾—é˜…è¯»çš„æ–‡ç« ã€‚</p>
<h1 id="The-LAMBADA-dataset-Word-prediction-requiring-a-broad-discourse-context"><a href="#The-LAMBADA-dataset-Word-prediction-requiring-a-broad-discourse-context" class="headerlink" title="The LAMBADA dataset:Word prediction requiring a broad discourse context"></a><a href="http://aclweb.org/anthology/P/P16/P16-1144.pdf" target="_blank" rel="external">The LAMBADA dataset:Word prediction requiring a broad discourse context</a></h1><h2 id="å…³é”®è¯-9"><a href="#å…³é”®è¯-9" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>Machine Reading Comprehensionã€Dataset</p>
<h2 id="æ¥æº-9"><a href="#æ¥æº-9" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>ACL 2016</p>
<h2 id="é—®é¢˜-9"><a href="#é—®é¢˜-9" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>æ„å»ºäº†ä¸€ä¸ªéš¾åº¦æ›´å¤§çš„æœºå™¨é˜…è¯»ç†è§£æ•°æ®é›†ã€‚</p>
<h2 id="æ„å»ºæ€è·¯"><a href="#æ„å»ºæ€è·¯" class="headerlink" title="æ„å»ºæ€è·¯"></a>æ„å»ºæ€è·¯</h2><p>ä»¥Book Corpusçš„å°è¯´ä½œä¸ºæ•°æ®æºï¼Œæ„å»ºäº†10222ä¸ªpassagesï¼Œæ¯ä¸ªpassageåŒ…æ‹¬å¹³å‡4.6å¥è¯çš„contextå’Œç›¸é‚»ç€çš„ä¸€å¥targetï¼Œå®šä¹‰çš„ä»»åŠ¡æ˜¯é€šè¿‡ç†è§£contextæ¥é¢„æµ‹targetä¸­æœ€åä¸€ä¸ªè¯ï¼Œå¹³å‡æ¯ä¸ªpassageåŒ…æ‹¬çº¦75ä¸ªtokensã€‚å…¶ä¸­ï¼Œè¶…è¿‡80%çš„passage contextä¸­åŒ…æ‹¬äº†targetä¸­éœ€è¦é¢„æµ‹çš„è¯ï¼Œ48%çš„target wordsæ˜¯ä¸“æœ‰åè¯ï¼ˆproper nounsï¼‰ï¼Œ37%çš„è¯æ˜¯ä¸€èˆ¬åè¯ï¼ˆcommon nounsï¼‰ï¼Œçº¦7.7%çš„æ˜¯åŠ¨è¯ã€‚è¿™é‡Œï¼Œä¸“æœ‰åè¯å’Œä¸€èˆ¬åè¯æ˜¯æœ€éš¾çŒœå‡ºæ¥çš„ï¼ŒåŠ¨è¯æœ‰ä¸€å®šçš„æ¦‚ç‡å¯ä»¥ä¸éœ€è¦contextï¼Œè€Œç›´æ¥ä»target sentenceåˆ©ç”¨è¯­è¨€æ¨¡å‹çŒœå‡ºæ¥ã€‚</p>
<p>åœ¨å¤„ç†åŸå§‹æ•°æ®æ—¶ï¼Œä½œè€…åšäº†ä¸€å±‚è¿‡æ»¤ï¼Œå°†å®¹æ˜“ä»target sentenceä¸­ç›´æ¥çŒœå‡ºtarget wordçš„passagesç»Ÿç»Ÿä¸¢æ‰ï¼Œå°†å‰©ä¸‹çš„éƒ¨åˆ†æ”¾åœ¨ä¼—åŒ…ç½‘ç«™ä¸Šè¿›è¡Œäººå·¥ç­›é€‰ï¼Œç­›é€‰çš„è¿‡ç¨‹æ¯”è¾ƒé•¿ï¼Œç›®çš„æ˜¯è®©ç•™åœ¨æ•°æ®é›†ä¸­çš„æ•°æ®æœ‰ä¸‹é¢çš„æ•ˆæœï¼šé€šè¿‡åˆ†æpassageçš„contextå¯ä»¥ç»™å‡ºæ­£ç¡®çš„target wordï¼Œè€Œå¦‚æœåªæ˜¯ç»™å®štarget sentenceçš„è¯ï¼Œæ˜¯çŒœä¸å‡ºæ­£ç¡®çš„target wordã€‚</p>
<h2 id="èµ„æº-6"><a href="#èµ„æº-6" class="headerlink" title="èµ„æº"></a>èµ„æº</h2><p>æœ¬æ–‡æ•°æ®é›†Lambada dataset: <a href="http://clic.cimec.unitn.it/lambada/" target="_blank" rel="external">http://clic.cimec.unitn.it/lambada/</a><br>ä¼—åŒ…ç½‘ç«™Crowdflower: <a href="http://www.crowdflower.com/" target="_blank" rel="external">http://www.crowdflower.com/</a><br>åŸå§‹æ•°æ®é›†Book Corpus: <a href="http://www.cs.toronto.edu/~mbweb/" target="_blank" rel="external">http://www.cs.toronto.edu/~mbweb/</a><br>CNN/Daily Mail dataset: <a href="https://github.com/deepmind/rc-data" target="_blank" rel="external">https://github.com/deepmind/rc-data</a><br>CBT dataset: <a href="http://fb.ai/babi/" target="_blank" rel="external">http://fb.ai/babi/</a><br>MSRCC dataset:  <a href="https://www.microsoft.com/en-us/research/publication/the-microsoft-research-sentence-completion-challenge/" target="_blank" rel="external">https://www.microsoft.com/en-us/research/publication/the-microsoft-research-sentence-completion-challenge/</a></p>
<h2 id="ç›¸å…³æ•°æ®é›†"><a href="#ç›¸å…³æ•°æ®é›†" class="headerlink" title="ç›¸å…³æ•°æ®é›†"></a>ç›¸å…³æ•°æ®é›†</h2><p><img src="media/1.png" alt="1"></p>
<h2 id="ç®€è¯„-9"><a href="#ç®€è¯„-9" class="headerlink" title="ç®€è¯„"></a>ç®€è¯„</h2><p>å¤§å‹æ•°æ®é›†æ˜¯æ·±åº¦å­¦ä¹ æŠ€æœ¯å‘å±•çš„é‡è¦åŸºç¡€ï¼Œæ•°æ®é›†çš„è´¨é‡å’Œéš¾åº¦ä¹Ÿç›´æ¥å…³ç³»ç€æ¨¡å‹çš„è´¨é‡å’Œå®ç”¨æ€§ã€‚æœºå™¨é˜…è¯»ç†è§£çš„æ•°æ®é›†æœ‰å¾ˆå¤šï¼ŒåŒ…æ‹¬ä¸­æ–‡å’Œè‹±æ–‡çš„æ•°æ®é›†ï¼Œæ¯ä¸€ä¸ªçš„æ„å»ºéƒ½ä¼šå¸¦æ¥æ¨¡å‹çš„åˆ›æ–°ï¼Œéšç€éš¾åº¦ä¸æ–­å¢åŠ ï¼Œå¯¹æ¨¡å‹ä¹Ÿæå‡ºäº†æ›´é«˜çš„è¦æ±‚ã€‚æœ¬æ–‡åœ¨æ„å»ºæ•°æ®é›†è¿‡ç¨‹ä¸­ä¸ºäº†ä¿è¯ä»»åŠ¡çš„éš¾åº¦æ‰€é‡‡å–çš„æ–¹æ³•æ˜¯å€¼å¾—å€Ÿé‰´çš„ã€‚</p>
<h1 id="è‡´è°¢"><a href="#è‡´è°¢" class="headerlink" title="è‡´è°¢"></a>è‡´è°¢</h1><p>æœ¬æœŸçš„10ç¯‡æ–‡ç« ç”±ä»¥ä¸‹åŒå­¦å®Œæˆï¼š</p>
<p>è‹è¾‰ã€Xiaoyuã€èƒ¡å°æ˜ã€èµµè¶Šã€å‘¨é’å®‡ã€éŸ©æ™“ä¼Ÿã€Eric Yuanã€Zewei Chuã€tonyaã€å¼ ä¿Šã€‚</p>
<p>æ„Ÿè°¢å¤§å®¶åœ°è¾›å‹¤ä»˜å‡ºã€‚</p>
<h1 id="å¹¿å‘Šæ—¶é—´"><a href="#å¹¿å‘Šæ—¶é—´" class="headerlink" title="å¹¿å‘Šæ—¶é—´"></a>å¹¿å‘Šæ—¶é—´</h1><p>PaperWeeklyæ˜¯ä¸€ä¸ªåˆ†äº«çŸ¥è¯†å’Œäº¤æµå­¦é—®çš„æ°‘é—´ç»„ç»‡ï¼Œå…³æ³¨çš„é¢†åŸŸæ˜¯NLPçš„å„ä¸ªæ–¹å‘ã€‚å¦‚æœä½ ä¹Ÿç»å¸¸è¯»paperï¼Œä¹Ÿå–œæ¬¢åˆ†äº«çŸ¥è¯†ï¼Œä¹Ÿå–œæ¬¢å’Œå¤§å®¶ä¸€èµ·è®¨è®ºå’Œå­¦ä¹ çš„è¯ï¼Œè¯·é€Ÿé€Ÿæ¥åŠ å…¥æˆ‘ä»¬å§ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly<br><img src="media/14727755950469.jpg" alt=""></p>
<p>å¾®åšè´¦å·ï¼šPaperWeeklyï¼ˆ<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ï¼‰<br>çŸ¥ä¹ä¸“æ ï¼šPaperWeeklyï¼ˆ<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ï¼‰<br>å¾®ä¿¡äº¤æµç¾¤ï¼šå¾®ä¿¡+ zhangjun168305ï¼ˆè¯·å¤‡æ³¨ï¼šåŠ ç¾¤ or åŠ å…¥paperweeklyï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-26T16:20:19.000Z"><a href="/2016/08/26/cs-CL-weekly-2016-08-22-2016-08-26/">2016-08-26</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/26/cs-CL-weekly-2016-08-22-2016-08-26/">cs.CL weekly 2016.08.22-2016.08.26</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="ç®€ä»‹"><a href="#ç®€ä»‹" class="headerlink" title="ç®€ä»‹"></a>ç®€ä»‹</h1><p>è¿™ä¸ªæ ç›®æ˜¯å°†ä¸€å‘¨å†…arxiv cs.CLåˆ·å‡ºçš„å¥½æ–‡è¿›è¡Œä¸€ä¸ªç®€å•çš„æ±‡æ€»ï¼Œå¹¶é…æœ‰ä¸€å¥è¯æ€»ç»“ï¼Œæ—¨åœ¨å¸®åŠ©å¤§å®¶è¿‡æ»¤æ‰cs.CLä¸Šçš„æ°´æ–‡ï¼Œå¹¶ä¸”ä¸ºPaperWeeklyå›¢é˜Ÿé€‰æ–‡æä¾›é«˜è´¨é‡paperã€‚</p>
<h1 id="Learning-Word-Embeddings-from-Intrinsic-and-Extrinsic-Views"><a href="#Learning-Word-Embeddings-from-Intrinsic-and-Extrinsic-Views" class="headerlink" title="Learning Word Embeddings from Intrinsic and Extrinsic Views"></a><a href="http://120.52.73.78/arxiv.org/pdf/1608.05852v1.pdf" target="_blank" rel="external">Learning Word Embeddings from Intrinsic and Extrinsic Views</a></h1><p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ä¾é intrinsic (descriptive) and extrinsic (contextual) informationæ¥å­¦ä¹ è¯å‘é‡çš„æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•ä¸­å¯¹ä½é¢‘è¯å­¦ä¹ å­˜åœ¨çš„é—®é¢˜ã€‚ </p>
<h1 id="Context-Gates-for-Neural-Machine-Translation"><a href="#Context-Gates-for-Neural-Machine-Translation" class="headerlink" title="Context Gates for Neural Machine Translation"></a><a href="http://120.52.73.78/arxiv.org/pdf/1608.06043v1.pdf" target="_blank" rel="external">Context Gates for Neural Machine Translation</a></h1><p>æœ¬æ–‡æå‡ºäº†ä¸€ç§context gateæ¥åŠ¨æ€åœ°æ§åˆ¶æœºå™¨ç¿»è¯‘ä¸­sourceã€target contextå¯¹word generationçš„å½±å“ï¼Œå®éªŒè¯æ˜åœ¨BLEUæŒ‡æ ‡ä¸‹æ¯”attention-basedçš„æ–¹æ³•æé«˜äº†2.3ã€‚</p>
<h1 id="Topic-Sensitive-Neural-Headline-Generation"><a href="#Topic-Sensitive-Neural-Headline-Generation" class="headerlink" title="Topic Sensitive Neural Headline Generation"></a><a href="http://120.52.73.80/arxiv.org/pdf/1608.05777v1.pdf" target="_blank" rel="external">Topic Sensitive Neural Headline Generation</a></h1><p>æœ¬æ–‡é’ˆå¯¹ä¼ ç»Ÿæ¨¡å‹ä¸­å¿½ç•¥topical similaritieså’Œdifferences of documentsçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°æ–¹æ¡ˆï¼Œå…ˆå°†documentsæŒ‰ç…§topicsåˆ†ç±»ï¼Œæ¯ä¸€ç±»ä¸­çš„patternæ¯”è¾ƒæ¥è¿‘ï¼Œç„¶åå†åšsentence level summaryï¼Œå¾—åˆ°äº†æ›´å¥½çš„æ•ˆæœã€‚ </p>
<h1 id="Towards-Machine-Comprehension-of-Spoken-Content-Initial-TOEFL-Listening-Comprehension-Test-by-Machine"><a href="#Towards-Machine-Comprehension-of-Spoken-Content-Initial-TOEFL-Listening-Comprehension-Test-by-Machine" class="headerlink" title="Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine"></a><a href="http://120.52.73.77/arxiv.org/pdf/1608.06378v1.pdf" target="_blank" rel="external">Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine</a></h1><p>æœ¬æ–‡ä»¥æ‰˜ç¦å¬åŠ›é¢˜ä½œä¸ºæ•°æ®é›†ï¼Œå°è¯•å¯¹å¤šåª’ä½“ä¿¡æ¯è¿›è¡Œç†è§£ã€‚å¬åŠ›é—®é¢˜æ˜¯å¬å®Œä¸€æ®µè¯ï¼Œç†è§£ä¹‹åï¼Œè¿›è¡Œ4é€‰1ï¼Œè€Œä¸æ˜¯ä¹‹å‰å¸¸è§çš„cloze-styleç†è§£ä»»åŠ¡ã€‚</p>
<h1 id="A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems"><a href="#A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems" class="headerlink" title="A Context-aware Natural Language Generator for Dialogue Systems"></a><a href="http://120.52.73.79/arxiv.org/pdf/1608.07076v1.pdf" target="_blank" rel="external">A Context-aware Natural Language Generator for Dialogue Systems</a></h1><p>æœ¬æ–‡çš„æ¨¡å‹æ˜¯ä¸€ç§ç«¯åˆ°ç«¯çš„æ¨¡å‹ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡å’Œç”¨æˆ·è¯´è¯çš„æ–¹å¼æ¥ç”Ÿæˆå¯¹è¯ã€‚æ˜¯ä¸€ç¯‡SIGDIAL 2016 short paperã€‚é…å¥—çš„ä»£ç å·²å‘å¸ƒäº<a href="https://github.com/UFAL-DSG/tgen" target="_blank" rel="external">Github</a></p>
<h1 id="About"><a href="#About" class="headerlink" title="About"></a>About</h1><p>å¯¹NLPé«˜è´¨é‡åŸåˆ›å†…å®¹å’Œè®¨è®ºæ„Ÿå…´è¶£çš„ä½ ï¼Œèµ¶å¿«æ¥å…³æ³¨ï¼š</p>
<p>1ã€PaperWeekly<a href="http://weibo.com/2678093863/" target="_blank" rel="external">å®˜æ–¹å¾®åš</a></p>
<p>2ã€PaperWeeklyå®˜æ–¹å¾®ä¿¡</p>
<p><img src="media/qrcode_for_gh_5138cebd4585_430.jpg" alt="qrcode_for_gh_5138cebd4585_430"></p>
<p>3ã€PaperWeekly<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">çŸ¥ä¹ä¸“æ </a></p>
<p>4ã€PaperWeeklyå¾®ä¿¡äº¤æµç¾¤ï¼ˆ+å¾®ä¿¡zhangjun168305å…¥ç¾¤ï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-22T02:05:52.000Z"><a href="/2016/08/21/ä»api-aiå·¥ä½œåŸç†æ¥çœ‹æ„å»ºç®€å•åœºæ™¯chatbotçš„ä¸€èˆ¬æ–¹æ³•/">2016-08-21</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/21/ä»api-aiå·¥ä½œåŸç†æ¥çœ‹æ„å»ºç®€å•åœºæ™¯chatbotçš„ä¸€èˆ¬æ–¹æ³•/">ä»api.aiå·¥ä½œåŸç†æ¥çœ‹æ„å»ºç®€å•åœºæ™¯chatbotçš„ä¸€èˆ¬æ–¹æ³•</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•"><a href="#å¼•" class="headerlink" title="å¼•"></a>å¼•</h1><p>chatbotæ— ç–‘æ˜¯å½“å‰éå¸¸ç«çš„ä¸€ä¸ªç ”ç©¶é¢†åŸŸå’Œäº§å“æ–¹å‘ï¼Œç®€å•åœ°å¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼Œå¼€æ”¾åŸŸbotå’Œå°é—­åŸŸbotï¼Œå¼€æ”¾åŸŸbotå€¾å‘äºè§£å†³æ‰€æœ‰çš„äº‹æƒ…ï¼Œè€Œå°é—­åŸŸbotå€¾å‘äºè§£å†³æŸä¸€ä¸ªç»†åˆ†é¢†åŸŸä¸­çš„äº‹æƒ…ï¼Œæ—¨åœ¨ç”¨AIæŠ€æœ¯æé«˜æ•ˆç‡ï¼Œæé«˜ç”Ÿäº§åŠ›ã€‚ç°é˜¶æ®µçš„å¼€æ”¾åŸŸbotæˆ‘ä¸ªäººæ„Ÿè§‰æ›´åƒæ˜¯å¤šä¸ªå¸¸ç”¨å°é—­åŸŸbotçš„å åŠ ï¼Œå½“ç”¨æˆ·å‘èµ·ä¸€ä¸ªè¯·æ±‚ï¼Œç³»ç»Ÿä¼šåˆ¤æ–­å‡ºå±äºå“ªä¸ªç»†åˆ†é¢†åŸŸï¼Œç„¶åè½¬åˆ°ç›¸åº”çš„ç¨‹åºä¸­å»æ‰§è¡Œå¹¶ç»™å‡ºåé¦ˆï¼Œé¡ºç€è¿™ä¸ªé€»è¾‘æ¥çœ‹ï¼Œç ”ç©¶ç®€å•åœºæ™¯ä¸‹çš„chatbotæ˜¯ä¸ªé‡è¦çš„åŸºç¡€å·¥ä½œï¼Œè¿™ç±»ç ”ç©¶æˆ–è€…äº§å“çš„è´¨é‡ç›´æ¥å†³å®šäº†å¤æ‚åœºæ™¯æˆ–è€…å¼€æ”¾åŸŸbotçš„è´¨é‡ã€‚å½“ç„¶é€—ä¹å‹çš„botå¹¶ä¸å±äºæœ¬æ–‡è®¨è®ºçš„èŒƒå›´ã€‚<br><img src="media/1.png" alt="1"><br>å›¾ç‰‡æ¥è‡ªpaper <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" target="_blank" rel="external">The Dialog State Tracking Challenge Series- A Review</a></p>
<p>chatbotæ˜¯åœºäº¤äº’é©å‘½ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå¤šæŠ€æœ¯èåˆçš„å¹³å°ã€‚ä¸Šå›¾ç»™å‡ºäº†æ„å»ºä¸€ä¸ªchatbotéœ€è¦å…·å¤‡çš„ç»„ä»¶ï¼Œç®€å•åœ°è¯´chatbot = NLU(Natural Language Understanding) + NLG(Natural Language Generation).(æœ¬æ–‡åªå…³æ³¨NLPç›¸å…³çš„æŠ€æœ¯ï¼Œå¯¹è¯­éŸ³è¯†åˆ«å¹¶æ— è®¨è®º)</p>
<p>å¯¹äºå°é—­åŸŸçš„chatbotï¼ŒNLUçš„å·¥ä½œå°±æ˜¯DST(Dialog State Tracker)ï¼Œç”¨æˆ·ç»™å‡ºè¾“å…¥ä¹‹åï¼Œç³»ç»Ÿå¯ä»¥ç»™å‡ºä¸‹é¢çš„å½¢å¼ä½œä¸ºstateï¼š</p>
<p><b>Act(Slot=Value)</b></p>
<p>Actè¡¨ç¤ºç”¨æˆ·è¡Œä¸ºçš„ç±»å‹ï¼Œæ¯”å¦‚è¯·æ±‚ã€æŸ¥è¯¢ã€æ‰“æ‹›å‘¼ç­‰ç­‰ï¼›Slotè¡¨ç¤ºç”¨æˆ·è¾“å…¥ä¸­åŒ…å«çš„æŸç§Actä¸‹çš„Entityï¼Œæ¯”å¦‚æŸ¥è¯¢é…’åº—çš„ä½ç½®ã€ä»·æ ¼è¿™äº›å®ä½“ï¼›Valueæ˜¯æŒ‡Slotä¸­Entityå¯¹åº”çš„å€¼ï¼Œæ¯”å¦‚ä½ç½®åœ¨åŒ—è¾¹ï¼Œä»·æ ¼åœ¨500-800ä¹‹é—´ç­‰ç­‰ã€‚æ¯ä¸€å¥è¯ä¸­å¯èƒ½åŒ…æ‹¬å¤šä¸ªAct-Slot-Valueå¯¹ï¼Œchatbotéœ€è¦åšçš„äº‹æƒ…å°±æ˜¯å‡†ç¡®åœ°è¯†åˆ«å‡ºActï¼Œå¹¶ä¸”æŠ½å–å‡ºç›¸åº”çš„Slotå’ŒValueã€‚</p>
<p>ç´§æ¥ç€æ˜¯NLGçš„éƒ¨åˆ†ï¼Œå‰å‡ å¤©åœ¨<a href="http://rsarxiv.github.io/2016/08/16/PaperWeekly-%E7%AC%AC%E4%BA%8C%E6%9C%9F/">PaperWeeklyç¬¬äºŒæœŸ</a>ä¸­åˆ†äº«äº†ä¸‰ç¯‡paperï¼Œå…¶ä¸­ä¸¤ç¯‡æ­£æ˜¯ç ”ç©¶åŸºäºDSTçš„NLGé—®é¢˜ã€‚</p>
<p>æœ¬æ–‡é¦–å…ˆä»<a href="api.ai">api.ai</a>è¿™å®¶ä¼ä¸šæä¾›çš„æœåŠ¡è¯´èµ·ï¼Œé€šè¿‡ç ”ç©¶å…¶æä¾›çš„å°é—­åŸŸbotæ„å»ºæŠ€æœ¯ï¼Œæ¥æç‚¼æ„å»ºç®€å•åœºæ™¯chatbotçš„ä¸€èˆ¬æ–¹æ³•ï¼Œä¸ºæ„å»ºå¤æ‚åœºæ™¯æˆ–è€…æ‰¾å‡ºç°æœ‰chatbotå­˜åœ¨çš„æŠ€æœ¯é—®é¢˜å’Œé¢ä¸´çš„æŠ€æœ¯éš¾ç‚¹æ‰“ä¸‹åŸºç¡€ã€‚</p>
<h1 id="api-ai"><a href="#api-ai" class="headerlink" title="api.ai"></a>api.ai</h1><h2 id="api-aiå…¬å¸ä»‹ç»"><a href="#api-aiå…¬å¸ä»‹ç»" class="headerlink" title="api.aiå…¬å¸ä»‹ç»"></a>api.aiå…¬å¸ä»‹ç»</h2><blockquote>
<p>Api.ai provides developers and companies with the advanced tools they need to build conversational user interfaces for apps and hardware devices.</p>
</blockquote>
<p>è¿™å®¶å…¬å¸æ˜¯ä¸€å®¶å…¸å‹çš„B2Då…¬å¸ï¼Œæä¾›äº†ä¸€äº›å·¥å…·å¸®åŠ©å¼€å‘è€…è½»æ¾åœ°å¼€å‘ä¸€æ¬¾botï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾åœ°å‘å¸ƒåˆ°å„ç§messageå¹³å°ä¸Šã€‚å•†ä¸šæ¨¡å¼ä¹Ÿéå¸¸ç®€å•ï¼Œå…è´¹ç”¨æˆ·æœ‰ä¸€å®šæ¬¡æ•°çš„è°ƒç”¨æƒé™ï¼Œéœ€è¦å¤§é‡è°ƒç”¨çš„è¯ï¼Œåˆ™ä»˜è´¹è´­ä¹°ï¼Œä¸åŒçš„æƒé™æœ‰ä¸åŒçš„ä»·æ ¼ï¼Œè¯¥å…¬å¸ä¹Ÿæä¾›é«˜çº§å®šåˆ¶åŒ–æœåŠ¡ã€‚</p>
<p>api.aiå…¬å¸æˆç«‹äº2010å¹´ï¼ˆæ•°æ®æ¥è‡ª<a href="https://www.crunchbase.com/organization/api-ai#/entity" target="_blank" rel="external">CrunchBase</a>ï¼‰ï¼Œå…¶æ—©æœŸä¸šåŠ¡ä¸æ¸…æ¥šï¼Œä½†å¯ä»¥ä»æä¾›çš„æœåŠ¡ä¸­æ¨æ–­å‡ºæ—©æœŸæ”’äº†å¤§é‡çš„ç”¨æˆ·æ•°æ®ï¼Œè€Œä¸”æ¶‰åŠçš„é¢†åŸŸéå¸¸å¤šï¼Œæ¯”å¦‚ï¼š<br><img src="media/2.png" alt="2"></p>
<p>æ¯ä¸ªé¢†åŸŸéƒ½æœ‰ä¸€ä¸ªçŸ¥è¯†åº“ï¼Œå¦‚æœä½ è¦å¼€å‘æŸä¸ªå¸¸ç”¨é¢†åŸŸå†…çš„chatbotï¼Œé‚£ä¹ˆè¿™ä¸ªçŸ¥è¯†åº“å°†ä¼šéå¸¸æœ‰ç”¨ã€‚</p>
<h2 id="é‡è¦æ¦‚å¿µå’Œå·¥ä½œåŸç†"><a href="#é‡è¦æ¦‚å¿µå’Œå·¥ä½œåŸç†" class="headerlink" title="é‡è¦æ¦‚å¿µå’Œå·¥ä½œåŸç†"></a>é‡è¦æ¦‚å¿µå’Œå·¥ä½œåŸç†</h2><h3 id="é‡è¦æ¦‚å¿µ"><a href="#é‡è¦æ¦‚å¿µ" class="headerlink" title="é‡è¦æ¦‚å¿µ"></a>é‡è¦æ¦‚å¿µ</h3><p>1ã€Agentsã€‚è¿™ä¸ªæ˜¯ä¸€ä¸ªå¯¹å¤–æ¥å£ï¼Œä¸å…¶ä»–åº”ç”¨ç¨‹åºæˆ–ä½ çš„appè¿›è¡Œæ•´åˆçš„éƒ¨åˆ†ã€‚å¦‚ä¸‹å›¾ï¼š<br><img src="media/3.png" alt="3"></p>
<p>2ã€Entitiesã€‚è¿™é‡Œçš„å®ä½“å’Œå¼•è¨€ä¸­æåˆ°çš„Slotç±»ä¼¼ï¼Œæ˜¯æŒ‡æŸä¸ªç‰¹å®šé¢†åŸŸå†…çš„å®ä½“ï¼Œæ˜¯ä¸€ç±»ä¸œè¥¿çš„æŠ½è±¡æ¦‚æ‹¬ï¼Œæ¯”å¦‚HotelNameè¿™ä¸€å®ä½“ï¼Œå¯¹åº”ç€å¾ˆå¤šçš„é…’åº—åå­—ï¼Œå‡¯å®¾æ–¯åŸºã€å¦‚å®¶ç­‰ç­‰ã€‚æœ‰Entityï¼Œå°±ä¸€å®šæœ‰valueï¼Œchatbotä¸­é‡è¦çš„ä¸€æ­¥æ­£æ˜¯ä»user inputä¸­æŠ½å–å‡ºå¯¹åº”é¢„å…ˆè®¾å®šå¥½entityçš„valueï¼Œæ˜¯ä¸€ä¸ªå…¸å‹çš„Named Entity Recognitionä»»åŠ¡ã€‚</p>
<p>è¿™é‡Œç»å…¸çš„NERä»»åŠ¡æ˜¯è¯†åˆ«å‡ºuser inputä¸­çš„personã€timeã€placeç­‰ç­‰å‡ ä¸ªåŸºæœ¬å…ƒç´ ï¼Œapi.aiå°†è¿™äº›å¸¸è§çš„entityå®šä¹‰ä¸ºsystemçº§çš„ï¼Œå³é»˜è®¤æä¾›äº†è®­ç»ƒå¥½çš„è¯†åˆ«å™¨ï¼Œå½“ç„¶ä¸ä»…ä»…é™äºè¿™å‡ ç±»åŸºæœ¬çš„ï¼›è€Œç‰¹å®šé¢†åŸŸçŸ¥è¯†åº“çš„é‡è¦ä½œç”¨ä¹Ÿæ­£æ˜¯åœ¨äºè¯†åˆ«è¯¥é¢†åŸŸå†…çš„entityã€‚é™¤äº†system levelçš„NERä¹‹å¤–ï¼Œéœ€è¦developerè‡ªå®šä¹‰ä¸€äº›entityï¼Œæ¯”å¦‚èœåï¼Œè€Œä¸”è¦ç»™å®šå…·ä½“çš„èœåå’Œç›¸ä¼¼çš„è¡¨è¾¾ä½œä¸ºsamplesè¿›è¡Œè®­ç»ƒã€‚</p>
<p>3ã€Intentsã€‚è¿™ä¸ªç›¸å½“äºæ˜¯ä»user inputåˆ°chatbotæ‰§è¡ŒæŸä¸ªactionä¹‹é—´çš„ä¸€ä¸ªæ˜ å°„å…³ç³»ï¼Œç”¨æˆ·è¾“å…¥ä¸€å¥è¯ä¹‹åï¼Œchatbotå°±å¯ä»¥ç†è§£å…¶æ„å›¾ï¼Œæ˜¯åœ¨æ‰“æ‹›å‘¼ï¼Œè¿˜æ˜¯æŸ¥è¯¢ï¼Œè¿˜æ˜¯åšäº›åˆ«çš„äº‹æƒ…ã€‚è¿™éƒ¨åˆ†api.aiæä¾›äº†è®­ç»ƒå™¨ï¼Œä½†æ˜¯éœ€è¦developerå®šä¹‰ä¸€äº›æ ‡æ³¨å¥½çš„examplesï¼Œæ ‡æ³¨çš„å½¢å¼å¦‚ä¸‹ï¼š<br><img src="media/4.png" alt="4"></p>
<p>è¿™é‡Œç”¨æˆ·è¾“å…¥æ˜¯book a ticket to Los Angeles on Mondayï¼Œæ‰€è°“æ ‡æ³¨åŒ…æ‹¬ä¸¤ä¸ªlevelï¼Œä¸€ä¸ªæ˜¯entityæ ‡æ³¨ï¼Œä¸€ä¸ªæ˜¯intentæ ‡æ³¨ï¼Œå‰ä¸€ä¸ªæ˜¯ä¸ºäº†è®­ç»ƒNERå·¥å…·ï¼Œåä¸€ä¸ªæ˜¯ä¸ºäº†è¯†åˆ«intentã€‚è¿™é‡Œå› ä¸ºLAæ˜¯åœ°åï¼ŒMondayæ˜¯æ—¶é—´ï¼Œæ‰€ä»¥éƒ½ä¼šè¢«api.aiçš„ç³»ç»Ÿè‡ªåŠ¨æ ‡æ³¨å‡ºæ¥ã€‚</p>
<p>4ã€Actionsã€‚è¿™ä¸ªæ˜¯ç”±intentsè¿›è¡Œtriggerçš„ï¼Œactionså°±å’Œå¼•è¨€ä¸­çš„Actç±»ä¼¼ï¼Œæ˜¯ä¸€ä¸ªå…·ä½“çš„åŠ¨ä½œï¼Œæ¯”å¦‚è¯´æŸ¥è¯¢ï¼Œä½†æ‰§è¡ŒåŠ¨ä½œçš„æ—¶å€™ä¸€èˆ¬éƒ½è¦å¸¦ä¸Šå…·ä½“çš„å‚æ•°valueï¼Œç”¨æˆ·è¾“å…¥ï¼šâ€œä¸‰é‡Œå±¯æœ€è¿‘çš„é˜¿è¿ªè¾¾æ–¯åº—åœ¨ä»€ä¹ˆä½ç½®ï¼Ÿâ€ï¼Œchatboté¦–å…ˆä¼šæå–å‡ºplace-&gt;ä¸‰é‡Œå±¯ï¼Œquery-&gt;é˜¿è¿ªè¾¾æ–¯åº—ï¼Œç„¶åè½¬æ¢ä¸ºjsonä¸¢ç»™åå°çš„æŸ¥è¯¢æœåŠ¡ï¼ŒæŸ¥è¯¢åˆ°ç»“æœåç»™å‡ºç­”æ¡ˆã€‚è¿™é‡Œçš„valueæŠ½å–å…¶å®å°±æ˜¯ç¬¬äºŒä¸ªæ¦‚å¿µæåˆ°çš„entity valueã€‚</p>
<p>5ã€Contextsã€‚ä¸Šä¸‹æ–‡æ˜¯ä¸€ä¸ªéå¸¸é‡è¦ä½†å´è§£å†³ä¸æ˜¯å¾ˆå¥½çš„ç‚¹ï¼Œapi.aiæä¾›çš„æ–¹å¼æ˜¯è‡ªå®šä¹‰ä¸€äº›context conditionï¼Œå½“conditionæ»¡è¶³æ—¶ï¼Œè‡ªåŠ¨triggerå‡ºcontextå…³è”å†…å®¹templateï¼Œç„¶åfilling slotsï¼Œç”Ÿæˆresponseã€‚</p>
<h3 id="å·¥ä½œåŸç†"><a href="#å·¥ä½œåŸç†" class="headerlink" title="å·¥ä½œåŸç†"></a>å·¥ä½œåŸç†</h3><p>ä»¥RSarXiv chatbotä¸ºä¾‹ï¼Œç®€å•ä»‹ç»ä¸‹å·¥ä½œåŸç†ã€‚<br>ï¼ˆæ³¨ï¼šRSarXivæ˜¯æˆ‘ä¹‹å‰å†™çš„ä¸€ä¸ªarxiv paperæ¨èç³»ç»Ÿï¼‰</p>
<p>step 1 è‡ªå®šä¹‰Entityï¼Œè¿™é‡Œæˆ‘å®šä¹‰äº†ä¸¤ä¸ªentitiesï¼Œä¸€ä¸ªæ˜¯keywordså’Œsubjectã€‚keywordsæ˜¯ä¸ºsearchåŠŸèƒ½æä¾›valueï¼Œè€Œsubjectæ˜¯ä¸ºupdate new papersåŠŸèƒ½æä¾›valueã€‚<br><img src="media/5.png" alt="5"><br>å®šä¹‰å¥½subject entityä¹‹åï¼Œæˆ‘ç»™å‡ºäº†å‡ ä¸ªexamplesï¼ŒåŒæ—¶ä¹ŸåŒ…æ‹¬å…¶synonymsï¼Œkeywords entityç±»ä¼¼ã€‚</p>
<p>step 2  è‡ªå®šä¹‰Intentsï¼Œè¿™é‡Œæˆ‘å®šä¹‰äº†ä¸¤ä¸ªIntentsï¼Œåˆ†åˆ«æ˜¯updateå’Œsearchã€‚ä¸‹å›¾æ˜¯updateçš„examplesï¼Œæ˜¯æˆ‘è‡ªå®šä¹‰çš„å‡ ä¸ªä¾‹å­ã€‚api.aiä¼šæ ¹æ®æˆ‘å®šä¹‰å¥½çš„entityè¿›è¡Œè‡ªåŠ¨æ ‡æ³¨ï¼Œæ¯”å¦‚cs.CLï¼Œtodayæ˜¯ç³»ç»Ÿé»˜è®¤çš„entityæ‰€ä»¥ä¹Ÿè¿›è¡Œäº†è‡ªåŠ¨æ ‡æ³¨ã€‚è‡ªåŠ¨æ ‡æ³¨æ˜¯ä¸ºäº†åå°çš„æœºå™¨å­¦ä¹ ç®—æ³•å¯¹æ ‡æ³¨å¥½çš„examplesè¿›è¡Œå­¦ä¹ ï¼Œä»¥æé«˜chatbotçš„NLUå‡†ç¡®ç‡ã€‚<br><img src="media/6.png" alt="6"></p>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘éœ€è¦å®šä¹‰ä¸‹Actionsï¼Œå¦‚ä¸‹å›¾ï¼š<br><img src="media/7.png" alt="7"><br>Actionè¢«ç§°ä¸ºupdateï¼Œå¿…é¡»åŒ…å«çš„å‚æ•°æ˜¯subjectï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬ä¸Šé¢è®²åˆ°çš„ä¸€ä¸ªentityï¼Œdateå‚æ•°å¹¶ä¸æ˜¯å¿…é¡»çš„ã€‚æ‰€ä»¥ï¼Œè¿™é‡Œå¦‚æœç”¨æˆ·çš„inputè¢«è¯†åˆ«å‡ºæ˜¯update intentsçš„è¯ï¼Œå°±å¿…é¡»åŒ…æ‹¬subjectå‚æ•°ï¼Œå¦åˆ™chatbotä¼štriggerä¸€ä¸ªresponseï¼Œç±»ä¼¼â€œè¯·ç”¨æˆ·è¾“å…¥subjectâ€è¿™æ ·çš„è¯ã€‚</p>
<p>step 3 ç®€å•æµ‹è¯•ï¼Œåœ¨ç•Œé¢çš„å³ä¾§æœ‰ä¸€ä¸ªconsoleï¼Œç”¨æ¥æµ‹è¯•å½“å‰chatbotçš„æ•ˆæœï¼Œæˆ‘è¾“å…¥update cs.CLï¼Œå¾—åˆ°ä¸‹é¢çš„æ•ˆæœï¼š<br><img src="media/8.png" alt="8"><br>chatbotè¯†åˆ«å‡ºIntentæ˜¯Updateï¼ŒActionæ˜¯updateï¼ŒParameteræ˜¯dateå’Œsubjectï¼Œå¹¶ä¸”subjectçš„å€¼æ˜¯cs.CLï¼Œä¸‹é¢çš„Show JSONæ˜¯api.aiä¸ºdeveloperç”Ÿæˆçš„ï¼Œç”¨æ¥ä¸developerè‡ªå·±çš„web serviceè¿›è¡Œæ•°æ®äº¤æ¢ã€‚</p>
<p>step 4 è®­ç»ƒã€‚è®­ç»ƒåŒ…æ‹¬ä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€æ˜¯è®­ç»ƒNERï¼ŒäºŒæ˜¯è®­ç»ƒIntent Classificationã€‚è®­ç»ƒå™¨æ˜¯api.aiæä¾›çš„ï¼Œä½†æ˜¯æ ‡æ³¨æ•°æ®æ˜¯developerè‡ªå·±æä¾›çš„ï¼Œå½“ç„¶è®­ç»ƒæ•°æ®è¶Šå¤šï¼Œæ ‡æ³¨è¶Šå‡†ï¼Œåˆ†ç±»å™¨çš„å‡†ç¡®ç‡å°±è¶Šé«˜ï¼Œchatbotçš„NLUå‡†ç¡®ç‡è¶Šé«˜ã€‚è‡³äºè®­ç»ƒæ–¹æ³•ï¼Œdocsä¸­æ²¡æœ‰ç»†è¯´ï¼Œæˆ‘ç®€å•çŒœæµ‹ä¸€ä¸‹ï¼ŒNERå¯ä»¥å½“åšSequence Labelingä»»åŠ¡ï¼Œå’ŒIntent Recognitionç±»ä¼¼ï¼Œéƒ½å¯ä»¥çœ‹ä½œæ˜¯å¤šåˆ†ç±»é—®é¢˜ï¼Œä¸ç®¡æ˜¯ä¼ ç»Ÿçš„åˆ†ç±»æ–¹æ³•è¿˜æ˜¯å½“ä¸‹æµè¡Œçš„deep learningæ–¹æ³•éƒ½èƒ½å¾—åˆ°ä¸é”™çš„å‡†ç¡®ç‡ã€‚éšç€user logsçš„å¢å¤šï¼Œè®­ç»ƒæ•°æ®ä¼šè¶Šæ¥è¶Šå¤šï¼Œchatboté€šè¿‡å­¦ä¹ å°±ä¼šå˜å¾—è¶Šæ¥è¶Šâ€œèªæ˜â€ã€‚ä½†è¿™é‡Œæœ‰ä¸ªé—®é¢˜ï¼Œtraining dataè¶Šå¤šï¼Œéœ€è¦æ ‡æ³¨æˆ–è€…ä¿®æ”¹æ ‡æ³¨çš„æ•°æ®å°±ä¼šè¶Šå¤šï¼Œä¹Ÿæ˜¯ä¸€ä¸ªéº»çƒ¦äº‹å„¿ã€‚</p>
<p>step 5 æ•´åˆã€å‘å¸ƒã€‚api.aiæ”¯æŒçš„å¹³å°éå¸¸å¤šï¼ŒåŒ…æ‹¬å½“ä¸‹æµè¡Œçš„messageå¹³å°ï¼Œè¿˜æœ‰å„ç§æ“ä½œç³»ç»Ÿå¹³å°ã€‚åœ¨messageå¹³å°ä¸Šæä¾›äº†ä¸€é”®æ•´åˆçš„åŠŸèƒ½ï¼Œåœ¨æ“ä½œç³»ç»Ÿä¸Šæä¾›äº†SDKã€‚è¿™é‡Œæˆ‘ç”¨äº†slackå¹³å°ï¼Œapi.aiæ‰“é€šäº†å’Œslackçš„æ¥å£ï¼Œä¹Ÿæä¾›äº†webhookï¼Œè¿æ¥äº†æˆ‘ä¹‹å‰å†™å¥½çš„web serviceï¼Œåªéœ€è¦æŒ‰ç…§å®ƒç»™å®šçš„æ¶ˆæ¯æ¥å£è¿›è¡Œå®šä¹‰å³å¯ã€‚</p>
<h3 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h3><p>ç›®å‰RSarXivåªæä¾›ä¸¤ä¸ªç®€å•çš„åŠŸèƒ½ï¼Œä¸€ä¸ªæ˜¯updateä»Šå¤©æœ€æ–°çš„arxiv paperï¼Œä½ å¯ä»¥é€šè¿‡show me new papers in cs.CLç­‰ç±»ä¼¼çš„è¯æ¥è·å–cs.CLè¿™ä¸ªé¢†åŸŸä¸­æœ€æ–°çš„paperï¼›ä¸€ä¸ªæ˜¯searchåŠŸèƒ½ï¼Œä½ å¯ä»¥é€šè¿‡search LSTMç­‰ç±»ä¼¼çš„è¯æ¥è·å–åŒ…æ‹¬LSTMè¿™ä¸ªå…³é”®è¯çš„paperã€‚ç”±äºæ˜¯ä¸€ä¸ªæµ‹è¯•ç”¨çš„demoï¼Œå°±æ²¡åšä»€ä¹ˆå¤æ‚çš„åŠŸèƒ½ã€‚<br><img src="media/10.png" alt="10"></p>
<p>å¤§å®¶å¦‚æœæ„Ÿå…´è¶£çš„è¯ï¼Œå¯ä»¥ç•™è¨€ç»™æˆ‘æˆ–è€…å‘é‚®ä»¶ç»™æˆ‘(mcgrady150318@gmail.com/mcgrady150318@163.com)ï¼Œæˆ‘é‚€è¯·å¤§å®¶åˆ°è¿™ä¸ªslack teamä¸­ã€‚</p>
<h1 id="ç®€å•åœºæ™¯chatbotæ„å»ºæ–¹æ³•"><a href="#ç®€å•åœºæ™¯chatbotæ„å»ºæ–¹æ³•" class="headerlink" title="ç®€å•åœºæ™¯chatbotæ„å»ºæ–¹æ³•"></a>ç®€å•åœºæ™¯chatbotæ„å»ºæ–¹æ³•</h1><p>ä»‹ç»äº†ä¸‹api.aiæä¾›çš„æœåŠ¡ï¼Œä¸‹é¢ç®€å•åœ°æç‚¼ä¸€ä¸‹ã€‚</p>
<p>chatbot = NLU + NLG</p>
<p>api.aiè§£å†³çš„é‡ç‚¹é—®é¢˜æ˜¯NLUçš„é—®é¢˜ï¼ŒNLUä¹Ÿæ˜¯Dialogue State Tracker(DST)çš„æ ¸å¿ƒå’ŒåŸºç¡€ï¼Œè€ŒDSTæ˜¯chatbotçš„æ ¸å¿ƒã€‚è¿™é‡Œçš„NLUåŒ…æ‹¬ä¸¤ä¸ªé—®é¢˜ï¼š</p>
<p>1ã€ä»user inputsä¸­è¯†åˆ«å‡ºuser intentå’Œå¯¹åº”çš„actionã€‚</p>
<p>2ã€ä»user inputsä¸­æŠ½å–å‡ºé¢„å…ˆè®¾å®šå¥½çš„entity valueï¼Œä½œä¸ºactionçš„parameterã€‚</p>
<p>NLGåœ¨api.aiè¿™é‡ŒåŸºæœ¬ä¸Šé€šè¿‡developeråœ¨Intentä¸­è®¾å®šresponseï¼Œå½“è¯†åˆ«å‡ºæ˜¯å“ªä¸ªintentä¹‹åï¼Œresponseè‡ªç„¶å°±æœ‰äº†ï¼Œæœ€å¤šç©ºä¸€äº›slotï¼Œç”¨ç»“æœè¿›è¡Œå¡«å……ã€‚å¦‚æœdeveloperé€‰æ‹©äº†webhookï¼Œå³éœ€è¦ä»è‡ªå®šä¹‰çš„web serviceä¸­ç»™å®šresponseã€‚å¦‚ä¸‹å›¾ï¼š<br><img src="media/9.png" alt="9"></p>
<p>è·‘äº†ä¸€ä¸ªç®€å•åœºæ™¯çš„chatbot demoä¹‹åï¼Œç®€å•å½’çº³ä¸‹æ„å»ºæ–¹æ³•ï¼š</p>
<p>1ã€ä»ç‰¹å®šä»»åŠ¡ä¸­å½’çº³å‡ºIntentsã€Actionsã€Entitiesã€‚</p>
<p>2ã€åˆ†åˆ«ç¼–å†™Intentsã€Entitiesçš„examplesï¼Œä¸¤ç±»examplesæ˜¯åšDSTçš„åŸºç¡€ï¼Œç”¨æ¥è®­ç»ƒchatbotå‡†ç¡®åœ°è¯†åˆ«user intentså’Œentity parametersï¼Œè‡³äºç®—æ³•ï¼Œè‡ªå·±å†™ä¹Ÿå¯ä»¥ï¼Œç”¨api.aiä¹Ÿå¯ä»¥ã€‚</p>
<p>3ã€åšå¥½DSTä¹‹åï¼Œchatbotå°±çŸ¥é“ç”¨æˆ·çš„æ„å›¾å’Œç›¸åº”çš„å‚æ•°ï¼Œä¸¢ç»™åå°çš„web serviceå»æ‰§è¡Œï¼Œå¹¶å¾—åˆ°æ‰§è¡Œçš„ç»“æœï¼Œç„¶åå¡«å……é¢„å…ˆå®šä¹‰å¥½çš„templatesï¼Œç”Ÿæˆresponseï¼Œè¿”å›ç»™ç”¨æˆ·ã€‚</p>
<h1 id="ç»“æŸè¯­"><a href="#ç»“æŸè¯­" class="headerlink" title="ç»“æŸè¯­"></a>ç»“æŸè¯­</h1><p>ç®€å•åœºæ™¯çš„chatbotå…³é”®ä¹‹å¤„åœ¨äºåšå¥½DSTï¼Œæœ‰ä¸€ä¸ªå«Dialogue State Tracking Challengeçš„æ¯”èµ›æ­£å¼ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜è€Œä¸¾åŠçš„ã€‚æˆ‘ä»¬è¯´ï¼Œå°é—­åŸŸçš„chatbotæ¶‰åŠä¸¤ä¸ªæ–¹é¢ï¼Œä¸€æ˜¯NLUï¼Œä¸€æ˜¯NLGï¼Œå‰è€…é€šè¿‡å¤§é‡çš„examplesæ¥å­¦ä¹ ä¸€ä¸ªåˆ†ç±»å™¨å’ŒæŠ½å–å™¨ï¼Œå¾—åˆ°Dialogue Stateï¼Œè€Œåè€…æ ¹æ®Dialogue Stateï¼Œç”Ÿæˆåˆé€‚çš„responseã€‚</p>
<p>NLUä¸æ˜¯ä¸€ä¸ªç®€å•çš„äº‹æƒ…ï¼Œå°¤å…¶æ˜¯æ ‡æ³¨å¤§é‡çš„examplesä¸æ˜¯é‚£ä¹ˆå®¹æ˜“ï¼›NLGåŒæ ·ä¹Ÿä¸æ˜¯ä¸€ä¸ªå¥½è§£å†³çš„é—®é¢˜ï¼Œé¢„å…ˆå®šä¹‰çš„templateä¼šè®©chatbotå—é™åˆ¶äºtemplateçš„å¤šå°‘ï¼Œæ‰‹å·¥ç—•è¿¹å¤ªé‡ï¼Œéœ€è¦ä¸€ç§æ›´ç‰›çš„è§£å†³æ–¹æ¡ˆæ¥ä»£æ›¿ã€‚ï¼ˆå…¶å®æŒºå¤špaperéƒ½åœ¨åšè¿™ä»¶äº‹æƒ…ï¼ŒPaperWeeklyä¹Ÿåˆ†äº«è¿‡å‡ ç¯‡ç›¸å…³çš„paperï¼Œdata drivençš„NLGæ–¹æ¡ˆåŒæ ·éœ€è¦å¤§é‡çš„examplesåšè®­ç»ƒã€‚ï¼‰</p>
<p>Contextæ˜¯ä¸ªæŒºéš¾çš„äº‹æƒ…ï¼Œç°æœ‰çš„ã€æˆç†Ÿçš„è§£å†³æ–¹æ¡ˆä»æ˜¯æ‰‹å·¥æ¥å®šä¹‰æ¡ä»¶ï¼Œç„¶åæ ¹æ®æ¡ä»¶æ¥triggerã€‚æˆ‘åœ¨æƒ³ï¼Œèƒ½å¦æ„å»ºä¸€ä¸ªåŠ¨æ€çš„DSTï¼Œå¯ä»¥æ˜¯ä¸€å¼ åŠ¨æ€hash tableï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªåŠ¨æ€graphï¼Œè®°å½•ç€æŸä¸€ä¸ªuseræ–¹æ–¹é¢é¢çš„çŠ¶æ€ï¼Œè€Œä¸ä»…ä»…æ˜¯æŸä¸€è½®å¯¹è¯ä¸­æŠ½å–å‡ºçš„ä¿¡æ¯ï¼Œè€Œæ˜¯å¤šè½®å¯¹è¯ä¸­çš„ä¿¡æ¯ï¼Œä¸ä»…åœ¨intentè¯†åˆ«ä¸­å¯ä»¥ç”¨åˆ°contextï¼Œåœ¨ç”Ÿæˆresponseæ—¶ä¹Ÿå¯ä»¥ç”¨åˆ°ï¼Œå¤šè½®å¯¹è¯å’Œä¸ªæ€§åŒ–å¯¹è¯éƒ½å°†ä¸æ˜¯ä»€ä¹ˆé—®é¢˜äº†ã€‚æˆ–è€…ï¼Œç”¨ç°åœ¨æµè¡Œçš„è¡¨ç¤ºå­¦ä¹ æ€ç»´æ¥æƒ³è¿™ä¸ªé—®é¢˜çš„è¯ï¼Œä¹Ÿè®¸contextå¯ä»¥æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼è¡¨ç¤ºï¼Œuser profileä¹Ÿæ˜¯ä¸€ä¸ªè¡¨ç¤ºï¼ŒNLGæ—¶ä»¥context distributionä¸ºconditionæ¥åšgeneratationã€‚</p>
<p>æœ¬æ–‡ä»‹ç»äº†æ„å»ºç®€å•åœºæ™¯ä¸‹chatbotçš„ä¸€èˆ¬æ–¹æ³•ï¼Œç”¨api.aiç¡®å®å¾ˆå®¹æ˜“åšä¸€ä¸ªchatbotï¼Œè€Œå¯¹äºå¤æ‚åœºæ™¯ï¼Œæˆ‘è§‰å¾—ç”¨api.aiæ¥å¼€å‘ä¹Ÿæ²¡æœ‰å¤ªå¤§é—®é¢˜ï¼Œæœ€è´¹æ—¶çš„å¯èƒ½æ˜¯æ„å»ºcontext triggerã€‚api.aiå› ä¸ºæ˜¯é¢å‘developerçš„ï¼Œæ‰€ä»¥å¯¹äºæ™®é€šçš„ç”¨æˆ·å¹¶ä¸é€‚åˆï¼Œä½†å¯¹äºæœ‰ä¸€å®šç»éªŒçš„developeræ¥è¯´ï¼Œä½¿ç”¨èµ·æ¥å°±éå¸¸ç®€å•ï¼Œæä¾›çš„webç•Œé¢ä¹Ÿå¾ˆå¥½ç”¨ï¼Œå¦‚æœè¯´chatbotæ˜¯ä¸€ä¸ªå¹³å°çš„è¯ï¼Œé‚£ä¹ˆapi.aiæ­£åƒæ˜¯ä¸€ä¸ªå¼€å‘å·¥å…·ï¼Œæé«˜äº†å¼€å‘chatbotçš„æ•ˆç‡ï¼Œè™½ç„¶NLGå’Œcontextè¿™ä¸¤ä¸ªé—®é¢˜å¯ä»¥åšçš„æ›´å¥½ï¼Œä½†æ•´ä½“æ¥è¯´é™ä½äº†å¼€å‘chatbotçš„é—¨æ§›ï¼Œæ˜¯ä¸ªå¾ˆæœ‰æ„ä¹‰å’Œé’±æ™¯çš„æœåŠ¡ã€‚</p>
<h1 id="PaperWeeklyæ‹›äººå¹¿å‘Š"><a href="#PaperWeeklyæ‹›äººå¹¿å‘Š" class="headerlink" title="PaperWeeklyæ‹›äººå¹¿å‘Š"></a>PaperWeeklyæ‹›äººå¹¿å‘Š</h1><p>PaperWeeklyæ¯å‘¨ä¼šåˆ†äº«Nç¯‡å½“ä¸‹æœ€æµè¡Œã€æœ€æœ‰è¶£çš„NLP paperï¼Œæ—¨åœ¨ç”¨æœ€ç²¾ç‚¼çš„è¯è¯´æ˜ç™½paperçš„è´¡çŒ®å’Œåˆ›æ–°ã€‚ç›®å‰è¿è¥åœ¨å…¬ä¼—å·å’ŒçŸ¥ä¹ä¸“æ ä¸¤ä¸ªå¹³å°ä¸Šï¼Œç°åœ¨çš„å½¢å¼æ˜¯æ¯å‘¨åˆ†äº«ä¸€ç¯‡NLP Paperå‘¨æŠ¥ï¼Œå¶å°”ä¹Ÿä¼šå†™ä¸€äº›NLPç›¸å…³çš„åšå®¢ï¼Œç”±äºæœ¬äººç²¾åŠ›å’Œæ°´å¹³æœ‰é™ï¼Œç°é‚€è¯·å„ä½å¯¹NLPæŠ€æœ¯ã€NLP Paperæ„Ÿå…´è¶£çš„ç«¥é‹åŠ å…¥ä¸€åŒè¿è¥ï¼Œåœ¨æ¨è¿›å›½å†…NLPæŠ€æœ¯å‘å±•çš„è·¯ä¸Šè´¡çŒ®ä¸€ä»½è‡ªå·±çš„åŠ›é‡ã€‚</p>
<p>å¾®ä¿¡å…¬ä¼—å·ï¼šPaperWeekly</p>
<p><img src="media/qrcode.jpg" alt="qrcode"></p>
<p>çŸ¥ä¹ä¸“æ ï¼š<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">PaperWeekly</a></p>
<p>å¾®ä¿¡äº¤æµç¾¤ï¼š</p>
<p><img src="media/paperweekly.jpg" alt="paperweekly"></p>
<p>ç¾¤å·²æ»¡100äººï¼Œæ— æ³•æ‰«ç åŠ ç¾¤ï¼Œå¤§å®¶åŠ zhangjun168305ï¼Œæˆ‘æ‹‰å¤§å®¶å…¥ç¾¤ã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-16T23:53:50.000Z"><a href="/2016/08/16/PaperWeekly-ç¬¬äºŒæœŸ/">2016-08-16</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/16/PaperWeekly-ç¬¬äºŒæœŸ/">PaperWeekly ç¬¬äºŒæœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•"><a href="#å¼•" class="headerlink" title="å¼•"></a>å¼•</h1><p><img src="media/1.png" alt="1"><br>å›¾ç‰‡æ¥è‡ªpaper <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" target="_blank" rel="external">The Dialog State Tracking Challenge Series- A Review</a></p>
<p>äººæœºå¯¹è¯ç³»ç»Ÿé€šå¸¸åŒ…æ‹¬ä¸Šé¢çš„å‡ ä¸ªéƒ¨åˆ†ï¼Œtask-oriented chatboté‡ç‚¹å…³æ³¨çš„æ˜¯DSTå’ŒNLGé—®é¢˜ï¼Œå…¶ä¸­DSTæ˜¯æ ¸å¿ƒé—®é¢˜ï¼Œæ²¡æœ‰å¤ªå¤šå…³æ³¨è¿™ä¸ªæ¯”èµ›ï¼Œä½†ä¸ªäººç†è§£DSTçš„ä½œç”¨ç±»ä¼¼äºä¸€å¼ user conversation logsçŠ¶æ€è¡¨ï¼Œè®°å½•ç€ç”¨æˆ·å½“å‰çš„çŠ¶æ€ï¼Œä»¥è®¢æœºç¥¨ä¸ºä¾‹ï¼Œè¿™å¼ è¡¨çš„keyæ˜¯é¢„å…ˆè®¾å®šå¥½çš„slotsï¼Œæ¯”å¦‚ç›®çš„åœ°ã€å‡ºå‘åœ°ã€å‡ºå‘æ—¶é—´ç­‰ç­‰ï¼Œä¸ç³»ç»ŸèƒŒåçš„ä¸šåŠ¡æ•°æ®è¡¨ä¸­çš„attributesç›¸å…³è”ï¼Œä¸æ–­åœ°ä»user conversationä¸­æŠ½å–ç›¸åº”çš„valuesæ¥å¡«å……è¿™ä¸ªè¡¨æ ¼ï¼Œæˆ–è€…å°†å…¶å®šä¹‰ä¸ºä¸€ä¸ªå¤šåˆ†ç±»ä»»åŠ¡ï¼Œä¸æ–­åœ°ä»å¯¹è¯ä¸­åˆ¤æ–­è¿™å¥è¯ä¸­åŒ…æ‹¬å“ªäº›slotså’Œvaluesï¼ˆè¿™é‡Œçš„valuesæ˜¯å¤šä¸ªåˆ†ç±»ç»“æœï¼‰ï¼Œå½“çŠ¶æ€è¡¨ä¸­çš„ä¿¡æ¯å­˜åœ¨ç©ºç™½æ—¶ï¼Œbotä¼šæ ¹æ®ç©ºç™½çš„slotsæ¥æé—®å¹¶è·å–valuesï¼Œç›´åˆ°è·å–åˆ°è¶³å¤Ÿçš„slotsï¼Œç»™å‡ºç”¨æˆ·suggestionï¼Œæˆ–è€…è¿›è¡Œç›¸åº”çš„æœåŠ¡ã€‚</p>
<p>DSTçš„é—®é¢˜è§£å†³ä¹‹åï¼Œå°±æ˜¯NLGçš„é—®é¢˜ã€‚ä¼ ç»Ÿçš„NLGé‡‡ç”¨rule-basedæˆ–è€…template-basedçš„æ–¹æ³•ï¼Œéœ€è¦å¾ˆå¤šçš„æ‰‹åŠ¨è®¾ç½®ï¼Œæ¨ªå‘æ‰©å±•æ€§è¾ƒå·®ï¼Œç»´æŠ¤æˆæœ¬é«˜ã€‚æœ€è¿‘æµè¡Œçš„end-to-endæ–¹æ¡ˆå¾ˆé€‚åˆè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç»™å®šç”¨æˆ·çš„queryï¼Œç»“åˆç€å½“å‰DSTï¼Œè‡ªåŠ¨ç”Ÿæˆresponseï¼Œå®Œå…¨çš„data drivenï¼Œä¸éœ€è¦ä»€ä¹ˆäººå·¥å¹²é¢„ã€‚</p>
<p>ç”Ÿæˆresponseé™¤äº†rule-basedå’Œend-to-endçš„æ–¹æ³•ä¹‹å¤–ï¼Œå·¥ä¸šç•Œä¸­æ›´åŠ å¸¸è§çš„æ˜¯retrieve-basedçš„æ–¹æ³•ï¼Œå³ä»åºå¤§çš„example baseä¸­è¿›è¡Œretrieveï¼Œä¸€æ–¹é¢é¿å…äº†NLGç”Ÿæˆresponseæ—¶å¸¸é‡åˆ°çš„grammaticalé—®é¢˜ï¼Œå¦ä¸€æ–¹é¢å½“å‰çš„IRæŠ€æœ¯å¾ˆå®¹æ˜“é›†æˆåˆ°æ­¤ç±»botç³»ç»Ÿä¸­ï¼Œé™ä½äº†é—¨æ§›ã€‚</p>
<p>æœ¬æœŸçš„ä¸‰ç¯‡paperä¸­å‰ä¸¤ç¯‡éƒ½æ˜¯å…³äºtask-oriented botçš„NLGé—®é¢˜ï¼Œç¬¬ä¸‰ç¯‡æ˜¯åœ¨retrieve-based botçš„æ¯ä¸ªç»†å°ç¯èŠ‚ä¸­åº”ç”¨äº†deep learningæŠ€æœ¯ï¼Œå¹¶ä¸”å°†å¤–éƒ¨çš„éç»“æ„åŒ–æ–‡æœ¬ä½œä¸ºæ•°æ®æºï¼Œä»ä¸­select responsesã€‚</p>
<h1 id="Semantically-Conditioned-LSTM-based-Natural-Language-Generation-for-Spoken-Dialogue-Systems"><a href="#Semantically-Conditioned-LSTM-based-Natural-Language-Generation-for-Spoken-Dialogue-Systems" class="headerlink" title="Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems"></a><a href="http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP199.pdf" target="_blank" rel="external">Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems</a></h1><h2 id="å…³é”®è¯ï¼šNLGã€botã€è‡ªå®šä¹‰LSTM"><a href="#å…³é”®è¯ï¼šNLGã€botã€è‡ªå®šä¹‰LSTM" class="headerlink" title="å…³é”®è¯ï¼šNLGã€botã€è‡ªå®šä¹‰LSTM"></a>å…³é”®è¯ï¼šNLGã€botã€è‡ªå®šä¹‰LSTM</h2><h2 id="æ¥æºï¼šEMNLP-2015"><a href="#æ¥æºï¼šEMNLP-2015" class="headerlink" title="æ¥æºï¼šEMNLP 2015"></a>æ¥æºï¼šEMNLP 2015</h2><h2 id="é—®é¢˜ï¼štask-oriented-bot-NLGé—®é¢˜ï¼Œç»™å®šäº†user-queryå’ŒDSTï¼Œå¦‚ä½•ç”Ÿæˆä¸€ä¸ªæ›´å¥½çš„responseï¼Ÿ"><a href="#é—®é¢˜ï¼štask-oriented-bot-NLGé—®é¢˜ï¼Œç»™å®šäº†user-queryå’ŒDSTï¼Œå¦‚ä½•ç”Ÿæˆä¸€ä¸ªæ›´å¥½çš„responseï¼Ÿ" class="headerlink" title="é—®é¢˜ï¼štask-oriented bot NLGé—®é¢˜ï¼Œç»™å®šäº†user queryå’ŒDSTï¼Œå¦‚ä½•ç”Ÿæˆä¸€ä¸ªæ›´å¥½çš„responseï¼Ÿ"></a>é—®é¢˜ï¼štask-oriented bot NLGé—®é¢˜ï¼Œç»™å®šäº†user queryå’ŒDSTï¼Œå¦‚ä½•ç”Ÿæˆä¸€ä¸ªæ›´å¥½çš„responseï¼Ÿ</h2><h2 id="æ–¹æ³•ï¼š"><a href="#æ–¹æ³•ï¼š" class="headerlink" title="æ–¹æ³•ï¼š"></a>æ–¹æ³•ï¼š</h2><p>é¦–å…ˆå®šä¹‰äº†ä¸¤ä¸ªæ¦‚å¿µdelexicalisationå’Œlexicalisationï¼Œå‰ä¸€ä¸ªçš„æ„æ€æ˜¯å°†å¥å­ä¸­çš„slot-valueç”¨ç‰¹å®šçš„tokenæ¥æ›¿æ¢ï¼Œåƒæ˜¯ä¸€ç§æŠ½è±¡ï¼Œæ¯”å¦‚ç”¨foodæ¥ä»£æ›¿å¯¹è¯ä¸­çš„å„ç§é£Ÿç‰©åç§°ï¼›åä¸€ä¸ªçš„æ„æ€æ˜¯å°†å¥å­ä¸­çš„ç‰¹å®štokenè¿˜åŸå›å…·ä½“çš„valueã€‚</p>
<p>æœ¬æ–‡æœ€å¤§çš„äº®ç‚¹åœ¨äºå°†ä¼ ç»Ÿçš„LSTMé‡æ–°å®šä¹‰ï¼Œé’ˆå¯¹è¿™ä¸ªå…·ä½“é—®é¢˜åœ¨LSTM celléƒ¨åˆ†ä¸­æ·»åŠ äº†ä¸€å±‚ï¼ŒDialogue Act Cellï¼Œé€šè¿‡gateæœºåˆ¶æ¥ä¿ç•™åˆé€‚çš„ä¿¡æ¯ï¼Œæ¯”å¦‚slot keywordsï¼Œå¦‚ä¸‹å›¾ï¼š</p>
<p><img src="media/2.png" alt="2"></p>
<p>è¿™ä¸€å±‚cellæ›´åƒæ˜¯ä¸€ä¸ªkeyword detectorsï¼Œæ•´ä¸ªNLGä»æ˜¯é‡‡ç”¨encoder-decoderæ¡†æ¶ã€‚</p>
<h2 id="è¯„è®ºï¼š"><a href="#è¯„è®ºï¼š" class="headerlink" title="è¯„è®ºï¼š"></a>è¯„è®ºï¼š</h2><p>è¿™å±‚Dialogue Act Cellçš„ç›®çš„æ˜¯ç¡®ä¿åœ¨decodingéƒ¨åˆ†ï¼Œä¸ä¼šé—æ¼ä»»ä½•ä¸€ä¸ªslotï¼Œæ‰€ä»¥ä¸“é—¨å¢åŠ äº†ä¸€å±‚cellæ¥encoding actã€slot-valueä¿¡æ¯ï¼Œåœ¨ç”Ÿæˆæ—¶ä½œä¸ºcontext vectorã€‚æˆ‘è§‰å¾—modelçš„è¿™ä¸ªè®¾è®¡ä¸attentionæœºåˆ¶æœ‰ä¸€ç‚¹ç±»ä¼¼ï¼Œåªæ˜¯attentionæ›´åŠ åœ°å¹³æ»‘ï¼Œå¯¹æ¯ä¸ªwordéƒ½æœ‰ä¸€ä¸ªweightï¼Œè€Œä¸æ˜¯æœ¬æ–‡ä¸­çš„gateï¼Œé0å³1ã€‚æ•´ä½“æ¥è¯´ï¼Œè‡ªå®šä¹‰çš„cellæ˜¯ä¸€ä¸ªå¾ˆæœ‰å¯å‘æ€§çš„æ€è·¯ï¼Œé’ˆå¯¹å…·ä½“é—®é¢˜çš„ç‰¹ç‚¹ï¼Œä¿®æ”¹ç°æœ‰çš„cellç»“æ„ï¼Œä¹Ÿè®¸ä¼šèµ·åˆ°éå¸¸å…³é”®çš„ä½œç”¨ã€‚</p>
<h1 id="Natural-Language-Generation-in-Dialogue-using-Lexicalized-and-Delexicalized-Data"><a href="#Natural-Language-Generation-in-Dialogue-using-Lexicalized-and-Delexicalized-Data" class="headerlink" title="Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data"></a><a href="http://101.110.118.75/128.84.21.199/pdf/1606.03632v1.pdf" target="_blank" rel="external">Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data</a></h1><h2 id="å…³é”®è¯ï¼šNLGã€botã€è‡ªå®šä¹‰LSTM-1"><a href="#å…³é”®è¯ï¼šNLGã€botã€è‡ªå®šä¹‰LSTM-1" class="headerlink" title="å…³é”®è¯ï¼šNLGã€botã€è‡ªå®šä¹‰LSTM"></a>å…³é”®è¯ï¼šNLGã€botã€è‡ªå®šä¹‰LSTM</h2><h2 id="æ¥æºï¼šarXiv-2016-06-11-cs-CL"><a href="#æ¥æºï¼šarXiv-2016-06-11-cs-CL" class="headerlink" title="æ¥æºï¼šarXiv 2016.06.11 cs.CL"></a>æ¥æºï¼šarXiv 2016.06.11 cs.CL</h2><h2 id="é—®é¢˜ï¼štask-oriented-bot-NLGé—®é¢˜ï¼Œæ˜¯ç¬¬ä¸€ç¯‡çš„å‡çº§ç‰ˆã€‚"><a href="#é—®é¢˜ï¼štask-oriented-bot-NLGé—®é¢˜ï¼Œæ˜¯ç¬¬ä¸€ç¯‡çš„å‡çº§ç‰ˆã€‚" class="headerlink" title="é—®é¢˜ï¼štask-oriented bot NLGé—®é¢˜ï¼Œæ˜¯ç¬¬ä¸€ç¯‡çš„å‡çº§ç‰ˆã€‚"></a>é—®é¢˜ï¼štask-oriented bot NLGé—®é¢˜ï¼Œæ˜¯ç¬¬ä¸€ç¯‡çš„å‡çº§ç‰ˆã€‚</h2><h2 id="æ–¹æ³•ï¼š-1"><a href="#æ–¹æ³•ï¼š-1" class="headerlink" title="æ–¹æ³•ï¼š"></a>æ–¹æ³•ï¼š</h2><p>æœ¬æ–‡æ˜¯é’ˆå¯¹ç¬¬ä¸€ç¯‡æ–‡ç« è¿›è¡Œçš„æ”¹è¿›ç‰ˆï¼Œæ”¹è¿›çš„åœ°æ–¹åœ¨äºä¸ä»…ä»…åˆ©ç”¨äº†delexicalisationè¿›è¡Œè®­ç»ƒï¼Œè€Œä¸”åˆ©ç”¨äº†lexicalisationæ•°æ®ï¼Œä»è€Œæé«˜äº†å‡†ç¡®ç‡ï¼ŒåŸºæœ¬çš„æ¨¡å‹æ¡†æ¶ä¸ç¬¬ä¸€ç¯‡æ–‡ç« ç±»ä¼¼ï¼Œä¸åŒçš„åœ¨äºè¾“å…¥çš„å¤„ç†ï¼Œå°±æ˜¯dialogue actçš„è¡¨ç¤ºï¼Œå¦‚ä¸‹å›¾ï¼š</p>
<p><img src="media/3.png" alt="3"></p>
<p>æ¯ä¸€ä¸ªact representationç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼Œä¸€éƒ¨åˆ†æ˜¯actã€slotsçš„one-hotè¡¨ç¤ºï¼Œä¸æ–‡ç« ä¸€ç±»ä¼¼çš„ç»“æ„ï¼Œå¦ä¸€éƒ¨åˆ†æ˜¯ç”±valueçš„æ¯ä¸ªword embeddingç»„åˆè€Œæˆã€‚</p>
<p>task-oriented bot NLGå­˜åœ¨çš„ä¸€ä¸ªæ›´åŠ ç°å®çš„é—®é¢˜æ˜¯dataè§„æ¨¡å¤ªå°ï¼Œcoverçš„featureså¤ªå°‘ï¼Œç”Ÿæˆè´¨é‡ä¸é«˜ï¼Œæœ¬æ–‡é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œç”¨ç›¸ä¼¼domainçš„ã€å¤§é‡çš„reviewsæˆ–è€…å…¶ä»–ç›¸å…³æ•°æ®ä½œä¸ºcorpusé¢„è®­ç»ƒå‡ºä¸€ä¸ªæ•ˆæœä¸é”™çš„LMï¼Œåœ¨decodingéƒ¨åˆ†é‡‡ç”¨é¢„è®­ç»ƒå¥½çš„LMæ¨¡å‹æƒé‡è¿›è¡ŒNLGã€‚</p>
<h2 id="è¯„è®ºï¼š-1"><a href="#è¯„è®ºï¼š-1" class="headerlink" title="è¯„è®ºï¼š"></a>è¯„è®ºï¼š</h2><p>æœ¬æ–‡ä¸­æœ€å€¼å¾—å€Ÿé‰´çš„åœ°æ–¹åœ¨äºtransfer learningï¼Œè™½ç„¶DLæ•ˆæœå¾ˆå¥½ï¼Œä½†å®é™…åº”ç”¨ä¸­å¸¸å¸¸é‡åˆ°dataè§„æ¨¡å¤ªå°çš„é—®é¢˜ï¼ŒDLéš¾ä»¥å‘æŒ¥ä½œç”¨ï¼Œä½†å¦‚æœä»å¤§é‡ç›¸ä¼¼çš„domain dataä¸­å­¦ä¹ ä¸€äº›è¡¨ç¤ºæ¨¡å‹ï¼Œç„¶åè¿ç§»åˆ°å¾…è§£å†³çš„é—®é¢˜ä¸Šï¼Œè¿™æ˜¯ä¸€ä»¶å¹¸äº‹ï¼Œä¹Ÿå°±æ˜¯äººä»¬å¸¸è¯´çš„ä¸¾ä¸€åä¸‰ã€‚æ··åˆå¤§é‡çš„ç›¸ä¼¼domainæ•°æ®ï¼Œä¼šcoveråˆ°æ›´ä¸°å¯Œçš„featuresï¼Œä¸ºDLæä¾›äº†å¹¿é˜”çš„èˆå°ã€‚</p>
<h1 id="DocChat-An-Information-Retrieval-Approach-for-Chatbot-Engines-Using-Unstructured-Documents"><a href="#DocChat-An-Information-Retrieval-Approach-for-Chatbot-Engines-Using-Unstructured-Documents" class="headerlink" title="DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents"></a><a href="http://aclweb.org/anthology/P16-1049" target="_blank" rel="external">DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents</a></h1><h2 id="å…³é”®è¯ï¼šRetrieve-Based-Botï¼ŒUnstructured-Documents"><a href="#å…³é”®è¯ï¼šRetrieve-Based-Botï¼ŒUnstructured-Documents" class="headerlink" title="å…³é”®è¯ï¼šRetrieve-Based Botï¼ŒUnstructured Documents"></a>å…³é”®è¯ï¼šRetrieve-Based Botï¼ŒUnstructured Documents</h2><h2 id="æ¥æºï¼šACL-2016"><a href="#æ¥æºï¼šACL-2016" class="headerlink" title="æ¥æºï¼šACL 2016"></a>æ¥æºï¼šACL 2016</h2><h2 id="é—®é¢˜ï¼šå¦‚ä½•ä»å¤§é‡éç»“æ„åŒ–æ–‡æœ¬ä¸­selectå‡ºåˆé€‚çš„responseè¿”å›ç»™ç”¨æˆ·ï¼Ÿ"><a href="#é—®é¢˜ï¼šå¦‚ä½•ä»å¤§é‡éç»“æ„åŒ–æ–‡æœ¬ä¸­selectå‡ºåˆé€‚çš„responseè¿”å›ç»™ç”¨æˆ·ï¼Ÿ" class="headerlink" title="é—®é¢˜ï¼šå¦‚ä½•ä»å¤§é‡éç»“æ„åŒ–æ–‡æœ¬ä¸­selectå‡ºåˆé€‚çš„responseè¿”å›ç»™ç”¨æˆ·ï¼Ÿ"></a>é—®é¢˜ï¼šå¦‚ä½•ä»å¤§é‡éç»“æ„åŒ–æ–‡æœ¬ä¸­selectå‡ºåˆé€‚çš„responseè¿”å›ç»™ç”¨æˆ·ï¼Ÿ</h2><h2 id="æ–¹æ³•ï¼š-2"><a href="#æ–¹æ³•ï¼š-2" class="headerlink" title="æ–¹æ³•ï¼š"></a>æ–¹æ³•ï¼š</h2><p>æœ¬æ–‡ç ”ç©¶çš„é—®é¢˜æ˜¯ç»™å®šå¤§é‡çš„éç»“æ„åŒ–çš„documentså’Œç”¨æˆ·çš„queryï¼Œä»ä¸­é€‰æ‹©å¹¶è¿”å›ä¸€ä¸ªæ»¡æ„çš„responseï¼Œå…¸å‹çš„IRé—®é¢˜ï¼Œä½œè€…å°†è§£å†³æ–¹æ¡ˆåˆ†ä¸ºä¸‰æ­¥ï¼š</p>
<p>1ã€responseæ£€ç´¢ï¼Œæ ¹æ®queryï¼Œä»documentsä¸­æ‰¾åˆ°åˆé€‚çš„Nå¥è¯ä½œä¸ºå€™é€‰ã€‚</p>
<p>2ã€responseæ’åºï¼Œå°†å€™é€‰ä¸­çš„utterancesè¿›è¡Œæ’åºã€‚</p>
<p>æœ¬æ–‡å¤§å¤šæ•°çš„å·¥ä½œåœ¨ranking modelä¸Šï¼Œæå‡ºäº†7ç§levelçš„featuresæ¥å¯¹candidateè¿›è¡Œæ‰“åˆ†ï¼Œé€šè¿‡å®éªŒå‘ç°sentence-level featureæœ€æœ‰åŒºåˆ†åº¦ã€‚</p>
<p>3ã€responseè§¦å‘ï¼Œå¹¶ä¸æ˜¯ä¸€å®šå¯ä»¥ä»documentsæ‰¾åˆ°åˆé€‚çš„responseï¼Œæ‰€ä»¥æœ€åæ·»åŠ ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œæ¥åˆ¤æ–­æœ€ä¼˜çš„responseæ˜¯å¦åˆé€‚ï¼Œåˆé€‚åˆ™è¾“å‡ºï¼Œä¸åˆé€‚åˆ™è¾“å‡ºç©ºã€‚</p>
<h2 id="è¯„è®ºï¼š-2"><a href="#è¯„è®ºï¼š-2" class="headerlink" title="è¯„è®ºï¼š"></a>è¯„è®ºï¼š</h2><p>æœ¬æ–‡è§£å†³çš„é—®é¢˜æ€è·¯æ¯”è¾ƒç®€å•ï¼Œä½†ä¸­é—´ç”¨åˆ°äº†å¾ˆå¤šå¤æ‚çš„DL modelï¼Œä¸ªäººæ„Ÿè§‰æœ‰ç‚¹æ€é¸¡ç”¨ç‰›åˆ€ã€‚æœ¬æ–‡çš„æ€è·¯æ›´åŠ é€‚åˆinformativeå¼çš„queryï¼Œå¹¶ä¸é€‚åˆå¨±ä¹å’Œé—²èŠã€‚ä½†ç”¨å¤–éƒ¨çŸ¥è¯†ï¼Œå°¤å…¶æ˜¯å¤§é‡çš„éç»“æ„åŒ–çš„ã€å¯èƒ½è¿˜å¸¦æœ‰å™ªå£°çš„èµ„æºæ¥æä¾›responseï¼Œæ˜¯ä¸€ä¸ªå¾ˆä¸é”™çš„æ€è·¯ï¼Œå¼¥è¡¥äº†åªç”¨training dataæˆ–è€…å¾ˆæœ‰é™çš„exampleså­˜åœ¨çš„å±€é™æ€§é—®é¢˜ï¼Œå¦‚æœå¯ä»¥å°†ä¸¤è€…è¿›è¡Œç»“åˆï¼Œæ˜¯ä¸€ä¸ªéå¸¸å¥½çš„å®ç”¨æ–¹æ¡ˆã€‚</p>
<h1 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h1><p>å¼•èµ·å¤§å®¶çš„è®¨è®ºæ˜¯ä¸€ä»¶æŒºéš¾çš„äº‹æƒ…ï¼Œæ‰€ä»¥è¿™ä¸€æœŸä¸å†æå‡ºé—®é¢˜ã€‚ä¹‹å‰æœ‰åŒå­¦é—®å¦‚ä½•è¯»paperï¼Œè¿™é‡Œç®€å•åˆ†äº«ä¸€ä¸ªç®€å•çš„tipï¼Œåç»­çš„æ¯ä¸€æœŸå¯èƒ½éƒ½ä¼šåˆ†äº«ä¸€ä¸ªtipã€‚</p>
<p>1ã€å¦‚æœåˆšåˆšè¿›å…¥ä¸€ä¸ªé¢†åŸŸï¼Œå»ºè®®è¯»ä¸€äº›è¿™ä¸ªé¢†åŸŸçš„surveyæˆ–reviewç±»å‹çš„paperï¼Œè¿™ç±»å‹çš„paperåŸºæœ¬ä¸Šä¼šå°†æœ€è¿‘çš„æ–¹æ³•å½’ç±»è¿›è¡Œæ€»ç»“ï¼Œä»ä¸€ä¸ªè¾ƒé«˜çš„å±‚æ¬¡æ¥è§£è¯»æ¯ä¸€ç¯‡paperçš„è´¡çŒ®å’Œä¼˜ç¼ºç‚¹ï¼Œå¯¹å¿«é€Ÿäº†è§£ä¸€ä¸ªé¢†åŸŸå¾ˆæœ‰å¸®åŠ©ã€‚å¦‚æœä½ å…³æ³¨çš„è¿™ä¸ªé¢†åŸŸæ²¡æœ‰surveyï¼Œé‚£ä¹ˆæ­å–œä½ ï¼Œè¯´æ˜ä½ å¯èƒ½èµ°åˆ°äº†å‰æ²¿ï¼Œç”¨å…³é”®è¯å»googleä¸€ç¯‡æˆ–è€…å‡ ç¯‡ç›¸å…³çš„new paperï¼Œè¯»Related Worké‚£ä¸€èŠ‚ï¼Œç›¸ä¿¡ä½ ä¼šæœ‰æ‰€æ”¶è·ã€‚ï¼ˆæ³¨ï¼šè¿™ä¸ªæ–¹æ³•æ˜¯ä»æ¸…åå¤§å­¦åˆ˜çŸ¥è¿œåšå£«é‚£é‡Œå­¦æ¥çš„ï¼‰</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-16T16:06:36.000Z"><a href="/2016/08/16/pat-baby-and-bot/">2016-08-16</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/16/pat-baby-and-bot/">pet,baby and bot</a></h1>
  

    </header>
    <div class="entry">
      
        <p>æœ¬æ–‡çš„æƒ³æ³•æ¥æºäºæŸä¸€å¤©å¯¹å®¶é‡Œç‹—å­Hareä¸€äº›è¡Œä¸ºä»¥åŠèº«è¾¹ä¸¤ä¸ªä¸åˆ°3å²çš„å°æœ‹å‹ä¸€äº›èªæ˜è¡Œä¸ºçš„è§‚å¯Ÿå’Œæ€è€ƒï¼Œç„¶åå°†è¿™äº›è¡Œä¸ºå’Œæ€è€ƒä¸å½“å‰æµè¡Œçš„botè”ç³»ä¸€ä¸‹ï¼Œå½¢æˆäº†æœ¬æ–‡çš„å†…å®¹ã€‚</p>
<p>é¦–å…ˆï¼Œä»petèŠèµ·ã€‚æˆ‘å®¶å…»äº†ä¸€åªèªæ˜çš„å°æ³°è¿ªç‹—ï¼Œå¿ƒçœ¼ç‰¹åˆ«å¤šï¼Œä¼šæ’’å¨‡ä¼šæ‰“æ»šä¼šå®‰æ…°äººï¼Œéå¸¸èªæ˜ï¼Œä»–å«Hareã€‚Hareä»ä¸¤ä¸ªæœˆå¤§åˆ°äº†å®¶é‡Œï¼Œä»å¼€å§‹ä»€ä¹ˆéƒ½ä¸ä¼šï¼Œé€šè¿‡ä¸€å¤©å¤©åœ°è®­ç»ƒï¼Œå­¦ä¼šäº†èµ°ã€è·‘ã€è·³ã€åƒé¥­ã€å–æ°´ã€ä¸Šå•æ‰€ã€åä¸‹ã€æ¡æ‰‹å’Œå“­ã€‚å› ä¸ºä»–çš„å¤–å©†ï¼ˆæˆ‘çš„ä¸ˆæ¯å¨˜ï¼‰æ¯å¤©éƒ½å’Œä»–è¯´å¾ˆå¤šè¯ï¼Œæ•™ä»–è®¤è¯†å¾ˆå¤šä¸œè¥¿ï¼Œæ‰€ä»¥ä»–å¯ä»¥è½»æ¾åœ°åˆ†è¾¨å‡ºå“ªä¸ªç©å…·å«ä»€ä¹ˆåå­—ï¼Œå¯ä»¥è½»æ¾åœ°ç†è§£æˆ‘ä»¬è¯´çš„å¾ˆå¤šè¯ï¼Œä¸åªæ˜¯ä¸€äº›å£ä»¤ã€‚å½“æˆ‘è¯´å‡ºé—¨ä¸å¸¦ä»–ç©çš„è¯ï¼Œä»–ä¼šéå¸¸æ‚²ä¼¤ã€å¯æ€œåœ°å¼€å§‹å“­æ³£ï¼ˆçœŸçš„å’Œå°å­©å­å“­ä¸€æ¨¡ä¸€æ ·ï¼‰ï¼›å½“æˆ‘è¯´å¸¦ä»–å‡ºå»çš„æ—¶å€™ï¼Œä»–å°±ä¼šéå¸¸å…´å¥‹åœ°ä¸Šè¹¿ä¸‹è·³ï¼›å½“æˆ‘è¯´æˆ‘è¦å‡ºé—¨åŠäº‹ä¸å¯ä»¥å¸¦ä»–çš„æ—¶å€™ï¼Œä»–å°±ä¹–ä¹–ååœ¨é—¨å£ç›®é€ä½ èµ°ï¼Œä¸å“­ä¸é—¹ã€‚æ‰€ä»¥ï¼Œæˆ‘åœ¨æƒ³Hareåº”è¯¥ä¸æ˜¯ç®€å•åœ°é€šè¿‡è§‚å¯Ÿæˆ‘ä»¬çš„è„¸è‰²å’Œè¯­æ°”æ¥è¯†åˆ«æˆ‘ä»¬çš„æƒ…ç»ªï¼Œä»–å¯èƒ½çœŸçš„å¬å¾—æ˜ç™½å¾ˆå¤šçš„è¯ï¼Œä½†ä¸€å®šä¸æ˜¯å…¨éƒ¨ï¼Œå› ä¸ºä»–çš„çŸ¥è¯†å¾ˆæœ‰é™ï¼Œå¯¹è¿™ä¸ªä¸–ç•Œçš„è®¤è¯†ä¹Ÿå¾ˆæœ‰é™ã€‚Hareçš„å­¦ä¹ ç»å¤§å¤šæ•°æ˜¯ç›‘ç£å­¦ä¹ ï¼Œé€šè¿‡ä¸€äº›æ­£ä¾‹å’Œè´Ÿä¾‹è¿›è¡Œè®­ç»ƒï¼Œå¤§å¤šæ•°çš„è®­ç»ƒç”¨æ­£ä¾‹æ•ˆæœéå¸¸æ˜æ˜¾ï¼Œå”¯ç‹¬è®­ç»ƒä»–ä¸Šå•æ‰€ï¼Œç”¨äº†ä¸å°‘è´Ÿä¾‹ï¼Œè®©ä»–åƒäº†ä¸å°‘è‹¦å¤´ï¼Œè¿™ä¹Ÿå¸¦æ¥ä¸å°‘çš„å¥½å¤„ï¼Œç›‘ç£å­¦ä¹ å¾ˆèŠ±è´¹æ—¶é—´ï¼Œæ ·æœ¬çš„é‡çº§å¾ˆé‡è¦ï¼Œé€šè¿‡å¤§é‡çš„è®­ç»ƒ+æ¿€åŠ±è®©Hareå…»æˆäº†è‰¯å¥½çš„ä¹ æƒ¯ï¼Œæˆä¸ºäº†ä¸€åªå¬è¯çš„petã€‚</p>
<p>æˆ‘ä¸€ç›´åœ¨æ€è€ƒä¸€ä¸ªé—®é¢˜ï¼Œpetåœ¨å¬ä¸»äººè¯´è¯çš„æ—¶å€™ï¼Œæ˜¯å¬æ‡‚äº†æŸäº›ä»–å¯ä»¥ç†è§£çš„å…³é”®è¯è¿˜æ˜¯ä»–ç¡®å®å¬æ‡‚äº†æ•´å¥è¯ï¼Œåˆ°åº•æ˜¯å­—é¢æ„æ€è¿˜æ˜¯semantic levelå‘¢ï¼Ÿæˆ‘æƒ³ä»–åº”è¯¥æœ‰ä¸€å®šçš„è‡ªä¸»å­¦ä¹ èƒ½åŠ›ï¼Œåšåˆ°ä¸¾ä¸€åä¸‰å¯èƒ½å¾ˆéš¾ï¼Œä½†ä¸¾ä¸€åäºŒè¿˜æ˜¯æœ‰å¯èƒ½çš„ï¼Œè€Œä¸ä»…ä»…æ˜¯ä»å¤§é‡çš„examplesä¸­è¿›è¡Œå­¦ä¹ ï¼Œç¡®å®èƒ½å¤Ÿç†è§£ä¸€äº›ç®€å•çš„è¯ï¼ŒåŒä¸€ä¸ªæ„æ€çš„ä¸åŒè¯´æ³•ä»–éƒ½å¯ä»¥ç†è§£ã€‚ç§‘å­¦çš„è§£é‡Šéœ€è¦åšäº›å®éªŒæ¥ç ”ç©¶ï¼Œè¿™é‡Œæˆ‘æœ‰ä¸€äº›ç®€å•çš„è§£é‡Šï¼Œç¬¬ä¸€ï¼Œä»–æœ‰å¤§è„‘ï¼Œè™½ç„¶æ²¡æœ‰äººç±»å‘è¾¾ï¼Œä½†æ™ºå•†å¯ä»¥å’Œ5ã€6å²çš„å­©å­ç›¸åª²ç¾ï¼›ç¬¬äºŒï¼Œä»–çš„ç›‘ç£å­¦ä¹ ä¸ä»…ä»…æ˜¯ä»query-response pairsè¿™æ ·çš„examplesä¸­è¿›è¡Œï¼Œè€Œæ˜¯æ›´å¤šçš„ç»´åº¦ï¼ŒåŒ…æ‹¬æ¯ä¸€æ¬¡actionä¹‹åçš„æ¿€åŠ±rewardï¼Œåšå¯¹ä¸€æ¬¡åŠ¨ä½œä¹‹åèµ¢å¾—ä¸€ä¸ªå¥–åŠ±ï¼Œåšé”™äº†å—åˆ°æƒ©ç½šï¼Œä»–ä¸ä»…ä»…ä»ä¸»äººçš„è¯­è¨€ä¸­æ¥ç†è§£æ„æ€ï¼Œè¿˜ä¼šç»“åˆåˆ«çš„å› ç´ ï¼Œæ¯”å¦‚è¯­è°ƒã€è¯­å¢ƒã€å‰ä¸€ä¸ªæ—¶åˆ»ä»–çš„çŠ¶æ€ç­‰ç­‰ï¼Œè€Œä¸”ä»–å¯ä»¥çœ‹åˆ°ä¸»äººçš„è¡¨æƒ…å’ŒåŠ¨ä½œï¼Œè¿™äº›å› ç´ éƒ½å¯ä»¥æŠ½è±¡æˆä¸€ç§contextã€‚Hareå¦‚æœå‰ä¸€ç§’åˆšåˆšçŠ¯äº†ä½çº§é”™è¯¯ï¼Œè¿™ä¸€ç§’å¦‚æœæˆ‘æ‹¿ä¸€ä¸ªé›¶é£Ÿçš„å«ä»–è¿‡æ¥æ¥åƒçš„è¯ï¼Œä»–å°±ä¼šæ˜ç™½ï¼Œè¿™å…¶ä¸­ä¸€å®šæœ‰è¯ˆï¼Œä»–ä¸€å®šä¸ä¼šè¿‡æ¥ï¼Œè™½ç„¶æˆ‘å¹¶æ²¡æœ‰è¡¨ç°å‡ºç”Ÿæ°”çš„æ ·å­ã€‚</p>
<p>petçš„äº‹æƒ…æˆ‘ä»¬å…ˆèŠåˆ°è¿™é‡Œï¼Œæ¥ä¸‹æ¥èŠä¸€èŠbabyçš„äº‹æƒ…ã€‚</p>
<p>èº«è¾¹æ­£å¥½å¯ä»¥æ¥è§¦åˆ°ä¸¤ä¸ªä¸åˆ°ä¸‰å²çš„å°å®å®ï¼Œä¸€ä¸ªç”·å­©ä¸€ä¸ªå¥³å­©ï¼Œä»–ä»¬æœ‰å¾ˆå¤šèªæ˜çš„è¡Œä¸ºéƒ½è®©æˆ‘æ„Ÿåˆ°åƒæƒŠã€‚å…ˆä»å°ç”·å­©è¯´èµ·ï¼Œå°ç”·å­©æ¯æ¬¡æ¥ä¸€èµ·åƒé¥­çš„æ—¶å€™ï¼Œéƒ½ä¼šç»™å¤§å®¶è¡¨æ¼”ä»–çš„ç»æŠ€â€”â€”è®¤è½¦ç‰Œã€‚èµ°åœ¨è·¯ä¸Šï¼Œä½ éšæ„æŒ‡ä¸€è¾†è½¦ï¼Œä»–å‡ ä¹å¯ä»¥ä¸å‡ºé”™åœ°è¯´å‡ºè¿™è¾†è½¦æ˜¯æœ¬ç”°è¿˜æ˜¯ä¸°ç”°ã€è¿˜æ˜¯èµ·äºšï¼Œè¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„æœ‰ç›‘ç£å¤šåˆ†ç±»å­¦ä¹ ä»»åŠ¡ï¼Œä»–çš„çˆ¶æ¯æœ‰æ„æ— æ„åœ°æ•™ä»–è®¤è¯†å„ç§å„æ ·çš„è½¦ï¼Œç»è¿‡ä¸€å®šæ—¶é—´å’Œexampleçš„ç§¯ç´¯ï¼Œä»–ä¸æ–­åœ°å°†å‡†ç¡®ç‡æå‡ï¼Œå¯èƒ½å¤§è„‘çš„å‘è‚²å’Œå°†deep learningæ¨¡å‹ä¸æ–­åœ°å¤æ‚åŒ–é“ç†ç±»ä¼¼å§ã€‚å­¦ä¹ çš„è¿‡ç¨‹æ˜¯ç§¯ç´¯çŸ¥è¯†çš„è¿‡ç¨‹ï¼Œå°ç”·å­©æ…¢æ…¢åœ°è®¤è¯†äº†è¶Šæ¥è¶Šå¤šçš„è½¦å­ï¼Œå½“ç„¶è¿™éœ€è¦ä¸æ–­åœ°æ•™å’Œå­¦ï¼Œä½†æ— ç–‘ä»–æœ¬èº«å°±æ˜¯ä¸€ä¸ªçŸ¥è¯†åº“ï¼ˆknowledge baseï¼‰ï¼Œè€Œä¸”è®¤è¯†å¾ˆå¤šæˆ‘éƒ½ä¸è®¤è¯†çš„è½¦å­ï¼Œæ‰€ä»¥å½“æˆ‘é—®ä»–é‚£æ˜¯ä»€ä¹ˆè½¦çš„æ—¶å€™ï¼Œä»–æ€»æ˜¯èƒ½å¤Ÿç»™æˆ‘ä¸€ä¸ªä¸é”™çš„ç­”æ¡ˆã€‚</p>
<p>è¯´å®Œå°ç”·å­©çš„äº‹æƒ…ï¼Œå†èŠä¸€èŠå°å¥³å­©çš„äº‹æƒ…ã€‚å°å¥³å­©è¯­è¨€èƒ½åŠ›å¾ˆå¼ºï¼Œå¯ä»¥è¯´å¾ˆå¤šçš„è¯ï¼Œè€Œä¸”å¾ˆå¤šè¯éƒ½éå¸¸çš„funnyã€‚åŸºæœ¬ä¸Šå’Œå°å¥³å­©èŠå¤©ï¼Œå°±æ˜¯ä¸€ä¸ªæœ‰è¶£çš„é—®ç­”è¿‡ç¨‹ï¼Œè¿™é‡Œçš„é—®ç­”ä¸åªæ˜¯æˆ‘é—®å¥¹ç­”ï¼Œè¿˜æœ‰å¥¹é—®æˆ‘ç­”ã€‚å°å¥³å­©ç»å¸¸å’Œæˆ‘å¦ˆå¦ˆåœ¨ä¸€èµ·ï¼Œå¦ˆå¦ˆä¼šæ•™å¥¹è®¤è¯†å„ç§ä¸œè¥¿ï¼Œå› ä¸ºå¦ˆå¦ˆä¿¡åŸºç£æ•™ï¼Œä¼šæ•™å¥¹åšç¥·å‘Šï¼Œä¿ä½‘è‡ªå·±ä¸€ç”Ÿå¹³å®‰ï¼Œæ‰€ä»¥è¯´å¥¹ä¸ä»…ä»…å¯ä»¥å›ç­”ä¸€äº›åŸºæœ¬çš„è®¤çŸ¥é—®é¢˜ï¼Œè€Œä¸”æœ‰è‡ªå·±çš„ç‰¹æ®ŠæŠ€èƒ½ï¼Œè¡¨æ¼”â€œç¥·å‘Šâ€ï¼Œè€Œä¸”åšçš„æœ‰æ¨¡æœ‰æ ·ã€‚å¥¹æ˜¯ä¸ªæ±‚çŸ¥æ¬²éå¸¸å¼ºçš„é—®é¢˜å®å®ï¼Œå¥¹æ€»æ˜¯æŒ‡ç€ä¸€ä¸ªä¸œè¥¿ï¼Œç„¶åå¼€å§‹é—®æˆ‘ï¼Œâ€œè¿™æ˜¯ä¸ªä»€ä¹ˆä¸œè¥¿ï¼Ÿâ€ï¼Œå¥¹ä¸»åŠ¨å­¦ä¹ çš„æ¬²æœ›å¾ˆå¼ºï¼Œè¿™æ„å‘³ç€å¥¹çš„çŸ¥è¯†åº“ç§¯ç´¯åœ°å¾ˆå¿«ã€‚ä»¥ä¸Šéƒ½æ˜¯æ¯”è¾ƒå¸¸è§„çš„ï¼Œæœ€å€¼å¾—æ€è€ƒçš„æ˜¯å¥¹çš„åˆ›é€ åŠ›ã€‚å¥¹è®¤è¯†å¾ˆå¤šçš„åŠ¨ç‰©ï¼Œä¹ŸçŸ¥é“æ€ä¹ˆç§°å‘¼è¿™äº›åŠ¨ç‰©ï¼Œå¥¹æ ¹æ®å®¶é‡Œæ¯ä¸€ä¸ªäººçš„åå­—ï¼Œèµ·äº†ç›¸åº”çš„åŠ¨ç‰©å¤–å·ï¼Œè¿™ä¸ªä¸æ˜¯è°æ•™å¥¹çš„ï¼Œæ˜¯å¥¹è‡ªå·±è¯´å‡ºæ¥çš„ä¸œè¥¿ï¼›ä¹‹å‰æåˆ°çš„ç¥·å‘Šè¯ä¸­ï¼ŒåŸè¯åº”è¯¥æ˜¯å¸Œæœ›ä¸Šå¸å¯ä»¥èµç»™å¥¹ä¸€äº›èªæ˜æ™ºæ…§ï¼Œé‚£å¤©åœ¨ç»™æˆ‘ä»¬â€œè¡¨æ¼”â€çš„æ—¶å€™è¯´å‡ºæ¥çš„æ˜¯â€œç»™å¥¹å¼„ä¸€äº›èªæ˜æ™ºæ…§â€ï¼Œæˆ‘æƒ³è¿™ä¸ªâ€œå¼„ä¸€äº›â€ä¸€å®šæ˜¯å…¶ä»–çš„åœ°æ–¹å­¦æ¥çš„ï¼Œä½†å¥¹è¿ç§»åˆ°äº†è¿™ä¸ªè¯­å¢ƒä¸­ï¼Œè¿™ä¸ªè¿ç§»èƒ½åŠ›æ˜¯å€¼å¾—æ€è€ƒçš„ã€‚æˆ‘ä»¬éƒ½è¯´ç†è§£ä¸€ä¸ªä¸œè¥¿ä¸ç®—å‰å®³ï¼Œå¦‚æœèƒ½å¤ŸæŒæ¡æˆ–è€…æ§åˆ¶ä¸€ä¸ªä¸œè¥¿æ‰ç®—çœŸæ­£çš„å‰å®³ï¼Œå¥¹å¦‚æœåªæ˜¯ç®€å•åœ°é‡å¤å·²ç»å­¦ä¼šçš„çŸ¥è¯†ï¼Œä¹Ÿå¹¶ä¸ç¨€å¥‡ï¼Œä½†å¥¹å¶å°”ä¼šæœ‰æ„åœ°è£…ç³Šæ¶‚ï¼Œæ•…æ„åœ°è¯´ä¸€äº›é”™çš„ä¸œè¥¿çœ‹ä½ èƒ½ä¸èƒ½è¯†åˆ«å‡ºæ¥å¥¹çš„é”™è¯¯ï¼Œå¥¹å¯¹ä¸€äº›ä¿¡æ¯çš„æŒæ¡ç¨‹åº¦å¾ˆé«˜ã€‚</p>
<p>å°ç›†å‹çš„åˆ›é€ åŠ›è®©äººæƒŠå¥‡ï¼Œæœ‰å¾ˆå¤šå€¼å¾—æ€è€ƒçš„åœ°æ–¹ï¼Œç›¸æ¯”äºpetæ¥è¯´ï¼Œbabyçš„å­¦ä¹ èƒ½åŠ›æ›´å¼ºï¼Œå¸¦ç»™äººçš„æƒŠå–œåº¦æ›´å¤§ã€‚chatbotï¼Œä¸€ä¸ªçƒ­é—¨çš„topicï¼Œä¸€ä¸ªå¤§å®¶æ¯å¤©éƒ½åœ¨è°ˆè®ºçš„ä¸œè¥¿ï¼Œç¡®å®è¿˜æœ‰å¾ˆé•¿çš„è·¯è¦èµ°ï¼Œå¤ªå¤šçš„åœ°æ–¹ä¸èƒ½ä»¤äººæ»¡æ„ã€‚</p>
<p>1ã€æœ€ç®€å•çš„ä¸€é—®ä¸€ç­”ç°åœ¨éƒ½æ²¡æœ‰åšçš„å¾ˆå¥½ï¼Œexample-basedå’Œrule-basedè™½ç„¶å¯ä»¥workï¼Œä½†é™åˆ¶å¤ªå¤§ï¼Œå‰è€…è¢«exampleæ‰€é™åˆ¶ï¼Œè€Œåè€…è¢«ruleæ‰€é™åˆ¶ï¼Œè€Œpaperä¸­è¿‘ä¸€æ®µæ—¶é—´æµè¡Œçš„æ‰€è°“generativeå¼çš„botçœ‹èµ·æ¥å¥½åƒéå¸¸æ™ºèƒ½ï¼Œè¯»è¿‡paperä¹‹åä¼šå‘ç°ä»æ˜¯åŸºäºexampleç»Ÿè®¡çš„ï¼Œä¸ç®¡å¤šä¹ˆç‰›çš„æ¨¡å‹ï¼Œéƒ½æ˜¯ä»exampleä¸­å­¦ä¹ featuresï¼Œexampleçš„è§„æ¨¡å’Œç±»å‹éƒ½ä¼šä¸¥é‡åˆ¶çº¦modelï¼Œè€Œä¸”åœ¨ç”Ÿæˆresponseæ—¶é¢ä¸´ç€è¿è´¯æ€§å’Œè¯­è¨€å­¦çš„é—®é¢˜ï¼Œè¿™ä¹Ÿæ˜¯è¢«è¯Ÿç—…æœ€å¤šçš„åœ°æ–¹ï¼Œä¹Ÿå°±æ˜¯ä¸ºä»€ä¹ˆexample-based retrieveå¼çš„æ–¹æ³•ä»æ˜¯ä¸»æµçš„åŸå› ã€‚</p>
<p>2ã€botåº”è¯¥åƒäººä¸€æ ·å…·æœ‰å­¦ä¹ èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯ä¸»åŠ¨å­¦ä¹ èƒ½åŠ›ã€‚ç°åœ¨çš„botæœ‰self-taughtçš„èƒ½åŠ›ï¼Œé€šå¸¸æ¯”è¾ƒè¢«åŠ¨ï¼Œå¹¶ä¸å…·å¤‡ä¸»åŠ¨å­¦ä¹ çš„æ„è¯†å’Œèƒ½åŠ›ã€‚botå…¬å¸å®£ä¼ çš„å­¦ä¹ èƒ½åŠ›ä¹Ÿé€šå¸¸æ˜¯æŒ‡å¯¹logçš„æŒ–æ˜ï¼Œä»ä¸­æ‰¾åˆ°ä¸€äº›æœ‰ç”¨çš„ä¸œè¥¿å­˜åœ¨çŸ¥è¯†åº“é‡Œï¼Œä¸°å¯Œç°æœ‰çš„example baseã€‚botå¯ä»¥è¯•ç€å¤šæä¸€äº›questionï¼Œè€Œä¸ä»…ä»…æ˜¯åšanswerï¼Œä¸»åŠ¨åœ°å­¦ä¹ ä¸€äº›ä¸œè¥¿ã€‚</p>
<p>3ã€å¯¹contextçš„åˆ©ç”¨å’Œåˆ†æè¿˜æœ‰å¾ˆé•¿çš„è·¯è¦èµ°ï¼Œcontextæœ‰å¾ˆå¤šç§ï¼Œå¦‚æœæ˜¯çº¯ç²¹çš„è¯­è¨€botï¼Œé‚£ä¹ˆå°±æ˜¯userä¹‹å‰è¯´è¿‡çš„è¯ï¼Œuserçš„æƒ…ç»ªï¼Œuserçš„æ„å›¾ç­‰ç­‰ï¼Œå¦‚æœä¸ä»…ä»…æ˜¯è¯­è¨€çš„è¯ï¼Œæ­£å¦‚å‰é¢åœ¨è¯´petæ—¶æåˆ°çš„ï¼Œcontextå¯ä»¥åŒ…æ‹¬å›¾åƒã€è¯­è°ƒç­‰ç­‰ã€‚è€ƒè™‘çš„ä¸œè¥¿è¶Šå¤šï¼Œbotçš„å›ç­”è´¨é‡å°±ä¼šè¶Šé«˜ã€‚</p>
<p>4ã€å‰å‡ å¤©çœ‹äº†å‡ å®¶ç§‘æŠ€åª’ä½“å¯¹æ–°ä¸€ä»£å¾®è½¯å°å†°çš„æŠ¥é“ï¼Œè¯´å®è¯ä¸¢å‡ºæŒºå¤šæ¦‚å¿µçš„ï¼Œä»”ç»†çœ‹äº†ä¸‹æ˜¯ç”¨å¢å¼ºå­¦ä¹ çš„æ€è·¯æ¥åšï¼Œå’Œè®­ç»ƒpetæ¯”è¾ƒç±»ä¼¼ï¼Œç”¨ä¸€ä¸ªrewardä½œä¸ºç‰µå¼•ï¼Œå¸¦ç€botå­¦ä¹ programmerå¸Œæœ›botå­¦ä¹ çš„actionã€‚</p>
<p>5ã€äººä¼šä¸¾ä¸€åä¸‰ï¼Œèªæ˜çš„åŠ¨ç‰©ä¼šä¸¾ä¸€åäºŒï¼Œè¿ç§»èƒ½åŠ›å¾ˆé‡è¦ï¼Œbotå­¦ä¹ è¿‡ç±»ä¼¼çš„ä¸œè¥¿ï¼Œå°±åº”è¯¥å¯ä»¥åšç±»ä¼¼çš„äº‹æƒ…ï¼Œè€Œä¸æ˜¯æ¯æ¬¡éƒ½éœ€è¦é‡æ–°ä»å¤´å¼€å§‹å­¦ä¹ ï¼Œå¦‚ä½•å°†å·²ç»å­¦ä¹ åˆ°çš„çŸ¥è¯†è¿ç§»åˆ°æ–°çš„é¢†åŸŸä¹Ÿæ˜¯ä¸€ä¸ªéå¸¸æœ‰æ„ä¹‰çš„topicã€‚</p>
<p>ä»petåˆ°babyï¼Œå†åˆ°botï¼Œä»åŠ¨ç‰©åˆ°äººç±»ï¼Œå†åˆ°æœºå™¨äººï¼Œæœ‰ç€éš¾ä»¥è·¨è¶Šçš„é¸¿æ²Ÿï¼Œä½†petã€babyçš„è¡Œä¸ºå¯ä»¥å¸¦æ¥å¯å‘å’Œæ€è€ƒï¼Œç»™ç›®å‰ä»åœç•™åœ¨åˆæ­¥é˜¶æ®µçš„botå¸¦æ¥ä¸€ä¸æ˜¥é£ï¼Œä¸€ä¸å¸Œæœ›ã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-05T18:22:47.000Z"><a href="/2016/08/05/PaperWeekly-2016-08-05-ç¬¬ä¸€æœŸ/">2016-08-05</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/05/PaperWeekly-2016-08-05-ç¬¬ä¸€æœŸ/">PaperWeekly 2016.08.05 ç¬¬ä¸€æœŸ</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="å¼•"><a href="#å¼•" class="headerlink" title="å¼•"></a>å¼•</h1><p>å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„éœ€æ±‚å’Œå…³æ³¨ç‚¹ä¸åŒï¼Œå­¦æœ¯ç•Œæ›´åŠ æ³¨é‡æœªçŸ¥é¢†åŸŸçš„æ¢ç´¢å’Œæ–¹æ³•çš„åˆ›æ–°ï¼Œç ”ç©¶çš„é—®é¢˜æ¯”è¾ƒæŠ½è±¡ï¼Œè€Œå·¥ä¸šç•Œæ›´åŠ å…³æ³¨å®é™…é—®é¢˜ï¼Œæ–¹æ³•ä¸ç®¡æ˜¯å¦åˆ›æ–°ï¼Œåªè¦èƒ½å¤Ÿè§£å†³é—®é¢˜å°±æ˜¯å¥½æ–¹æ³•ï¼Œæ‰€é¢å¯¹çš„é—®é¢˜æ¯”paperä¸­æç‚¼å‡ºçš„æ•°å­¦é—®é¢˜æ›´åŠ å…·ä½“ï¼Œéœ€è¦å¤„ç†çš„ç»†èŠ‚æ›´å¤šã€‚</p>
<p>paperçš„æ°´å¹³ä¹Ÿæ˜¯è‰¯è ä¸é½ï¼Œå°¤å…¶æ˜¯arxivä¸Šåˆ·å‡ºæ¥çš„paperæ›´æ˜¯æ°´å¹³å„å¼‚ã€‚ä½†æ•´ä½“æ¥è¯´ï¼Œè¯»paperä¼šå¸¦æ¥å¾ˆå¤šçš„å¯å‘ï¼Œå¯ä»¥è·Ÿè¸ªå­¦æœ¯ç•Œå¯¹æŸä¸€ç±»é—®é¢˜çš„ç ”ç©¶è¿›å±•ï¼Œä¸æ–­åœ°æ›´æ–°æŠ€æœ¯ã€‚å…³æ³¨å·¥ä¸šç•ŒæŠ€æœ¯çš„åº”ç”¨å’Œäº§å“çš„æ›´è¿­ï¼Œå¯ä»¥ä¸æ–­åœ°æç‚¼å‡ºæ–°çš„éœ€æ±‚ã€æ–°çš„æ•°å­¦é—®é¢˜ï¼Œä»è€Œä¿ƒè¿›å­¦æœ¯åœ°å‘å±•ï¼Œä¸¤è€…å…¶å®å…³ç³»éå¸¸ç´§å¯†ã€‚</p>
<p>æœ¬å‘¨å¼€å§‹ï¼Œå°†paperweeklyè¿›è¡Œæ”¹ç‰ˆï¼Œä»ä¹‹å‰çš„æ¯å¤©ä¸€ç¯‡paperï¼Œæ”¹ä¸ºæ¯å‘¨ä¸€ç¯‡ï¼Œå†…å®¹åŒ…æ‹¬å¤šç¯‡paperï¼Œè¿™äº›paperå¯èƒ½ç›¸å…³ã€ä¹Ÿå¯èƒ½ä¸é‚£ä¹ˆç›¸å…³ï¼Œä½†ä¼šè¯´æ¸…æ¯ç¯‡paperè§£å†³çš„é—®é¢˜å’Œè§£å†³çš„æ–¹æ³•ï¼Œæ—¨åœ¨æ‹“å®½è§†é‡ï¼Œå¸¦æ¥å¯å‘ã€‚æœ¬æœŸæ˜¯æ”¹ç‰ˆåçš„ç¬¬ä¸€æœŸï¼Œå½¢å¼ä¼šä¸€ç›´ä¸æ–­åœ°æ”¹è¿›ï¼Œå¸Œæœ›å·¥ä¸šç•Œå’Œå­¦æœ¯ç•Œçš„æœ‹å‹éƒ½èƒ½å¤Ÿæœ‰æ‰€æ”¶è·ã€‚</p>
<h1 id="DeepIntent-Learning-Attentions-for-Online-Advertising-with-Recurrent-Neural-Networks"><a href="#DeepIntent-Learning-Attentions-for-Online-Advertising-with-Recurrent-Neural-Networks" class="headerlink" title="DeepIntent: Learning Attentions for Online Advertising with Recurrent Neural Networks"></a><a href="http://www.kdd.org/kdd2016/papers/files/rfp0289-zhaiA.pdf" target="_blank" rel="external">DeepIntent: Learning Attentions for Online Advertising with Recurrent Neural Networks</a></h1><h2 id="å…³é”®è¯"><a href="#å…³é”®è¯" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>åœ¨çº¿å¹¿å‘Šã€RNNã€Attention</p>
<h2 id="æ¥æº"><a href="#æ¥æº" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>kdd2016</p>
<h2 id="é—®é¢˜"><a href="#é—®é¢˜" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>å¦‚ä½•ç”¨deep learningæ¨¡å‹æŒ–æ˜click logsæ¥ç†è§£ç”¨æˆ·Intentï¼Ÿ</p>
<h2 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h2><p><img src="media/1.png" alt="1"></p>
<p>å¯¹äºä¸€ä¸ª(query,ad)æ•°æ®å¯¹ï¼Œåˆ†åˆ«ç”¨LSTM encodeï¼Œç„¶åç”¨ä¸‹å›¾çš„æ–¹æ³•è®¡ç®—ä¸€ä¸ªattentionï¼Œå¾—åˆ°æœ€ç»ˆçš„queryå’Œad vectorï¼Œæ„é€ loss functionï¼Œå–logsä¸­(query,ad)ä½œä¸ºæ­£ä¾‹d+ï¼Œå°†adæ›¿æ¢ä¸ºå…¶ä»–æ— å…³adä½œä¸ºè´Ÿä¾‹d-ï¼Œè®­ç»ƒçš„ç›®æ ‡æ˜¯è®©d+çš„scoreå°½é‡å¤§ï¼Œè®©d-çš„scoreå°½é‡å°ã€‚</p>
<p><img src="media/2.png" alt="2"></p>
<h2 id="è¯„è®º"><a href="#è¯„è®º" class="headerlink" title="è¯„è®º"></a>è¯„è®º</h2><p>å·¥ä¸šç•Œæœ‰ç€å­¦æœ¯ç•Œæ— æ³•æ¯”æ‹Ÿçš„æ•°æ®ï¼Œå¤§è§„æ¨¡çš„çœŸå®æ•°æ®æ˜¯åšdeep learningçš„åŸºç¡€ï¼Œå¤§å‹å•†ä¸šæœç´¢å¼•æ“ç§¯ç´¯äº†å¤§é‡çš„ad click logsï¼Œåˆ©ç”¨å¥½è¿™äº›logså¯ä»¥èµšåˆ°æ›´å¤šçš„é’±ã€‚attentionæœºåˆ¶åœ¨2015å¹´å¼€å§‹é€æ¸æˆä¸ºä¸€ç§æµè¡Œè¶‹åŠ¿ï¼Œå€Ÿé‰´äºäººç±»çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œè®©modelå°†æ›´å¤šçš„æ³¨æ„åŠ›æ”¾åœ¨éœ€è¦æ³¨æ„çš„åœ°æ–¹ï¼Œè€Œä¸æ˜¯æ¯ä¸€ä¸ªåœ°æ–¹ã€‚æœ¬æ–‡å¹¶æ²¡æœ‰å¤ªå¤šmodelä¸Šçš„åˆ›æ–°ï¼Œåªæ˜¯ç®€å•åœ°å°†æµè¡Œçš„modelåº”ç”¨äº†è‡ªå·±ç ”ç©¶çš„é¢†åŸŸä¸­ï¼Œå¯¹å·¥ä¸šç•Œæ›´æœ‰å‚è€ƒä»·å€¼ã€‚</p>
<h1 id="A-Neural-Knowledge-Language-Model"><a href="#A-Neural-Knowledge-Language-Model" class="headerlink" title="A Neural Knowledge Language Model"></a><a href="http://120.52.73.76/arxiv.org/pdf/1608.00318v1.pdf" target="_blank" rel="external">A Neural Knowledge Language Model</a></h1><h2 id="å…³é”®è¯-1"><a href="#å…³é”®è¯-1" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>è¯­è¨€æ¨¡å‹ã€çŸ¥è¯†å›¾è°±</p>
<h2 id="æ¥æº-1"><a href="#æ¥æº-1" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>arXiv cs.CL 2016.08.01</p>
<h2 id="é—®é¢˜-1"><a href="#é—®é¢˜-1" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>åœ¨è‡ªç„¶è¯­è¨€ç”Ÿæˆ(NLG)é—®é¢˜ä¸­ï¼Œå‡ºç°æ¬¡æ•°éå¸¸å°‘çš„entityè¯¥å¦‚ä½•ç”Ÿæˆå‘¢ï¼Ÿ</p>
<h2 id="æ–¹æ³•-1"><a href="#æ–¹æ³•-1" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h2><p><img src="media/1-2.png" alt="1"></p>
<p>å››ä¸ªæ­¥éª¤ï¼š</p>
<p>1ã€Input Representation<br><img src="media/2-1.png" alt="2"></p>
<p>è¾“å…¥ç”±ä¸‰ä¸ªéƒ¨åˆ†æ‹¼æ¥è€Œæˆï¼Œç¬¬ä¸€éƒ¨åˆ†æ˜¯ä¸Šä¸€ä¸ªtime stepçš„factè¡¨ç¤ºï¼Œç¬¬äºŒéƒ¨åˆ†æ˜¯ä¸Šä¸€ä¸ªtime stepçš„è¯è¡¨ä¸­çš„è¯è¡¨ç¤ºï¼Œç¬¬ä¸‰éƒ¨åˆ†æ˜¯ä¸Šä¸€ä¸ªtime stepçš„fact descriptionè¡¨ç¤ºï¼Œè¿™é‡Œfactå°±æ˜¯(subject,relation,object)ï¼ŒçŸ¥è¯†å›¾è°±ä¸­çš„ä¸€æ¡äº‹å®ï¼Œè€Œåä¸¤ä¸ªéƒ¨åˆ†ä¸€å®šä¼šæœ‰ä¸€ä¸ªå…¨ä¸º0ï¼Œå› ä¸ºæ˜¯äºŒé€‰ä¸€çš„å…³ç³»ï¼Œä½†ä¸ºäº†ä¿è¯æ¯ä¸€æ¬¡çš„è¾“å…¥éƒ½æ˜¯ç­‰é•¿å‘é‡ï¼Œæ‰€ä»¥ç”¨æ‹¼æ¥æ¥åšã€‚å¾—åˆ°è¾“å…¥ä¹‹åï¼Œç”¨LSTMæ¥encodeã€‚</p>
<p>2ã€Fact Prediction</p>
<p>é€šè¿‡1çš„ç»“æœæ¥é¢„æµ‹å½“å‰wordå¯èƒ½ç›¸å…³çš„factï¼Œå¾—åˆ°çš„ç»“æœæ˜¯ä¸€ä¸ªindexï¼Œç„¶åä»topic knowledgeä¸­è·å¾—ç›¸åº”çš„è¡¨ç¤ºï¼Œè¿™é‡Œçš„knowledge embeddingéƒ½æ˜¯ç”¨transEè®­ç»ƒå¥½çš„ï¼Œåœ¨æ•´ä¸ªæ¨¡å‹è®­ç»ƒä¸­å¹¶ä¸æ›´æ–°ã€‚</p>
<p>3ã€Knowledge-Copy Switch</p>
<p>æ ¹æ®1å’Œ2çš„ç»“æœï¼Œå…±åŒæ¥é¢„æµ‹å½“å‰è¦ç”Ÿæˆçš„è¯æ˜¯ä»è¯è¡¨ä¸­è·å–çš„é«˜é¢‘è¯è¿˜æ˜¯ä»knowledgeä¸­è·å–çš„entityï¼Œå…¸å‹çš„äºŒåˆ†ç±»é—®é¢˜ã€‚</p>
<p>4ã€Word Generation</p>
<p>æ ¹æ®3çš„ç»“æœï¼Œæ¥ç”Ÿæˆå½“å‰time stepçš„è¯ã€‚å¯¹äºè¯è¡¨ä¸­çš„é«˜é¢‘è¯ï¼Œå’Œä¹‹å‰çš„ç”Ÿæˆæ–¹æ³•ä¸€è‡´ï¼›å¯¹äºfact descriptionä¸­çš„entityè¯ï¼Œé€šè¿‡é¢„æµ‹è¯çš„positionæ¥copyè¿™ä¸ªè¯ã€‚</p>
<h2 id="è¯„è®º-1"><a href="#è¯„è®º-1" class="headerlink" title="è¯„è®º"></a>è¯„è®º</h2><p>è¯­è¨€æ¨¡å‹æ˜¯ä¸€ä¸ªåŸºæœ¬é—®é¢˜ï¼Œä¼ ç»Ÿçš„æ–¹æ³•éƒ½æœ‰ç€ä¸€ä¸ªå°´å°¬ä¹‹å¤„æ˜¯ï¼Œä¼šç”Ÿæˆå¤§é‡çš„<unk>å‡ºæ¥ï¼Œåªè¦æ˜¯æ¶‰åŠåˆ°NLUçš„é—®é¢˜ï¼ŒåŸºæœ¬éƒ½ä¼šé‡åˆ°è¿™ä¸ªé—®é¢˜ã€‚æœ¬æ–‡æä¾›äº†ä¸€ä¸ªå¾ˆæœ‰å¯å‘æ€§çš„æ–¹æ³•ï¼Œå€ŸåŠ©äºçŸ¥è¯†å›¾è°±è¿™ç§å¤–éƒ¨çŸ¥è¯†æ¥å¸®åŠ©ç”Ÿæˆæ•ˆæœæ›´å¥½çš„è¯ï¼Œå•çº¯åœ°é modelæ¥æå‡æ•ˆæœæ˜¯ä¸€ä»¶æ¯”è¾ƒå›°éš¾çš„äº‹æƒ…ï¼Œä½†å¢åŠ ä¸€äº›å¤–éƒ¨ä¿¡æ¯è¿›æ¥åˆ™ä¼šå¸¦æ¥æ›´å¤šçš„å¯èƒ½æ€§ã€‚ç”±äºçŸ¥è¯†å›¾è°±çš„æ„å»ºæœ¬èº«å°±æ˜¯ä¸€ä»¶ä¸æ˜“çš„äº‹æƒ…ï¼Œå› æ­¤æœ¬æ–‡çš„å­¦æœ¯æ„ä¹‰è¿œå¤§äºå®é™…åº”ç”¨æ„ä¹‰ï¼Œä¸ºåç»­è¿™ç§äº¤å‰å¼ç ”ç©¶ï¼ˆçŸ¥è¯†å›¾è°±+æ·±åº¦å­¦ä¹ ï¼‰æ‰“å¼€äº†ä¸€æ‰‡é—¨ï¼Œå¤§å®¶å¯ä»¥å°è¯•æ›´å¤šçš„ç»„åˆå’Œå¯èƒ½ã€‚</unk></p>
<h1 id="Neural-Sentence-Ordering"><a href="#Neural-Sentence-Ordering" class="headerlink" title="Neural Sentence Ordering"></a><a href="https://arxiv.org/pdf/1607.06952v1.pdf" target="_blank" rel="external">Neural Sentence Ordering</a></h1><h2 id="å…³é”®è¯-2"><a href="#å…³é”®è¯-2" class="headerlink" title="å…³é”®è¯"></a>å…³é”®è¯</h2><p>å¥å­æ’åº</p>
<h2 id="æ¥æº-2"><a href="#æ¥æº-2" class="headerlink" title="æ¥æº"></a>æ¥æº</h2><p>arXiv cs.CL 2016.07.23</p>
<h2 id="é—®é¢˜-2"><a href="#é—®é¢˜-2" class="headerlink" title="é—®é¢˜"></a>é—®é¢˜</h2><p>ç»™å®šä¹±åºçš„Nå¥è¯ï¼Œå¦‚ä½•å°†å…¶æŒ‰ç…§é€»è¾‘æ’åˆ—å¥½ï¼Ÿï¼ˆè²Œä¼¼æ˜¯è‹±è¯­è€ƒè¯•ä¸­çš„ä¸€ç§é¢˜å‹ï¼‰</p>
<h2 id="æ–¹æ³•-2"><a href="#æ–¹æ³•-2" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h2><p><img src="media/1-3.png" alt="1"></p>
<p>æœ¬æ–‡å®šä¹‰çš„é—®é¢˜æ˜¯ç»™å®šnå¥è¯ï¼Œæ‰¾å‡ºæœ€ä¼˜æ’åºï¼Œå°†è¿™ä¸ªé—®é¢˜é™ç»´åˆ°äºŒç»´ï¼Œå°±æ˜¯å¦‚ä½•æ’åˆ—ä¸¤å¥è¯çš„é¡ºåºã€‚ä¸Šå›¾ç»™å‡ºäº†modelçš„æ€è·¯ï¼Œå¯¹ä¸¤å¥è¯åˆ†åˆ«è¿›è¡Œencodeï¼Œå¾—åˆ°ä¸¤ä¸ªå‘é‡è¡¨ç¤ºï¼Œç„¶åè¿›è¡Œæ‰“åˆ†ï¼Œåˆ†æ•°è¡¨ç¤ºå½“å‰é¡ºåºæ˜¯æ­£ç¡®é¡ºåºçš„æ¦‚ç‡ã€‚è¿™é‡Œçš„encodeéƒ¨åˆ†ï¼Œåˆ†åˆ«ç”¨äº†æ¯å¥è¯ä¸­word embeddingsçš„åŠ æƒå¹³å‡ã€RNNå’ŒCNNæ¥è¡¨ç¤ºã€‚</p>
<p>å¾—åˆ°ä¸¤ä¸¤çš„æ’åºä¹‹åï¼Œæœ¬æ–‡ç”¨beam searchæ¥å¾—åˆ°æ•´ä½“æœ€ä¼˜çš„æ’åºã€‚</p>
<h2 id="è¯„è®º-2"><a href="#è¯„è®º-2" class="headerlink" title="è¯„è®º"></a>è¯„è®º</h2><p>å¤šæ–‡æ¡£æ‘˜è¦é—®é¢˜ä¸­é€šç”¨çš„ä¸€ç§åšæ³•æ˜¯ä»æ¯ç¯‡æ–‡æ¡£ä¸­éƒ½æå–å‡ºä¸€å¥æˆ–å‡ å¥é‡è¦çš„è¯ï¼Œç„¶åè¿›è¡Œæ’åºã€‚åœ¨è‹±è¯­è€ƒè¯•ä¸­ï¼Œæœ‰ä¸€ç§é¢˜å‹æ˜¯ç»™å®šä½ æ‰“ä¹±é¡ºåºçš„å‡ æ®µè¯ï¼Œç„¶åæ ¹æ®é€»è¾‘å°†å…¶æ’åºã€‚æœ¬æ–‡åœ¨å­¦æœ¯ä¸Šæ²¡æœ‰ä»€ä¹ˆæ–°çš„ä¸œè¥¿ï¼Œä½†æœ¬æ–‡åœ¨æ„å»ºneural modelçš„æ—¶å€™ï¼Œç”¨åˆ°çš„æ•°æ®é›†å´éå¸¸å®¹æ˜“æ„å»ºï¼Œè¿™æ„å‘³ç€ä½ åœ¨å·¥ç¨‹ä¸­åº”ç”¨è¿™ä¸ªæ–¹æ³•æ¥è§£å†³æ’åºé—®é¢˜æ˜¯å¯è¡Œçš„æ–¹æ¡ˆï¼Œæ‰€ä»¥æœ¬æ–‡æ›´åŠ é€‚åˆæœ‰å¥å­æ’åºåº”ç”¨éœ€æ±‚çš„å·¥ç¨‹äººå‘˜æ¥ç²¾è¯»ã€‚</p>
<h1 id="æé—®"><a href="#æé—®" class="headerlink" title="æé—®"></a>æé—®</h1><p>è®¡ç®—æœºçš„ä¼šè®®éå¸¸å¤šï¼Œå„ç§levelçš„éƒ½æœ‰ï¼ŒarXivä¸Šæ¯å¤©éƒ½å¯ä»¥åˆ·å‡ºä¸€äº›paperï¼Œä¸åŒç±»å‹ã€ä¸åŒlevelçš„paperé€‚åˆä¸åŒéœ€æ±‚çš„äººæ¥è¯»ï¼Œæˆ‘è§‰å¾—å¥½ä¸œè¥¿çš„æ ‡å‡†æ˜¯é€‚åˆè€Œä¸æ˜¯åœ¨æŸä¸€ä¸ªå…·ä½“æŒ‡æ ‡ä¸Šè¾¾åˆ°æœ€å¤§ï¼Œå¯¹ä½ æœ‰ç”¨çš„ä¸œè¥¿æ‰æ˜¯é€‚åˆä½ çš„å¥½ä¸œè¥¿ï¼Œæœ‰äº›ç‰¹åˆ«ç‰›é€¼çš„ä¸œè¥¿ï¼Œæœ‰ç€æé«˜å­¦æœ¯ä»·å€¼çš„ä¸œè¥¿ä¸è§å¾—é€‚åˆå·¥ç¨‹äººå‘˜æ¥è¯»ï¼Œä½†ä¹Ÿä¸åº”è¯¥æ˜¯é‚£ç§è§‰å¾—å­¦æœ¯ä¸Šçš„ä¸œè¥¿ç¦»å·¥ç¨‹å¤ªè¿œï¼Œæ²¡æœ‰ä»€ä¹ˆå…·ä½“ç”¨çš„æ€åº¦ï¼Œä»å„ç§å„æ ·çš„ä¸œè¥¿æ±²å–å…»åˆ†ï¼Œä¸°å¯Œå’Œå……å®è‡ªå·±æ‰æ˜¯ç¡¬é“ç†ã€‚è¯»äº†ä¸€äº›paperï¼Œä¹Ÿè¯¥æ€è€ƒä¸€äº›é—®é¢˜äº†ï¼Œè¿™é‡Œæå‡ºä¸€äº›æ¯”è¾ƒnaiveçš„é—®é¢˜ï¼Œæ¬¢è¿å¤§å®¶è¸Šè·ƒç•™è¨€å’Œè®¨è®ºã€‚</p>
<p>1ã€<unk>è¿™ç§out-of-vocabularyçš„é—®é¢˜æ˜¯ä¸€ä¸ªéå¸¸å¸¸è§çš„é—®é¢˜ï¼Œæœ‰å“ªäº›ä¸é”™çš„æ€è·¯å¯ä»¥æ¥è§£å†³è¿™ä¸ªé—®é¢˜å‘¢ï¼Ÿ</unk></p>
<p>2ã€attention modelå‡ ä¹æ»¡å¤§è¡—éƒ½æ˜¯ï¼Œæœ€æ—©åœ¨æœºå™¨ç¿»è¯‘é¢†åŸŸä¸­å¼€å§‹ç”¨è¿™ç§æ¨¡å‹ï¼Œè™½ç„¶åœ¨å…¶ä»–nlpé¢†åŸŸä¸­éƒ½å–å¾—äº†ä¸é”™çš„æˆç»©ï¼Œä½†ç›®å‰çš„attentionçœŸçš„é€‚åˆæ¯ä¸€ç±»å…·ä½“é—®é¢˜å—ï¼Ÿæ˜¯ä¸æ˜¯æœ‰ä¸€ç‚¹ä¸ºäº†attentionè€Œattentionçš„æ„Ÿè§‰ï¼Ÿneural summarizationå’Œmachine translationçœŸçš„å¯ä»¥å®Œå…¨ç±»æ¯”å—ï¼Ÿæˆ–è€…è¯´attentioné€‚åˆè§£å†³å…·æœ‰ä»€ä¹ˆç‰¹å¾çš„é—®é¢˜å‘¢ï¼Ÿ</p>
<p>3ã€ä¿¡æ¯è¶Šå¤šï¼Œmodelçš„æ•ˆæœä¸€å®šä¼šè¶Šå¥½ã€‚ç°åœ¨å¤–éƒ¨ä¿¡æ¯éå¸¸ä¸°å¯Œï¼Œä½†æ˜¯å¦‚ä½•èåˆåˆ°å½“å‰æµè¡Œçš„modelä¸­æ¥å‘¢ï¼Ÿå¦‚ä½•å°†ç‰¹å®šé¢†åŸŸå†…æ„å»ºçš„çŸ¥è¯†å›¾è°±å®Œç¾åœ°ä¸ç‰¹å®šä»»åŠ¡ä¸­çš„modelè¿›è¡Œç»“åˆå‘¢ï¼Ÿä»¥task-oriented botä¸ºä¾‹ï¼Œèƒ½å¤Ÿå°†å®¢æˆ·çš„é¢†åŸŸçŸ¥è¯†ä¸bot responseåŠŸèƒ½ç»“åˆèµ·æ¥ï¼Œåšæˆä¸€ä¸ªæ›´åŠ é«˜çº§çš„botå‘¢ï¼Ÿ</p>
<p>è¿™é‡Œï¼Œæˆ‘æŠ›ä¸ªç –ï¼Œå¼•ä¸ªç‰ï¼Œå¸Œæœ›æ›´å¤šçš„äººèƒ½å¤Ÿå‚ä¸è®¨è®ºå’Œæå‡ºé—®é¢˜ã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-02T18:54:22.000Z"><a href="/2016/08/02/æ—§å¹•è½ä¸‹ï¼Œæ–°å¹•å‡èµ·/">2016-08-02</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/02/æ—§å¹•è½ä¸‹ï¼Œæ–°å¹•å‡èµ·/">æ—§å¹•è½ä¸‹ï¼Œæ–°å¹•å‡èµ·</a></h1>
  

    </header>
    <div class="entry">
      
        <p>ä»è¿‡å¹´é‚£ä¼šç­¹åˆ’ä¸€äº›å©šç¤¼çš„æƒ³æ³•å¼€å§‹ï¼Œåˆ°æ‹å©šçº±ç…§ã€æ‰¾å©šåº†ã€è·Ÿæ‹ã€æ‘„åƒã€åŒ–å¦†ã€æœè£…ã€åœºåœ°ã€å–œå®´ã€å®‰æ’æ¥é€è½¦è¾†ã€äº²æœ‹ä½å®¿ä»¥åŠæœ€è¿‘ä¸€ä¸ªæœˆç–¯ç‹‚åœ°åœ¨æ·˜å®ä¸Šè´­ä¹°å„ç§æ‰€éœ€çš„ä¸œè¥¿ï¼ŒèŠ±è´¹çš„æ‰€æœ‰æ—¶é—´å’Œç²¾åŠ›éšç€2016.07.31è¿™ä¸€å¤©è¿™ä¸€åœºå©šç¤¼ä¸€èµ·å®Œç¾è°¢å¹•äº†ï¼Œæ•´ä¸ªå©šç¤¼ç»“æŸä¹‹åï¼Œæˆ‘å¸¦ç€æˆ‘çš„æ–°å¨˜å­åç€åœ°é“å›å®¶ï¼Œæƒ³æƒ³å¤§æ¦‚ä¹Ÿæ²¡æœ‰è°äº†ã€‚</p>
<p><img src="media/1.pic.jpg" alt="1.pi"></p>
<p>ä¸¤å¤©è¿‡å»äº†ï¼Œä»ç„¶æ²¡æœ‰ä»7.31çš„é‚£åœºæ¢¦é‡Œé†’æ¥ã€‚æ„Ÿè°¢å„ä½æ¥å®¾ï¼Œæ„Ÿè°¢å„ä½å·¥ä½œäººå‘˜ï¼Œæ„Ÿè°¢ä¿éšœå°ç»„çš„å‡ ä½ç«¥é‹ï¼Œæ„Ÿè°¢çƒå“¥çš„ä¹é˜Ÿï¼Œæ„Ÿè°¢ç¥ç¦æˆ‘ä»¬çš„æ¯ä¸€ä½ï¼</p>
<p>å½“æ—¶å®¶é‡Œä¸å»ºè®®7.31ç»“å©šï¼Œå› ä¸ºä»–ä»¬å¾ˆè¿·ä¿¡åœ°è¯´8.1æˆ–è€…7.29æ›´åŠ é€‚åˆç»“å©šï¼Œè€Œä¸”æˆ‘å¦ˆæå‰åŠä¸ªæœˆå°±çœ‹å¤©æ°”é¢„æŠ¥è¯´31å·é‚£å¤©æœ‰å¤§é›¨ï¼ˆæˆ‘æ—©å°±æ–­å®šå¤©æ°”é¢„æŠ¥ä¸å‡†ï¼Œè€Œä¸”æå‰é‚£ä¹ˆæ—©çœ‹æ ¹æœ¬æ²¡ç”¨ï¼‰ï¼Œä½†æˆ‘ä»¬ä»ç„¶åšæŒå°±æ˜¯7.31ï¼Œä¸ç®¡é‚£å¤©ä»€ä¹ˆå¤©æ°”ï¼Œéƒ½ä¸€å®šæ˜¯è¿™ä¸€å¤©ï¼Œå› ä¸º2015.7.31è¿™ä¸€å¤©æˆ‘ä»¬æ­£å¼åœ¨æ³•å¾‹å±‚é¢ä¸Šæˆä¸ºäº†å¤«å¦»ï¼Œå½“æ—¶ç¦»ä¸ƒå¤•å¾ˆè¿‘ï¼Œä½†æˆ‘ä»¬è§‰å¾—éèŠ‚æ—¥çš„ä¸€å¤©æ›´åŠ é€‚åˆä½œä¸ºæˆ‘ä»¬çš„çºªå¿µæ—¥ï¼Œäºæ˜¯å°±åœ¨é‚£å¤©é¢†äº†è¯ï¼Œå½“æ—¶æˆ‘å°±å¯¹éŸµéŸµè¯´ï¼Œæ˜å¹´çš„ä»Šå¤©å°±æ˜¯æˆ‘ä»¬å¤§å©šçš„æ—¥å­ï¼Œæˆ‘ä»¬è¦åŠæœ€æœ‰æ„æ€ã€æœ€ä¸ä¸€æ ·çš„å©šç¤¼ï¼Œå¥¹ç‚¹å¤´ç­”åº”ã€‚æˆ‘ä»¬çš„åšæŒã€æˆ‘ä»¬çš„å›ºæ‰§è¯æ˜äº†7.31è¿™ä¸€å¤©å°±æ˜¯å±äºæˆ‘ä»¬çš„ï¼Œéå¸¸æ£’çš„å¤©æ°”è®©æ•´ä¸ªå©šç¤¼è¿›è¡Œçš„éå¸¸é¡ºåˆ©ï¼Œéå¸¸å®Œç¾ã€‚</p>
<p><img src="media/3.pic.jpg" alt="3.pi"></p>
<p>å›ç¤¼çš„å‡†å¤‡èŠ±è´¹äº†æˆ‘ä»¬å¤ªå¤šçš„æ—¶é—´å’Œç²¾åŠ›ï¼Œç›´åˆ°å©šç¤¼å‰ä¸‰å¤©æ‰å‡†å¤‡å¥½æ‰€æœ‰çš„å›ç¤¼ã€‚é•¿æ²™è¿™è¾¹çš„ä¸€èˆ¬åšæ³•éƒ½æ˜¯å‡†å¤‡ä¸€ç›’çƒŸã€ä¸€è¢‹æ§Ÿæ¦”å’Œä¸€ç›’å–œç³–ï¼Œå½“æ—¶æˆ‘ä»¬å°±è¯´è¦åšçš„ä¸ä¸€æ ·ï¼Œäºæ˜¯éŸµéŸµå¼€å§‹äº†æ¯å¤©é•¿è¾¾ä¸¤å°æ—¶çš„æ·˜å®ç”Ÿæ¶¯ï¼Œå¹¶ä¸”ä¹æ­¤ä¸ç–²ï¼Œä¸€ç›†å¤šè‚‰ã€ä¸€ç›’æœé…±å’Œä¸€ç›’æ‰‹å·¥å–œç³–ã€‚150ä»½å›ç¤¼ï¼Œéœ€è¦ç§150ç›†èŠ±ï¼Œæ‰‹å·¥è£…150ä¸ªå–œç³–ç›’å­ï¼Œè£…150ä¸ªæœé…±ç›’ï¼Œå¤šäºäº†å‡ ä½å°åŒå­¦çš„å¸®å¿™ï¼Œæ‰èƒ½é¡ºåˆ©åœ°å‡†å¤‡å¥½è¿™äº›ä¸œè¥¿ï¼ŒéŸµéŸµå–œæ¬¢å…”å­ï¼Œæ‰€ä»¥è¢‹å­ä¹Ÿæ˜¯å…”å­ï¼Œå¤šè‚‰çš„åŒ…è£…ä¸Šè´´ç€ä¸€å¼ å…”å­è´´çº¸ï¼Œæ˜¯æˆ‘ä»¬è¿™æ¬¡å©šç¤¼çš„logoï¼Œæ˜¯å©šåº†ä¸“é—¨è®¾è®¡çš„ã€‚å…¶å®å®Œå…¨å¯ä»¥æ²¡å¿…è¦è¿™ä¹ˆç´¯ï¼Œç›´æ¥ä¹°ç°æˆçš„å°±å¥½ï¼Œä½†æ˜¯éŸµéŸµåšæŒè¦æ‰‹å·¥åšæ¯ä¸€ä¸ªç»†èŠ‚ï¼Œå¸Œæœ›æ¯ä¸€ä¸ªç»†èŠ‚éƒ½åšåˆ°å®Œç¾ï¼Œç»™å®¾å®¢ä»¬å¸¦æ¥ä¸ä¸€æ ·çš„æ„Ÿè§‰ã€‚å¥¹åšåˆ°äº†ï¼å¤§å®¶éƒ½éå¸¸å–œæ¬¢è¿™ä»½å›ç¤¼ã€‚</p>
<p><img src="media/2.pic.jpg" alt="2.pi"></p>
<p>å©šç¤¼ä¸»æŒäººå¸Œæœ›æˆ‘ä»¬ä¸¤ä¸ªåœ¨å©šç¤¼ç°åœºå¯ä»¥çœŸæƒ…å‘Šç™½ä¸€ä¸‹ï¼Œäºæ˜¯å©šç¤¼å‰çš„ä¸€å‘¨å°±æ²¡æœ‰è¸å®åœ°ç¡å¥½è¿‡ï¼Œæœ‰ä¸€å¤©å¤œé‡Œæƒ³ç€æˆ‘ä»¬åœ¨ä¸€èµ·çš„è¿™ä¸€å¹´å¤šæ—¶é—´ï¼Œç‚¹ç‚¹æ»´æ»´éƒ½å†å†åœ¨ç›®ï¼Œåˆå¤±çœ äº†ï¼é‚£ä¸€æ™šæƒ³äº†å¾ˆå¤šå¾ˆå¤šï¼Œæ¯ä¸€ä»¶äº‹æƒ…çš„æ¯ä¸€ä¸ªç»†èŠ‚éƒ½è®°å¿†çŠ¹æ–°ï¼Œæƒ³äº†å¾ˆå¤šæƒ³è¦å¯¹å¥¹è¯´çš„è¯ï¼Œå¹³æ—¶ä¹Ÿä¸ä¼šè¯´ä»€ä¹ˆæ·±æƒ…çš„è¯ï¼Œå› ä¸ºæˆ‘ä¹Ÿä¸æ˜¯ä¸€ä¸ªæ‡‚æµªæ¼«çš„äººã€‚å¥¹ä¸€ç›´åœ¨å¿™ç€ä¹°å„ç§å„æ ·å¿…é¡»çš„ä¸œè¥¿ï¼Œæ‰€ä»¥ç›´åˆ°å©šç¤¼å‰ä¸€å¤©æ™šä¸Šåœ¨é…’åº—é‡Œç­‰æˆ‘ç¡ç€äº†æ‰å¼€å§‹å‡†å¤‡å‘Šç™½çš„è¯ï¼Œ2ç‚¹é’Ÿæ‰ç¡è§‰ï¼Œ5ç‚¹å°±èµ·æ¥å‡†å¤‡åŒ–å¦†äº†ã€‚å©šç¤¼æ­£å¼å¼€å§‹äº†ï¼Œæˆ‘ä¹‹å‰å‡†å¤‡å¥½çš„è¯åŸºæœ¬ä¸Šéƒ½å¿˜è®°äº†ï¼Œç¡®å®æœ‰äº›ç´§å¼ ï¼Œä½†å½“æˆ‘çœ‹åˆ°ç¾ä¸½çš„æ–°å¨˜ç«™åœ¨æˆ‘çš„é¢å‰æ—¶ï¼Œæˆ‘å°±ä¸€ç‚¹éƒ½ä¸ç´§å¼ äº†ï¼Œå¾ˆè‡ªç„¶åœ°è¯´å‡ºäº†æˆ‘å†…å¿ƒæœ€çœŸå®çš„æ„ŸåŠ¨ï¼Œä»¥è‡´äºç¬¬ä¸€ä½ä¼´å¨˜å“­çš„ç¨€é‡Œå“—å•¦çš„ï¼ŒéŸµéŸµçš„å°é£æ¯”æˆ‘å¥½ï¼Œä¸€å¥ä¸€å¥åœ°è®²å‡ºäº†æˆ‘ä»¬åœ¨ä¸€èµ·çš„ç¾å¥½ï¼</p>
<p><img src="media/4.pic.jpg" alt="4.pi"></p>
<p>æˆ‘å’ŒéŸµéŸµæ­£å¼åœ¨ä¸€èµ·æ˜¯åœ¨é©¬é ”çš„æ¼”å”±ä¼šä¸Šï¼Œæ˜¯åœ¨2015.03.18ï¼Œæ˜¯æˆ‘ä»¬è®¤è¯†åçš„ç¬¬åå¤©ï¼Œä¸€åˆ‡çœ‹èµ·æ¥éƒ½å¾ˆè‡ªç„¶è€Œç„¶ï¼Œæ²¡æœ‰ä»»ä½•åˆ»æ„çš„å®‰æ’ã€‚æˆ‘ä¸€ç›´æœ‰ä¸€ä¸ªå¿ƒæ„¿å°±æ˜¯èƒ½å¤ŸåŠä¸€åœºlive concertï¼Œä¸ºæˆ‘å¿ƒçˆ±çš„äººçŒ®ä¸Šå¥¹æœ€çˆ±çš„æ­Œæ›²ã€‚äºæ˜¯ï¼Œæˆ‘å†³å®šåœ¨å©šç¤¼ç»“æŸåï¼Œå®‰æ’ä¸€åœºæ°‘è°£é£live concertï¼Œé‚€è¯·å–œæ¬¢å”±æ­Œçš„åŒå­¦ä»¬ä¸€èµ·æ¥å—¨ã€‚concertå¾ˆæˆåŠŸï¼Œæ°›å›´éå¸¸å¥½ï¼Œçƒå“¥çš„ç°åœºæ²¡çš„è¯´ï¼Œåœ¨åº§çš„æ¯ä¸€ä½éƒ½æ²‰æµ¸åœ¨äº†å½“æ—¶çš„æ°›å›´ä¸­ï¼Œæˆ‘å”±äº†é©¬é ”çš„ã€Šå—å±±å—ã€‹ï¼ŒéŸµéŸµå”±äº†hebeçš„ã€Šå°å¹¸è¿ã€‹ï¼Œä¸€åˆ‡éƒ½æ˜¯é‚£ä¹ˆåœ°æ£’ï¼</p>
<p><img src="media/6.pic_hd.jpg" alt="6.pic_hd"></p>
<p>éŸµéŸµè¯´å¥¹æœ€å¹¸ç¦çš„æ—¶åˆ»å°±æ˜¯æ¯å¤©æ—©ä¸Šé†’æ¥ï¼Œçœ‹åˆ°èº«è¾¹çš„æˆ‘å’Œhareæ­£åœ¨é…£ç¡ã€‚hareæ˜¯æˆ‘ä»¬å®¶çš„å°ç‹—ï¼Œä½†å…¨å®¶éƒ½æ²¡æœ‰æŠŠä»–å½“åšç‹—ç‹—æ¥å…»ï¼Œæˆ‘å’ŒéŸµéŸµæ˜¯ä»–çš„çˆ¸çˆ¸å’Œå¦ˆå¦ˆï¼Œä»–è¿˜æœ‰å¤–å©†ã€çˆ·çˆ·å’Œå¥¶å¥¶ï¼Œæ¯ä¸ªäººéƒ½ç‰¹åˆ«çˆ±ä»–ï¼Œä»–ä¹Ÿæ˜¯å…¨å®¶çš„å¼€å¿ƒæœã€‚å¦‚æœè¯´å©šç¤¼æœ‰é—æ†¾çš„è¯ï¼Œé‚£å°±æ˜¯hareæ²¡èƒ½æ¥åˆ°ç°åœºè§è¯ä»–çˆ¸çˆ¸å¦ˆå¦ˆæœ€å¹¸ç¦çš„ä¸€åˆ»äº†ã€‚hareä¹‹æ‰€å«è¿™ä¸ªåå­—ï¼Œæ˜¯å› ä¸ºä»–åˆšåˆšæ¥å®¶é‡Œé‚£ä¼šï¼Œæˆ‘æ­£å¯¹Air Jordançš„Hareçƒé‹ç—´è¿·ï¼ŒHareæœ¬æ˜¯å…”å…«å“¥çš„åå­—ï¼Œæ‰€ä»¥å°±ç»™ä»–å–äº†è¿™ä¸ªåå­—ï¼Œåæ¥ä¸æ–­åœ°æœ‰äº†å¾ˆå¤šçš„åå­—ï¼Œå¼ ç”œå¿ƒã€å¼ ç”œç”œã€å°é»‘ã€å¿ƒå¿ƒç­‰ç­‰å¥½å¤šçš„åå­—ï¼Œä»–æœ‰ä¸€é˜µå­æœ‰ä¸€äº›å‡Œä¹±ï¼Œçªç„¶ä¸çŸ¥é“è‡ªå·±å«ä»€ä¹ˆäº†ã€‚</p>
<p><img src="media/6.pic.jpg" alt="6.pi"></p>
<p>ä¼´éƒå’Œä¼´å¨˜éƒ½éå¸¸åœ°å¸…æ°”å’Œç¾ä¸½ï¼Œä»–ä»¬ç»™äº†æˆ‘ä»¬å¾ˆå¤šçš„å¸®åŠ©å’Œæ”¯æŒã€‚ä¼´å¨˜éƒ½æ˜¯éŸµéŸµçš„å¥½é—ºèœœï¼Œæœ‰é™ªå¥¹ä¸€èµ·é•¿å¤§çš„ï¼Œæœ‰é™ªå¥¹ä¸€èµ·å·¥ä½œçš„ï¼Œæœ‰ä¸€ä¸ªæ˜¯è¿™ä¸ªä¸–ç•Œä¸Šçš„å¦å¤–ä¸€ä¸ªå¥¹ï¼Œå¥¹ä»¬ç›¸ä¼¼çš„ç»å†ï¼Œè®©å¥¹ä»¬æ— è¯ä¸è°ˆï¼Œå©šç¤¼ç°åœºä¹Ÿå°±æ˜¯å¥¹å“­çš„æœ€å‰å®³äº†ã€‚ä¼´éƒéƒ½æ˜¯æˆ‘çš„å°å…„å¼Ÿï¼Œä»–ä»¬æ›¿æˆ‘æ‰›äº†å¾ˆå¤šæŠ¢äº²æ—¶çš„æŠ˜ç£¨ï¼Œæ›¿æˆ‘æŒ¡äº†å¾ˆå¤šçš„é…’ï¼Œä¸‰ä½ä¼´éƒåœ¨æ•¬é…’æ—¶æ¯«æ— ä¿ç•™ï¼Œæœ€åé€šé€šå€’ä¸‹ï¼Œæœ‰ä¸€ç‚¹é—æ†¾ï¼Œæ²¡æœ‰èƒ½å¤Ÿå‚åŠ æœ€åçš„concertã€‚æ„Ÿè°¢ä½ ä»¬ï¼Œå› ä¸ºä½ ä»¬ï¼Œæˆ‘å’ŒéŸµéŸµæ‰ä¼šæ›´åŠ å¹¸ç¦ï¼</p>
<p><img src="media/7.pic.jpg" alt="7.pi"></p>
<p>å©šç¤¼ç»“æŸäº†ï¼Œæ–°çš„ç”Ÿæ´»å¼€å§‹äº†ï¼ä»Šå¹´27å²ï¼Œä¹Ÿè¯¥æœ‰ä¸€ä»½è‡ªå·±çš„äº‹ä¸šäº†ï¼Œä¸ç®¡ç°åœ¨å›°éš¾æœ‰å¤šå°‘ï¼Œé˜»ç¢æœ‰å¤šå¤§ï¼Œæˆ‘å’ŒéŸµéŸµéƒ½è¦å¼€å§‹ä¸ºæˆ‘ä»¬çš„äº‹ä¸šå¥‹æ–—äº†ï¼æˆ‘ä¸€ç›´è§‰å¾—éŸµéŸµä¸ä»…ä»…æ˜¯ç”Ÿæ´»ä¸Šçš„ä¼´ä¾£ï¼Œæ›´æ˜¯å¿ƒçµçš„ä¼´ä¾£ï¼Œå¥¹æœ€æ‡‚æˆ‘çš„å¿ƒï¼Œä¹Ÿä¸é¡¾ä¸€åˆ‡åœ°æ”¯æŒæˆ‘æƒ³åšçš„äº‹ä¸šï¼Œä¹Ÿæ„¿æ„å’Œæˆ‘ä¸€èµ·æ¥å¥‹æ–—è¿™ä»½äº‹ä¸šã€‚å¥¹ç»†å¿ƒã€èªæ˜ã€å¥½å­¦ã€çƒ­çˆ±ç”Ÿæ´»ã€çœ¼å…‰ç‹¬åˆ°ï¼Œæ‰€æœ‰ç¾å¥½çš„æ ‡ç­¾è´´åœ¨å¥¹èº«ä¸Šéƒ½ä¸ä¸ºè¿‡ï¼Œå¥¹è®©æˆ‘çœ‹åˆ°äº†æ›´å¤§çš„ä¸–ç•Œï¼Œè®©æˆ‘æ˜ç™½äº†ç”Ÿæ´»çš„æ„ä¹‰ï¼Œèµ°è¿›äº†æˆ‘çš„å†…å¿ƒæ·±å¤„è®©æˆ‘ä¸å†å­¤ç‹¬ï¼Œå¥¹çš„å‹‡æ•¢ã€çŸ¥æ€§ã€ç‹¬ç«‹éƒ½è®©æˆ‘é’¦ä½©ï¼Œç»™äº†æˆ‘è«å¤§çš„å‹‡æ°”ï¼Œè®©æˆ‘å¯ä»¥æ›´åŠ è‡ªä¿¡åœ°æ´»åœ¨è¿™ä¸ªä¸–ç•Œä¸Šï¼Œå»å‹‡æ•¢åœ°æŒ‘æˆ˜ä¸€äº›æ›´éš¾çš„äº‹æƒ…ã€‚äººç”Ÿå°±æ˜¯ä¸€åœºå¥‡é‡ï¼Œæ„Ÿè°¢ä¸Šå¸è®©æˆ‘é‡è§ä½ ï¼è°¢è°¢ä½ ï¼ŒéŸµéŸµï¼Œæˆ‘çˆ±ä½ ï¼</p>
<p>æ—§çš„ä¸€å¹•å·²ç»è½ä¸‹ï¼Œæ–°çš„ä¸€å¹•æ­£åœ¨å‡èµ·ã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-26T00:06:49.000Z"><a href="/2016/07/25/å¦‚æœæˆ‘ä¹Ÿåšbot/">2016-07-25</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/25/å¦‚æœæˆ‘ä¹Ÿåšbot/">å¦‚æœæˆ‘ä¹Ÿåšbot</a></h1>
  

    </header>
    <div class="entry">
      
        <p>æœ€è¿‘åˆæ­¥åœ°ç ”ç©¶äº†ä¸‹botè¿™ä¸ªé¢†åŸŸï¼Œæœ‰äº†ä¸€ç‚¹æµ…è–„çš„ç†è§£ï¼Œäºæ˜¯å¼€å§‹æƒ³ï¼Œå¦‚æœæˆ‘ä¹Ÿåšbotçš„è¯ï¼Œè§£å†³å¥½å“ªäº›é—®é¢˜æ‰ä¼šåšå¥½è¿™ä»¶äº‹æƒ…ï¼Ÿ</p>
<p>1ã€åˆ›ä¸šæ˜¯ä¸€ä»¶ä¸¥è‚ƒçš„äº‹æƒ…ï¼Œä¸æ˜¯å„¿æˆï¼Œéœ€è¦åšå¥½å……è¶³çš„å‡†å¤‡ï¼Œè°ƒç ”å’Œç§¯ç´¯éƒ½æ˜¯éå¸¸é‡è¦çš„ï¼Œåªæœ‰åšå¥½100åˆ†çš„å‡†å¤‡ï¼Œæ‰å¯èƒ½åœ¨é¢å¯¹å„ç§æœªçŸ¥çš„å›°éš¾æ—¶ä¸æ…Œä¹±ã€‚æ‰€ä»¥ï¼Œç¬¬ä¸€æ­¥å°±æ˜¯è°ƒç ”ï¼Œç ”ç©¶botï¼Œä»æ–¹æ–¹é¢é¢ï¼Œæ¯”å¦‚ï¼š</p>
<p>ï¼ˆ1ï¼‰botä¸ºä»€ä¹ˆä¼šç«ï¼Ÿ<br>ï¼ˆ2ï¼‰å›½å†…å“ªäº›ä¼ä¸šåœ¨åšbotï¼Ÿä»–ä»¬çš„äº§å“æœ‰å“ªäº›ä¼˜ç¼ºç‚¹ï¼Ÿ<br>ï¼ˆ3ï¼‰å›½å¤–å“ªäº›ä¼ä¸šåœ¨åšbotï¼Ÿæœ‰å“ªäº›ä¼˜ç¼ºç‚¹ï¼Ÿ<br>ï¼ˆ4ï¼‰æŠ•èµ„æƒ…å†µå¦‚ä½•ï¼ŸæŠ•èµ„äººæ€ä¹ˆçœ‹å¾…è¿™ä¸ªæ–¹å‘ï¼Ÿ<br>ï¼ˆ5ï¼‰botéœ€è¦å“ªäº›æŠ€æœ¯ç§¯ç´¯ï¼Ÿ</p>
<p>2ã€ä»åª’ä½“ã€æŠ•èµ„äººçš„è§‚ç‚¹æ¥çœ‹ï¼Œbotæ•´ä¸ªå¤§æ–¹å‘æ²¡æœ‰é”™ï¼Œé‚£ä¹ˆåˆ°åº•åº”è¯¥åšå“ªä¸ªå­é¢†åŸŸå‘¢ï¼Ÿæ˜¯å®¢æœï¼Ÿè¿˜æ˜¯æŠ€æœ¯æ”¯æŒï¼ŸæŠ€æœ¯å¹³å°ï¼Ÿå‚ç›´ç§äººåŠ©ç†ï¼Ÿå¹³å°ä¸Šåº”ç”¨ï¼Ÿå¯åšçš„äº‹æƒ…å…¶å®å¾ˆå¤šï¼Œ16å¹´å¼€å§‹æ‰äº•å–·å¼åœ°ç‚’ä½œbotè¿™ä¸ªæ¦‚å¿µï¼Œæ‰€ä»¥ä»Šå¹´å¯ä»¥å½“åšæ˜¯botå…ƒå¹´ï¼Œæ—¢ç„¶æ˜¯åˆšåˆšèµ·æ­¥çš„ä¸€ä¸ªé¢†åŸŸï¼Œå°±æœ‰ä¸€ä¸ªå¤©ç„¶çš„å¥½å¤„ï¼Œè›‹ç³•è¶³å¤Ÿå¤§ï¼Œå“ç±»è¶³å¤Ÿå¤šï¼Œçœ‹ä½ æƒ³åƒå“ªä¸€å—ï¼Ÿå½“ç„¶ä¹Ÿæœ‰ä¸€ä¸ªå¤©ç„¶çš„åå¤„ï¼Œå°±æ˜¯æ— ç« å¯å¾ªï¼Œå¤§å®¶éƒ½æ˜¯æ‘¸ç€çŸ³å¤´è¿‡æ²³ã€‚</p>
<p>ï¼ˆ1ï¼‰å›½å†…çš„æƒ…å†µæ˜¯ï¼Œå®¢æœå·²ç»æœ‰å¾ˆå¤šå®¶ä¼ä¸šåœ¨åšäº†ï¼Œåšçš„æ¨¡å¼å¤§åŒå°å¼‚ï¼ŒæŠ€æœ¯æ–¹é¢å„æœ‰ç‰¹è‰²å§ï¼Œå¯èƒ½èµ·æ­¥æ—©çš„ç°åœ¨è§„æ¨¡å¤§ä¸€äº›ï¼Œæ™šçš„å°ä¸€äº›ï¼Œä½†æ•´ä½“æ¥çœ‹å·®å¼‚åŒ–ä¸å¤§ã€‚å¦‚æœé€‰æ‹©è¿™ä¸ªæ–¹å‘çš„è¯ï¼Œå¿…é¡»åšå‡ºå·®å¼‚åŒ–ï¼Œç ”ç©¶ç°æœ‰æ–¹æ¡ˆçš„ç¼ºç‚¹ï¼Œä¹‹å‰å†™è¿‡ä¸€ç¯‡æ–‡ç« ï¼Œç®€å•å‰–æäº†ç°æœ‰æ–¹æ¡ˆçš„ç¼ºç‚¹å’Œå¯æ”¹è¿›çš„ç‚¹ï¼Œè®©ç›®å‰çš„å®¢æœbotæ›´è¿›ä¸€æ­¥ï¼Œè¦ä¹ˆå°±æ˜¯åšä¸€å®¶å®¢æœbotï¼Œäº§å“æ›´å®Œç¾ã€æŠ€æœ¯æ›´å¥½ï¼Œå’Œå¤§å®¶åˆ†ä¸€æ¯ç¾¹ï¼›è¦ä¹ˆå°±æ˜¯æä¾›æŠ€æœ¯æ”¯æŒï¼Œå¸®ç°æœ‰çš„botä¼ä¸šæ›´è¿›ä¸€æ­¥ï¼Œèµšä»–ä»¬çš„é’±ã€‚</p>
<p>ï¼ˆ2ï¼‰å¦‚æœæ˜¯åšæŠ€æœ¯æ”¯æŒï¼Œå…¸å‹çš„SaaS+B2Bï¼Œç”¨è‡ªå·±çš„æŠ€æœ¯æœåŠ¡æ¥ä¸ºåˆ«çš„ä¼ä¸šæä¾›æ”¯æŒï¼Œresponse generationã€user modelingã€context modelingã€information extractionéƒ½æ˜¯ä¸é”™çš„æ–¹å‘ï¼Œæ¯ä¸€ä¸ªåšå¥½äº†éƒ½æœ‰å¹¿é˜”çš„å‰æ™¯ï¼Œä»¥ä¸ºæŠ€æœ¯æ”¯æŒä¸ç›´æ¥é¢å¯¹ä¸šåŠ¡ï¼Œè€Œæ˜¯å¸®åŠ©æ”¹è¿›ç°æœ‰ä¼ä¸šæå‡ç®—æ³•å’Œå»ºæ¨¡èƒ½åŠ›ï¼Œåº”ç”¨çš„é¢æ¯”è¾ƒå¹¿ï¼Œå¯ä»¥ç”¨åœ¨å„ç§ç±»å‹çš„botä¸Šä»¥åŠå…¶ä»–åº”ç”¨èƒŒæ™¯ä¸Šã€‚</p>
<p>ï¼ˆ3ï¼‰å¹³å°ä¸Šçš„åº”ç”¨ï¼Œæ¯”å¦‚slackä¸Šçš„botï¼Œåšä¸€ä¸ªæœ‰è¶£çš„å°åŠŸèƒ½ï¼Œæé«˜teamçš„å·¥ä½œæ•ˆç‡ã€‚è¿™ä¸ªåœ¨å›½å¤–éå¸¸åœ°ç«ï¼Œå¹³å°ä¹Ÿå¾ˆå¤šï¼Œå°±åƒæ˜¯ç°åœ¨iosä¸Šå¼€å‘appä¸€æ ·ï¼Œæ¯ä¸ªappéƒ½æœ‰è‡ªå·±çš„åŠŸèƒ½ã€‚æˆ‘è§‰å¾—è¿™å—è¦æ˜¯åšçš„è¯ï¼Œå¾ˆå®¹æ˜“åšå‡ºå·®å¼‚åŒ–ï¼Œç°åœ¨å·²ç»æœ‰å„å¼å„æ ·çš„startupsåšç€å„å¼å„æ ·çš„botã€‚ä½†æ•´ä½“æ¥è¯´ï¼ŒæŠ€æœ¯é—¨æ§›æ¯”è¾ƒä½ï¼Œæœ‰ä¸€ç‚¹APIæ•´åˆçš„æ„æ€ï¼Œä½†å¦‚æœä½ å°†è‡ªå·±çš„æŠ€æœ¯å°è£…æˆAPIï¼Œåœ¨ä¸Šé¢åšä¸€ä¸ªbotæä¾›æœåŠ¡ä¹Ÿæ˜¯ä¸€ç§ä¸é”™çš„å°è¯•ï¼Œè€Œä¸”äº§å“å‘¨æœŸç‰¹åˆ«çŸ­ï¼Œä½†ç»ˆç©¶å–ç‚¹åº”è¯¥è¿˜æ˜¯ä½ çš„æŠ€æœ¯æ”¯æŒï¼Œè€Œä¸æ˜¯è¿™ä¸ªbotã€‚</p>
<p>ï¼ˆ4ï¼‰æŠ€æœ¯å¹³å°çš„è¯ï¼Œç±»ä¼¼çš„æœ‰å¾ˆå¤šå¸®åŠ©ä¼ä¸šæˆ–ä¸ªäººæ„å»ºbotåœ¨å„ç§å¹³å°ä¸Šè·‘ï¼Œå‡å¦‚å¾®ä¿¡ç°åœ¨å¼€æ”¾äº†è¿™ä¸€å—ï¼ŒæŠ€æœ¯å¹³å°ä¸€å®šå¤§æœ‰ç”¨å¤„ï¼Œè¿™ä¸ªå±äºåŸºç¡€çš„å·¥å…·ç±»äº§å“ï¼Œå°†å¾ˆå¤æ‚çš„æŠ€æœ¯åšæˆäººäººå¯ä»¥è½»æ¾ä½¿ç”¨çš„å·¥å…·æ˜¯ä¸€ä»¶å¾ˆæœ‰æ„ä¹‰çš„äº‹æƒ…ï¼Œåƒæ˜¯IDEçš„æ„Ÿè§‰ï¼Œä¸ç®¡ä»€ä¹ˆèƒŒæ™¯ï¼Œåªè¦æ˜¯æœ‰æƒ³æ³•ï¼Œå°±å¯ä»¥é€šè¿‡è¿™ä¸ªå·¥å…·æ¥å®ç°ä¸€ä¸ªbotï¼Œå¦‚æœå¤æ‚çš„ï¼Œå¯èƒ½éœ€è¦å®šåˆ¶ã€‚</p>
<p>ï¼ˆ5ï¼‰ç‰¹å®šä»»åŠ¡çš„ç§äººåŠ©ç†ï¼Œæ¯”å¦‚å¸®å¿™ç®¡ç†æ—¥ç¨‹ã€åˆ¶å®šæ—…è¡Œè®¡åˆ’ä¹‹ç±»çš„ï¼Œæœ¯ä¸šæœ‰ä¸“æ”»å˜›ï¼Œè¿™ä¸ªæœ€å¥½æ˜¯ä¹‹å‰åœ¨å…¶ä»–å¹³å°ä¸Šåšç±»ä¼¼åŠŸèƒ½çš„ä¼ä¸šè½¬å‹åˆ°botè¿™é‡Œæ¥ï¼Œæœ‰ç€è¶³å¤Ÿçš„ç§¯æ·€ï¼Œèå…¥ä¸€äº›æ–°çš„äº¤äº’å’ŒæŠ€æœ¯æ¥æå‡äº§å“ä½“éªŒã€‚</p>
<p>ä¸Šé¢çš„æ¯ä¸ªå­é¢†åŸŸåœ¨å›½å¤–éƒ½æœ‰æ¨¡æ¿å¯ä»¥å‚è€ƒï¼Œå›½å†…çš„è¯è¿˜æ¯”è¾ƒå°‘ï¼Œæ‰€ä»¥æ˜¯å¾ˆå¤§çš„æœºä¼šï¼Œå…³é”®åœ¨äºåˆ¤æ–­ï¼Œåœ¨äºå…·ä½“æƒ…å†µå…·ä½“åˆ†æã€‚å› ä¸ºæœ‰äº›ä¸œè¥¿å¹¶ä¸é€‚åˆåšæˆbotè¿™ç§èŠå¤©å¼çš„äº¤äº’æ–¹å¼ï¼Œç®€å•çš„å‡ ä¸ªæŒ‰é’®æ“ä½œå°±å¯ä»¥è½»æ¾å®Œæˆçš„äº‹æƒ…ï¼Œä¸ºä»€ä¹ˆéè¦æ‰“å¾ˆå¤šçš„å­—æ¥åšå‘¢ï¼Ÿ</p>
<p>3ã€å£å’ã€‚ä½ çš„æ ¸å¿ƒç«äº‰åŠ›æ˜¯ä»€ä¹ˆï¼Ÿä»€ä¹ˆæ˜¯ä½ ä¼šåˆ«äººä¸ä¼šçš„ï¼Ÿå¦‚æœè…¾è®¯ä¹Ÿåšè¿™ä¸ªäº‹æƒ…ï¼Œä½ ä»¬è¯¥æ€ä¹ˆåŠï¼Ÿä½ çš„ä¼ä¸šå¢é•¿ç‚¹åœ¨å“ªé‡Œï¼Ÿå¦‚ä½•åšå¤§ï¼Ÿ</p>
<p>è¿™äº›é—®é¢˜æ˜¯æŠ•èµ„äººæœ€å…³æ³¨çš„é—®é¢˜ï¼Œå…¶å®ä¹Ÿæ˜¯åˆ›ä¸šå‰æœ€åº”è¯¥æƒ³æ˜ç™½çš„é—®é¢˜ï¼Œå¦‚æœè‡ªå·±éƒ½æƒ³ä¸æ˜ç™½ï¼Œæˆ–è€…å¾ˆå¤šé—®é¢˜éš¾ä»¥å›ç­”çš„è¯ï¼Œè¯´æ˜ç°åœ¨çš„æƒ…å†µè¿˜ä¸é€‚åˆåˆ›ä¸šæˆ–è€…æ‹¿æŠ•èµ„ã€‚æˆ‘è®¤ä¸ºï¼Œæ— è®ºä»€ä¹ˆæ—¶å€™äººéƒ½æ˜¯æœ€æ ¸å¿ƒçš„ç«äº‰åŠ›ï¼ŒæŠ€æœ¯å’Œäº¤äº’å½¢å¼æ—¥æ–°æœˆå¼‚ï¼Œæ›´è¿­å¾ˆå¿«ï¼Œå›¢é˜Ÿåªè¦å…·æœ‰å¾ˆå¼ºçš„å­¦ä¹ èƒ½åŠ›ï¼Œæ°¸è¿œéƒ½ä¸ä¼šè½äºä¸‹é£ã€‚æ²¡æœ‰ä»€ä¹ˆæŠ€æœ¯ä¸€å®šæ˜¯åªæœ‰ä½ ä¸€äººæ‰ä¼šçš„ï¼Œå·¥ç¨‹ä¸Šçš„æŠ€æœ¯å£å’ä¸åº”æ˜¯ä½ æå‡ºäº†ä¸€ä¸ªä¸¾ä¸–æ— åŒã€å¤©ä¸‹æ— æ•Œçš„ç®—æ³•ï¼Œè€Œæ˜¯ä½ åœ¨è¿™ä¸ªé¢†åŸŸå†…å®è·µå„ç§å„æ ·ç®—æ³•çš„ç»éªŒç§¯ç´¯ã€‚ä¸ºä»€ä¹ˆè¯´ä¸€å®šè¦ä¸“æ³¨åœ°åšå¥½ä¸€ä¸ªäº‹æƒ…ï¼Œåªåšè¿™ä¸€ä»¶äº‹æƒ…ï¼Œå°†è¿™ä»¶äº‹æƒ…åšåˆ°ç²¾ï¼Œå› ä¸ºå¯¹è¿™ä¹ˆç»†å°çš„é¢†åŸŸç†è§£åœ°å¦‚æ­¤ä¹‹æ·±çš„äººæ²¡æœ‰å‡ ä¸ªï¼Œè¿™æ˜¯ä½ çš„æŠ€æœ¯å£å’ï¼Œä¹Ÿæ˜¯ä¼ä¸šçš„ç”Ÿå­˜ä¹‹é“ï¼Œä¹Ÿæ˜¯å…¶ä»–å¤§å…¬å¸éš¾ä»¥æŠ„è¢­çš„é‡è¦åŸå› ã€‚è¿™ä¸ªé—®é¢˜ä¸€å®šè¦æƒ³æ¸…æ¥šï¼Œæœ€é‡è¦çš„æ˜¯äººï¼Œåœ¨æŠ€æœ¯å±‚é¢ä¸Šï¼Œä¸è¦æƒ³ç€æ‰¾åˆ°ä¸€ä¸ªç‹¬é—¨ç§˜ç±æ¥æ‰“å¤©ä¸‹ï¼Œè€Œæ˜¯å¯¹ä½ æ‰€ç ”ç©¶çš„é—®é¢˜æœ‰éå¸¸æ·±å…¥åœ°ç†è§£å’Œè§è§£ï¼Œè¿™æ˜¯æœ€åŸºæœ¬çš„ä¹Ÿæ˜¯æœ€æ ¸å¿ƒçš„ï¼›æ¥ä¸‹æ¥æ‰æ˜¯å¦‚ä½•å‘å±•å’Œå£®å¤§çš„é—®é¢˜ï¼Œè¿™ä¸ªé—®é¢˜éœ€è¦è®²æ•…äº‹çš„èƒ½åŠ›ï¼Œæç»˜å‡ºä¸€å¹…ç¾å¥½ç”»é¢çš„èƒ½åŠ›ã€‚</p>
<p>æˆ‘è§‰å¾—äººçš„èƒ½åŠ›æ˜¯æœ€æ ¹æœ¬çš„å£å’ï¼Œå½“ç„¶ä¼šæœ‰ä¸åŒçœ‹æ³•ã€‚æœ‰çš„ä¼ä¸šå¿«é€Ÿæ‰©å¼ ï¼Œç§¯ç´¯å®¢æˆ·ï¼Œå¯èƒ½è§‰å¾—ç§¯ç´¯çš„æ•°æ®å’Œå®¢æˆ·èµ„æºæ˜¯å£å’ï¼Œä½†æˆ‘è§‰å¾—å¦‚æœä¸€ä¸ªæ–°çš„æ›´å¥½ç”¨çš„æŠ€æœ¯å‡ºæ¥äº†ï¼Œè€Œä½ çš„ä¼ä¸šæŠ€æœ¯å´æ²¡è·Ÿä¸Šçš„è¯ï¼Œå¾ˆå®¹æ˜“å°±ä¼šè¢«å–ä»£çš„ï¼Œä¸ç®¡ä½ æ˜¯5w+ï¼Œè¿˜æ˜¯10w+çš„å®¢æˆ·ã€‚</p>
<p>ä¸€ç‚¹æ€è€ƒï¼Œæ¬¢è¿äº¤æµã€‚</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
  
    <a href="/page/2/" class="alignright next">ä¸‹ä¸€é¡µ</a>
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="æœç´¢">
    <input type="hidden" name="q" value="site:rsarxiv.github.io">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">æ ‡ç­¾</h3>
  <ul class="entry">
  
    <li><a href="/tags/Autoencoder/">Autoencoder</a><small>1</small></li>
  
    <li><a href="/tags/CNN/">CNN</a><small>2</small></li>
  
    <li><a href="/tags/DQN/">DQN</a><small>4</small></li>
  
    <li><a href="/tags/Memory-Network/">Memory Network</a><small>1</small></li>
  
    <li><a href="/tags/NLP/">NLP</a><small>2</small></li>
  
    <li><a href="/tags/PaperWeekly/">PaperWeekly</a><small>99</small></li>
  
    <li><a href="/tags/RNN/">RNN</a><small>1</small></li>
  
    <li><a href="/tags/RNNLM/">RNNLM</a><small>1</small></li>
  
    <li><a href="/tags/ROUGE/">ROUGE</a><small>1</small></li>
  
    <li><a href="/tags/RSarXiv/">RSarXiv</a><small>1</small></li>
  
    <li><a href="/tags/Reading-Comprehension/">Reading Comprehension</a><small>6</small></li>
  
    <li><a href="/tags/Representation/">Representation</a><small>1</small></li>
  
    <li><a href="/tags/Text-Comprehension/">Text Comprehension</a><small>1</small></li>
  
    <li><a href="/tags/api-ai/">api.ai</a><small>1</small></li>
  
    <li><a href="/tags/arXiv/">arXiv</a><small>2</small></li>
  
    <li><a href="/tags/arxiv/">arxiv</a><small>2</small></li>
  
    <li><a href="/tags/attention/">attention</a><small>3</small></li>
  
    <li><a href="/tags/bot/">bot</a><small>21</small></li>
  
    <li><a href="/tags/chatbot/">chatbot</a><small>2</small></li>
  
    <li><a href="/tags/dataset/">dataset</a><small>1</small></li>
  
    <li><a href="/tags/deep-learning/">deep learning</a><small>1</small></li>
  
    <li><a href="/tags/deeplearning/">deeplearning</a><small>1</small></li>
  
    <li><a href="/tags/language-model/">language model</a><small>1</small></li>
  
    <li><a href="/tags/nlp/">nlp</a><small>116</small></li>
  
    <li><a href="/tags/open-source/">open source</a><small>1</small></li>
  
    <li><a href="/tags/paper/">paper</a><small>7</small></li>
  
    <li><a href="/tags/paperweekly/">paperweekly</a><small>2</small></li>
  
    <li><a href="/tags/reading-comprehension/">reading comprehension</a><small>1</small></li>
  
    <li><a href="/tags/reinforcement-learning/">reinforcement learning</a><small>1</small></li>
  
    <li><a href="/tags/sentence-representations/">sentence representations</a><small>1</small></li>
  
    <li><a href="/tags/seq2seq/">seq2seq</a><small>17</small></li>
  
    <li><a href="/tags/text-comprehension/">text comprehension</a><small>1</small></li>
  
    <li><a href="/tags/torch/">torch</a><small>1</small></li>
  
    <li><a href="/tags/word-embedding/">word embedding</a><small>2</small></li>
  
    <li><a href="/tags/word-embeddings/">word embeddings</a><small>1</small></li>
  
    <li><a href="/tags/word2vec/">word2vec</a><small>1</small></li>
  
    <li><a href="/tags/åˆ›ä¸š/">åˆ›ä¸š</a><small>1</small></li>
  
    <li><a href="/tags/æ‹›è˜/">æ‹›è˜</a><small>1</small></li>
  
    <li><a href="/tags/æ¨èç³»ç»Ÿ/">æ¨èç³»ç»Ÿ</a><small>2</small></li>
  
    <li><a href="/tags/ç»¼è¿°/">ç»¼è¿°</a><small>1</small></li>
  
    <li><a href="/tags/è‡ªåŠ¨æ–‡æ‘˜/">è‡ªåŠ¨æ–‡æ‘˜</a><small>16</small></li>
  
    <li><a href="/tags/éšç¬”/">éšç¬”</a><small>4</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- rsarxiv -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-7417238904018690"
     data-ad-slot="4681057960"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2017 PaperWeekly
  
</div>
<div class="clearfix"></div>
<!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a class="jiathis_button_xiaoyou"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END --></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>