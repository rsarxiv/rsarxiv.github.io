<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>PaperWeekly</title>
  
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="PaperWeekly"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="PaperWeekly" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-77933764-1', 'auto');
	ga('send', 'pageview');

</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">PaperWeekly</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/atom.xml">Rss</a></li>
    
      <li><a href="/about/index.html">About</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-10-21T06:30:26.000Z"><a href="/2016/10/20/PaperWeekly-第十期/">2016-10-20</a></time>
      
      
  
    <h1 class="title"><a href="/2016/10/20/PaperWeekly-第十期/">PaperWeekly 第十期</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="引"><a href="#引" class="headerlink" title="引"></a>引</h2><p>本期PaperWeekly的主题是基于翻译模型(Trans系列)的知识表示学习，主要用来解决知识表示和推理的问题。表示学习旨在将研究对象的语义信息表示为稠密低维实值向量，知识表示学习主要是面向知识图谱中的实体和关系进行表示学习。使用建模方法将实体和向量表示在低维稠密向量空间中，然后进行计算和推理。一般而言的应用任务为triplet classification 和link prediction.自从2013年TransE模型提出后，产生了一系列模型对TransE模型进行改进和补充,比如TransH、TransG等等。本期PaperWeekly主要提供了Trans系列的7篇文章供大家赏读。</p>
<p>paper目录：<br>（1）TransE，NIPS2013，Translating embeddings for modeling multi-relational data。<br>（2）TransH，AAAI2014，Knowledge graph embedding by translating on hyperplanes。<br>（3）TransD，ACL2015，Knowledge graph embedding via dynamic mapping matrix。<br>（4）TransA，arXiv2015，An adaptive approach for knowledge graph embedding。<br>（5）TransG，arxiv2015，A Generative Mixture Model for Knowledge Graph Embedding)<br>（6）KG2E，CIKM2015，Learning to represent knowledge graphs with gaussian embedding。<br>（7）TranSparse，AAAI2016，Knowledge graph completion with adaptive sparse transfer matrix。 </p>
<h1 id="TransE-Translating-Embeddings-for-Modeling-Multi-relational-Data"><a href="#TransE-Translating-Embeddings-for-Modeling-Multi-relational-Data" class="headerlink" title="TransE:Translating Embeddings for Modeling Multi-relational Data"></a><a href="http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf" target="_blank" rel="external">TransE:Translating Embeddings for Modeling Multi-relational Data</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>A Bordes, N Usunier, A Garcia-Duran, J Weston, O Yakhnenko</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>CNRS, Google inc.</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Embedding entities and relationships, Multi-relational data, link prediction</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>NIPS 2013/12</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>如何建立简单且易拓展的模型把知识库中的实体和关系映射到低维向量空间中，从而计算出隐含的关系？</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>传统训练知识库中三元组(head,relation,tail)建模的方法参数特别多，导致模型太复杂难以解释，并且需要很大的计算代价，很容易出现过拟合或欠拟合问题。而简单的模型在表现上与复杂的模型几乎一样，但更易拓展。TransE的训练过程如下图：</p>
<p><img src="media/TransE_1.png" alt=""></p>
<p>TransE模型的训练中，第12步是损失函数，对E和L做uniform初始化之后，让正确的h+l-t结果趋近于0，让错误的h‘+l-t’的结果变大，损失函数结果大于0取原值，小于0则取0，这种hinge loss function可以尽可能的将对和错分开，模型使用SGD训练，每次更新可以只更新这个batch里的三元组的向量，因为参数之间并没有冲突。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>数据集 WordNet    <a href="http://wordnet.princeton.edu/wordnet/download/" target="_blank" rel="external">http://wordnet.princeton.edu/wordnet/download/</a><br>数据集 Freebase   <a href="http://developers.google.com/freebase/" target="_blank" rel="external">http://developers.google.com/freebase/</a><br>Code: <a href="https://github.com/thunlp/KB2E" target="_blank" rel="external">https://github.com/thunlp/KB2E</a></p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文提出了一种将实体与关系嵌入到低维向量空间中的简单模型，弥补了传统方法训练复杂、不易拓展的缺点。尽管现在还不清楚是否所有的关系种类都可以被本方法建模，但目前这种方法相对于其他方法表现不错。TransE更是作为知识库vector化的基础，衍生出来了很多变体。</p>
<h1 id="TransH-Knowledge-Graph-Embedding-by-Translating-on-Hyperplanes"><a href="#TransH-Knowledge-Graph-Embedding-by-Translating-on-Hyperplanes" class="headerlink" title="TransH:Knowledge Graph Embedding by Translating on Hyperplanes"></a><a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/view/8531" target="_blank" rel="external">TransH:Knowledge Graph Embedding by Translating on Hyperplanes</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Zhen Wang1, Jianwen Zhang2, Jianlin Feng1, Zheng Chen2</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>Sun Yat-sen University<br>microsoft</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>knowledge graph embedding, Multi-relational data</p>
<h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p>AAAI 2014</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>对知识库中的实体关系建模,特别是一对多,多对一,多对多的关系。设计更好的建立负类的办法用于训练。 </p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>过去指示图库建模的方法参数过多, TransE在一定程度上解决了这个问题, 但是TransE过于简单，很难对一对多,多对一和多对多关系建模。所以为了平衡模型复杂度和建模效果，TransH将把关系映射到另一个空间（如下图 ）。 注意: 这种想法和Distant Model (Bordes et al. 2011)很相似，但是TransH用了更少的参数， 因为TransH假设关系是向量而不是距离。<br><img src="media/TransH_1.png" alt="TransH_1"></p>
<p>这个模型的一个亮点就是用尽量少的参数对复杂的关系建模。 下图罗列了相关工作的模型以及复杂度。图中可以看到从TransE到TransH并没有添加太多的参数（Unstructured只是TransE简化版）。Bilinear，Single Layer， NTN对关系或者实体进行了非线性的转换，作者认为是没有必要的（增加了模型复杂度）。</p>
<p><img src="media/TransH_2.png" alt="TransH_2"></p>
<p>TransH模型的训练和TransE类似 （SGD优化） ，下面是损失函数（因为一些限制，后面加入了拉格朗日乘数）。论文另一个亮点是设计了一种负类抽样的方法，即一对多的时候，给head更多的抽样概率， 同样的多对一的时候，给tail更多抽样概率。<br><img src="media/TransH_3.png" alt="TransH_3"></p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>数据集 WordNet:<a href="http://wordnet.princeton.edu/wordnet/download/" target="_blank" rel="external">http://wordnet.princeton.edu/wordnet/download/</a><br>数据集 Freebase:  <a href="http://developers.google.com/freebase/" target="_blank" rel="external">http://developers.google.com/freebase/</a><br>Code:<a href="https://github.com/thunlp/KB2E" target="_blank" rel="external">https://github.com/thunlp/KB2E</a></p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>（1）TransE (Bordes et al. 2013b): 和TransH相比，它没有将关系映射到另一个空间，关系由一个向量r表示。<br>（2）Unstructured Model：简化版的TransE，假设r = 0。<br>（3）Structured Embedding：  使用了两个关系相关的矩阵，分别用于头h和尾t，评估函数为:<br><img src="media/TransH_4.PNG" alt=""><br>该方法并没有抓住实体和关系之间的关系。<br>（4）Single Layer Model(SLM)：使用了神经网络，评估函数为:<br><img src="media/TransH_5.PNG" alt=""><br>（5）Distant Model (Bordes et al. 2011)：它将实体映射到另一个空间，然后假定关系是距离而不是向量（因为用了2个不同矩阵映射实体，所以对实体关系建模并不是很好）。<br>（6）Bilinear Model (Jenatton et al. 2012; Sutskever, Tenen- baum, and Salakhutdinov 2009)，Single Layer Model (Socher et al. 2013)，NTN (Socher et al. 2013)：他们都是使用非线性函数映射实体，这样模型表达能力虽然好但是太多参数也太复杂了（容易过拟合）。</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>论文提出的TransH模型，为了解决TransE对一对多，多对一，多对多关系建模的难题。它权衡模型复杂度和模型表达能力。而且还设计了复杂取样的办法用于训练。</p>
<h1 id="TransD-knowledge-graph-embedding-via-dynamic-mapping-matrix"><a href="#TransD-knowledge-graph-embedding-via-dynamic-mapping-matrix" class="headerlink" title="TransD: knowledge graph embedding via dynamic mapping matrix"></a><a href="http://www.aclweb.org/anthology/P15-1067.pdf" target="_blank" rel="external">TransD: knowledge graph embedding via dynamic mapping matrix</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Guoliang Ji, Shizhu He, Liheng Xu, Kang Liu and Jun Zhao</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>中国科学院自动化研究所  National Laboratory of Pattern Recognition (NLPR)</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>knowledge graph embedding, link prediction.</p>
<h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p>ACL2015</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>知识图谱中的link prediction。</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>在link prediction上的TransE扩展模型，函数仍然为:   </p>
<p> <img src="media/TransD_1.PNG" alt=""> </p>
<p>但h丄和t丄为entity向量h和entity向量t在该relation r上的投影表示。投影定义为：</p>
<p> <img src="media/TransD_2.PNG" alt=""></p>
<p>其中(h_p)^T为某entity的投影向量，h为该entity的表示向量。</p>
<h2 id="资源-2"><a href="#资源-2" class="headerlink" title="资源"></a>资源</h2><p>数据集 WordNet <a href="http://wordnet.princeton.edu/" target="_blank" rel="external">http://wordnet.princeton.edu/</a><br>数据集 FreeBase <a href="https://developers.google.com/freebase/" target="_blank" rel="external">https://developers.google.com/freebase/</a></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>如果TransD的所有投影向量为0，TransD就是TransE。类似的还有TransR/CTransR，他们对每个relation定义了一个mapping矩阵，参数更多计算复杂度更大。</p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>模型只涉及vector的相乘，因此计算复杂度较小，效果也取得了state-of-the-art，适合用于规模很大的知识图谱。</p>
<h1 id="TransA-An-Adaptive-Approach-for-Knowledge-Graph-Embedding"><a href="#TransA-An-Adaptive-Approach-for-Knowledge-Graph-Embedding" class="headerlink" title="TransA:An Adaptive Approach for Knowledge Graph Embedding"></a><a href="https://arxiv.org/pdf/1509.05490v2.pdf" target="_blank" rel="external">TransA:An Adaptive Approach for Knowledge Graph Embedding</a></h1><h2 id="作者-3"><a href="#作者-3" class="headerlink" title="作者"></a>作者</h2><p>Hao Xian, Minlin  Huang,  Hao Yu,  Xiaoyan  Zhu</p>
<h2 id="单位-3"><a href="#单位-3" class="headerlink" title="单位:"></a>单位:</h2><p> 清华大学  State Key Lab on Intelligent Technology and Systems</p>
<h2 id="关键词："><a href="#关键词：" class="headerlink" title="关键词："></a>关键词：</h2><p>knowledge graph embedding,  elliptical equipotential hypersurfaces,  metric learning.</p>
<h2 id="文章来源-3"><a href="#文章来源-3" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv</p>
<h2 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h2><p>如何解决了translation-based 知识表示方法存在的过于简化损失度量，没有足够竞争力去度量知识库中实体/关系的多样性和复杂性问题。</p>
<h2 id="模型-3"><a href="#模型-3" class="headerlink" title="模型"></a>模型</h2><p>知识图谱在AI搜索和应用中扮演着越来越重要的角色，但是它是符号表示，有一定的逻辑性的，因此如何表示这些关系就成了一个很大的挑战，为了解决这个挑战，很多模型如TransE, TransH, TransR纷纷被提出来，在这些模型中，基于几何关系的方法是很重要的一个分支，而基于几何关系的方法是使用K维的向量表示实体或者关系，然后利用一个函数f_r(h,t)来度量三元组(h, r, t)，而他们都是基于一个准则h+r=t。<br>因此就使用了同一个损失度量h+r=t，这种损失度量其实是利用了在一个球形等价超平面，越接近中心，三元组的可信度越高，因此从未匹配的t中寻找合适的t就变得很苦难，同时这种方法也很难处理一对多，多对一，多对多的关系。因此这些方法不够灵活。<br>具体可以从图1(a)看出。同时这种方法将等价对待向量中的每一维，但实际上各个维度的重要性是不同的，只有一些维度是有效的，其他维度可以认为是噪音，会降低效果，具体见图2(a).</p>
<p>因此作者提出了另一种损失度量函数</p>
<p><img src="media/TransA-2.PNG" alt=""></p>
<p>通过增加一个矩阵Wr​，首先利用了一个椭圆等价超平面，解决了上述问题1，具体见图1(b)；同时利用LDL分解，公式变为:</p>
<p><img src="media/TransA-3.PNG" alt=""></p>
<p>其中D_r就是一个对角阵，而对角阵中的每个值的大小，正好说明了每一维的不同重要程度，也就解决了上述问题2，具体减图2(b)。</p>
<p><img src="media/TransA-4.JPG" alt="figure 1"><br>图1<br><img src="media/TransA-5.JPG" alt="figure 2"><br>图2</p>
<h2 id="资源-3"><a href="#资源-3" class="headerlink" title="资源"></a>资源</h2><p>数据集 Wordnet <a href="http://wordnet.princeton.edu/" target="_blank" rel="external">http://wordnet.princeton.edu/</a><br>数据集 FreeBase <a href="https://developers.google.com/freebase/" target="_blank" rel="external">https://developers.google.com/freebase/</a></p>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><p>如模型部分介绍的，当前的一些现有模型都是基于一个准则h+r=t，因此就使用了同一个损失度量h_r+r=t_r，只是在h_r和t_r的表示上有不同：</p>
<p>（1）TransE  h_r = h, t_r = t<br>（2）TransH  h_r = h - (w_r)^T.h.w_r,  t_r = t - (w_r)^T.t.w_r<br>（3）TransR  h_r = M_r.h,  t_r = M_r.t<br>（4）TransM则是预先计算了出每一个训练三元组的直接权重</p>
<p>还有很多类似的模型，这里就不再介绍了。</p>
<h2 id="简评-3"><a href="#简评-3" class="headerlink" title="简评"></a>简评</h2><p>感觉这篇文章的思路比较简单，就是针对当前模型的一些不足，更换了一个损失度量函数。但是几点还是值得学习的，首先通过图像来描述不同的损失度量函数，给人一个更直观的感觉；其次针对向量表示中的区别对待，感觉很有attention mechanism的感觉，对不同的triple关注向量表示的不同维度，以取得最好的效果，这点是非常值得借鉴参考的。</p>
<h1 id="TransG-A-Generative-Mixture-Model-for-Knowledge-Graph-Embedding"><a href="#TransG-A-Generative-Mixture-Model-for-Knowledge-Graph-Embedding" class="headerlink" title="TransG : A Generative Mixture Model for Knowledge Graph Embedding"></a><a href="https://arxiv.org/abs/1509.05488" target="_blank" rel="external">TransG : A Generative Mixture Model for Knowledge Graph Embedding</a></h1><h2 id="作者-4"><a href="#作者-4" class="headerlink" title="作者"></a>作者</h2><p> Han Xiao, Minlie Huang, Yu Hao, Xiaoyan Zhu</p>
<h2 id="单位-4"><a href="#单位-4" class="headerlink" title="单位"></a>单位</h2><p>清华大学  State Key Lab on Intelligent Technology and Systems</p>
<h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>knowledge graph embedding, generative mixture model, multiple relration semantics.</p>
<h2 id="文章来源-4"><a href="#文章来源-4" class="headerlink" title="文章来源"></a>文章来源</h2><p>arXiv2015</p>
<h2 id="问题-4"><a href="#问题-4" class="headerlink" title="问题"></a>问题</h2><p>解决多关系语义(multiple relation semantics)的问题。</p>
<h2 id="模型-4"><a href="#模型-4" class="headerlink" title="模型"></a>模型</h2><p>传统的基于翻译的模型采用h_r+r= t_r(其中，h_r为头部实体，t_r为尾部实体，r为头部<br>实体跟尾部实体的关系)，仅仅对一个关系赋予一种翻译向量。<br>它们不能细分多关系语义，比如，(Atlantics, HasPart, NewYorkBay)和(Table, HasPart, Leg)两个的关系都是HasPart，但是这两个的关系在语义上不同，第一个是“部件”的关系，第二个是“位置”的关系。TransG能够解决关系的多语义问题。如图所示，多关系语义分析可以提高三元组的分类准确度。</p>
<p><img src="media/TransG.png" alt="figure 1"></p>
<p>TransG利用贝叶斯非参数无限混合模型对一个关系生成多个翻译部分，根据三元组的特定语义得到当中的最佳部分。最大数据相似度原理用来训练，优化采用SGD。实验结果在link prediction和triple classification这两种任务上都优于目前最好的结果，运行速度与TransE(最快的方法)成正相关，系数为关系语义部分的数目。</p>
<h2 id="资源-4"><a href="#资源-4" class="headerlink" title="资源"></a>资源</h2><p>数据集 WordNet    <a href="http://wordnet.princeton.edu/wordnet/download/" target="_blank" rel="external">http://wordnet.princeton.edu/wordnet/download/</a><br>数据集 Freebase   <a href="http://developers.google.com/freebase/" target="_blank" rel="external">http://developers.google.com/freebase/</a></p>
<h2 id="相关工作-3"><a href="#相关工作-3" class="headerlink" title="相关工作"></a>相关工作</h2><p>大多数都已介绍，这里就只说明CTransR，其中关系的实体对被分类到不同的组，同一组的实体对共享一个关系向量。相比较而言，TransG不需要对聚类的预处理。</p>
<h2 id="简评-4"><a href="#简评-4" class="headerlink" title="简评"></a>简评</h2><p>这篇文章的idea比较重要，考虑到一种关系存在的多语义问题，相当于对关系进行了细化，就是找到关系的隐形含义，最终从细化的结果中选出一个最佳的关系语义。这个在应用中很有意义，不同的语义可能需要不同的应对方法，可以借鉴。</p>
<h1 id="KG2E-KG2E-learning-to-represent-knowledge-graphs-with-gaussian-embedding"><a href="#KG2E-KG2E-learning-to-represent-knowledge-graphs-with-gaussian-embedding" class="headerlink" title="KG2E:KG2E_learning to represent knowledge graphs with gaussian embedding"></a><a href="http://dl.acm.org/citation.cfm?id=2806502" target="_blank" rel="external">KG2E:KG2E_learning to represent knowledge graphs with gaussian embedding</a></h1><h2 id="作者-5"><a href="#作者-5" class="headerlink" title="作者"></a>作者</h2><p>Shizhu He, Kang Liu, Guoliang Ji and Jun Zhao</p>
<h2 id="单位-5"><a href="#单位-5" class="headerlink" title="单位"></a>单位</h2><p>National Laboratory of Pattern Recognition<br>Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China</p>
<h2 id="关键词-4"><a href="#关键词-4" class="headerlink" title="关键词"></a>关键词</h2><p>Distributed Representation, Gaussian Embedding, Knowledge Graph</p>
<h2 id="文章来源-5"><a href="#文章来源-5" class="headerlink" title="文章来源"></a>文章来源</h2><p>CIKM 2015</p>
<h2 id="问题-5"><a href="#问题-5" class="headerlink" title="问题"></a>问题</h2><p>本文所解决的问题是知识图谱的表示问题（即将知识图谱表示为低维连续向量空间），本文使用Gaussian Distribution 来表示实体和关系，提出了用Gaussian Distribution的协方差来表示实体和关系的不确定度的新思想，提升了已有模型在link prediction和triplet classification问题上的准确率。</p>
<h2 id="模型-5"><a href="#模型-5" class="headerlink" title="模型"></a>模型</h2><p>传统的表示学习的表示学习的方法和计算比较复杂，自TransE模型诞生后，很多模型都是在TransE的基本思想上加以改进，KG2E模型也是一样。<br>KG2E模型使用高斯分布来表示实体和关系。<br>模型实例见下图：<br><img src="media/KG2E_example.png" alt="model example"></p>
<p>每个圆圈代表不同实体与关系的表示，它们分别于“Bill Clinton”构成三元组关系，圆圈大小表示的是不同实体或关系的不确定度。</p>
<p>模型算法流程图如下：<br><img src="media/KG2E_Algorithm.png" alt="model algorithm"></p>
<p>算法解读：<br>输入：训练集三元组，KG中所有的实体和关系，以及其它的一些参数。<br>输出：KG中所有实体和关系建模后生成的Gaussian Embeddings.（主要包含两个部分，均值（向量）和协方差（矩阵））<br>line 1到line 4主要是数据的归一化<br>line 5到line 15是算法实现部分：模型采用的是minibatch的训练方法，每一个minibatch的训练中都会进行负采样，并将负采样的样例和正例样例混合在一起学习，然后使用评分函数进行评估，要达到的目的是正例三元组的得分比负例三元组高或者低（高低取决于具体的评分而函数的设定）。在一次一次的迭代中不断更新结果，最后将得到的means和covariance进行正则化。</p>
<p>文章核心公式：<br>（1）评分函数<br><img src="media/KG2E_Score_function.png" alt="score function"></p>
<p>（2）KL散度的能量函数</p>
<p><img src="media/KG2E_KL_function.png" alt="KL energy function"></p>
<p>（3）期望概率能量函数<br><img src="media/KG2E_EL_function.png" alt="EL energy function"></p>
<h2 id="资源-5"><a href="#资源-5" class="headerlink" title="资源"></a>资源</h2><p>数据集：<br>    <a href="https://github.com/Mrlyk423/Relation_Extraction/blob/master/data.zip" target="_blank" rel="external">WN18</a><br>    <a href="https://github.com/dddoss/tensorflow-socher-ntn/tree/master/data/Wordnet" target="_blank" rel="external">WN11</a><br>    <a href="https://github.com/dddoss/tensorflow-socher-ntn/tree/master/data/Freebase" target="_blank" rel="external">FB13K</a><br>    <a href="https://github.com/Mrlyk423/Relation_Extraction/blob/master/data.zip" target="_blank" rel="external">FB15K</a></p>
<h2 id="相关工作-4"><a href="#相关工作-4" class="headerlink" title="相关工作"></a>相关工作</h2><p>（1）TransR，2015年AAAI，Learning entity and relation embeddings for knowledgh completition。</p>
<h2 id="简评-5"><a href="#简评-5" class="headerlink" title="简评"></a>简评</h2><p>创新点：<br>    （1）以前的文章是属于point-based，KG2E是属于density-based的。<br>    （2）提出了(un)certainty的概念，在建模过程中融入了关系和实体语义本身的不确定性的知识，使用高斯分布的协方差表示该实体或关系的不确定度，高斯分布的均值表示实体或关系在语义空间中的中心值。<br>    （3）使用了新的score funciton：KL-divergence和expected likelihood<br>应用场景：link prediction，triplet classification,knowledge reasoning<br>不足之处：本文提出的方法在link prediction的many-to-many relations上的预测性能不是很好，主要原因是KG2E模型没有考虑实体的类型和粒度。</p>
<p>7.TranSparse</p>
<h1 id="Knowledge-Graph-Completion-with-Adaptive-Sparse-Transfer-Matrix"><a href="#Knowledge-Graph-Completion-with-Adaptive-Sparse-Transfer-Matrix" class="headerlink" title="Knowledge Graph Completion with Adaptive Sparse Transfer Matrix"></a><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11982/11693" target="_blank" rel="external">Knowledge Graph Completion with Adaptive Sparse Transfer Matrix</a></h1><h2 id="作者-6"><a href="#作者-6" class="headerlink" title="作者"></a>作者</h2><p>Guoliang Ji, Kang Liu, Shizhu He, Jun Zhao</p>
<h2 id="单位-6"><a href="#单位-6" class="headerlink" title="单位"></a>单位</h2><p>中科院模式识别国家重点实验室</p>
<h2 id="关键词-5"><a href="#关键词-5" class="headerlink" title="关键词"></a>关键词</h2><p>Knowledge Graph Embedding,Sparse Matrix</p>
<h2 id="文章来源-6"><a href="#文章来源-6" class="headerlink" title="文章来源"></a>文章来源</h2><p>AAAI 2016</p>
<h2 id="问题-6"><a href="#问题-6" class="headerlink" title="问题"></a>问题</h2><p>针对不同难度的实体间关系，使用不同稀疏程度的矩阵（不同数量的参数）来进行表征，从而防止对复杂关系欠拟合或者对简单关系过拟合。</p>
<h2 id="模型-6"><a href="#模型-6" class="headerlink" title="模型"></a>模型</h2><p>本文的模型与TransR类似，即对每一个关系r学习一个转换矩阵M_r,将h和t的向量映射到关系向量所在的空间。</p>
<p>不过本文注意到knowledge graph中面临两个问题，分别是heterogeneous（有的实体关系十分复杂，连接许多不同的实体）和unbalanced（很多关系连接的head和tail数目很不对等）。如果只使用一个模型应对所有情况的话可能会导致对复杂关系underfit，对简单关系overfit。因此本文认为需要对症下药，复杂的关系就需要下猛药（用有更多的参数的复杂模型），简单关系就简单处理（较少的参数）。</p>
<p>但是怎么实现这样灵活的建模？在方法上本文借用了SparseMatrix，如果关系比较复杂就用比较稠密的矩阵，如果关系简单则用稀疏矩阵进行表达。文章假设关系的复杂程度正比于包含该关系的triplet数目，并根据两类问题提出了对应的稀疏矩阵初始化方法。不过并没有提出同时解决两类问题的统一方案。</p>
<ul>
<li>针对heterogeneity问题的模型叫做TranSparse(share)，模型参数sparse degree，theta_r，是由下列公式确定:</li>
</ul>
<p><img src="media/TranSparse_equation1.png" alt="alt text"><br>其中N_r是该关系r所连接的triplet数目，N_r*是数据集中最大的关系triplet数目。通过这个sparse degree我们就可以确定参数矩阵的稀疏程度了。entity的向量通过下式进行转换：<br><img src="media/TranSparse_equation2.png" alt="alt text"></p>
<ul>
<li>针对imbalance问题提出的TranSparse(separate)方法也十分类似，即在关系的head和tail两端使用不同复杂度的matrix。sparse degree的公式与上面TranSparse(share)的几乎一样，只不过N_r和N_r*替换成了entity的个数。如果某一端要连接更多不同的entity，那么这一端就需要更复杂的模型来表征（matrix有更多非零参数）。</li>
</ul>
<p>确定这个sparse degree之后，我们就可以初始化对应的稀疏参数矩阵了（原文中提到了Structured与Unstructured两种矩阵形式）。目标函数以及训练过程与其他工作一致，只不过在进行训练时我们只对矩阵中的非零部分进行更新。</p>
<p>最后模型在triplet分类和链接预测任务上进行实验，相比于先前模型取得了更好的成绩，不过相比于TranD优势并不十分明显。提出的两个模型中TranSparse(separate)的表现更好。</p>
<h2 id="资源-6"><a href="#资源-6" class="headerlink" title="资源"></a>资源</h2><p>数据集 WordNet    <a href="http://wordnet.princeton.edu/wordnet/download/" target="_blank" rel="external">http://wordnet.princeton.edu/wordnet/download/</a><br>数据集 Freebase   <a href="http://developers.google.com/freebase/" target="_blank" rel="external">http://developers.google.com/freebase/</a></p>
<h2 id="相关工作-5"><a href="#相关工作-5" class="headerlink" title="相关工作"></a>相关工作</h2><p>上面的相关工作已经介绍差不多了，这里不再赘述。</p>
<h2 id="简评-6"><a href="#简评-6" class="headerlink" title="简评"></a>简评</h2><p>TranSparse模型主要是为了解决关系和实体的异质性和不平衡性而提出，问题针对性强。</p>
<h2 id="总结与展望"><a href="#总结与展望" class="headerlink" title="总结与展望"></a>总结与展望</h2><p>最近几年人们对知识表示方法的探究一直都在进行，知识表示学习对于计算机如何理解和计算知识的意义是重大的。在2013年embedding的思想出现之前，人们基本采用one-hot的表示方法来表示实体，近几年知识表示的核心思想就是如何找到合适的方法来将知识图谱emmbedding到向量空间，从而在向量空间中进行计算，并且也在这方面取得了不错的进展。</p>
<p>但知识表示学习仍然面临着挑战，主要包括以下几个方面：（1）对于多源知识融合的表示学习，如何将知识库中的文本等信息加入到学习中。（2）如何进行更加复杂的知识推理。（3）对于知识图谱无法表达的信息，应该进行如何表示和推理。（4）如何在知识库中融入常识信息。<br>参考文献说明：本文主要参考清华大学刘知远老师的《知识表示学习研究进展》这篇综述。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-10-15T17:39:35.000Z"><a href="/2016/10/15/cs-CL-weekly-2016-10-10-2016-10-14/">2016-10-15</a></time>
      
      
  
    <h1 class="title"><a href="/2016/10/15/cs-CL-weekly-2016-10-10-2016-10-14/">cs.CL weekly 2016.10.10-2016.10.14</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="一周值得读"><a href="#一周值得读" class="headerlink" title="一周值得读"></a>一周值得读</h1><h2 id="Personalizing-a-Dialogue-System-with-Transfer-Learning"><a href="#Personalizing-a-Dialogue-System-with-Transfer-Learning" class="headerlink" title="Personalizing a Dialogue System with Transfer Learning"></a><a href="https://arxiv.org/pdf/1610.02891v1.pdf" target="_blank" rel="external">Personalizing a Dialogue System with Transfer Learning</a></h2><p>【对话系统】【迁移学习】面向具体任务的对话系统由于数据不充分，面临难以训练的尴尬境地。解决这一问题的方法之一是用迁移学习来做，本文提出了一种基于POMDP的迁移学习框架。并且在购买咖啡的实际场景中得到了应用，取得了不错的效果。港科大杨强老师是迁移学习领域的专家，而迁移学习是解决机器学习中领域数据过小问题的一种有效方法，现有的特有对话系统面临着这个问题，尤其是要求对话系统具有个性化的特点时。本文对于研究语音对话系统和聊天机器人都有一定的启发性。</p>
<h2 id="Dialogue-Session-Segmentation-by-Embedding-Enhanced-TextTiling"><a href="#Dialogue-Session-Segmentation-by-Embedding-Enhanced-TextTiling" class="headerlink" title="Dialogue Session Segmentation by Embedding-Enhanced TextTiling"></a><a href="https://arxiv.org/pdf/1610.03955v1.pdf" target="_blank" rel="external">Dialogue Session Segmentation by Embedding-Enhanced TextTiling</a></h2><p>【chatbot】【上下文处理】本文研究的内容是开放域聊天机器人context处理的问题，当前聊天的内容很大程度上都会与之前的聊天内容有相关，但并不是每一句都相关，因此算好相关度很有必要。</p>
<h2 id="Exploiting-Sentence-and-Context-Representations-in-Deep-Neural-Models-for-Spoken-Language-Understanding"><a href="#Exploiting-Sentence-and-Context-Representations-in-Deep-Neural-Models-for-Spoken-Language-Understanding" class="headerlink" title="Exploiting Sentence and Context Representations in Deep Neural Models for Spoken Language Understanding"></a><a href="https://arxiv.org/pdf/1610.04120v1.pdf" target="_blank" rel="external">Exploiting Sentence and Context Representations in Deep Neural Models for Spoken Language Understanding</a></h2><p>【对话系统】【深度学习】本文是steve young组的一篇新文，旨在探索CNN表示对话句子和LSTM表示上下文信息在对话理解问题上的效果，相比于传统方法，DNN方法鲁棒性更强。</p>
<h2 id="Latent-Sequence-Decompositions"><a href="#Latent-Sequence-Decompositions" class="headerlink" title="Latent Sequence Decompositions"></a><a href="https://arxiv.org/pdf/1610.03035v1.pdf" target="_blank" rel="external">Latent Sequence Decompositions</a></h2><p>【seq2seq】本文研究的内容是对seq2seq框架中输入和输出序列进行有意义分解的问题，而不是简单地分解为char，提出了一种Latent Sequence Decompositions框架，在语音识别问题上取得了不错的效果。其实不仅仅是语音识别问题，在用seq2seq框架时总会遇到OOV的问题，char是一种方法，但信息量太少，如果能够将word sequence分解为更加有意义的子序列，既兼顾了信息量，又降低了词表维度。对英文系的语言效果好一些，中文效果应该不会那么明显。</p>
<h2 id="Diverse-Beam-Search-Decoding-Diverse-Solutions-from-Neural-Sequence-Models"><a href="#Diverse-Beam-Search-Decoding-Diverse-Solutions-from-Neural-Sequence-Models" class="headerlink" title="Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models"></a><a href="https://arxiv.org/pdf/1610.02424v1.pdf" target="_blank" rel="external">Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models</a></h2><p>【seq2seq】seq2seq框架中在解码阶段，常常会用beam search来从左至右、贪心地生成N个最好的输出，不仅仅效率低下，而且在很多复杂任务中效果不好。本文提出了一种新的搜索算法。算法会在解空间内exploration和exploitation，通过设定diverse的目标进行训练，得到结果。相比之下，本文的方法更加高效。并且在image  caption、VQA和MT等任务中进行了验证。</p>
<h2 id="Gated-End-to-End-Memory-Networks"><a href="#Gated-End-to-End-Memory-Networks" class="headerlink" title="Gated End-to-End Memory Networks"></a><a href="https://arxiv.org/pdf/1610.04211v1.pdf" target="_blank" rel="external">Gated End-to-End Memory Networks</a></h2><p>【seq2seq】【memory networks】端到端的记忆网络在简单的机器阅读理解任务上取得了不错的效果，但复杂的事实问答和对话理解相关的任务处理的并不好，原因在于记忆单元与模型之间交互复杂。本文针对该问题，提出了一种Gated记忆网络，取得了不错的效果。本文模型在机器阅读理解bAbI dataset和task-oriented 对话系统任务DSTC2中均取得了非常好的结果。</p>
<h2 id="Neural-Paraphrase-Generation-with-Stacked-Residual-LSTM-Networks"><a href="#Neural-Paraphrase-Generation-with-Stacked-Residual-LSTM-Networks" class="headerlink" title="Neural Paraphrase Generation with Stacked Residual LSTM Networks"></a><a href="https://arxiv.org/pdf/1610.03098v3.pdf" target="_blank" rel="external">Neural Paraphrase Generation with Stacked Residual LSTM Networks</a></h2><p>【paraphrase】本文提出用多层残差LSTM网络来做paraphrase的任务，得到了比之前seq2seq以及seq2seq+attention更好的效果。转述在某个角度上和标题生成（句子level摘要）类似，方法可借鉴。</p>
<h2 id="SentiHood-Targeted-Aspect-Based-Sentiment-Analysis-Dataset-for-Urban-Neighbourhoods"><a href="#SentiHood-Targeted-Aspect-Based-Sentiment-Analysis-Dataset-for-Urban-Neighbourhoods" class="headerlink" title="SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods"></a><a href="https://arxiv.org/pdf/1610.03771v1.pdf" target="_blank" rel="external">SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods</a></h2><p>【观点挖掘】【数据集】本文给出了一个观点挖掘的数据集，数据源来自Yahoo问答中与London相关的提问。这个数据集适合这样的场景，一段评论中包含了多个entity的多个aspect的观点，相互之间有一些比较。</p>
<h2 id="Domain-specific-Question-Generation-from-a-Knowledge-Base"><a href="#Domain-specific-Question-Generation-from-a-Knowledge-Base" class="headerlink" title="Domain-specific Question Generation from a Knowledge Base"></a><a href="https://arxiv.org/pdf/1610.03807v1.pdf" target="_blank" rel="external">Domain-specific Question Generation from a Knowledge Base</a></h2><p>【问题生成】问答系统是一个热门研究领域，其关注点在于如何理解问题然后选择或者生成相应的答案。而本文研究的问题是如何根据知识图谱生成高质量的问题。提出高质量的问题难度很大，且看本文内容。</p>
<h2 id="Compressing-Neural-Language-Models-by-Sparse-Word-Representations"><a href="#Compressing-Neural-Language-Models-by-Sparse-Word-Representations" class="headerlink" title="Compressing Neural Language Models by Sparse Word Representations"></a><a href="https://arxiv.org/pdf/1610.03950v1.pdf" target="_blank" rel="external">Compressing Neural Language Models by Sparse Word Representations</a></h2><p>【语言模型】【提升效率】本文解决的是在学习语言模型时输出层词表过大的问题，词表过大导致效率过低，本文针对这一问题，提出了一种压缩方法，常见词用dense向量来表示，而罕见词用常见词的线性组合来表示。</p>
<h1 id="一周资源"><a href="#一周资源" class="headerlink" title="一周资源"></a>一周资源</h1><h2 id="CCL-amp-NLP-NABD-2016论文集"><a href="#CCL-amp-NLP-NABD-2016论文集" class="headerlink" title="CCL &amp; NLP-NABD 2016论文集"></a><a href="http://www.cips-cl.org/static/CCL2016/index.html" target="_blank" rel="external">CCL &amp; NLP-NABD 2016论文集</a></h2><p>由Springer出版的CCL &amp; NLP-NABD 2016论文集已经公布，并在10月10日-11月10日期间可以免费下载。免费下载方式如下：（1）访问会议首页；（2）点击该页面最新“会议论文下载”中的链接；（3）点击新页面的“Download Book (PDF, 35547KB)”按钮。</p>
<h2 id="北京大学万小军老师组开源自动摘要小工具PKUSUMSUM"><a href="#北京大学万小军老师组开源自动摘要小工具PKUSUMSUM" class="headerlink" title="北京大学万小军老师组开源自动摘要小工具PKUSUMSUM"></a><a href="http://www.icst.pku.edu.cn/lcwm/wanxj/pkusumsum.htm" target="_blank" rel="external">北京大学万小军老师组开源自动摘要小工具PKUSUMSUM</a></h2><p>本组推出文档自动摘要小工具PKUSUMSUM，集成多种无监督摘要提取算法，支持多种摘要任务与多种语言，采用Java编写，代码完全开源，欢迎批评指正，也欢迎同行一起完善该工具。</p>
<h2 id="斯坦福大学NLP组2016年秋季paper阅读周计划"><a href="#斯坦福大学NLP组2016年秋季paper阅读周计划" class="headerlink" title="斯坦福大学NLP组2016年秋季paper阅读周计划"></a><a href="http://nlp.stanford.edu/read/" target="_blank" rel="external">斯坦福大学NLP组2016年秋季paper阅读周计划</a></h2><p>斯坦福大学NLP组2016年秋季paper阅读周计划，挺多篇都是对话系统相关的。 </p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-10-14T04:09:21.000Z"><a href="/2016/10/13/PaperWeekly-第九期/">2016-10-13</a></time>
      
      
  
    <h1 class="title"><a href="/2016/10/13/PaperWeekly-第九期/">PaperWeekly 第九期</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>深度生成模型基本都是以某种方式寻找并表达（多变量）数据的概率分布。有基于无向图模型（马尔可夫模型）的联合概率分布模型，另外就是基于有向图模型（贝叶斯模型）的条件概率分布。前者的模型是构建隐含层(latent)和显示层（visible)的联合概率，然后去采样。基于有向图的则是寻找latent和visible之间的条件概率分布，也就是给定一个随机采样的隐含层，模型可以生成数据。</p>
<p>生成模型的训练是一个非监督过程，输入只需要无标签的数据。除了可以生成数据，还可以用于半监督的学习。比如，先利用大量无标签数据训练好模型，然后利用模型去提取数据特征（即从数据层到隐含层的编码过程），之后用数据特征结合标签去训练最终的网络模型。另一种方法是利用生成模型网络中的参数去初始化监督训练中的网络模型，当然，两个模型需要结构一致。</p>
<p>由于实际中，更多的数据是无标签的，因此非监督和半监督学习非常重要，因此生成模型也非常重要。本篇主要介绍一种基于对抗模式的生成模型，GAN － 从第一篇提出此模型的论文开始，之后紧接着两篇基于它的实现以及改进。三篇文章一脉相承，可以看到结合这种模型的研究进展及方向。</p>
<h1 id="Generative-Adversarial-Nets"><a href="#Generative-Adversarial-Nets" class="headerlink" title="Generative Adversarial Nets"></a><a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="external">Generative Adversarial Nets</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>Universite of Montreal</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>生成模型 （Generative model）</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>NIPS 2014</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>通过模拟对抗过程，提出一种新的生成模型框架</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><ul>
<li>建模</li>
</ul>
<p>在对抗生成模型中，同时训练两个网络，第一个网络是生成网络，G(z)，输入z一般是来自常见概率分布函数的样本向量，维度一般比较低，比如100。生成网络输入向量z，输出图片样例，如果使用卷机网实现的话，整个网络可以看过一个反向的CNN，其中的卷积层替换成 transposed convolution layer。第二个网络是识别网络discriminator net - D(x)，输入为一张图片x，而输出为一个标量，用来代表x来自真实图片的概率。</p>
<ul>
<li>训练</li>
</ul>
<p>整个网络的loss定义为</p>
<p>V = E’[log D(x)] + E’’[log (1 - D(G(z)) )]<br>E’ - 当x来自真实数据的期望<br>E’’ - 当x来自生成网络的期望</p>
<p>很显然，在对抗网络中，生成模型希望能够增大D(G(z))，即，希望生成的图片越真实而让识别模型“误以为”是来自真实的图片集。</p>
<p>如果生成网络G的参数用theta表示，识别模型的参数用theta_d表示，在使用SGD训练的时候，两组参数分别进行训练，对于D来说，需要对上面的公式求Gradient，但是只更新自己的参数。对G来说，只有第二项是相关的，而且可以等效的转换为maximize log D(G(z))。两个网络的参数更新交替进行。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>网上有很多实现，比如:</p>
<p><a href="https://github.com/goodfeli/adversarial" target="_blank" rel="external">goodfeli/adversarial</a>: Theano GAN implementation released by the authors of the GAN paper.<br><a href="https://github.com/Newmu/dcgan_code" target="_blank" rel="external">Newmu/dcgan_code</a>: Theano DCGAN implementation released by the authors of the DCGAN paper.<br><a href="https://github.com/carpedm20/DCGAN-tensorflow" target="_blank" rel="external">carpedm20/DCGAN-tensorflow</a>: Unofficial TensorFlow DCGAN implementation.</p>
<p>这些实现一般都会包含MNIST测试集。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>其他的生成模型包括restricted Boltzmann machine (RBM), deep Boltzmann machine (DBM) 以及 variational autoencoder</p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>其他生成模型中训练过程涉及intractable的计算，在实际实现时往往采取马尔可夫链模特卡洛采样(MCMC)。对抗生成模型(GAN)则不需要，整个网络的训练可以使用backpropagation来实现。</p>
<p>缺点包括训练不稳定，生成网络会塌陷到某些数据点（比如这些数据点目前看最像真实数据，生成网络会不停生成这些数据点），接下来的几篇中将提及如何改进。</p>
<h1 id="Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks-https-arxiv-org-abs-1511-06434"><a href="#Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks-https-arxiv-org-abs-1511-06434" class="headerlink" title="[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks] (https://arxiv.org/abs/1511.06434)"></a>[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks] (<a href="https://arxiv.org/abs/1511.06434" target="_blank" rel="external">https://arxiv.org/abs/1511.06434</a>)</h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Alec Radford, Luke Metz, Soumith Chintala</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>facebook</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>DCGAN, Representation Learning</p>
<h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR 2016</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>基于深度卷积网络的生成对抗模型(DCGAN)实现</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>在GAN的论文中提出的对抗模型的原型，但是对抗模型是一个大的框架，并不局限于某种网络实现。本文给出了基于卷机网的实现。</p>
<p>生成网络<br><img src="media/gen-architecture-1.png" alt="gen-architecture"></p>
<p>其中反卷积的过程是</p>
<p><img src="media/padding_strides_transposed-1.gif" alt="padding_strides_transposed"></p>
<p>识别网络是传统的CNN</p>
<p><img src="media/discrim-architecture.png" alt="discrim-architecture"></p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本文紧密承接上篇论文，描述了实现过程中的细节，比如参数设置。也提到了解决GAN中训练不稳定的措施，但是并非完全解决。文中还提到利用对抗生成网络来做半监督学习。在训练结束后，识别网络可以用来提取图片特征，输入有标签的训练图片，可以将卷基层的输出特征作为X，标签作为y做训练。</p>
<h1 id="Improved-Techniques-for-Training-GANs"><a href="#Improved-Techniques-for-Training-GANs" class="headerlink" title="Improved Techniques for Training GANs"></a><a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="external">Improved Techniques for Training GANs</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>OpenAI</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>DCGAN</p>
<h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR 2016</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>提出改进DCGAN的措施</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>这篇论文同样跟前文非常紧密，具体针对DCGAN中的问题，提出了改进方法。具体有</p>
<ul>
<li>feature matching 解决训练不稳定instability的问题</li>
<li>minibatch discrimination 解决生成网络生成图片集中的问题，原理是让识别网络一次看一组图片，而不是一张图片</li>
<li>如果对实现感兴趣，其他改进细节可以参见论文</li>
</ul>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>对抗生成网络的模型很有意思，Bengio, Hinton等都表达了很高的评价。相对其他生成模式而言，对抗生成模式模型清晰简单，目前来看效果也比较不错。但是目前对抗生成网络也有很多问题，比如生成模型是通过来自概率分布的向量生成样本，而不是直接表示输入的概率分布，因此，生成的图片可能不稳定之类。此外，希望能看到GAN在语言模型中的应用。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>GAN这种模型非常新颖，从论文中的结果来看，在图像生成上取得了不错的效果，对于MNIST这种简单的图形数据集，生成的图片已经可以“以假乱真”。对于另外的图片，比如在第二篇论文中的LSUN bedroom图片集以及人脸图片集上，生成的图片效果也不错（分辨率64×64）。<br>GAN目前来看已经卷积网络图像生成中取得了不错的效果，但是还有很多问题需要继续研究改进， 比如<br>如何生成高像素高质量的图片。目前一般像素不超过64。<br>如何提高复杂图片的质量。目前在CIFAR，ILSVRC等图片集上训练生成的图片还是很糟糕。<br>如何提高整个模型的稳定性。在实际中，尤其对于复杂图形，生成器经常很快收敛到某些单个数据集，使得整个模型的训练陷入僵局。<br>如何在其他领域，比如NLP使用GAN，如何将GAN和LSTM结合的。目前来看，还没有成功的应用。原文作者在reddit上回答内容来看，由于GAN的输入是采样自连续分布，而NLP中，每个单词的表达往往是离散的，作者提到NLP可以用增强训练的方法替代。但是也不排除可以有其他方法将GAN和LSTM结合起来的，这也是以后的一个研究点。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-10-08T02:06:28.000Z"><a href="/2016/10/07/cs-CL-weekly-2016-10-03-2016-10-07/">2016-10-07</a></time>
      
      
  
    <h1 class="title"><a href="/2016/10/07/cs-CL-weekly-2016-10-03-2016-10-07/">cs.CL weekly 2016.10.03-2016.10.07</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="一周值得读（偏学术）"><a href="#一周值得读（偏学术）" class="headerlink" title="一周值得读（偏学术）"></a>一周值得读（偏学术）</h1><h2 id="Controlling-Output-Length-in-Neural-Encoder-Decoders"><a href="#Controlling-Output-Length-in-Neural-Encoder-Decoders" class="headerlink" title="Controlling Output Length in Neural Encoder-Decoders"></a><a href="https://arxiv.org/pdf/1609.09552v1.pdf" target="_blank" rel="external">Controlling Output Length in Neural Encoder-Decoders</a></h2><p>本文针对encoder-decoder框架在应用时无法控制生成序列长度（比如文本摘要）的问题，作者提出了一种基于学习的模型来解决这个问题。encoder-decoder框架已经被成功应用于各大任务中，加上attention，不同变种的attention，研究的人很多。本文也是属于变种之一，考虑了在实际应用中文本摘要长度需要被控制的问题，提出了本文的模型。</p>
<h2 id="Embracing-data-abundance-BookTest-Dataset-for-Reading-Comprehension"><a href="#Embracing-data-abundance-BookTest-Dataset-for-Reading-Comprehension" class="headerlink" title="Embracing data abundance: BookTest Dataset for Reading Comprehension"></a><a href="https://arxiv.org/pdf/1610.00956v1.pdf" target="_blank" rel="external">Embracing data abundance: BookTest Dataset for Reading Comprehension</a></h2><p>【数据福利】本文发布了一个新的机器阅读理解数据集BookTest，该数据集最大的亮点是规模大，是Facebook发布的Children’s Book Test的60倍之大。</p>
<h2 id="Visual-Question-Answering-Datasets-Algorithms-and-Future-Challenges"><a href="#Visual-Question-Answering-Datasets-Algorithms-and-Future-Challenges" class="headerlink" title="Visual Question Answering: Datasets, Algorithms, and Future Challenges"></a><a href="https://arxiv.org/pdf/1610.01465v1.pdf" target="_blank" rel="external">Visual Question Answering: Datasets, Algorithms, and Future Challenges</a></h2><p>【综述】这是一篇Visual Question Answer任务的综述性文章，系统地总结、讨论和对比了近几年该领域的数据集和算法，并给出了一些该领域未来的研究方向。</p>
<h2 id="Multi-View-Representation-Learning-A-Survey-from-Shallow-Methods-to-Deep-Methods"><a href="#Multi-View-Representation-Learning-A-Survey-from-Shallow-Methods-to-Deep-Methods" class="headerlink" title="Multi-View Representation Learning: A Survey from Shallow Methods to Deep Methods"></a><a href="https://arxiv.org/pdf/1610.01206v1.pdf" target="_blank" rel="external">Multi-View Representation Learning: A Survey from Shallow Methods to Deep Methods</a></h2><p>【综述】本文是一篇2015年出版的多模态表示学习的综述文章，非常适合刚刚了解或者准备进入这个领域的童鞋来读。 </p>
<h2 id="Neural-based-Noise-Filtering-from-Word-Embeddings"><a href="#Neural-based-Noise-Filtering-from-Word-Embeddings" class="headerlink" title="Neural-based Noise Filtering from Word Embeddings"></a><a href="https://arxiv.org/pdf/1610.01874v1.pdf" target="_blank" rel="external">Neural-based Noise Filtering from Word Embeddings</a></h2><p>词向量已经是NLP中各任务的基础部件，对词向量的研究工作也非常多。本文研究的切入点是从语料中的噪声入手，提出了两种无监督去噪模型，取得了不错的效果。</p>
<h1 id="一周值得读（偏应用）"><a href="#一周值得读（偏应用）" class="headerlink" title="一周值得读（偏应用）"></a>一周值得读（偏应用）</h1><h2 id="Learning-to-Translate-in-Real-time-with-Neural-Machine-Translation"><a href="#Learning-to-Translate-in-Real-time-with-Neural-Machine-Translation" class="headerlink" title="Learning to Translate in Real-time with Neural Machine Translation"></a><a href="https://arxiv.org/pdf/1610.00388v2.pdf" target="_blank" rel="external">Learning to Translate in Real-time with Neural Machine Translation</a></h2><p>本文研究的内容实时机器翻译，与传统的翻译问题不同，该任务需要在翻译质量和速度两个方面寻找一个平衡点，NMT已经证明了其强大的实<br>力，在此基础上用增强学习做训练，以满足两个方面的需求。</p>
<h2 id="A-Tour-of-TensorFlow"><a href="#A-Tour-of-TensorFlow" class="headerlink" title="A Tour of TensorFlow"></a><a href="https://arxiv.org/pdf/1610.01178v1.pdf" target="_blank" rel="external">A Tour of TensorFlow</a></h2><p>本文系统的剖析了TensorFlow的计算图架构和分布式执行模型，并且系统地对比了TF和其他框架的性能。本文的结论对于框架选择困难的童鞋有一定参考意义，内容对于有志于深挖TF原理和想开发框架的童鞋具有较强的指导意义。对于立志于成为一名TFBoys（TensorFlow）的童鞋，本文是一篇不错的文章。</p>
<h1 id="一周资源"><a href="#一周资源" class="headerlink" title="一周资源"></a>一周资源</h1><h2 id="Chatbots-–-Conversational-UI-and-the-Future-of-Online-Interaction-Swat-io-Blog"><a href="#Chatbots-–-Conversational-UI-and-the-Future-of-Online-Interaction-Swat-io-Blog" class="headerlink" title="Chatbots – Conversational UI and the Future of Online Interaction | Swat.io Blog"></a><a href="https://pan.baidu.com/s/1nuT9qnZ" target="_blank" rel="external">Chatbots – Conversational UI and the Future of Online Interaction | Swat.io Blog</a></h2><p>研究chatbot的童鞋，这本电子书值得一看，或许会有一些思考和启发！ </p>
<h2 id="王威廉老师关于如何做科研的微博"><a href="#王威廉老师关于如何做科研的微博" class="headerlink" title="王威廉老师关于如何做科研的微博"></a><a href="http://weibo.com/1657470871/EbJnqBBJ5?type=comment#_rnd1475892970397" target="_blank" rel="external">王威廉老师关于如何做科研的微博</a></h2><p>“什么是研究？本科生如何做好研究？我今天在组会上简单地给组里的本科生介绍了一点个人做研究的经验，与大家分享一下。”</p>
<h2 id="Configuring-Eclipse-with-Torch-–-Lighting-Torch"><a href="#Configuring-Eclipse-with-Torch-–-Lighting-Torch" class="headerlink" title="Configuring Eclipse with Torch – Lighting Torch"></a><a href="http://www.lighting-torch.com/2015/07/27/configuring-eclipse-with-torch/" target="_blank" rel="external">Configuring Eclipse with Torch – Lighting Torch</a></h2><p>将Torch配置到Eclipse中进行开发和调试。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-10-07T18:22:30.000Z"><a href="/2016/10/07/PaperWeekly-第八期/">2016-10-07</a></time>
      
      
  
    <h1 class="title"><a href="/2016/10/07/PaperWeekly-第八期/">PaperWeekly 第八期</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>SIGDIAL是ACL所属的关于对话系统的兴趣小组，SIG的文章针对性比较强，但文章的质量良莠不齐，本期给大家精心挑选了4篇SIGDIAL 2016的文章，带着大家一起来看看对话系统最新的研究成果。4篇文章分别是：</p>
<p>1、Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks, 2016<br>2、Neural Utterance Ranking Model for Conversational Dialogue Systems, 2016<br>3、A Context-aware Natural Language Generator for Dialogue Systems, 2016<br>4、Task Lineages: Dialog State Tracking for Flexible Interaction, 2016</p>
<h1 id="Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks"><a href="#Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks" class="headerlink" title="Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks"></a><a href="http://arxiv.org/pdf/1609.01462v1.pdf" target="_blank" rel="external">Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Bing Liu, Ian Lane</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>Carnegie Mellon University, Electrical and Computer Engineering</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Spoken Language Understanding, RNN</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>SIGDIAL 2016</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>如何将自然语言理解的两大问题和语言模型结合在同一个模型中进行训练，以达到实时理解语言的目的？</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>特定任务下的Chatbot在理解人类语言时需要重点解决好两个问题：意图识别(Intent Detection)和槽填充(Slot Filling)，本文提出一种融合Intent Detection、Slot Filling和Language Model的模型，相比于之前的模型，本文模型的一大优势在于做自然语言理解的时候不需要等待整个word sequence完整展现，而是可以在线处理每一个arrived word。如下图：<br><img src="media/3.png" alt="3"></p>
<p>意图识别是个典型的多分类任务，而槽填充是个典型的序列标注任务。RNN的每个step都以当前word作为输入，输出是意图class、该word的label和下一个word，每个step的隐层都包含了之前所有的word、class、label信息。此模型为基本模型，在此基础上做了一些变形，得到下面四个变种：</p>
<p><img src="media/4.png" alt="4"></p>
<p>文章在Airline Travel Information Systems(ATIS)数据集上进行了实验，在语言模型评测指标和意图识别分类准确率上相比之前的模型都得到了一定地提升。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>本文Code: <a href="http://speech.sv.cmu.edu/software.html" target="_blank" rel="external">http://speech.sv.cmu.edu/software.html</a><br>ATIS Dataset: <a href="https://github.com/mesnilgr/is13" target="_blank" rel="external">https://github.com/mesnilgr/is13</a></p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文的创新点在于将意图分类、槽填充和语言模型三者合一，相比之前的独立模型来说，每一步产生的信息更多，在预测下一步的时候context内容更加丰富，从而提高了识别的准确率和降低了语言模型的混乱度。</p>
<p>NLP中的很多任务都可以归纳为根据context来预测某一个word、label或者class这种范式，解决的思路也都基本类似，RNN或者GRU、LSTM作为encoder和decoder，配上attention机制来提升结果，context的信息量和质量直接影响着预测的效果，user information、user profile等等都可能作为context来构建模型，得到更好的结果。</p>
<h1 id="Neural-Utterance-Ranking-Model-for-Conversational-Dialogue-Systems"><a href="#Neural-Utterance-Ranking-Model-for-Conversational-Dialogue-Systems" class="headerlink" title="Neural Utterance Ranking Model for Conversational Dialogue Systems"></a><a href="http://www.sigdial.org/workshops/conference17/proceedings/pdf/SIGDIAL48.pdf" target="_blank" rel="external">Neural Utterance Ranking Model for Conversational Dialogue Systems</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Michimasa Inaba, Kenichi Takahashi</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>Hiroshima City University, 3-4-1 Ozukahigashi, Asaminami-ku</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>Ranking Model, Utterance Selection</p>
<h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p>SIGDIAL 2016</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>在做检索式对话时，对话语句该怎样表示，context信息该怎样引入到模型中？</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>本文实现的是一个检索式的对话模型，模型分为两部分，分别是：<br>1、Utterance Encoding<br>检索式对话，对话语句的encoding是很重要的一部分，文中使用了RNN encoder模型来实现对语句的encoding。在训练过程中，作者把encoder生成的向量，在decode成一个目标语句，即通过一个完整的seq2seq模型来训练encoder。<br>2、Ranking Candidate Utterances<br>在对候选语句排序时，作者考虑到了context的问题，他把前几次说的语句分别encode成向量，并依次输入到LSTM。如下图所示：</p>
<p><img src="media/5.png" alt="5"></p>
<p>图中u1到un是整个对话中的前n句话，ai是第i个候选语句。模型中，分别把u1…un以及ai分成用户说的和系统本身输出的，在输入到各自的RNN encoder中，得到向量vu1…vu和vai。最后将向量依次输入到RNN中，得到yai作为候选语句ai在当前context中的得分。<br>因为本文是一个ranking model，更关注的是候选语句的排序，最后候选集分数列表会转换成TOP 1的概率分布。并使用cross-entropy作为loss function。</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本文有两个创新点，首先通过单独训练seq2seq模型，来学习对话语句的encoder，从而降低了整个模型的学习成本，减少了需要标注的数据量。然后在排序模型中将对话的前几句语句有序输入到LSTM，达到融入了context信息的目的。</p>
<h1 id="A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems"><a href="#A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems" class="headerlink" title="A Context-aware Natural Language Generator for Dialogue Systems"></a><a href="https://arxiv.org/pdf/1608.07076" target="_blank" rel="external">A Context-aware Natural Language Generator for Dialogue Systems</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Ondrej Dusek, Filip Jurcicek</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>Charles University</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>Context-aware, Seq2seq</p>
<h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p>SIGDIAL 2016</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>如何使得task-oriented的对话生成系统中生成更加自然的回复？</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>本文是ACL2016 short paper Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings一文的拓展。原文提出基于seq2seq模型的将DA(dialogue acts)生成response的方案，其中输入是三元组(DA type,slot,value)的one-hot representation，输出是对应的response。如下图：</p>
<p><img src="media/6.png" alt="6"></p>
<p>延续原文的工作，作者为了使得生成的回复更加自然，将前面用户的提问也encode进来，具体是在原来模型的基础上加了两个encode的部分。Prepending context是把用户的问题和DA三元组前后拼接成新的表示再feed into encoder（这里要注意问题的dictionary和DA是不一样的）。Context encoder则是把单独把问题encode成和Prepending context相同大小的向量，再将两个encoder得到的向量拼接就得到最后的hidden states。最后decode部分仍然沿用lstm+attention的方法。如下图：</p>
<p><img src="media/7.png" alt="7"></p>
<p>文章在Alex Context NLG Dataset数据集上进行了实验，在BLEU/NIST scores和人工评价两方面成绩都得到了一定地提升。</p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>本文Code: <a href="https://github.com/UFAL-DSG/tgen" target="_blank" rel="external">https://github.com/UFAL-DSG/tgen</a><br>Alex Context NLG Dataset: <a href="https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1675" target="_blank" rel="external">https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1675</a></p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>本文的创新点在于将用户的问题也就是context显式的加入到模型中，相比之前的模型来说，生成的回复会更符合语境。先前的工作旨在将rule-based符号和seq2seq模型结合自动生成回复，本文的改进让一部分context得到保留，使得生成的回复内容更加丰富，从而显得自然不突兀。</p>
<h1 id="Task-Lineages-Dialog-State-Tracking-for-Flexible-Interaction"><a href="#Task-Lineages-Dialog-State-Tracking-for-Flexible-Interaction" class="headerlink" title="Task Lineages: Dialog State Tracking for Flexible Interaction"></a><a href="http://aclweb.org/anthology/W16-3602" target="_blank" rel="external">Task Lineages: Dialog State Tracking for Flexible Interaction</a></h1><h2 id="作者-3"><a href="#作者-3" class="headerlink" title="作者"></a>作者</h2><p>Sungjin Lee, Amanda Stent</p>
<h2 id="单位-3"><a href="#单位-3" class="headerlink" title="单位"></a>单位</h2><p>Yahoo Research</p>
<h2 id="文章来源-3"><a href="#文章来源-3" class="headerlink" title="文章来源"></a>文章来源</h2><p>SIGDIAL 2016</p>
<h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>complex interactions in spoken dialog system, Task Lineage-based Dialog State Tracking</p>
<h2 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h2><p>​如何将复杂的判别式模型来做DST，并且应用于复杂场景对话系统？</p>
<h2 id="模型-3"><a href="#模型-3" class="headerlink" title="模型"></a>模型</h2><p>本文在之前Dialog State Tracking方法的基础上提出了Task Lineage-based Dialog State Tracking（TL—DST）。本模型包括三个组成部分：<br>1、Task Frame Parsing，返回K-best task frame parses， task frame parses结构如下图：</p>
<p><img src="media/1.png" alt="1"></p>
<p>2、Context Fetching，在不同的phenomena中，根据不同的conversation history返回不同的相关信息。<br>3、Task State Update，可以通过调节context window参数选择使用不同的dialog state tracking方法。  </p>
<p>本文模型（TL-DST）处理流程如下图所示：<br><img src="media/2.png" alt="2"></p>
<p>在t轮，给定句子u，利用task frame parsing生成K-best task frame parses H，给定task frame f，task lineage l， agent output m，利用context features返回相关信息c。</p>
<p>本文在Dialog State Tracking Challenge 的DSTC2和DSTC3数据集上进行了实验，均取得了较baseline好的结果。</p>
<h2 id="资源-2"><a href="#资源-2" class="headerlink" title="资源"></a>资源</h2><p>Dialog State Tracking Challenge比赛介绍: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" target="_blank" rel="external">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf</a></p>
<h2 id="简评-3"><a href="#简评-3" class="headerlink" title="简评"></a>简评</h2><p>本文基于DST的方法来处理口语对话系统中的多任务，跨领域，复杂目标的问题，由于缺乏多任务，跨领域，复杂目标的口语对话系统的数据集，本文实验在DSTC2和DSTC3上进行， 并取得了比baseline好的效果。将来的工作是要将TL-DST方法应用于真实环境中的多领域对话评估。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>对话系统(Dialogue Systems)是当前工业界最热门的方向之一，去掉语音部分，该问题退化为聊天机器人(chatbot)问题，两者虽然在输入处理中存在一定的差异，但自然语言理解、对话管理和自然语言生成等核心部件都是一样的，面临的很多问题都是共同的，所以相关的研究或多或少都会有参考意义。上下文(context)的理解和处理是一个重要的环节，直接决定了该bot是智能还是智障，挺多的paper都是针对这一问题进行研究的，但在实际应用当中，context的处理仍然不尽如人意，过多依赖人工设置，更像是一种触发开关，存在大量的if…else…。</p>
<p>seq2seq生成式的解决方案初见效果，但离真正应用还有很长的路要走，template-based和rule-based仍是主流解决方案，尤其是在面向具体任务的bot情景中。那么，直接生成回答很难的话，退一步来想这个问题，能否将seq2seq用在template或者rule的自动生成上？能否将paper中多信息融合（比如：user profile、dialogue context）的成果应用在当前bot的某一个阶段？能否训练一个bot simulator来丰富训练数据？每一篇paper都会有一些创新点，可能有的创新点是为了创新而创新，但总归会带来一定的思考和借鉴，尤其是针对某一个细节问题，我想这是paper对于工业界的参考意义，而不是说从paper中完全抠出一个成熟的解决方案来套，甚至把dataset和code都release出来，典型的“拿来主义”。</p>
<p>以上为本期Paperweekly的主要内容，感谢lshowway、zhangjun、zhangboyu和suhui四位同学的整理。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-30T23:11:04.000Z"><a href="/2016/09/30/cs-CL-weekly-2016-09-26-2016-09-30/">2016-09-30</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/30/cs-CL-weekly-2016-09-26-2016-09-30/">cs.CL weekly 2016.09.26-2016.09.30</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="一周值得读（偏学术）"><a href="#一周值得读（偏学术）" class="headerlink" title="一周值得读（偏学术）"></a>一周值得读（偏学术）</h1><h2 id="HyperNetworks"><a href="#HyperNetworks" class="headerlink" title="HyperNetworks"></a><a href="https://arxiv.org/pdf/1609.09106v1.pdf" target="_blank" rel="external">HyperNetworks</a></h2><p>an approach of using a small network, also known as a hypernetwork, to generate the weights for a larger network. 工作来自Google Brain。介绍HyperNetworks的博客：<a href="http://blog.otoro.net/2016/09/28/hyper-networks/" target="_blank" rel="external">http://blog.otoro.net/2016/09/28/hyper-networks/</a></p>
<h2 id="Incorporating-Relation-Paths-in-Neural-Relation-Extraction"><a href="#Incorporating-Relation-Paths-in-Neural-Relation-Extraction" class="headerlink" title="Incorporating Relation Paths in Neural Relation Extraction"></a><a href="https://arxiv.org/pdf/1609.07479v1.pdf" target="_blank" rel="external">Incorporating Relation Paths in Neural Relation Extraction</a></h2><p>本文研究内容为实体关系抽取，传统方法往往只利用同时包含两个目标实体的句子，而忽略包含单目标实体的句子，本文针对这一问题，在俩目标实体之间构建了一个用于推理的中间实体，并提出一种基于路径的关系抽取模型，实验结果表明该模型很好地利用了包含单目标实体的句子信息。本工作来自于刘知远老师组里。</p>
<h2 id="Language-as-a-Latent-Variable-Discrete-Generative-Models-for-Sentence-Compression"><a href="#Language-as-a-Latent-Variable-Discrete-Generative-Models-for-Sentence-Compression" class="headerlink" title="Language as a Latent Variable: Discrete Generative Models for Sentence Compression"></a><a href="https://arxiv.org/pdf/1609.07317v1.pdf" target="_blank" rel="external">Language as a Latent Variable: Discrete Generative Models for Sentence Compression</a></h2><p>本文研究内容为句子压缩，作者提出了一种VAE模型，先根据背景语言模型生成一个latent摘要句子，然后根据latent句子生成目标句子。实验中用到了抽取式和摘要式两种监督方法，并在最后探索出半监督方法的效果可能会好于监督学习的方法。句子压缩任务可以看做是sentence-level的文本摘要任务，本文的方法同样可以启发文本摘要任务的研究。本文工作来自deepmind，并且是EMNLP 2016 Accepted。</p>
<h2 id="Annotating-Derivations-A-New-Evaluation-Strategy-and-Dataset-for-Algebra-Word-Problems"><a href="#Annotating-Derivations-A-New-Evaluation-Strategy-and-Dataset-for-Algebra-Word-Problems" class="headerlink" title="Annotating Derivations: A New Evaluation Strategy and Dataset for Algebra Word Problems"></a><a href="https://arxiv.org/pdf/1609.07197v1.pdf" target="_blank" rel="external">Annotating Derivations: A New Evaluation Strategy and Dataset for Algebra Word Problems</a></h2><p>本文研究的内容很有意思，是algebra word problems，是自动求解代数问题的基础，这个问题可以等同为一个semantic parsing的问题，模型通过读入一段文本，理解其意思，然后构造出一个方程，最后给出方程的解。作者还给出了一个新的dataset和评价标准，本文工作来自伊大香槟分校和微软研究院。这个task本身非常有意思，也很有难度。</p>
<h2 id="Online-Segment-to-Segment-Neural-Transduction"><a href="#Online-Segment-to-Segment-Neural-Transduction" class="headerlink" title="Online Segment to Segment Neural Transduction"></a><a href="https://arxiv.org/pdf/1609.08194v1.pdf" target="_blank" rel="external">Online Segment to Segment Neural Transduction</a></h2><p>本文针对之前encoder-decoder模型面临的一个瓶颈，即将输入全部读入并保存为一个固定大小的hidden states，作者提出了一种新的attention机制，将attention权重作为一种隐变量，在句子摘要上证明了效果，本文工作来自deepmind。</p>
<h1 id="一周值得读（偏应用）"><a href="#一周值得读（偏应用）" class="headerlink" title="一周值得读（偏应用）"></a>一周值得读（偏应用）</h1><h2 id="Google’s-Neural-Machine-Translation-System-Bridging-the-Gap-between-Human-and-Machine-Translation"><a href="#Google’s-Neural-Machine-Translation-System-Bridging-the-Gap-between-Human-and-Machine-Translation" class="headerlink" title="Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"></a><a href="https://arxiv.org/pdf/1609.08144.pdf" target="_blank" rel="external">Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</a></h2><p>本周最受关注，也备受争议的一篇paper，Google放出了他们最新一代的机器翻译系统，一种神经网络翻译系统。指标上的提升，说明了效果确实有提升，但不代表具体到每一句话都能令人满意。</p>
<h2 id="UbuntuWorld-1-0-LTS-A-Platform-for-Automated-Problem-Solving-amp-Troubleshooting-in-the-Ubuntu-OS"><a href="#UbuntuWorld-1-0-LTS-A-Platform-for-Automated-Problem-Solving-amp-Troubleshooting-in-the-Ubuntu-OS" class="headerlink" title="UbuntuWorld 1.0 LTS - A Platform for Automated Problem Solving &amp; Troubleshooting in the Ubuntu OS"></a><a href="https://arxiv.org/pdf/1609.08524v1.pdf" target="_blank" rel="external">UbuntuWorld 1.0 LTS - A Platform for Automated Problem Solving &amp; Troubleshooting in the Ubuntu OS</a></h2><p>本文给出了一个Ubuntu系统问题咨询和错误排查的bot，可以在bash terminal中运行，通过增强学习进行训练，可以回答一些基本的问题和错误排查。demo bot被封装成一个python package，即插即用。回答问题的数据来自于Ask Ubuntu。测试了DQN在特定领域bot中的效果，定义了几组简单的命令作为action，open/close，install/remove等等，technical support是客户服务中难度非常大的一类，本文尝试了用一种完全端到端+增强学习的方案来探索解决此类问题。</p>
<h2 id="Character-Sequence-Models-for-ColorfulWords"><a href="#Character-Sequence-Models-for-ColorfulWords" class="headerlink" title="Character Sequence Models for ColorfulWords"></a><a href="https://arxiv.org/pdf/1609.08777v1.pdf" target="_blank" rel="external">Character Sequence Models for ColorfulWords</a></h2><p>本文研究的内容非常有意思，输入一个word，输出这个word对应的color并着色。作者构建了一组大型的color-name对数据集，来做一个color图灵测试。该系统的demo地址：<a href="http://colorlab.us./" target="_blank" rel="external">http://colorlab.us./</a></p>
<h2 id="Equation-Parsing-Mapping-Sentences-to-Grounded-Equations"><a href="#Equation-Parsing-Mapping-Sentences-to-Grounded-Equations" class="headerlink" title="Equation Parsing: Mapping Sentences to Grounded Equations"></a><a href="https://arxiv.org/pdf/1609.08824v1.pdf" target="_blank" rel="external">Equation Parsing: Mapping Sentences to Grounded Equations</a></h2><p>本文研究的内容非常有趣也很有实际意义，即从文本中抽取出数学关系，作者将该任务定义如下：给定一句话，抽取出其中的变量和数学关系，并用方程表示。这个研究可以被应用在新闻机器人上，财经、体育等。</p>
<h2 id="Inducing-Multilingual-Text-Analysis-Tools-Using-Bidirectional-Recurrent-Neural-Networks"><a href="#Inducing-Multilingual-Text-Analysis-Tools-Using-Bidirectional-Recurrent-Neural-Networks" class="headerlink" title="Inducing Multilingual Text Analysis Tools Using Bidirectional Recurrent Neural Networks"></a><a href="https://arxiv.org/pdf/1609.09382v1.pdf" target="_blank" rel="external">Inducing Multilingual Text Analysis Tools Using Bidirectional Recurrent Neural Networks</a></h2><p>资源稀缺语言的标注问题是一个经典的问题，一般的做法是将资源丰富的语音对齐映射过去进行标注，自动词对齐的错误会影响最终的效果。本文针对这个问题，提出了一种BiRNN模型，并且融合外部信息解决问题。该模型具有以下特点：1、不需要词对齐信息；2、不限定语言，可用于多种资源少的语言；3、提供一种真正的多语言tagger。</p>
<h1 id="一周资源"><a href="#一周资源" class="headerlink" title="一周资源"></a>一周资源</h1><h2 id="THULAC"><a href="#THULAC" class="headerlink" title="THULAC"></a><a href="https://github.com/thunlp/THULAC.so" target="_blank" rel="external">THULAC</a></h2><p>THULAC.so：一个高效的中文词法分析工具包，为了满足Python下分词对速度的要求，发布了一个产生.so文件的THULAC版本，并且提供Python调用的示例代码。这样THULAC在Python下的分词速度得到大幅度提高。</p>
<h2 id="tinyflow"><a href="#tinyflow" class="headerlink" title="tinyflow"></a><a href="https://github.com/tqchen/tinyflow" target="_blank" rel="external">tinyflow</a></h2><p>DMLC陈天奇开放了一个两千行代码的样例项目，教你如何从头开始打造一个和TensorFlow一样API的深度学习系统。其中涉及到一个非常重要的开源库NNVM，地址： <a href="https://github.com/dmlc/nnvm" target="_blank" rel="external">https://github.com/dmlc/nnvm</a> 。博客介绍：<a href="http://dmlc.ml/2016/09/30/build-your-own-tensorflow-with-nnvm-and-torch.html" target="_blank" rel="external">http://dmlc.ml/2016/09/30/build-your-own-tensorflow-with-nnvm-and-torch.html</a> ，中文版：<a href="http://weibo.com/ttarticle/p/show?id=2309404025388832575825#_0" target="_blank" rel="external">http://weibo.com/ttarticle/p/show?id=2309404025388832575825#_0</a></p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"><br>微博账号：PaperWeekly（<a href="http://weibo.com/u/paperweekly" target="_blank" rel="external">http://weibo.com/u/paperweekly</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-30T00:58:47.000Z"><a href="/2016/09/29/PaperWeekly-第七期/">2016-09-29</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/29/PaperWeekly-第七期/">PaperWeekly 第七期</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>神经网络机器翻译(NMT)是seq2seq模型的典型应用，从2014年提出开始，其性能就接近于传统的基于词组的机器翻译方法，随后，研究人员不断改进seq2seq模型，包括引入注意力模型、使用外部记忆机制、使用半监督学习和修改训练准则等方法，在短短2年时间内使得NMT的性能超过了传统的基于词组的机器翻译方法。在27号谷歌宣布推出谷歌神经网络机器翻译系统，实现了NMT的首个商业化部署，使得NMT真正从高校实验室走向了实际应用。本期Paperweekly的主题是神经网络机器翻译下的字符级方法，主要用来解决NMT中的out-of-vocabulary词问题，分别是：</p>
<ol>
<li>A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation，2016</li>
<li>Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models，2016</li>
<li>Character-based Neural Machine Translation，Costa-Jussa, 2016</li>
<li>Character-based Neural Machine Translation，Ling, 2016</li>
<li>Neural Machine Translation of Rare Words with Subword Units，2016</li>
</ol>
<h1 id="A-Character-Level-Decoder-without-Explicit-Segmentation-for-Neural-Machine-Translation"><a href="#A-Character-Level-Decoder-without-Explicit-Segmentation-for-Neural-Machine-Translation" class="headerlink" title="A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation"></a><a href="https://arxiv.org/abs/1603.06147" target="_blank" rel="external">A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Junyoung Chung, Kyunghyun Cho, Yoshua Bengio</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>Universite de Montreal</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Segmentation, Character-level, Bi-scale recurrent network</p>
<h2 id="文章来源"><a href="#文章来源" class="headerlink" title="文章来源"></a>文章来源</h2><p>ACL 2016</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>能否在不需要分词的前提下直接在字符级进行神经机器翻译。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>在讲模型之前，本文花了大量篇幅论证为何需要在不分词的前提下进行字符级翻译，首先作者总结了词级翻译的缺点。</p>
<p>词级翻译的缺点包括：</p>
<ol>
<li>任何一个语言都没有完美的分词算法，完美的分词算法应该能够将任意句子划分为lexemes和morphemes组成的序列</li>
<li>导致的问题就是在词典中经常充斥着许多共享一个lexeme但有着不同morphology的词，比如run,runs,ran,running可能都存在于词典中，每个词都对应一个词向量，但是它们明显共享相同的lexeme——run</li>
<li>存在unknown word问题和rare word问题，rare word问题是指某些词典中词在训练集中出现次数过少，导致无法训练得到很好的词向量；unknown word问题是指不在词典中的词被标记为UNK（OOV词）</li>
</ol>
<p>接着作者指出使用字符集翻译可以解决上述问题：</p>
<ol>
<li>使用LSTM或GRU可以解决长时依赖问题</li>
<li>使用字符级建模可以避免许多词态变形词出现在词典中</li>
</ol>
<p>然而上述字符级方法依然需要进行分词，然后对每个词的字符序列进行编码，因此引出了本文的motivation，即是否能直接在不分词的字符序列上进行翻译。</p>
<p>本文使用的模型同样是经典的seq2seq模型，其创新点主要在decoder端，引入了一种新的网络结构biscale RNN，来捕获字符和词两个timescale上的信息。具体来说，主要分为faster层和slower层，faster层的gated激活值取决于上一步的faster和slower层的激活值，faster层要想影响slower层，则必须要是faster层处理完当前数据，并且进行重置。换句话说，slower层无法接受faster层输入，直到faster层处理完其数据，因此比faster层要慢，而这样的层次结构也对应字符和词在timescale上的关系。下图为网络结构示意图。</p>
<p> <img src="media/1-figure1.png" alt="1-figure1"></p>
<p>在4种语言翻译任务上的实验显示完全可以在不分词的情况下进行字符级翻译，性能优于state-of-the-art的非神经翻译系统</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>Sennrich ACL2016提出使用BPE算法对subword建模。Kim AAAI2016中提出直接对字符进行encode，Costa-jussa ICLR2016中将该模型用在了NMT任务中。Ling ICLR2016的工作中使用Bi-RNN来编码字符序列。以上工作基于字符级展开，但它们都依赖于知道如何将字符分为词，即分词。本文研究能否在不分词的情况下进行字符级翻译。</p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文是Bengio组工作，Bi-scale RNN受启发于该组之前提出的GF-RNN，本文创新点主要是提出了一种新的RNN结构，可以在字符和词两个timescales上进行处理，输出字符序列不需要进行分词。不足是未考虑encoder端是否也可以直接使用未分词的字符序列，而是仅仅使用了分词后的BPE序列。</p>
<h1 id="Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models"><a href="#Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models" class="headerlink" title="Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models"></a><a href="https://arxiv.org/pdf/1604.00788v2.pdf" target="_blank" rel="external">Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Minh-Thang Luong and Christopher D. Manning</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>Stanford University</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>OOV, hybrid word-character models, NMT</p>
<h2 id="文章来源-1"><a href="#文章来源-1" class="headerlink" title="文章来源"></a>文章来源</h2><p>ACL 2016</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>机器翻译里面的OOV问题, 如何处理UNK</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>提出了一种混合word-character的NMT模型.在训练难度和复杂度不是很高的情况下,同时解决源语言和目标语言的OOV问题.<br><img src="media/2-1.png" alt="2-1"></p>
<p>这个图表达了模型的整体思路. 大多数情况下,模型在word-level进行translation. 当出现unk的时候,则会启用character-level的模型. 对source unk, 由character-level模型来得到它的representation; 对target unk, 用character-level模型来产生word.</p>
<ol>
<li>整体上采用他们组以前提出的基于global attention的encoder-decoder模型. RNN采用的是deep LSTM. </li>
<li>源语言端和目标语言端的character-level模型都是基于character的deep LSTM. 对源语言端来说, 它的character-level模型是context independent的. 隐层状态全部初始化为0, 因此在训练时可以预先计算mini-batch里的每一个rare word的representation. 而对于目标语言端来说, 它的character-level模型是context dependent的.它的第一层的hidden state要根据当前context来初始化, 其它部分都初始化为0.训练时, 在目标语言的decoder阶段, 首先用word-level的decoder产生句子, 这时句子里包含了一些unk. 接着对这些unk, 用character-level模型以batch mode来产生rare word.</li>
<li>对于目标语言端character-level模型的初始化问题, 作者提出了两种方法来表示当前的context. 一种叫做same-path, 用预测<unk>的softmax层之前的ht来表达. 但是因为ht是用来预测<unk>的, 所以所有ht的值都会比较相似,这样很难用来产生不同的目标rare word. 因此作者提出了第二种表达叫做separate-path, 用ht’来表达context. ht’不用预测unk, 是专门作为context在character-level的输入的. 它的计算方法和ht’相同,只是用了一个不一样的矩阵.</unk></unk></li>
<li>模型训练的目标函数是cross-entropy loss, 同时考虑了word level和character level的loss. </li>
</ol>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>NMT的模型分为word-level和character-level的. 对于word-level模型,要解决OOV问题, 之前的工作提出了unk replacement(Luong et al. 2015b), 使用大字典并在softmax时进行采样(Jean et al. 2015), 对unk进行Huffman编码(Chitnis et al. 2015)等方法. 而对于character-level的模型, 本身可以处理OOV词, 但是训练难度和复杂度会增加.</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本文的创新之处在于提出了混合word-character model的NMT模型. 这个混合模型结合了二者的优点, 在保证模型复杂度较低的同时,实现了很好的效果.因为加入了character, 特别适合单词有丰富变形的语言. </p>
<h1 id="Character-based-Neural-Machine-Translation"><a href="#Character-based-Neural-Machine-Translation" class="headerlink" title="Character-based Neural Machine Translation"></a><a href="http://arxiv.org/abs/1511.04586" target="_blank" rel="external">Character-based Neural Machine Translation</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Marta R. Costa-jussa and Jose A. R. Fonollosa </p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>TALP Research Center<br>Universitat Politecnica de Catalunya, Barcelona</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>NMT，character-based word embeddings，CNN</p>
<h2 id="文章来源-2"><a href="#文章来源-2" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR2016</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>本文提出使用character-based word embeddings的NMT，可以在一定程度上克服机器翻译中OOV问题。</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p><img src="media/3-encoder_decoder.png" alt="3-encoder_decode"></p>
<p>如上图所示，这篇论文使用的基本模型架构是一个带attention机制的seq2seq的encoder-decoder的架构，使用的神经网络单元是GRU。encoder把源句子转化成一个向量（双向），使用attention的机制来捕获context信息，decoder把context解码成目标句子。网络的输入仍然使用word embedding，但是作者在获取word embedding的时候使用的方法不同。本文是基于词中的character来生成word embedding的，具体方法如下图所示。<br><img src="media/3-embedding.png" alt="3-embedding"></p>
<p>上图中，最底层是一个character-based embedding组成的序列，对应的是每个词中的字母。然后这个序列被送入一个由不同长度的一维卷积过滤器组成的集合中进行处理，不同的长度对应单词中不同数量的字母（从1到7）。对于每个卷积过滤器，只取最大的值作为输出。然后把每个卷积过滤器输出的最大值连接起来组成一个向量。最后这个向量再通过两层Highway layer的处理作为最终的word embeddings。这个方法的详细信息可以参考Kim的论文<a href="http://arxiv.org/abs/1508.06615" target="_blank" rel="external">Character-Aware Neural Language Models</a>(2016)。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><ol>
<li>本文数据集[German-English WMT data] (<a href="http://www.statmt.org/wmt15/translation-task.html" target="_blank" rel="external">http://www.statmt.org/wmt15/translation-task.html</a>) <br></li>
<li>建立对比模型使用的软件包<a href="http://dl4mt.computing.dcu.ie/" target="_blank" rel="external">DL4MT</a> </li>
</ol>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><p>（1）2003年，基于短语的统计机器翻译模型。Statistical Phrase-Based Translation <br><br>（2）2013年，基于神经网络的机器翻译模型。Recurrent continuous translation models <br><br>（3）2014年，seq2seq的神经网络模型用于机器翻译。Sequence to sequence learning with neural networks </p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>本文作者将基于character来产生word embedding的方法应用于机器翻译，可以在一定程度上克服OOV的问题。同时，由于利用了单词内部的信息，这篇论文提出的方法对于词形变化丰富的语言的翻译也产生了更好的效果。但是，作者只是在source side使用了上述方法，对于target side，仍然面临词典大小的限制。</p>
<h1 id="CHARACTER-BASED-NEURAL-MACHINE-TRANSLATION"><a href="#CHARACTER-BASED-NEURAL-MACHINE-TRANSLATION" class="headerlink" title="CHARACTER-BASED NEURAL MACHINE TRANSLATION"></a><a href="http://arxiv.org/abs/1511.04586" target="_blank" rel="external">CHARACTER-BASED NEURAL MACHINE TRANSLATION</a></h1><h2 id="作者-3"><a href="#作者-3" class="headerlink" title="作者:"></a>作者:</h2><p>Wang Ling, Isabel Trancoso, Chris Dyer, Alan W Black</p>
<h2 id="单位-3"><a href="#单位-3" class="headerlink" title="单位"></a>单位</h2><ol>
<li>LF Spoken Systems Lab,Instituto Superior Tecnico Lisbon, Portugal</li>
<li>Language Technologies Institute, Carnegie Mellon University Pittsburga, PA 15213, USA</li>
</ol>
<h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>NMT, Character-Based</p>
<h2 id="文章来源-3"><a href="#文章来源-3" class="headerlink" title="文章来源"></a>文章来源</h2><p>ICLR 2016</p>
<h2 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h2><p>尝试在字符级别上应用神经机器学习方法</p>
<h2 id="模型-3"><a href="#模型-3" class="headerlink" title="模型"></a>模型</h2><p>在带注意力机制的神经机器学习模型的前后端增加字符到词（C2W)和词向量到字符（V2C）的模块。</p>
<p><img src="media/4-C2W.png" alt="4-C2"></p>
<p>图中，小矩形是一个双向LSTM，双向LSTM的前向和后向的最终状态以及bias之和为词的向量表示。</p>
<p><img src="media/4-V2C-1.png" alt="4-V2"></p>
<p>这个模块主要由三个步骤组成：</p>
<ol>
<li>将字符转换为向量表示。</li>
<li>将字符向量和之前模型产生注意力向量的a和目标词在前向LSTM中产生的向量表示做拼接并输入到LSTM。</li>
<li>将得到的向量输入到softmax层得到结果。</li>
</ol>
<h2 id="相关工作-3"><a href="#相关工作-3" class="headerlink" title="相关工作"></a>相关工作</h2><ol>
<li>Neural machine translation by jointly learning to align and translate. </li>
</ol>
<h2 id="简评-3"><a href="#简评-3" class="headerlink" title="简评"></a>简评</h2><p>这篇文章在基于注意力机制的机器翻译模型上增加了两个模块。由于是基于字符集别的模型，该模型自然可以学得一些语言中的前后缀在翻译中的关系。此外，基于字符级别的模型在翻译未知词时有灵活性。可是，文中也提到，该模型为能够准确的翻译未知词。并且该文也没有明确表明该模型和其他模型相比具有哪些明显的优势。从实际上来说，该模型在V2C部分的训练速度慢是一个很大的弱点，因此若仅根据文章的表述，该模型的实际应用价值应该有限。</p>
<h1 id="Neural-Machine-Translation-of-Rare-Words-with-Subword-Units"><a href="#Neural-Machine-Translation-of-Rare-Words-with-Subword-Units" class="headerlink" title="Neural Machine Translation of Rare Words with Subword Units"></a><a href="https://arxiv.org/abs/1508.07909" target="_blank" rel="external">Neural Machine Translation of Rare Words with Subword Units</a></h1><h2 id="作者-4"><a href="#作者-4" class="headerlink" title="作者"></a>作者</h2><p>Rico Sennrich and Barry Haddow and Alexandra Birch</p>
<h2 id="单位-4"><a href="#单位-4" class="headerlink" title="单位"></a>单位</h2><p>School of Informatics, University of Edinburgh</p>
<h2 id="关键词-4"><a href="#关键词-4" class="headerlink" title="关键词"></a>关键词</h2><p>NMT;Rare Words;Subword Units;BPE</p>
<h2 id="文章来源-4"><a href="#文章来源-4" class="headerlink" title="文章来源"></a>文章来源</h2><p>ACL 2016</p>
<h2 id="问题-4"><a href="#问题-4" class="headerlink" title="问题"></a>问题</h2><p>NMT中的OOV（集外词）和罕见词（Rare Words）问题通常用back-off 词典的方式来解决，本文尝试用一种更简单有效的方式（Subword Units）来表示开放词表。</p>
<h2 id="模型-4"><a href="#模型-4" class="headerlink" title="模型"></a>模型</h2><p>本文从命名实体、同根词、外来语、组合词（罕见词有相当大比例是上述几种）的翻译策略中得到启发，认为把这些罕见词拆分为“子词单元”(subword units)的组合，可以有效的缓解NMT的OOV和罕见词翻译的问题。<br>子词单元的拆分策略，则是借鉴了一种数据压缩算法：Byte Pair Encoding(BPE)(Gage,1994)算法。该算法的操作过程和示例如Figure1所示。<br><img src="media/5-Fig1.jpg" alt="5-Fig1"></p>
<p>不同于(Chitnis and DeNero,2015)提出的霍夫曼编码，这里的压缩算法不是针对于词做变长编码，而是对于子词来操作。这样，即使是训练语料里未见过的新词，也可以通过子词的拼接来生成翻译。<br>本文还探讨了BPE的两种编码方式：一种是源语言词汇和目标语言词汇分别编码，另一种是双语词汇联合编码。前者的优势是让词表和文本的表示更紧凑，后者则可以尽可能保证原文和译文的子词切分方式统一。从实验结果来看，在音译或简单复制较多的情形下（比如英德）翻译，联合编码的效果更佳。<br>实验结果分别在WMT15英德和英俄的任务上得到1.1和1.3个BLEU值的提升。</p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>本文提出的子词拆分算法代码在 <a href="https://github.com/rsennrich/subword-nmt" target="_blank" rel="external">https://github.com/rsennrich/subword-nmt</a><br>实验所用的NMT系统为Groundhog: github.com/sebastien-j/LV_groundhog<br>实验数据来自WMT 2015</p>
<h2 id="相关工作-4"><a href="#相关工作-4" class="headerlink" title="相关工作"></a>相关工作</h2><p>OOV的处理一直是机器翻译研究的重点。<br>基于字符的翻译在短语SMT模型中就已被提出，并在紧密相关的语种对上验证是成功的(Vilar et al., 2007; Tiedemann,2009; Neubig et al., 2012)。  此外还有各种形态素切分方法应用于短语模型，(Nießen and Ney,2000; Koehn and Knight, 2003; Virpioja et al.,2007; Stallard et al., 2012)。<br>对于NMT，也有很多基于字符或形态素的方法用于生成定长连续词向量(Luong et al., 2013; Botha and Blunsom, 2014; Ling et al., 2015a; Kim et al., 2015)。与本文类似的一项工作 (Ling et al., 2015b)发现在基于词的方法上没有明显提升。其与本文的一个区别在于，attention机制仍然在词层级进行操作，而本文在子词层级上。</p>
<h2 id="简评-4"><a href="#简评-4" class="headerlink" title="简评"></a>简评</h2><p>这篇文章的创新点在于提出了一种介乎字符和单词之间，也不同于字符n-gram的文本表示单元，并借鉴BPE压缩算法，在词表大小和文本长度两个方面取得一个较为平衡的状态。应用在非同源/近源的语言对（如英汉）是否可以有类似的效果，尚待研究。在NMT模型的优化上，也还有探讨的空间。<br>本文的实验评价方法值得学习，单看BLEU值并不觉得有惊艳之处，但加上CHR F3和(对所有词、罕见词和集外词分别统计的)unigram F1这两个评价指标，尤其是Figure2和3画出来的效果，还是让人比较信服的。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>OOV词对于翻译性能和实用性的影响非常巨大，如何处理OOV词并达到open vocabulary一直是NMT的主要研究方向。传统方法基于单词级别来处理该问题，比如使用UNK替换、扩大词典规模等方法，往往治标不治本。因此最近一些研究者提出基于字符的NMT模型，取得了不错的成绩，字符级方法的主要优势包括不受语言的形态变化、能预测出词典中未出现的单词并降低词典大小等。值得一提的是，基于字符的模型不仅局限于NMT上，任何生成模型都面临OOV词问题，因此是否能够将字符级方法用在其他NLP任务，比如阅读理解或文本摘要上，让我们拭目以待。</p>
<p>以上为本期Paperweekly的主要内容，感谢EdwardHux、Mygod9、Jaylee1992、Susie和AllenCai五位同学的整理。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"><br>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-24T16:57:50.000Z"><a href="/2016/09/24/cs-CL-weekly-2016-09-19-2016-09-23/">2016-09-24</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/24/cs-CL-weekly-2016-09-19-2016-09-23/">cs.CL weekly 2016.09.19-2016.09.23</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="一周值得读"><a href="#一周值得读" class="headerlink" title="一周值得读"></a>一周值得读</h1><h2 id="Long-Term-Trends-in-the-Public-Perception-of-Artificial-Intelligence"><a href="#Long-Term-Trends-in-the-Public-Perception-of-Artificial-Intelligence" class="headerlink" title="Long-Term Trends in the Public Perception of Artificial Intelligence"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.04904v1.pdf" target="_blank" rel="external">Long-Term Trends in the Public Perception of Artificial Intelligence</a></h2><p>本文研究了30年来纽约时报对AI的报道，研究了人们这30年来对AI的兴趣、关注度和各种各样的讨论。是一篇很有意思的文章，是一种长时间段内的舆情监测和分析。</p>
<h2 id="Distant-Supervision-for-Relation-Extraction-beyond-the-Sentence-Boundary"><a href="#Distant-Supervision-for-Relation-Extraction-beyond-the-Sentence-Boundary" class="headerlink" title="Distant Supervision for Relation Extraction beyond the Sentence Boundary"></a><a href="http://120.52.73.77/arxiv.org/pdf/1609.04873v1.pdf" target="_blank" rel="external">Distant Supervision for Relation Extraction beyond the Sentence Boundary</a></h2><p>本文研究的问题是非结构化文本中的关系抽取问题，针对传统方法在抽取关系时仅限于单个句子，本文提出了一种新的方法，从多个句子中进行关系抽取。</p>
<h2 id="What-You-Get-Is-What-You-See-A-Visual-Markup-Decompiler"><a href="#What-You-Get-Is-What-You-See-A-Visual-Markup-Decompiler" class="headerlink" title="What You Get Is What You See: A Visual Markup Decompiler"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.04938v1.pdf" target="_blank" rel="external">What You Get Is What You See: A Visual Markup Decompiler</a></h2><p>【转发较多】本文研究的问题是如何从web页面中生成html代码，以及如何从公式图片中生成latex代码，为此作者构造了两个相关的大型数据集，用了完全数据驱动的端到端训练方法得到了不错的效果。本文工作来自Harvard。</p>
<p>Demo|Dataset|Code: <a href="http://lstm.seas.harvard.edu/latex/" target="_blank" rel="external">http://lstm.seas.harvard.edu/latex/</a></p>
<h2 id="Select-Additive-Learning-Improving-Cross-individual-Generalization-in-Multimodal-Sentiment-Analysis"><a href="#Select-Additive-Learning-Improving-Cross-individual-Generalization-in-Multimodal-Sentiment-Analysis" class="headerlink" title="Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.05244v1.pdf" target="_blank" rel="external">Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis</a></h2><p>本文研究的内容是多模态情感分析，针对当前相关高质量数据集规模太小造成的情感依赖于个体特征的问题，提出了一种Select-Additive学习方法提高通用性。 </p>
<h2 id="Interactive-Spoken-Content-Retrieval-by-Deep-Reinforcement-Learning"><a href="#Interactive-Spoken-Content-Retrieval-by-Deep-Reinforcement-Learning" class="headerlink" title="Interactive Spoken Content Retrieval by Deep Reinforcement Learning"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.05234v1.pdf" target="_blank" rel="external">Interactive Spoken Content Retrieval by Deep Reinforcement Learning</a></h2><p>本文研究的内容是DQN算法来做语音内容检索，通过人机交互来完成内容检索。DQN相比传统的RL模型明显的优势在于不依赖hand-crafted features。本文被Interspeech 2016录用。</p>
<h2 id="Graph-Structured-Representations-for-Visual-Question-Answering"><a href="#Graph-Structured-Representations-for-Visual-Question-Answering" class="headerlink" title="Graph-Structured Representations for Visual Question Answering"></a><a href="http://arxiv.org/pdf/1609.05600v1.pdf" target="_blank" rel="external">Graph-Structured Representations for Visual Question Answering</a></h2><p>本文研究内容为VQA，VQA的主要挑战在于对visual和text两个领域都需要理解。传统的模型中常常忽略场景中的结构和问题中的语言结构，本文针对这两个问题提出了一种图模型，取得了不错的效果。</p>
<h2 id="Context-aware-Sequential-Recommendation"><a href="#Context-aware-Sequential-Recommendation" class="headerlink" title="Context-aware Sequential Recommendation"></a><a href="http://arxiv.org/pdf/1609.05787v1.pdf" target="_blank" rel="external">Context-aware Sequential Recommendation</a></h2><p>用户行为建模是推荐系统中的一个关键部件，行为数据是序列数据，天然适合用RNN来建模。但实际应用中context信息(time,location,weahter)也很重要，本文针对这个问题提出了一种CA-RNN模型将context考虑在内，取得了不错效果。</p>
<h2 id="ReasoNet-Learning-to-Stop-Reading-in-Machine-Comprehension"><a href="#ReasoNet-Learning-to-Stop-Reading-in-Machine-Comprehension" class="headerlink" title="ReasoNet: Learning to Stop Reading in Machine Comprehension"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.05284v1.pdf" target="_blank" rel="external">ReasoNet: Learning to Stop Reading in Machine Comprehension</a></h2><p>本文研究内容为机器阅读理解，之前效果不错的方法大多数停留在有限的几轮reasoning，本文用增强学习来动态地决定是否继续读下去或者停下来进行答案选择。本文工作来自微软研究院。</p>
<h2 id="Enhancing-and-Combining-Sequential-and-Tree-LSTM-for-Natural-Language-Inference"><a href="#Enhancing-and-Combining-Sequential-and-Tree-LSTM-for-Natural-Language-Inference" class="headerlink" title="Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.06038v1.pdf" target="_blank" rel="external">Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference</a></h2><p>本文研究内容为自然语言推理，作者认为LSTM类的模型潜力并没有被充分挖掘，基于此，本文在传统LSTM模型的基础上增加了syntactic parse信息，得到了更好的效果。</p>
<h2 id="A-framework-for-mining-process-models-from-emails-logs"><a href="#A-framework-for-mining-process-models-from-emails-logs" class="headerlink" title="A framework for mining process models from emails logs"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.06127v1.pdf" target="_blank" rel="external">A framework for mining process models from emails logs</a></h2><p>本文研究的内容是邮件日志的挖掘，作者提出了一种无监督的挖掘方法，并且提出了一种半自动化的邮件标注方法。</p>
<h2 id="Character-level-and-Multi-channel-Convolutional-Neural-Networks-for-Large-scale-Authorship-Attribution"><a href="#Character-level-and-Multi-channel-Convolutional-Neural-Networks-for-Large-scale-Authorship-Attribution" class="headerlink" title="Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.06686v1.pdf" target="_blank" rel="external">Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution</a></h2><p>本文研究内容为authorship attribution，是一个典型的多分类任务。作者利用字符级别的多通道CNN模型对大规模dataset进行了建模，取得了不错的结果。作者之一来自aylien.com 公司，一家非常出色的NLP SaaS 公司。</p>
<h2 id="Minimally-Supervised-Written-to-Spoken-Text-Normalization"><a href="#Minimally-Supervised-Written-to-Spoken-Text-Normalization" class="headerlink" title="Minimally Supervised Written-to-Spoken Text Normalization"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.06649v1.pdf" target="_blank" rel="external">Minimally Supervised Written-to-Spoken Text Normalization</a></h2><p>本文研究的内容是特定语言领域知识在构建text normalization system的时候应该如何做trade-off，本文作者来自Google。</p>
<h2 id="Recognizing-Implicit-Discourse-Relations-via-Repeated-Reading-Neural-Networks-with-Multi-Level-Attention"><a href="#Recognizing-Implicit-Discourse-Relations-via-Repeated-Reading-Neural-Networks-with-Multi-Level-Attention" class="headerlink" title="Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.06380v1.pdf" target="_blank" rel="external">Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention</a></h2><p>本文研究内容是如何识别隐式的discourse关系，作者提出了一种多层注意力模型，联合注意力机制和外部memory来做关系识别。本文是EMNLP2016的长文。</p>
<h2 id="SoftTarget-Regularization-An-Effective-Technique-to-Reduce-Over-Fitting-in-Neural-Networks"><a href="#SoftTarget-Regularization-An-Effective-Technique-to-Reduce-Over-Fitting-in-Neural-Networks" class="headerlink" title="SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.06693v2.pdf" target="_blank" rel="external">SoftTarget Regularization: An Effective Technique to Reduce Over-Fitting in Neural Networks</a></h2><p>【转发较多】本文提出了一种新的正则化方法，通过在训练过程中调整label来实现，达到了和Dropout接近的效果。</p>
<h2 id="The-Color-of-the-Cat-is-Gray-1-Million-Full-Sentences-Visual-Question-Answering-FSVQA"><a href="#The-Color-of-the-Cat-is-Gray-1-Million-Full-Sentences-Visual-Question-Answering-FSVQA" class="headerlink" title="The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA)"></a><a href="http://120.52.73.77/arxiv.org/pdf/1609.06657v1.pdf" target="_blank" rel="external">The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA)</a></h2><p>本文提出了一个1 million的Visual Question Answer Dataset，数据地址：<a href="http://www.mi.t.u-tokyo.ac.jp/static/projects/fsvqa/" target="_blank" rel="external">http://www.mi.t.u-tokyo.ac.jp/static/projects/fsvqa/</a></p>
<h2 id="Knowledge-Representation-via-Joint-Learning-of-Sequential-Text-and-Knowledge-Graphs"><a href="#Knowledge-Representation-via-Joint-Learning-of-Sequential-Text-and-Knowledge-Graphs" class="headerlink" title="Knowledge Representation via Joint Learning of Sequential Text and Knowledge Graphs"></a><a href="http://arxiv.org/pdf/1609.07075v1.pdf" target="_blank" rel="external">Knowledge Representation via Joint Learning of Sequential Text and Knowledge Graphs</a></h2><p>【转发较多】当前知识表示存在两个挑战：1、如何更好地利用entity的context；2、如何发现与entity相关的句子；针对这两个问题，本文提出了一种从多个句子中学习表示的模型。给定每个entity的参考句子，首先用带池化的RNN或LSTM来encode与该entity相关的句子，然后用attention模型来衡量每个句子的信息量，最后得到entity的表示。模型在triple classification和link prediction两个任务上都取得了满意的结果。本文工作来自@刘知远THU组。</p>
<p>刘知远：我觉得这个工作的最有意思的地方是，能够为实体找到最有信息量的句子，这些句子往往是该实体的定义或描述。这样，在构建知识图谱时，我们就可以自动为新增的实体构建对应的文本描述信息了。</p>
<h2 id="Semantic-Tagging-with-Deep-Residual-Networks"><a href="#Semantic-Tagging-with-Deep-Residual-Networks" class="headerlink" title="Semantic Tagging with Deep Residual Networks"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.07053v1.pdf" target="_blank" rel="external">Semantic Tagging with Deep Residual Networks</a></h2><p>本文提出一种多语言智能tagger，模型采用了char-level和word-level的深度残差网络，在词性标注任务中取得了不错的效果，本文COLING 2016在审。</p>
<h2 id="Image-embodied-Knowledge-Representation-Learning"><a href="#Image-embodied-Knowledge-Representation-Learning" class="headerlink" title="Image-embodied Knowledge Representation Learning"></a><a href="http://arxiv.org/pdf/1609.07028v1.pdf" target="_blank" rel="external">Image-embodied Knowledge Representation Learning</a></h2><p>【转发较多】entity图像中包含丰富的信息，大多数传统方法并没有利用这一点，本文提出了一种知识表示模型，利用了triples和image信息，并在知识图谱补全和triple分类两个任务中取得了不错的效果。本文是一篇典型的多信息融合的文章，非常值得思考！工作同样来自@刘知远THU老师组。</p>
<h2 id="Twitter-Network-Topic-Model-A-Full-Bayesian-Treatment-for-Social-Network-and-Text-Modeling"><a href="#Twitter-Network-Topic-Model-A-Full-Bayesian-Treatment-for-Social-Network-and-Text-Modeling" class="headerlink" title="Twitter-Network Topic Model: A Full Bayesian Treatment for Social Network and Text Modeling"></a><a href="http://120.52.73.80/arxiv.org/pdf/1609.06791v1.pdf" target="_blank" rel="external">Twitter-Network Topic Model: A Full Bayesian Treatment for Social Network and Text Modeling</a></h2><p>推特上的推对于topic建模有以下缺点：1、短；2、非结构化；3、口语化；也有优点：1、作者；2、hashtags；3、粉丝网络。本文结合推特信息的优点提出了一种新模型。topic model是个老话题了，多源信息的融合是突破研究瓶颈一个不错的方向，本文的方法同样可借鉴于微博和其他社交网络。</p>
<h2 id="Joint-CTC-Attention-based-End-to-End-Speech-Recognition-using-Multi-task-Learning"><a href="#Joint-CTC-Attention-based-End-to-End-Speech-Recognition-using-Multi-task-Learning" class="headerlink" title="Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.06773v1.pdf" target="_blank" rel="external">Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning</a></h2><p>【转发较多】Attention类模型在端到端语音识别领域取得了不错的效果，但当输入噪声非常大的的时候，识别长句子效果不是很好。CTC是另外一种不错的端到端模型，本文结合两者的优势构建模型。构建了联合模型之后，克服了之前的问题。大家都在用Attention，都说Attention好，但终究还是有些情境下attention并不能如人意。那么问题来了，到底哪些场景下attention表现不好，原因是什么？想清楚这个到底之后，改进的方法大概也就在路上了。#Attention Model的缺点#</p>
<h1 id="资源分享"><a href="#资源分享" class="headerlink" title="资源分享"></a>资源分享</h1><h2 id="Bots-Product-Hunt"><a href="#Bots-Product-Hunt" class="headerlink" title="Bots - Product Hunt"></a><a href="https://www.producthunt.com/topics/bots" target="_blank" rel="external">Bots - Product Hunt</a></h2><p>一个分享和点评各种好玩product的站点，其中一个栏目有各种各样的bot。</p>
<h2 id="Gorgonia-is-a-library-that-helps-facilitate-machine-learning-in-Go"><a href="#Gorgonia-is-a-library-that-helps-facilitate-machine-learning-in-Go" class="headerlink" title="Gorgonia is a library that helps facilitate machine learning in Go"></a><a href="https://github.com/chewxy/gorgonia" target="_blank" rel="external">Gorgonia is a library that helps facilitate machine learning in Go</a></h2><p>用Go写的机器学习开源框架。</p>
<h2 id="A-Thorough-Examination-of-the-CNN-Daily-Mail-Reading-Comprehension-Task"><a href="#A-Thorough-Examination-of-the-CNN-Daily-Mail-Reading-Comprehension-Task" class="headerlink" title="A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task"></a><a href="https://github.com/danqi/rc-cnn-dailymail" target="_blank" rel="external">A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task</a></h2><p>这篇paper的代码放出来了，同时包括CNN和Daily Mail的数据集。来自斯坦福Danqi Chen的工作。</p>
<h1 id="业界新闻"><a href="#业界新闻" class="headerlink" title="业界新闻"></a>业界新闻</h1><h2 id="API-AI-is-joining-Google"><a href="#API-AI-is-joining-Google" class="headerlink" title="API.AI is joining Google!"></a><a href="https://api.ai/blog/2016/09/19/api-ai-joining-google/" target="_blank" rel="external">API.AI is joining Google!</a></h2><p>chatbot构建平台api.ai被Google收购了</p>
<h2 id="Angel-ai-a-company-that-builds-chat-bots-acqui-hired-by-Amazon-TechCrunch"><a href="#Angel-ai-a-company-that-builds-chat-bots-acqui-hired-by-Amazon-TechCrunch" class="headerlink" title="Angel.ai, a company that builds chat bots, acqui-hired by Amazon | TechCrunch "></a><a href="https://techcrunch.com/2016/09/20/angel-ai-a-company-that-builds-chat-bots-acqui-hired-by-amazon/" target="_blank" rel="external">Angel.ai, a company that builds chat bots, acqui-hired by Amazon | TechCrunch </a></h2><p>TechCrunch报道称，继api.ai被google收购之后，一家做自然语言理解的公司angel.ai也几乎被Amazon收购。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）每天都会分享当天arXiv cs.CL板块刷新的高质量paper<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-23T03:51:47.000Z"><a href="/2016/09/22/PaperWeekly-第六期/">2016-09-22</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/22/PaperWeekly-第六期/">PaperWeekly 第六期</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>本期paperweekly的主题是Question Answering Models，解决这一类问题可以很好地展现AI理解人类自然语言的能力，通过解决此类dataset可以给AI理解人类语言很好的insights。问题的定义大致是，给定较长一段话的context和一个较短的问题，以及一些candidate answers，训练一些可以准确预测正确答案的模型。</p>
<p>此问题也存在一些变种，例如context可以是非常大块的knowledge base，可以不提供candidate answers而是在所有的vocabulary中搜索答案，或者是在context中提取答案。</p>
<p>基于(Recurrent) Neural Network的一些模型在这一类问题上给出了state of the art models，本期paperweekly就带领大家欣赏这一领域有趣的工作。</p>
<h1 id="Attention-over-Attention-Neural-Networks-for-Reading-Comprehension"><a href="#Attention-over-Attention-Neural-Networks-for-Reading-Comprehension" class="headerlink" title="Attention-over-Attention Neural Networks for Reading Comprehension"></a><a href="https://arxiv.org/abs/1607.04423" target="_blank" rel="external">Attention-over-Attention Neural Networks for Reading Comprehension</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Yiming Cui, Zhipeng Chen, Si Wei, Shijin Wang, Ting Liu and Guoping Hu</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>iFLYTEK Research, China<br>Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Question Answering, Attentive Readers</p>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>arXiv, 201608</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>本文优化了attention机制，同时apply question-to-document and document-to-question attention，提升了已有模型在Cloze-Style Question Answering Task上的准确率。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>本文解决的是Cloze-style question answering的问题，给定一个Document和一个Query，以及一个list的candidate answers，模型需要给出一个正确答案。</p>
<p>已有的模型大都通过比较每一个Query + candidate answer和context document的相似性来找出正确答案，这种相似性measure大都通过把query 投射到context document每个单词及所在context的相似性来获得。本文的不同之处在于模型还计算了context投射到每个query单词的相似度，进一步丰富了context和query相似度的计算。</p>
<p><img src="media/model_image.png" alt="model_image"></p>
<p>首先，document和query都会被model成biGRU。<br><img src="media/embedding_and_encoding.png" alt="embedding_and_encoding"></p>
<p>然后使用document biGRU和query biGRU的每一个position做inner product计算，可以得到一个similarity matrix。<br><img src="media/similarity_matrix.png" alt="similarity_matrix"></p>
<p>对这个matrix做一个column-wise softmax，可以得到每个query单词在每个document单词上的similarity。<br><img src="media/column_softmax.png" alt="column_softmax"></p>
<p>similarly，对这个matrix做一个row-wise softmax，可以得到每个document单词在每个query单词上的similarity。<br><img src="media/row_softmax.png" alt="row_softmax"></p>
<p>取个平均就得到了每个query单词在整个context document上的similarity。<br><img src="media/average.png" alt="average"></p>
<p>然后把alpha和beta做个inner product就得到了每个context document word的probability。<br><img src="media/context_word_probability.png" alt="context_word_probability"></p>
<p>每个candidate answer的probability就是它出现在上述s中的probability之和。<br><img src="media/attention_sum.png" alt="attention_su"></p>
<p>Loss Function可以定义为正确答案的log probability之和。<br><img src="media/loss_function.png" alt="loss_function"></p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><ul>
<li><a href="https://github.com/deepmind/rc-data" target="_blank" rel="external">cnn和daily mail datasets</a></li>
<li><a href="https://research.facebook.com/research/babi/" target="_blank" rel="external">Children’s book test</a></li>
</ul>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>利用attentive readers解决question answering问题最早出自deep mind: teaching machines to read and comprehend。后来又有Bhuwan Dhingra: Gated-Attention Readers for Text Comprehension和Danqi Chen: A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task，以及其他相关工作，在此不一一赘述。</p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文很好地完善了attentive reader的工作，同时考虑了query to document and document to query attentions，在几个data set上都取得了state of the art效果，思路非常清晰，在question answering问题上很有参考价值。</p>
<h1 id="MACHINE-COMPREHENSION-USING-MATCH-LSTM-AND-ANSWER-POINTER"><a href="#MACHINE-COMPREHENSION-USING-MATCH-LSTM-AND-ANSWER-POINTER" class="headerlink" title="MACHINE COMPREHENSION USING MATCH-LSTM AND ANSWER POINTER"></a><a href="http://120.52.73.76/arxiv.org/pdf/1608.07905v1.pdf" target="_blank" rel="external">MACHINE COMPREHENSION USING MATCH-LSTM AND ANSWER POINTER</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Shuohang Wang, Jing Jiang</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>Singapore Management University</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>Machine comprehension, Match-LSTM, Pointer Net</p>
<h2 id="来源-1"><a href="#来源-1" class="headerlink" title="来源"></a>来源</h2><p>arXiv，201608</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>提出一种结合match-LSTM和Pointer Net的端到端神经网络结构，来解决SQuAD数据集这类没有候选项且答案可能是多个词的machine comprehension问题。</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>本文提出的模型结合了match-LSTM(mLSTM)和Pointer Net(Ptr-Net)两种网络结构。</p>
<p>1、match-LSTM</p>
<p>mLSTM是由Wang和Jiang提出的一种解决文本蕴含识别（RTE）问题的一种神经网络结构。模型结构见下图，该模型首先将premise和hypothesis两句话分别输入到两个LSTM中，用对应LSTM的隐层输出作为premise和hypothesis中每个位置对应上下文信息的一种表示（分别对应图中的Hs和Ht）。对于hypothesis中的某个词的表示ht_i，与premise中的每个词的表示Hs计算得到一个权重向量，然后再对premise中的词表示进行加权求和，得到hti对应的上下文向量a_i（attention过程）。最后把hypothesis中该词的表示ht_i和其对应的context向量a_i拼接在一起，输入到一个新的LSTM中。该模型将两个句子的文本蕴含任务拆分成词和短语级别的蕴含识别，因此可以更好地识别词之间的匹配关系。<br><img src="media/mLSTM.png" alt="mLST"></p>
<p>2、 Pointer networks</p>
<p>该模型与基于attention的生成模型类似。区别之处在于，pointer networks生成的结果都在输入序列中，因此pointer networks可以直接将attention得到的align向量中的每个权重直接作为预测下一个词对应的概率值。</p>
<p>3、 Sequence Model &amp; Boundary Model</p>
<p>本文提出的模型结构见下图，具体到本文的神经网络结构，可以简单分为下面两部分：<br><img src="media/Seq_Bound.png" alt="Seq_Bound"><br>（1）Match-LSTM层：该部分将machine comprehension任务中的question作为premise，而passage作为hypothesis。直接套用上述的mLSTM模型得到关于passage每个位置的一种表示。为了将前后方向的上下文信息全部编码进来，还用相同的方法得到一个反向mLSTM表示，将两个正反方向的表示拼接在一起作为最终passage的表示。</p>
<p>（2）生成答案序列部分，论文中提出了两种生成方法：</p>
<ul>
<li><p>Sequence方法与Pointer Net相同，即根据每一个时刻attention的align向量生成一个词位置，直到生成终止符为止。</p>
</li>
<li><p>Boundary方法则是利用SQuAD数据集的答案均是出现在passage中连续的序列这一特点，该方法仅生成首尾两个位置，依据起始位置和终止位置来截取passage的一部分作为最终的答案。</p>
</li>
</ul>
<p>本文在SQuAD数据集上进行实验，两种方法实验结果较之传统LR方法均有大幅度提升。其中Boundary方法比Sequence方法效果更好。</p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><ul>
<li><a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank" rel="external">SQuAD</a></li>
</ul>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>数据集相关论文<br>SQuAD: 100,000+ Questions for Machine Comprehension of Text<br>模型相关论文<br>Learning Natural Language Inference with LSTM<br>Pointer networks</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本篇论文提出的模型是第一个在SQuAD语料上应用端到端神经网络的模型，该模型将Match-LSTM和Pointer Networks结合在一起，利用了文本之间的蕴含关系更好地预测答案。<br>本文提出了两种方法来生成答案，其中Boundary方法巧妙地利用SQuAD数据集的答案均是文本中出现过的连续序列这一特点，只生成答案的起始和终止位置，有效地提升了模型的效果。</p>
<h1 id="Dataset-and-Neural-Recurrent-Sequence-Labeling-Model-for-Open-Domain-Factoid-Question-Answering"><a href="#Dataset-and-Neural-Recurrent-Sequence-Labeling-Model-for-Open-Domain-Factoid-Question-Answering" class="headerlink" title="Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering"></a><a href="https://arxiv.org/pdf/1607.06275v2.pdf" target="_blank" rel="external">Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Peng Li, Wei Li, Zhengyan He, Xuguang Wang, Ying Cao, Jie Zhou, Wei Xu</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>Baidu IDL</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>Question Answering, Sequence Labeling, CRF</p>
<h2 id="来源-2"><a href="#来源-2" class="headerlink" title="来源"></a>来源</h2><p>arXiv, 201609</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>作者给出了一个新的中文的QA数据集, 并且提出了一个非常有意思的baseline model.</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>1、WebQA Dataset</p>
<p>作者来自百度IDL, 他们利用百度知道和一些其他的资源, 构建了这个中文的QA数据集. 这个数据集里所有的问题都是factoid类型的问题, 并且问题的答案都只包含一个entity (但是一个entity可能会包含多个单词). 对于每个问题, 数据集提供了若干个’evidence’, 这些evidence是利用搜索引擎在网络中检索的.</p>
<p>2、Recurrent Sequence Labeling Model</p>
<p>作者把QA类型的问题看做sequence labeling问题, 给出的模型大概分三部分:<br><img src="media/ericyuan_graph.png" alt="ericyuan_graph"></p>
<p>（1）Question LSTM<br>这部分很简单, 就是普通的单向LSTM, 对整个Question sequence进行encoding, 之后计算self-attention, 并用attention对question encoding求加权平均作为问题的representation.</p>
<p>（2）Evidence LSTMs<br>这部分比较有意思, 首先, 作者从数据中提取出两种feature: 每个词是否在question和evidence中共同出现, 以及每个词是否同时在多个evidence中出现. 之后, 模型用一个三层的单向LSTM对evidence/quesiton/feature进行编码. </p>
<ul>
<li>第一层: 将evidence/question representation/feature进行连接, 放进一个正向LSTM.</li>
<li>第二层: 将第一层的结果放入一个反向LSTM.</li>
<li>第三层: 将第一层和第二层的结果进行连接, 放进一个正向LSTM.</li>
</ul>
<p>（3）CRF<br>经过evidence LSTMs, question和evidence的representation已经揉在一起, 所以并不需要其他QA模型(主要是Attention Sum Reader)广泛用的, 用question representation和story representation进行dot product, 求cosine similarity. 这时候只需要对evidence representation的每一个time step进行分类就可以了, 这也是为什么作者将数据标注成IOB tagging的格式, 我们可以直接用一个CRF层对数据进行预测. 在一些实验中, 作者将答案之前的词用O1, 答案之后的词用O2进行标注, 这又给了模型关于非答案词的位置信息(正确答案是在这个词的前面还是后面). </p>
<h2 id="资源-2"><a href="#资源-2" class="headerlink" title="资源"></a>资源</h2><ul>
<li><a href="http://idl.baidu.com/webqa.html" target="_blank" rel="external">WebQA dataset</a></li>
<li><a href="https://github.com/baidu/Paddle" target="_blank" rel="external">Baidu Paddle</a></li>
</ul>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><ul>
<li>关于CRF进行序列标注的问题, 可以参考这篇文章.<br>Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF models for sequence tagging. arXiv:1508.01991v1.</li>
<li>关于multi-word答案选择在SQuAD dataset上的模型, 可以参考这篇.<br>Shuohang Wang, Jing Jiang. 2016. Machine Comprehension Using Match_LSTM and Answer Pointer. arXiv: 1608.07905v1.</li>
</ul>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>首先对所有release数据集的人表示感谢.<br>关于dataset部分, 百度利用了自己庞大的资源收集数据. 第一, 百度知道里的问题都是人类问的问题, 这一点相比于今年前半年比较流行的CNN/CBT等等cloze style的问题, 要强很多. 第二, 数据集中包含了很多由多个词组成的答案, 这也使数据集的难度大于CNN/CBT这种单个词作为答案的数据. 第三, 对于每个问题, 并没有给出备选答案, 这使得对于答案的搜索空间变大(可以把整个evidence看做是备选答案). 第四, 对于每一个问题, dataset中可能有多个supporting evidence, 这也迎合了最近multi-supporting story的趋势, 因为对于有些问题, 答案并不只在某一个单一的文章中(对于百度来说, 如果搜索一个问题, 那么答案并不一定在单一的搜索结果网页中), 那么一个好的model需要在有限的时间内对尽可能多的搜索结果进行检索. </p>
<p>关于model部分, 本文尝试将QA问题看做是序列标注问题, 某种意义上解决了multiword answer的难点. 熟悉前半年QA paper的人都会对Attention Sum Reader以及延伸出来的诸多模型比较熟悉, 由于用了类似Pointer Network的机制, 一般的模型只能从文中选择story和question的cosine similarity最高的词作为答案, 这使得multiple word answer很难处理, 尤其是当multiple answer word不连续的时候, 更难处理. 而CRF是大家都熟知的简单高效的序列标注工具, 把它做成可训练的, 并且放在end to end模型中, 看起来是非常实用的. 在Evidence LSTM的部分, 加入的两个feature据作者说非常有帮助, 看起来在deep learning 模型中加入一些精心设计的feature, 或者IR的要素, 有可能能够对模型的performance给予一定的提升. 在entropy的角度, 虽然不一定是entropy reduction, 因为这些信息其实本来已经包含在question/evidence中了, 但是有可能因为你提供给模型这些信息, 它就可以把更多精力用在一些其他的特征上?</p>
<p>另外值得一提的是, 最近Singapore Management University的Wang and Jiang也有所突破, 在SQuAD dataset(也是multiple word answer)上一度取得了state of the art的结果, 他们用的mLSTM模型也十分有趣. </p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这一类model都大量使用了Recurrent Neural Network(LSTM或者GRU)对text进行encoding，得到一个sequence的hidden state vector。然后通过inner product或者bilinear term比较不同位置hidden state vector之间的similarity来计算它们是正确答案的可能性。可见Recurrent Neural Network以及对于Similarity的定义依旧是解决此类问题的关键所在，更好地改良这一类模型也是提升准确率的主流方法。笔者认为，similarity的计算给了模型从原文中搜索答案的能力，然而模型非常缺乏的是推理和思考的能力（其实也有相关工作<a href="http://arxiv.org/abs/1508.05508" target="_blank" rel="external">Towards Neural Network-based Reasoning</a>），如果模型能够配备逻辑思考能力，那么解决问题的能力会大大增强。非常期待有新的思路能够出现在这一领域中，令AI能够更好地理解人类语言。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-18T05:05:11.000Z"><a href="/2016/09/17/paperweekly用户投票总结/">2016-09-17</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/17/paperweekly用户投票总结/">paperweekly用户投票总结</a></h1>
  

    </header>
    <div class="entry">
      
        <p>参与投票131人，远超我个人的预期，证明了发红包是一个非常有效的手段，感谢各位的参与。</p>
<p><img src="media/1.png" alt="1"></p>
<p>从第一个问题的回答来看，群里的童鞋基本上都喜欢读paper，并且大多数一周内可以读1-3篇，更有甚者可以读到6篇以上。关于读paper，以及从最开始做paperweekly，也是受了Ng一次采访内容的启发，他大概的意思是说，每天坚持读篇paper是一种长期投资，坚持做一年、两年之后会有显著地提高。（虽然不确定这话是不是Ng本人说的，但我比较认同这个观点）</p>
<p><img src="media/2.png" alt="2"></p>
<p>第二个问题是关于paper类型的，是一个多选题。群里的童鞋有的是学生，有的是工业界的朋友，有的大厂的工程师，有的是创业公司的大拿，不同的背景决定了导向不同。从结果分布来看，工程性强、热门的paper更受欢迎，这个结果可以也比较好理解，毕竟大众化的东西是更受大家欢迎，工程性强的文章一般来说可操作性都比较强，适合复现，并且可以有选择地应用在生产环境中；热门的文章是大家热议的话题，AlphaGo热炒那会，出门不聊几句增强学习都不好意思和人打招呼，甚至这个PR行为带动了一大批人开始学习下围棋，热门、话题性是是媒体感兴趣的，也是大众喜欢津津乐道的；理论性强的paper通常来说不好读，因为很难，需要很深的基础在那儿，不是一句、两句说得清的，但正是这些理论性强的paper真正地推动着AI在往前走；每个人的兴趣点可能都不是很相同，所以有28个童鞋选择了最后一个选项，也符合小众这个词的特点。</p>
<p>chatbot是当下可能最火的方向之一，但说句实话，10年前paper提出的方法可能在现在的系统中仍然是非常好用的，记得微博上看到过一个人说用正则可以解决大多数的问题，仔细想想rule-based是一个多么神通广大的事情啊。既然rule-based这么好，干嘛还研究那么多新东西、新概念呢？不就是因为人工智能太偏重于人工一词，离智能太远，离智障太近嘛。我一直是这么看待paper这个事儿的，paper针对的可能不是当下的问题，而是未来的问题，但不意味着当下的paper对于当下的问题没有参考和借鉴的意义。paperweekly的一个初衷是希望大家可以通过简单、清晰地描述来看看某一篇或者某几篇paper到底解决了什么问题，用了什么方法，结果如何，当然结果的可信度是另外一回事，但终究是会有启发的。</p>
<p><img src="media/3.png" alt="3"></p>
<p>这个问题少打两个字，但是感觉根据上下文大家应该是理解了我提的问题。我想了解，到底paperweekly写的文章有没有真正地解决了一点点需求，或者给大家带来那么一点点启发。答案告诉了我，确实有，某些细节或者思路确实很有借鉴意义，这件事情值得做。谢谢。</p>
<p><img src="media/4.png" alt="4"></p>
<p>这是一个多选题，初衷是想了解下哪种方式或者哪几种方式可以让交流变得更加高效率。毫无疑问，微信群是最多的答案，说句实话，微信群排第一是因为大家对微信的依赖强，黏性大，bbs排第二，其实bbs是更加好的讨论方式，但是黏性很差，讨论起来操作会麻烦一些，所以我这边有个非常naive的想法，就是想将bbs和微信群打通，群里有几个技术大牛也愿意一起来做这件事情，希望可以有一个方便大家的东西出来。</p>
<p><img src="media/5.png" alt="5"></p>
<p>复现别人paper这个事儿，我个人会选一般有。原因如下：1、首先paper的结果可能没有那么地好，只是说写的或者选的比较好而已；2、paper里的算法不见得适合你的问题；3、paper中的实验在实现过程中可能有很多的trick，并没有写明在paper中，这都是一个又一个的坑啊；4、有些paper有开源的code，可以拿来跑一跑看看效果再说。</p>
<p><img src="media/6.png" alt="6"></p>
<p>这个答案也是我预想之中的，摘要就是为了解决信息过载问题的。群里每天会产生一定数量的消息（不是很多其实），但没有赶上实时聊天的话，很容易错过一些精彩的对话或者干货分享。从这个角度来看，做digest这件事情就显得很有意义了。关于如何做，群里之前也有过不错的讨论，我也尝试标注了下数据，感觉难度不小，现在的想法是，我每天晚上花点时间手工摘要出来，分享在bbs和群里。（日后有机会可以将这个事情自动化）</p>
<p><img src="media/7.png" alt="7"></p>
<p>这个问题的结果基本上和我上面的想法吻合了。</p>
<p><img src="media/8.png" alt="8"></p>
<p>目前paperweekly运营团队里有四个活跃的小组，分别是chatbot、NMT、QA和representation，每个组每周负责出一期文章，包括3-5篇paper，KG这个组建立了，但是一直不够活跃，需要大牛的加入，来写KG方面的文章。</p>
<p>投票的结果和总结基本是这样的情况，投票可能设计的不科学也有些仓促，但基本达到了预期的目的，得到了充分的反馈，这里感谢各位的支持。谢谢大家！</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-17T04:34:58.000Z"><a href="/2016/09/16/cs-CL-weekly-2016-09-12-2016-09-16/">2016-09-16</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/16/cs-CL-weekly-2016-09-12-2016-09-16/">cs.CL weekly 2016.09.12-2016.09.16</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本周（2016.09.12-2016.09.16）质量较高的arXiv cs.CL的paper如下：<br>（点击标题可看原文）</p>
<h1 id="Dialogue-manager-domain-adaptation-using-Gaussian-process-reinforcement-learning"><a href="#Dialogue-manager-domain-adaptation-using-Gaussian-process-reinforcement-learning" class="headerlink" title="Dialogue manager domain adaptation using Gaussian process reinforcement learning"></a><a href="http://120.52.73.75/arxiv.org/pdf/1609.02846v1.pdf" target="_blank" rel="external">Dialogue manager domain adaptation using Gaussian process reinforcement learning</a></h1><p>本文是Steve Young组的一篇大作，文中详细介绍了Gaussian process reinforcement learning框架的思路和优势，并且在多个对话领域中进行了实验并得到更好的结果。</p>
<h1 id="A-Hierarchical-Model-of-Reviews-for-Aspect-based-Sentiment-Analysis"><a href="#A-Hierarchical-Model-of-Reviews-for-Aspect-based-Sentiment-Analysis" class="headerlink" title="A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.02745v1.pdf" target="_blank" rel="external">A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis</a></h1><p>本文提出用分层双向LSTM模型对网站评论数据进行观点挖掘，发表在EMNLP 2016。该作者今天在arxiv上提交了三篇同类问题不同解决方案的paper，对评论观点和情感挖掘的童鞋可作参考。</p>
<h1 id="Knowledge-as-a-Teacher-Knowledge-Guided-Structural-Attention-Networks"><a href="#Knowledge-as-a-Teacher-Knowledge-Guided-Structural-Attention-Networks" class="headerlink" title="Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.03286v1.pdf" target="_blank" rel="external">Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks</a></h1><p>本文提出了用先验知识+attention network的模型，用来解决了自然语言理解存在问题：通过从少量训练数据中捕获重要子结构，来缓解测试集中的unseen data问题，同时提高理解能力。</p>
<h1 id="Wav2Letter-an-End-to-End-ConvNet-based-Speech-Recognition-System"><a href="#Wav2Letter-an-End-to-End-ConvNet-based-Speech-Recognition-System" class="headerlink" title="Wav2Letter: an End-to-End ConvNet-based Speech Recognition System"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.03193v2.pdf" target="_blank" rel="external">Wav2Letter: an End-to-End ConvNet-based Speech Recognition System</a></h1><p>本文提出了一种语音识别的端到端模型，基于CNN和graph decoding，在不依赖因素对齐的前提下，输出letters。本文工作来自Facebook AI。</p>
<h1 id="Multimodal-Attention-for-Neural-Machine-Translation"><a href="#Multimodal-Attention-for-Neural-Machine-Translation" class="headerlink" title="Multimodal Attention for Neural Machine Translation "></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.03976v1.pdf" target="_blank" rel="external">Multimodal Attention for Neural Machine Translation </a></h1><p>本文通过利用image caption的多模态、多语言数据构建了一个NMT模型，模型的输入不仅是source language，还有所描述的图像，输出是target language。通过输入更多的信息，得到了更好的效果。</p>
<h1 id="Joint-Extraction-of-Events-and-Entities-within-a-Document-Context"><a href="#Joint-Extraction-of-Events-and-Entities-within-a-Document-Context" class="headerlink" title="Joint Extraction of Events and Entities within a Document Context"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.03632v1.pdf" target="_blank" rel="external">Joint Extraction of Events and Entities within a Document Context</a></h1><p>本文针对传统信息抽取方法将event和entity分开考虑的问题，提出了在docuemnt-level context下考虑event和entity之间关系进行信息抽取的新方法，取得了非常好的结果。本文发表在NAACL2016.</p>
<h1 id="Character-Level-Language-Modeling-with-Hierarchical-Recurrent-Neural-Networks"><a href="#Character-Level-Language-Modeling-with-Hierarchical-Recurrent-Neural-Networks" class="headerlink" title="Character-Level Language Modeling with Hierarchical Recurrent Neural Networks"></a><a href="http://120.52.73.75/arxiv.org/pdf/1609.03777v1.pdf" target="_blank" rel="external">Character-Level Language Modeling with Hierarchical Recurrent Neural Networks</a></h1><p>语言模型问题上，char-level可以很好地解决OOV的问题，但效果不如word-level，本文针对该问题提出了一种分层模型，同时兼顾word-level和char-level的优势。本文发表在nips2016。</p>
<h1 id="Neural-Machine-Translation-with-Supervised-Attention"><a href="#Neural-Machine-Translation-with-Supervised-Attention" class="headerlink" title="Neural Machine Translation with Supervised Attention"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.04186v1.pdf" target="_blank" rel="external">Neural Machine Translation with Supervised Attention</a></h1><p>attention机制可以动态地对齐source和target words，但准确率不如传统方法。本文提出了用传统方法作为teacher，来“教”model学习alignment，模型称为supervised attention。本文已投稿COLING2016，在审。</p>
<h1 id="Efficient-softmax-approximation-for-GPUs"><a href="#Efficient-softmax-approximation-for-GPUs" class="headerlink" title="Efficient softmax approximation for GPUs"></a><a href="http://120.52.73.76/arxiv.org/pdf/1609.04309v1.pdf" target="_blank" rel="external">Efficient softmax approximation for GPUs</a></h1><p>本文提出了一种高效的softmax近似方法，并且可以方便地进行并行计算。本文称之为adaptive softmax，根据词分布进行聚类，极大地提高了计算效率并保证了不错的准确率。本文工作来自Facebook AI Research。</p>
<p>在自然语言生成任务中常常面临word vocabulary size太大的困境，softmax的效率非常低，本文给出了一种快速计算的方法。Tomas Mikolov之前也提到过类似的思路。</p>
<h1 id="Characterizing-the-Language-of-Online-Communities-and-its-Relation-to-Community-Reception"><a href="#Characterizing-the-Language-of-Online-Communities-and-its-Relation-to-Community-Reception" class="headerlink" title="Characterizing the Language of Online Communities and its Relation to Community Reception"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.04779v1.pdf" target="_blank" rel="external">Characterizing the Language of Online Communities and its Relation to Community Reception</a></h1><p>本文研究了在线社区语言的style和topic哪个更具代表性，这里style用复合语言模型来表示，topic用LDA来表示，通过Reddit Forum实验得到style比topic更有代表性。</p>
<h1 id="Factored-Neural-Machine-Translation"><a href="#Factored-Neural-Machine-Translation" class="headerlink" title="Factored Neural Machine Translation"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.04621v1.pdf" target="_blank" rel="external">Factored Neural Machine Translation</a></h1><p>针对机器翻译领域中两个常见的问题：1、目标语言词汇表过大；2、OOV问题；利用了单词的词形和语法分解，提出了一种新的NMT模型，并取得了满意的效果。</p>
<h1 id="Context-Aware-Nonnegative-Matrix-Factorization-Clustering"><a href="#Context-Aware-Nonnegative-Matrix-Factorization-Clustering" class="headerlink" title="Context Aware Nonnegative Matrix Factorization Clustering"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.04628v1.pdf" target="_blank" rel="external">Context Aware Nonnegative Matrix Factorization Clustering</a></h1><p>大多数paper都在研究NMF在聚类中的初始化和优化部分，而本文关注的点在于最后的聚类分配上。本文被 ICPR 2016全文收录。</p>
<p>以下内容为arXiv外的优质内容：</p>
<h1 id="SIGDIAL-2016-Accepted-Paper"><a href="#SIGDIAL-2016-Accepted-Paper" class="headerlink" title="SIGDIAL 2016 Accepted Paper"></a><a href="http://www.sigdial.org/workshops/conference17/proceedings/SIGDIAL-2016.pdf" target="_blank" rel="external">SIGDIAL 2016 Accepted Paper</a></h1><p>SIGdial是ACL下面的一个关于对话系统地特别兴趣小组，每年开一次会。今年的会议最近正在开，会议录用的所有paper都已经放出。</p>
<h1 id="CMU-SPEECH-Team-Homepage"><a href="#CMU-SPEECH-Team-Homepage" class="headerlink" title="CMU SPEECH Team Homepage"></a><a href="http://speech.sv.cmu.edu/software.html" target="_blank" rel="external">CMU SPEECH Team Homepage</a></h1><p>CMU SPEECH Team的主页，包括他们的开源软件Yoda和publication及其开源实现。</p>
<h1 id="Machine-Learning-WAYR-What-Are-You-Reading"><a href="#Machine-Learning-WAYR-What-Are-You-Reading" class="headerlink" title="Machine Learning - WAYR (What Are You Reading)"></a><a href="https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/?st=ISZ6YT6D&amp;sh=02bd0722" target="_blank" rel="external">Machine Learning - WAYR (What Are You Reading)</a></h1><p>reddit上的这个帖子很有意思，和paperweekly想做的一个事情非常像，就是可以让读类似或者同一篇paper的童鞋得到充分交流。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"><br>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）每天都会分享当天arXiv cs.CL板块刷新的高质量paper<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-16T18:14:40.000Z"><a href="/2016/09/16/PaperWeekly-第五期/">2016-09-16</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/16/PaperWeekly-第五期/">PaperWeekly 第五期</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>Word2Vec从提出至今，已经成为了深度学习在自然语言处理中的基础部件，大大小小、形形色色的DL模型在表示词、短语、句子、段落等文本要素时都需要用word2vec来做word-level的embedding。Word2Vec的作者Tomas Mikolov是一位产出多篇高质量paper的学者，从RNNLM、Word2Vec再到最近流行的FastText都与他息息相关。一个人对同一个问题的研究可能会持续很多年，而每一年的研究成果都可能会给同行带来新的启发，本期的PaperWeekly将会分享其中三篇代表作，分别是：</p>
<p>1、Efficient Estimation of Word Representation in Vector Space, 2013<br>2、Distributed Representations of Sentences and Documents, 2014<br>3、Enriching Word Vectors with Subword Information, 2016</p>
<h1 id="Efficient-Estimation-of-Word-Representation-in-Vector-Space"><a href="#Efficient-Estimation-of-Word-Representation-in-Vector-Space" class="headerlink" title="Efficient Estimation of Word Representation in Vector Space"></a><a href="https://arxiv.org/pdf/1301.3781.pdf" target="_blank" rel="external">Efficient Estimation of Word Representation in Vector Space</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>Google Inc., Mountain View, CA</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Word Representation, Word Embedding, Neural Network, Syntactic Similarity, and Semantic Similarity</p>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>arXiv, 201309</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>如何在一个大型数据集上快速、准确地学习出词表示？</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>传统的NNLM模型包含四层，即输入层、映射层、隐含层和输出层，计算复杂度很大程度上依赖于映射层到隐含层之间的计算，而且需要指定上下文的长度。RNNLM模型被提出用来改进NNLM模型，去掉了映射层，只有输入层、隐含层和输出层，计算复杂度来源于上一层的隐含层到下一层隐含层之间的计算。</p>
<p>本文提出的两个模型CBOW (Continuous Bag-of-Words Model)和Skip-gram (Continuous Skip-gram Model)结合了上面两个模型的特点，都是只有三层，即输入层、映射层和输出层。CBOW模型与NNLM模型类似，用上下文的词向量作为输入，映射层在所有的词间共享，输出层为一个分类器，目标是使当前词的概率最大。Skip-gram模型与CBOW的输入跟输出恰好相反，输入层为当前词向量，输出层是使得上下文的预测概率最大，如下图所示。训练采用SGD。<br><img src="media/14740499814306.jpg" alt=""></p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>Code: <a href="https://code.google.com/archive/p/word2vec/" target="_blank" rel="external">C++代码</a><br>Dataset: <a href="https://sites.google.com/site/semeval2012task2/" target="_blank" rel="external">SemEval-2012</a>,用来评估语义相关性。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>Bengio[1]在2003年就提出了language model的思路，同样是三层（输入层，隐含层和输出层）用上下文的词向量来预测中间词，但是计算复杂度较高，对于较大的数据集运行效率低；实验中也发现将上下文的n-gram出现的频率结合进去会提高性能，这个优点体现在CBOW和Skip-gram模型的输出层中，用hierarchical softmax（with huffman trees）来计算词概率。</p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文的实验结果显示CBOW比NNLM在syntactic和semantic上的预测都要好，而Skip-gram在semantic上的性能要优于CBOW，但是其计算速度要低于CBOW。结果显示用较大的数据集和较少的epoch，可以取得较好的效果，并且在速度上有所提升。与LSI和LDA相比，word2vec利用了词的上下文，语义信息更加丰富。基于word2vec，出现了phrase2vec, sentence2vec和doc2vec，仿佛一下子进入了embedding的世界。NLP的这些思想也在用于recommendation等方面，并且与image结合，将image跟text之间进行转换。</p>
<h1 id="Distributed-Representations-of-Sentences-and-Documents"><a href="#Distributed-Representations-of-Sentences-and-Documents" class="headerlink" title="Distributed Representations of Sentences and Documents"></a><a href="http://120.52.73.76/arxiv.org/pdf/1405.4053v2.pdf" target="_blank" rel="external">Distributed Representations of Sentences and Documents</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Quoc V. Le, Tomas Mikolov</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>Google Inc, Mountain View, CA</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>sentence representation</p>
<h2 id="来源-1"><a href="#来源-1" class="headerlink" title="来源"></a>来源</h2><p>ICML 2014</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>基于word2vec的思路，如何表示sentence和document？</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p><img src="media/14740512129190.jpg" alt=""><br>利用one-hot的表示方法作为网络的输入，乘以词矩阵W，然后将得到的每个向量通过平均或者拼接的方法得到整个句子的表示，最后根据任务要求做一分类，而这过程中得到的W就是词向量矩阵，基本上还是word2vec的思路。</p>
<p>接下来是段落的向量表示方法：<br><img src="media/14740512491434.jpg" alt=""><br>依旧是相同的方法，只是在这里加上了一个段落矩阵，用以表示每个段落，当这些词输入第i个段落时，通过段落id就可以从这个矩阵中得到相对应的段落表示方法。需要说明的是，在相同的段落中，段落的表示是相同的。文中这样表示的动机就是段落矩阵D可以作为一个memory记住在词的context中遗失的东西，相当于增加了一个额外的信息。这样经过训练之后，我们的就得到了段落表示D，当然这个段落就可以是一段或者一篇文章。</p>
<p>最后一种就是没有词序的段落向量表示方法：<br><img src="media/14740512902836.jpg" alt=""><br>从图中就可以感觉到这个方法明显和skip-gram非常相似，这里只是把重点放在了段落的表示中，通过段落的表示，来预测相应的context 词的表示。最后我们依然可以得到段落矩阵D，这样就可以对段落进行向量化表示了。但是输入起码是句子级别的表示，而输出则是词的向量表示，因此个人比较怀疑这种方法的合理性。</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>这篇文章是word2vec的方法提出一年后提出的方法，因此本文并没有使用目前非常流行的word2vec的训练方法来训练词向量，而是利用word2vec的思路，提出了一种更加简单的网络结构来训练任意长度的文本表示方法。这样一方面好训练，另一方面减少了参数，避免模型过拟合。优点就是在训练paragraph vector的时候加入了一个paragraph matrix，这样在训练过程中保留了一部分段落或者文档信息。这点在目前看来也是有一定优势的。但是目前深度学习发展迅速，可以处理非常大的计算量，同时word2vec以及其变种被应用得非常普遍，因此该文章提出的方法思路大于模型，思路我们可以借鉴，模型就不具有优势了。</p>
<h1 id="Enriching-Word-Vectors-with-Subword-Information"><a href="#Enriching-Word-Vectors-with-Subword-Information" class="headerlink" title="Enriching Word Vectors with Subword Information"></a><a href="http://120.52.73.80/arxiv.org/pdf/1607.04606v1.pdf" target="_blank" rel="external">Enriching Word Vectors with Subword Information</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>Facebook AI Research</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>Word embedding, morphological, character n-gram</p>
<h2 id="来源-2"><a href="#来源-2" class="headerlink" title="来源"></a>来源</h2><p>arXiv, 201607</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>如何解决word2vec方法中罕见词效果不佳的问题，以及如何提升词形态丰富语言的性能？</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>word2vec在词汇建模方面产生了巨大的贡献，然而其依赖于大量的文本数据进行学习，如果一个word出现次数较少那么学到的vector质量也不理想。针对这一问题作者提出使用subword信息来弥补这一问题，简单来说就是通过词缀的vector来表示词。比如unofficial是个低频词，其数据量不足以训练出高质量的vector，但是可以通过un+official这两个高频的词缀学习到不错的vector。</p>
<p>方法上，本文沿用了word2vec的skip-gram模型，主要区别体现在特征上。word2vec使用word作为最基本的单位，即通过中心词预测其上下文中的其他词汇。而subword model使用字母n-gram作为单位，本文n取值为3~6。这样每个词汇就可以表示成一串字母n-gram，一个词的embedding表示为其所有n-gram的和。这样我们训练也从用中心词的embedding预测目标词，转变成用中心词的n-gram embedding预测目标词。</p>
<p>实验分为三个部分，分别是（1）计算两个词之间的语义相似度，与人类标注的相似度进行相关性比较；（2）与word2vec一样的词类比实验；（3）与其他考虑morphology的方法比较。结果是本文方法在语言形态丰富的语言（土耳其语，法语等）及小数据集上表现优异，与预期一致。</p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>源码公布在Facebook的fastText项目中： <a href="https://github.com/facebookresearch/fastText" target="_blank" rel="external">https://github.com/facebookresearch/fastText</a></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>利用语言形态学来改进nlp的研究源远流长，本文提及的许多关于character-level和morphology的有趣工作值得参考。</p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>文章中提出的思路对于morphologically rich languages（例如土耳其语，词缀的使用极为普遍而有趣）来说十分有意义。词缀作为字母与单词之间的中层单位，本身具有一定的语义信息。通过充分利用这种中层语义来表征罕见词汇，直观上讲思路十分合理，也是应用了compositionality的思想。</p>
<p>利用形态学改进word embedding的工作十分丰富，但中文NLP似乎很难利用这一思路。其实个人感觉中文中也有类似于词缀的单位，比如偏旁部首等等，只不过不像使用字母系统的语言那样容易处理。期待今后也有闪光的工作出现在中文环境中。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>从Word2Vec到FastText，从word representation到sentence classification，Tomas Mikolov的工作影响了很多人。虽然有个别模型和实验结果曾遭受质疑，但终究瑕不掩瑜。word2vec对NLP的研究起到了极大地推动作用，其实不仅仅是在NLP领域中，在其他很多领域中都可以看到word2vec的思想和作用，也正是从word2vec开始，这个世界变得都被vector化了，person2vec，sentence2vec，paragraph2vec，anything2vec，world2vec。</p>
<p>以上为本期Paperweekly的主要内容，感谢memray、zhkun、gcyydxf、jell四位同学的整理。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"><br>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-10T19:38:13.000Z"><a href="/2016/09/10/cs-CL-weekly-2016-09-05-2016-09-09/">2016-09-10</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/10/cs-CL-weekly-2016-09-05-2016-09-09/">cs.CL weekly 2016.09.05-2016.09.09</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本周（2016.09.05-2016.09.09）质量较高的arXiv cs.CL的paper如下：<br>（点击标题可看原文）</p>
<h1 id="Convolutional-Neural-Networks-for-Text-Categorization-Shallow-Word-level-vs-Deep-Character-level"><a href="#Convolutional-Neural-Networks-for-Text-Categorization-Shallow-Word-level-vs-Deep-Character-level" class="headerlink" title="Convolutional Neural Networks for Text Categorization: Shallow Word-level vs. Deep Character-level"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.00718v1.pdf" target="_blank" rel="external">Convolutional Neural Networks for Text Categorization: Shallow Word-level vs. Deep Character-level</a></h1><p>张潼老师的文章，通过实验对比了shallow word-level CNN（本文工作）和deep char-level CNN模型在而文本分类任务上的表现，结论是本文工作又快又准。</p>
<p>（这篇文章对于选择char-level还是word-level做文本分类非常有指导意义）</p>
<h1 id="Skipping-Word-A-Character-Sequential-Representation-based-Framework-for-Question-Answering"><a href="#Skipping-Word-A-Character-Sequential-Representation-based-Framework-for-Question-Answering" class="headerlink" title="Skipping Word: A Character-Sequential Representation based Framework for Question Answering"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.00565v1.pdf" target="_blank" rel="external">Skipping Word: A Character-Sequential Representation based Framework for Question Answering</a></h1><p>本文用char-level CNN模型来做句子表示，然后进行question和answer之间的相关匹配学习，CIKM2016 short paper accepted。</p>
<h1 id="End-to-End-Reinforcement-Learning-of-Dialogue-Agents-for-Information-Access"><a href="#End-to-End-Reinforcement-Learning-of-Dialogue-Agents-for-Information-Access" class="headerlink" title="End-to-End Reinforcement Learning of Dialogue Agents for Information Access"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.00777v1.pdf" target="_blank" rel="external">End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a></h1><p>本文是微软研究软邓力老师的文章，构建了一种从知识图谱中形成response的聊天机器人KB-InfoBot，并且提出了一种端到端的增强学习训练方案。</p>
<p>（本文对于构建一个端到端的KB + task-oriented chatbot非常有启发和指导意义）</p>
<h1 id="Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks"><a href="#Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks" class="headerlink" title="Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.01462v1.pdf" target="_blank" rel="external">Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks</a></h1><p>本文提出一种模型，将intent detection、slot filling和language modeling融合在一起进行学习，用于解决对话系统中的SLU task。本文是SIGDIAL 2016 paper。</p>
<p>用到的数据集在Dropbox有一份<a href="http://t.cn/Rcbcpfl" target="_blank" rel="external">copy</a></p>
<h1 id="Attention-Based-Recurrent-Neural-Network-Models-for-Joint-Intent-Detection-and-Slot-Filling"><a href="#Attention-Based-Recurrent-Neural-Network-Models-for-Joint-Intent-Detection-and-Slot-Filling" class="headerlink" title="Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.01454v1.pdf" target="_blank" rel="external">Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling</a></h1><p>和上一篇paper是同一个作者，解决的是同一个问题。将RNN换成了attention-based RNN，被另外一个会议录取。(有点灌水的意思)</p>
<h1 id="Ask-the-GRU-Multi-task-Learning-for-Deep-Text-Recommendations"><a href="#Ask-the-GRU-Multi-task-Learning-for-Deep-Text-Recommendations" class="headerlink" title="Ask the GRU: Multi-task Learning for Deep Text Recommendations"></a><a href="http://120.52.73.77/arxiv.org/pdf/1609.02116v1.pdf" target="_blank" rel="external">Ask the GRU: Multi-task Learning for Deep Text Recommendations</a></h1><p>本文提出了用端到端的解决方案来做paper的推荐任务，用GRU将文本序列（标题、摘要等）encode到一个latent vector中。并且通过多任务学习来完成内容推荐和条目预测两个task，取得了不错的效果。</p>
<p>以下内容为arXiv外的<b>优质内容</b>：</p>
<h1 id="Discriminative-Methods-for-Statistical-Spoken-Dialogue-Systems"><a href="#Discriminative-Methods-for-Statistical-Spoken-Dialogue-Systems" class="headerlink" title="Discriminative Methods for Statistical Spoken Dialogue Systems"></a><a href="http://www.matthen.com/research/papers/Discriminative_Methods_for_Statistical_Spoken_Dialogue_Systems_Matthew_Henderson_PhD_Thesis.pdf" target="_blank" rel="external">Discriminative Methods for Statistical Spoken Dialogue Systems</a></h1><p>剑桥大学Spoken Dialogue System组毕业的Matthew Henderson博士，师从于Steve Young教授，研究领域是对话系统中的Dialogue State Tracking，主要特色是用transfer learning来解决discriminative model的扩展性和通用性。</p>
<p>如果你对chatbot感兴趣，强烈建议好好研读一下这篇博士论文。</p>
<h1 id="CONNECTING-IMAGES-AND-NATURAL-LANGUAGE"><a href="#CONNECTING-IMAGES-AND-NATURAL-LANGUAGE" class="headerlink" title="CONNECTING IMAGES AND NATURAL LANGUAGE"></a><a href="http://cs.stanford.edu/people/karpathy/main.pdf" target="_blank" rel="external">CONNECTING IMAGES AND NATURAL LANGUAGE</a></h1><p>斯坦福大学Feifei Li的博士生Andrej Karpathy的PhD thesis，Karpathy维护着几个非常流行的开源代码库，并且有着一个影响力非常大的博客。名师出高徒，这篇博士博士论文值得一看！</p>
<p>最近，他更新了一篇博客，谈论了一些自己对读博的思考和建议。 <a href="http://karpathy.github.io/2016/09/07/phd/" target="_blank" rel="external">A Survival Guide to a PhD</a></p>
<h1 id="Mendeley-Docs"><a href="#Mendeley-Docs" class="headerlink" title="Mendeley Docs"></a><a href="https://pan.baidu.com/share/link?shareid=317480&amp;uk=1594817379" target="_blank" rel="external">Mendeley Docs</a></h1><p>paper越看越多，一个优秀的paper管理工具就变得非常必要了，Mendeley是其中最优秀的代表之一。</p>
<p>Easily organize your papers, read &amp; annotate your PDFs, collaborate in private or open groups, and securely access your research from everywhere.</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly</p>
<p><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-09T19:48:42.000Z"><a href="/2016/09/09/PaperWeekly第四期/">2016-09-09</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/09/PaperWeekly第四期/">PaperWeekly第四期</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>2013年以来Deep mind团队相继在NIPS和Natures上发表了用深度增强（强化）学习玩Atari游戏，并取得良好的效果，随后Alpha go与李世乭的一战更使得深度增强学习家喻户晓。在游戏上取得了不错的成果后，深度增强学习也逐渐被引入NLP领域。本期介绍目前NLP领域较为热点的研究方向，基于强化学习的文本生成技术（NLG），共选择了三篇文章，分别为：</p>
<p>(1)《Generating Text with Deep Reinforcement Learning》<br>应用Deep Q-Network作为生成模型用于改善seq2seq模型</p>
<p>(2)    《Deep Reinforcement Learning for Dialogue Generation》<br>应用强化学习进行开放领域的文本生成任务，并对比了有监督的seq2seq加attention模型和基于最大互信息的模型</p>
<p>(3)《Hierarchical Reinforcement Learning for Adaptive Text Generation_lshowway》<br>以任务为导向的户内导航对话系统用分层强化学习进行文本生成</p>
<p>以下为三篇文章的主要信息：</p>
<h1 id="Generating-Text-with-Deep-Reinforcement-Learning"><a href="#Generating-Text-with-Deep-Reinforcement-Learning" class="headerlink" title="Generating Text with Deep Reinforcement Learning"></a><a href="http://120.52.73.76/arxiv.org/pdf/1510.09202v1.pdf" target="_blank" rel="external">Generating Text with Deep Reinforcement Learning</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Hongyu Guo</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>National Research Council Canada</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Reinforcement Learning、Seq2Seq、Text Generation</p>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>NIPS2015 Workshop (2015.10.30)</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>本文提出将Deep Q-Network作为生成模型用于改善seq2seq模型，将decoding修改为迭代式的过程，实验表明本模型具有更好的泛化性。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>对seq2seq模型改进的论文层出不穷，本文率先引入深度强化学习的思想，将DQN用于文本生成。对DQN还不了解的同学可以先阅读DeepMind的论文Playing Atari with Deep Reinforcement Learning。本文的模型如下：</p>
<p><img src="media/14734508069657.jpg" alt=""></p>
<p>如同一般的神经网络，我们也可以把DQN当做一个黑盒来使用。只需要准备好DQN需要的四个元素s(i),a(i),r(i),s(i+1)，分别代表i时刻下state,action,reword和i+1时刻的state。</p>
<p>对照上图我们把算法解剖分为4个步骤：</p>
<p>Step 1: 先是传统的seq2seq模型。通过LSTM先把输入序列encode为一个定长向量EnSen(i)，然后作为decode阶段的初始状态依次生成新的序列DeSen(i)（decoding search使用beam search算法来 expand next words）。经过第一步我们得到初始state：(EnSen(i), DeSen(i))和action集合：每个位置的hypotheses。</p>
<p>Step 2: 接下来从hypotheses（actions）中选择一个可以获得最大reward的单词（action）作为该位置新生成的词，用新单词来代替之前的旧词，于是生成新的state：(EnSen(i), DeSen(i+1))。</p>
<p>Step 3: 接着就是标准的DQN的部分，计算Loss函数并对其应用梯度下降。</p>
<p>Step 4: 回到Step 2，对得到的state继续迭代，每一次迭代都只生成一个新词来代替旧词，直到迭代次数达到设好的值（作者将次数定为句子长度的两倍，同学们可以思考一下理由）。</p>
<p>总结DQN所需的四个元素对应如下：<br>(1) i时刻下的state：(EnSen(i), DeSen(i))；<br>(2) i时刻下的action：beam search得到的每个位置的hypotheses；<br>(3) i时刻下的reword：target sentence和DeSen(i+1)的相似度（BLEU score）；<br>(4) i+1时刻下的state：(EnSen(i), DeSen(i+1))；</p>
<p>为了更好的提取句子的特征，作者在decode阶段使用了双向LSTM。同时还在reinforcement learning中加入attention机制，可以达到先decode比较简单的部分再处理困难部分的效果。最后在生成相似句子的实验中得到了比只用LSTM decoder效果更好的结论：</p>
<p><img src="media/14734509263452.jpg" alt=""></p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="media/14734510298695.jpg" alt=""></p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文的思想其实非常符合写作的一种情况，就像贾岛推敲的故事，回想小时候刚学习写句子时，也不能一次写好，总会不断对一些词语进行修改。Google DeepMind的文章《DRAW：A Recurrent Neural Network For Image》也和本文异曲同工：画画也不是一次画好，也要不断的完善。不同之处在于本文率先引入DQN做文本生成。在机器学习各个分支下，强化学习和人类与环境的交互方式非常相似，在许多领域开始初露头角，期待看到更多将强化学习结合语言模型的应用。</p>
<h1 id="Deep-Reinforcement-Learning-for-Dialogue-Generation"><a href="#Deep-Reinforcement-Learning-for-Dialogue-Generation" class="headerlink" title="Deep Reinforcement Learning for Dialogue Generation"></a><a href="http://120.52.73.76/arxiv.org/pdf/1606.01541v3.pdf" target="_blank" rel="external">Deep Reinforcement Learning for Dialogue Generation</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Jiwei Li, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, Dan Jurafsky</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>(1) Stanford University, Stanford, CA, USA<br>(2) Microsoft Research, Redmond, WA, USA<br>(3) Ohio State University, OH, USA</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>Reinforcement Learning、Seq2Seq、Text Generation</p>
<h2 id="来源-1"><a href="#来源-1" class="headerlink" title="来源"></a>来源</h2><p>arXiv.org(2016.06.25)</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>本文提出利用强化学习进行开放领域的文本生成任务，并对比了有监督的seq2seq加attention模型和基于最大互信息的模型</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>强化学习中的reward</p>
<p><img src="media/14734512073402.jpg" alt=""></p>
<p>易被响应（Ease of answering），不容易出现对话僵局，其中 S 是无意义回答合集，s是某一时刻的响应</p>
<p><img src="media/14734512278456.jpg" alt=""></p>
<p>信息流，若开辟新的话题，有利于对话的继续发展，隐层表示 hpi 和 hpi+1 的夹角余弦</p>
<p><img src="media/14734512443645.jpg" alt=""></p>
<p>语义连贯性，减少与对话无关问题的影响，其中，pseq2seq(a|pi,qi) 是由上一轮状态得到响应的概率，后一项是由当前产生响应通过网络生成之前的 qi 的概率。</p>
<p><img src="media/14734512828474.jpg" alt=""></p>
<p>最终的reward是对三者加权求和，系数分别为：0.25、0.25、0.5.</p>
<p>对比试验：<br>(1) 对话初始状态为一个SEQ2SEQ加attention的模型作为强化学习的初始状态。</p>
<p>(2) 在前面的基础上将最大互信息加入其中作为reward，对于一个给定的输入[pi,qi]，可以根据模型生成一个候选回答集合A。对于A中的每一个回答a,从预训练模型中得到的概率分布上可以计算出互信息的值 m(a,[pi,qi])。</p>
<p>(3) 将互信息训练过的模型作为初始模型，用策略梯度更新参数并加入课程学习策略，最终最多限定五轮对话。</p>
<p><img src="media/14734513584870.jpg" alt=""></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="media/14734513827800.jpg" alt=""></p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本文作者提出了一个强化学习框架，模拟两个agent让其自动对话训练神经网络SEQ2SEQ模型，将Encoder-Decoder模型和强化学习整合，从而能保证使对话轮数增加。文中使用的模型非常简洁，reward函数定义清晰，评价指标也较为科学，可以生成信息更为丰富、易于响应的对话系统。</p>
<h1 id="Hierarchical-Reinforcement-Learning-for-Adaptive-Text-Generation"><a href="#Hierarchical-Reinforcement-Learning-for-Adaptive-Text-Generation" class="headerlink" title="Hierarchical Reinforcement Learning for Adaptive Text Generation"></a><a href="http://www.aclweb.org/anthology/W10-4204" target="_blank" rel="external">Hierarchical Reinforcement Learning for Adaptive Text Generation</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Nina Dethlefs, Heriberto Cuay´ahuitl</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>University of Bremen, Germany</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>NLG, 分层强化学习, 文本生成, wayfinding</p>
<h2 id="来源-2"><a href="#来源-2" class="headerlink" title="来源"></a>来源</h2><p>国际自然语言生成会议INLG(2010)</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>在wayfinding（户内导航对话系统）领域利用分层强化学习进行文本生成。该方法的目标是对wayfinding的NLG任务整合进行优化，并在模拟系统中验证该方法的有效性。</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>本文任务在wayfinding中的NLG任务有多个，且各个任务之间并非独立。从而提出应该根据用户类型，导航距离， 环境条件等作出不同的导航策略，介绍了分层强化学习。</p>
<p>文章将户内导航对话系统的文本生成问题分为四块：</p>
<p>(1) Content Selection：给不熟悉环境的用户的导航要比熟悉环境的用户的导航更细致<br>(2) Text Structure：根据导航距离以及用户熟悉环境程度给予不同类型的导航，如大白话的，以fisrt， second…表达或者示意性的。<br>(3) Referring Expression Generation：一间房间可以叫“A203”，也可以叫“办公室”或者“小白楼”<br>(4) Surface Realisation：往前走可以用“go”也可以用“walk”等。</p>
<p>强化学习示意图如下，分层强化学习的思想与强化学习类似，但在强化学习的基础上加上层次，不同层次的模型处理不同层次的问题。<br><img src="media/14734516131737.jpg" alt=""></p>
<p>agent根据当前状态，执行动作a与环境交互，之后环境产生一个新的状态s并返回给agent一个奖赏r（可正可负），强化学习的目标函数便是使agent获得奖赏r最大。</p>
<p>分层增强学习包含L个层，每层N个模型，如Figure 1是有15个agents的hierarchy，其中不同的agent负责不同的层次。</p>
<p><img src="media/14734516802648.jpg" alt=""></p>
<p>每个agent定义为半马尔科夫决策过程，可以表示成一个四元组</p>
<p><img src="media/14734517382304.jpg" alt=""></p>
<p>分别为状态集，动作集，转换函数，奖励函数。</p>
<p>奖励函数表示agent在时间t状态s是执行动作a转换到新的状态s’所获得的奖励。半马尔科夫的目标是找到policy π*，</p>
<p><img src="media/14734524023811.jpg" alt=""></p>
<p>使得在从当前状态转换到新的状态获得的累计奖励最多。</p>
<p>本文使用两种奖励函数，一种着重在 interaction length， 另一种着重在alignment and variation之间的平衡（具体公式可见论文）。</p>
<p>本文是在模拟环境中进行试验，其中模拟环境包括user type（熟悉环境，不熟悉环境）， information need（高，低），length of the current route（短，中长，长），next action to perform（转，直走），current focus of attention（继续走，关注标识）。baseline为为部分agent随机选择action，即不考虑用户类型，导航距离等因素。经与baseline比较，效果较好。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>词性标注工具：<a href="http://nlp.stanford.edu/software/tagger.shtml" target="_blank" rel="external">http://nlp.stanford.edu/software/tagger.shtml</a></p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>将来的工作：将分层强化学习应用于其他NLG任务<br>不足之处：实验是在模拟环境下进行的，未来应该在真实环境进行评估。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这三篇文章皆是强化学习在NLP领域的应用，第一篇主要侧重点在于应用DQN进行文本生成，并用BLUE指标进行评价，对比传统的LSTM-decoder和加入DQN之后的结果；第二篇文章侧重点在于虚拟两个Agent，在传统Seq2Seq的基础上加入强化学习从而使得聊天能够持续下去；第三篇文章侧重点在于任务驱动的对话系统应用分层强化学习，针对不同情况进行分层处理。</p>
<p>以上为本期Paperweekly的主要内容，感谢lshowway、美好时光海苔、Tonya三位同学的整理。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-03T17:02:40.000Z"><a href="/2016/09/03/cs-CL-weekly-2016-08-29-2016-09-02/">2016-09-03</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/03/cs-CL-weekly-2016-08-29-2016-09-02/">cs.CL weekly 2016.08.29-2016.09.02</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本周（2016.08.29-2016.09.02）质量较高的arXiv cs.CL的paper如下：<br>（点击标题可看原文）</p>
<h1 id="Abstractive-Text-Summarization-Using-Sequence-to-Sequence-RNNs-and-Beyond"><a href="#Abstractive-Text-Summarization-Using-Sequence-to-Sequence-RNNs-and-Beyond" class="headerlink" title="Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond"></a><a href="http://120.52.73.75/arxiv.org/pdf/1602.06023v5.pdf" target="_blank" rel="external">Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond</a></h1><p>一篇老文的update，seq2seq+attention的机制来解决abstractive text summarization，针对文本摘要的关键问题在基础模型中增加了对关键词、词句层次性和低频词的处理。</p>
<h1 id="Machine-Comprehension-Using-Match-LSTM-and-Answer-Pointer"><a href="#Machine-Comprehension-Using-Match-LSTM-and-Answer-Pointer" class="headerlink" title="Machine Comprehension Using Match-LSTM and Answer Pointer"></a><a href="http://120.52.73.76/arxiv.org/pdf/1608.07905v1.pdf" target="_blank" rel="external">Machine Comprehension Using Match-LSTM and Answer Pointer</a></h1><p>本文基于Match-LSTM和Answer Pointer两个模型在Stanford Question Answering Dataset (SQuAD)上得到了state-of-the-art的结果。 </p>
<h1 id="Measuring-Machine-Intelligence-Through-Visual-Question-Answering"><a href="#Measuring-Machine-Intelligence-Through-Visual-Question-Answering" class="headerlink" title="Measuring Machine Intelligence Through Visual Question Answering"></a><a href="http://120.52.73.75/arxiv.org/pdf/1608.08716v1.pdf" target="_blank" rel="external">Measuring Machine Intelligence Through Visual Question Answering</a></h1><p>本文指出了image caption作为评测AI效果的任务存在的缺陷，同时提出用visual QA作为评测任务更加有效，并且给出了一个大型Visual QA的数据集。数据集地址：www.visualqa.org.</p>
<h1 id="How-Much-is-131-Million-Dollars-Putting-Numbers-in-Perspective-with-Compositional-Descriptions"><a href="#How-Much-is-131-Million-Dollars-Putting-Numbers-in-Perspective-with-Compositional-Descriptions" class="headerlink" title="How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.00070v1.pdf" target="_blank" rel="external">How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions</a></h1><p>文章提出了一个好玩的任务，以一个统计数字作为上下文来生成一段简短的描述，描述的内容是一种带有这个数字的观点。整个过程分为两步：公式的构建和观点的生成。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-1-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -1-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ），每天会发布arXiv cs.CL高质量paper和简评。<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-01T21:58:14.000Z"><a href="/2016/09/01/PaperWeekly-第三期/">2016-09-01</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/01/PaperWeekly-第三期/">PaperWeekly 第三期</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>历经半个月时间终于发布了新一期PaperWeekly，大家久等了。在这个半个月里，PaperWeekly发生了一些明显的变化。维护和运营从我一个人变成了一个十人左右的团队来一起做，小伙伴们来自全球各地，颠倒着黑夜和白天进行沟通。团队中的每个人都有一颗热爱知识和分享知识的心，都认为分享是一种美德，是一种付出，更是一种回报。可能我们不完美，但我们相信我们正在追求完美的路上坚定地走着。</p>
<p>有了更多的同学加入，PaperWeekly会更加多元化，不再受限于我个人感兴趣的方向和阅读、写作习惯。PaperWeekly会坚持每周发布一期文章，每一期的文章尽量围绕同一个topic展开，在微信公众号、官方微博和知乎专栏会同步更新，除了这一篇文章，我们还会坚持在微博上提供一个新的服务，cs.CL daily，帮助大家过滤掉arXiv cs.CL上比较水的paper，留下质量高的paper，并且用简评的方式分享在微博上，每周末会更新一篇cs.CL weekly出来，将一周值得读的cs.CL paper汇总发布。</p>
<p>PaperWeekly组织了一个高质量的NLP讨论群，只要有你相关的问题，群里的高手会第一时间站出来解答或者讨论你的问题，有的时候会给出一些开源code和相关的paper，提问者、讨论者和潜水者都会有很大的收获。分享paper导读的意义在于讨论，大家一起来讨论，才能更加充分地吸收paper里的营养，这也是我为什么组织一个讨论群的原因。</p>
<p>寒暄的话就说到这里，本期分享的topic是ACL 2016，一共10篇文章，涉及的内容包括：Logic Form、NMT、Summarization、QA、Chatbot等。</p>
<h1 id="Sentence-Rewriting-for-Semantic-Parsing"><a href="#Sentence-Rewriting-for-Semantic-Parsing" class="headerlink" title="Sentence Rewriting for Semantic Parsing"></a><a href="http://aclweb.org/anthology/P/P16/P16-1073.pdf" target="_blank" rel="external">Sentence Rewriting for Semantic Parsing</a></h1><h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Semantic Parsing、Sentence Rewriting</p>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>语义分析的表现形式是将自然语言（natural language）转化成逻辑形式（logic form）。因语言表达多样性的问题导致两者间存在mismatch problem。</p>
<h2 id="文章思路"><a href="#文章思路" class="headerlink" title="文章思路"></a>文章思路</h2><p>先给出一个语义分析的例子：</p>
<p><img src="media/14727920453411.jpg" alt=""></p>
<p>给句子换个表达（How many people live in Berlin?），对应的逻辑形式就变得复杂很多(count(λx.person(x)∧live(x,Berlin)))。</p>
<p>作者认为，原句子和逻辑形式之间存在的结构不匹配导致了语义分析的困难，而结构不匹配的核心是词汇的不匹配。作者率先提出先把句子重写再转成目标逻辑形式的语义分析方案，如下图：</p>
<p><img src="media/14727921250895.jpg" alt=""></p>
<p>针对词汇不匹配问题的两种情况分别给出基于字典和基于模板两种方法。</p>
<p>1）问题一：1-N mismatch<br>是指一个单词（word）对应一个复合的逻辑形式（compound formula）。</p>
<p>例如daughter对应 child ∩ female。但在开放域的知识体系下，制定这些规则十分困难。于是作者提出将句子中的常用名词替换为字典（Wiktionary）中的解释，比如先把刚才的daughter转换为female child，接着再转换为逻辑形式child ∩ female就十分自然了。</p>
<p>2）问题二：N-1 mismatch<br>是指将复杂的自然语言表达对应为单个逻辑表达。</p>
<p>例如将How many people live in Berlin?转化为λx.population(Berlin,x)的分析过程中，How many people live in被对应为逻辑式常量population。如同问题一，这样的规则实在过多，作者的思路是将复杂的表达式转化为简单的形式。</p>
<p>沿用之前的句子来了解算法流程。</p>
<p><img src="media/14727921375652.jpg" alt=""></p>
<p>Step 1 替换实体生成候选template，例如得到模板how many people live in #y。<br>Step 2 检索template pairs来替换模板，例如找到(a：how many people live in #y, b：what is the population of #y)的模板对，于是将b作为新模板，<br>Step 3 把实体替换回去得到容易生成逻辑形式的what is the population of Berlin。 </p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="media/14727925154995.jpg" alt=""></p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>如今深度学习在自然语言处理领域大红大紫，也给语义分析的方法带来更多的思考。比如ACL2016另外一篇文章Language to Logical Form with Neural Attention，就把语义分析转换为seq2seq问题，进而使用深度学习的方法来解决。如果我们把词向量这样的表示形式比喻为粗糙的连结主义，那么逻辑表达就好比精细的形式主义。两者各有优势，希望以后会有更多结合两种思想的工作出现。</p>
<h1 id="Language-to-Logical-Form-with-Neural-Attention"><a href="#Language-to-Logical-Form-with-Neural-Attention" class="headerlink" title="Language to Logical Form with Neural Attention"></a><a href="http://aclweb.org/anthology/P/P16/P16-1004.pdf" target="_blank" rel="external">Language to Logical Form with Neural Attention</a></h1><h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>Logical Forms, Sequence to Sequence</p>
<h2 id="来源-1"><a href="#来源-1" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>如何把自然语言转化成Structured Logical Forms？</p>
<h2 id="文章思路-1"><a href="#文章思路-1" class="headerlink" title="文章思路"></a>文章思路</h2><p><img src="media/14727925632141.jpg" alt=""></p>
<p>模型总体是一个encoder-decoder架构，input sequence首先通过LSTM encoder转化成一个vector，然后这个vector通过LSTM decoder被转化成Logical Forms。在decode过程中用到了一个attention layer去获取context信息。</p>
<p><img src="media/14727705332596.jpg" alt=""></p>
<p>和encoder-decoder模型类似，作者提出了一种hierarchical decoder。与普通的decoder不同，首先，decode之后的sequence中存在一个特殊字符<n>代表nonterminal。在nonterminal的基础上，decoder可以继续进行下一个layer的decoding。每一次decoding的输入不仅包含current hidden state,还包含这一个parent nonterminal的hidden state。</n></p>
<p><img src="media/14727925854664.jpg" alt=""></p>
<p>作者还使用了一种attention机制，在构建current hidden state的时候将hidden state与所有encoder中的hidden state进行对比，给每一个encoder hidden state一个weight。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>代码：<a href="https://github.com/donglixp/lang2logic" target="_blank" rel="external">https://github.com/donglixp/lang2logic</a><br>Jobs和GEO数据集：<a href="http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf" target="_blank" rel="external">http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf</a></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>之前的大部分工作都采用一些parsing models，string-to-tree transformation rules，文中没有提到之前有人采用seq2seq/deep learning的方法。本文中使用的seq2seq方法主要来自Kalchbrenner, Blunsom, Cho, Sutskever 在machine translation中提出的模型。</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本文解决的是一个非常有趣的问题，将自然语言转换成结构化的Logical Forms。试想如果此模型能够很好的解决这个问题，那么将来的各种query language甚至programming languages都可以由自然语言转换而成。</p>
<h1 id="Neural-Summarization-by-Extracting-Sentences-and-Words"><a href="#Neural-Summarization-by-Extracting-Sentences-and-Words" class="headerlink" title="Neural Summarization by Extracting Sentences and Words"></a><a href="http://aclweb.org/anthology/P/P16/P16-1046.pdf" target="_blank" rel="external">Neural Summarization by Extracting Sentences and Words</a></h1><h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>Summarization、Hierarchical Document Encoder、Attention-based Extractor</p>
<h2 id="来源-2"><a href="#来源-2" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>如何使用数据驱动的方法来做提取式摘要？</p>
<h2 id="文章思路-2"><a href="#文章思路-2" class="headerlink" title="文章思路"></a>文章思路</h2><p>本文针对的任务分为sentence和word两个level的summarization。sentence level是一个序列标签问题，每个句子有0或1两个标签，为1表示需要提取该句作为总结。而word level则是一个限定词典规模下的生成问题，词典规模限定为原文档中所有出现的词。</p>
<p>使用的模型也比较有特点，首先在encoder端将document分为word和sentence来encode，word使用CNN encode得到句子表示，接着将句子表示输入RNN得到encoder端隐藏层状态。从word到sentence的encode体现了本文的hierarchical document encoder的概念。</p>
<p><img src="media/14727709292807.jpg" alt=""></p>
<p>在decoder端根据任务的不同使用不同网络结构，sentence任务就是一个简单的有监督下二分类问题，使用RNN网络结构更新decoder端隐藏层状态， decoder端隐藏层状态串联encoder端隐藏层状态后接入一个MLP层再接sigmoid激活函数得到句子是否被extract的概率。</p>
<p>word任务则是使用传统的attention-based的方法来计算每个词的概率。但要注意本文的计算的attention不是word-level attention，而是encoder端sentence-level attention。</p>
<p><img src="media/14727709957739.jpg" alt=""></p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>数据集：<a href="http://homepages.inf.ed.ac.uk/s1537177/resources.html" target="_blank" rel="external">http://homepages.inf.ed.ac.uk/s1537177/resources.html</a></p>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><p>之前大多数extractive methods都基于human-engineered特征来给句子建模，通常会对每个句子计算一个分数，然后再使用诸如binary classifiers，hidden Markov模型，graph-based算法或integer linear programming等方法来选择句子构成总结。</p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>之前基于data-driven的seq2seq模型在abstractive summarization任务上大放异彩，本文提出了使用类似的模型来解决extractive summarization任务。不过针对的依旧是single-document summarization任务，未来需要将工作拓展至multi-document summarization任务上。</p>
<h1 id="Sequence-to-Sequence-Generation-for-Spoken-Dialogue-via-Deep-Syntax-Trees-and-Strings"><a href="#Sequence-to-Sequence-Generation-for-Spoken-Dialogue-via-Deep-Syntax-Trees-and-Strings" class="headerlink" title="Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings"></a><a href="http://aclweb.org/anthology/P/P16/P16-2008.pdf" target="_blank" rel="external">Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings</a></h1><h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>Sequence to Sequence、Natural Language Generation、Chatbot</p>
<h2 id="来源-3"><a href="#来源-3" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h2><p>如何通过小规模、未对齐语料生成对话语句？</p>
<h2 id="文章思路-3"><a href="#文章思路-3" class="headerlink" title="文章思路"></a>文章思路</h2><p>作者介绍了两个模型:</p>
<p>1、通过DA(diglogue acts)生成句法依赖树，再利用external surface realizer，生成语句。（如下图）</p>
<p><img src="media/14727713613292.jpg" alt=""></p>
<p>2、将两部分结合起来，直接生成语句。步骤如下：</p>
<p>Step 1 将DA(dialogue acts)中的每个slot(表示特定信息)表示成三元组(DA type,slot,value)并结合(下图左)</p>
<p><img src="media/14727714252636.jpg" alt=""></p>
<p>Step 2 基于seq2seq generation technique生出语句或句法依赖树。<br>Step 3 结合beam search和n-best列表重排序（list reranker）以减少输出中的不相关信息。</p>
<h2 id="资源-2"><a href="#资源-2" class="headerlink" title="资源"></a>资源</h2><p>代码: <a href="https://github.com/UFAL-DSG/tgen" target="_blank" rel="external">https://github.com/UFAL-DSG/tgen</a></p>
<h2 id="相关工作-3"><a href="#相关工作-3" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="media/14727926849132.jpg" alt=""></p>
<h2 id="简评-3"><a href="#简评-3" class="headerlink" title="简评"></a>简评</h2><p>该方法基于广泛使用的seq2seq模型，可以用未对齐的MR对(pair of  meaning representation)和句子进行训练，且只要小规模的语料就可以有很好的效果。生成器可以从数据中学会slot的对齐和值，生成流利的domain style)语句，虽然语义错误还是很频繁，但还是取得了不错的成绩。</p>
<h1 id="On-line-Active-Reward-Learning-for-Policy-Optimisation-in-Spoken-Dialogue-Systems"><a href="#On-line-Active-Reward-Learning-for-Policy-Optimisation-in-Spoken-Dialogue-Systems" class="headerlink" title="On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems"></a><a href="http://aclweb.org/anthology/P/P16/P16-1230.pdf" target="_blank" rel="external">On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems</a></h1><h2 id="关键词-4"><a href="#关键词-4" class="headerlink" title="关键词"></a>关键词</h2><p>Dialogue System、Reinforcement Learning、Online Active Reward Learning</p>
<h2 id="来源-4"><a href="#来源-4" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-4"><a href="#问题-4" class="headerlink" title="问题"></a>问题</h2><p>文章提出一种在线学习框架，通过高斯过程分类模型进行主动学习，训练对话策略和奖励模型，减少数据标注的花费和用户反馈中的噪声。</p>
<h2 id="文章思路-4"><a href="#文章思路-4" class="headerlink" title="文章思路"></a>文章思路</h2><p><img src="media/14727785168705.jpg" alt=""></p>
<p>框架分为三部分：对话策略、对话嵌入函数、用户反馈主动奖励模型。</p>
<p>无监督学习输入为双向LSTM，通过Encoder-Decoder模型表征用户意图，将对话的成功与否看做高斯过程的一个二元分类问题，当模型对当前结果不能评判时，主动学习，通过reward模型决定是否询问用户反馈，当模型不确定时，生成增强信号来训练策略。</p>
<h2 id="资源-3"><a href="#资源-3" class="headerlink" title="资源"></a>资源</h2><p>数据集：<a href="http://camdial.org/~mh521/dstc/" target="_blank" rel="external">http://camdial.org/~mh521/dstc/</a></p>
<h2 id="相关工作-4"><a href="#相关工作-4" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、之前的工作有用任务完成度和对话持续情况做Reward，但任务完成度不好衡量<br>2、用协同过滤表征用户偏好<br>3、用逆强化学习从行为中推出reward</p>
<h2 id="简评-4"><a href="#简评-4" class="headerlink" title="简评"></a>简评</h2><p>用lSTM Encoder-Decoder表征用户意图，无需大规模标注语料和构建用户模拟器来进行训练，在较小的训练语料中取得了不错的效果，率先实现了在真实场景中的应用。但Reward函数只关心对话任务是否成功，模型过于简单。</p>
<h1 id="Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models"><a href="#Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models" class="headerlink" title="Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models"></a><a href="http://aclweb.org/anthology/P/P16/P16-1100.pdf" target="_blank" rel="external">Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models</a></h1><h2 id="关键词-5"><a href="#关键词-5" class="headerlink" title="关键词"></a>关键词</h2><p>Neural Machine Translation、UNK Words</p>
<h2 id="来源-5"><a href="#来源-5" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-5"><a href="#问题-5" class="headerlink" title="问题"></a>问题</h2><p>如何解决机器翻译中的未登录词问题？</p>
<h2 id="文章思路-5"><a href="#文章思路-5" class="headerlink" title="文章思路"></a>文章思路</h2><p>文章提出了一个混合（层次）模型。该模型由两部分组成，分别为：<br>a. 传统的基于词（word level）的seq2seq模型；<br>b. 基于字母级别（character level）的LSTM模型，由一个将字母encode成单词的encoder和一个根据状态生成低频词的decoder组成。其中a部分负责进行翻译，b部分负责处理低频词（unk）。</p>
<p><img src="media/14727723863213.jpg" alt=""></p>
<p>具体地，a部分的encoder遇到unk时，会使用character level对该低频词进行encode，并使用encode出的representation作为输入。而decoder遇到unk时，会利用attention机制将当前上下文和LSTM状态初始化character level decoder。此处的初始化采用的是文章提出的separate path模式，即利用一个MLP作为character level decoder的初始化网络。值得注意的是此处word level decoder仍会选择用<unk>作为下一步的输入。</unk></p>
<h2 id="相关工作-5"><a href="#相关工作-5" class="headerlink" title="相关工作"></a>相关工作</h2><p>Unk问题属于NMT中长期存在问题。目前多是采取后处理的方法。今年ACL有两篇paper，分别是李航老师实验室的copynet和Bengio实验室的pointing the unknown words，但对机器翻译任务参考意义有限。<br>另外一种思路则是加大词典，比较知名工作有On Using Very Large Target Vocabulary for Neural Machine Translation。此外该工作还借鉴了Jiwei Li的hierarchical auto encoder。</p>
<h2 id="简评-5"><a href="#简评-5" class="headerlink" title="简评"></a>简评</h2><p>文章思路新颖且简单明了。因为NMT中存在unk的问题，作者直接利用character level RNN来生成一个词替代unk。该工作对拼音文字有一定意义，对中日韩文的参考意义有限。</p>
<h1 id="Pointing-the-Unknown-Words"><a href="#Pointing-the-Unknown-Words" class="headerlink" title="Pointing the Unknown Words"></a><a href="http://aclweb.org/anthology/P/P16/P16-1014.pdf" target="_blank" rel="external">Pointing the Unknown Words</a></h1><h2 id="关键词-6"><a href="#关键词-6" class="headerlink" title="关键词"></a>关键词</h2><p>Neural Machine Translation、UNK Words</p>
<h2 id="来源-6"><a href="#来源-6" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-6"><a href="#问题-6" class="headerlink" title="问题"></a>问题</h2><p>如何解决机器翻译中的未登录词问题？</p>
<h2 id="文章思路-6"><a href="#文章思路-6" class="headerlink" title="文章思路"></a>文章思路</h2><p>作者在有注意力的机器翻译模型上增加了一个开关来判断和是否复制原文。</p>
<p>1、Attention-based机器翻译模型<br><img src="media/14727726836085.jpg" alt=""><br>经典的attention model这里不再赘述。</p>
<p>2、Pointer Softmax模型<br><img src="media/14727727829495.jpg" alt=""></p>
<p>两个问题有待解决解决：<br>a. 是否进行copy？<br>b. copy的位置在哪？</p>
<p>先说第二个问题，作者先引入shortlist softmax和location softmax。前者来确定要从shortlist中选取哪一个单词作为输出，后者确定在哪个位置要进行copy操作。</p>
<p>再看第一个问题，作者引入一个二值变量（可以想象为一个开关）来选择使用shortlist softmax还是location softmax。当值为1的时候不进行copy操作，使用shortlist softmax来从shortlist中选一个词作为输出。当值为0的时候进行copy操作，使用location softmax，将原文的词直接copy到指定位置。</p>
<h2 id="资源-4"><a href="#资源-4" class="headerlink" title="资源"></a>资源</h2><p>代码：<a href="https://github.com/caglar/pointer_softmax" target="_blank" rel="external">https://github.com/caglar/pointer_softmax</a></p>
<h2 id="简评-6"><a href="#简评-6" class="headerlink" title="简评"></a>简评</h2><p>本文的想法很有趣，直接从原文照抄罕见词和未知词很符合日常生活中人类的处理方法。从文中实验结果来看，该模型有一定的提升效果。注意力模型的提出与对人类行为的观察密不可分，而copy机制也是从生活中提炼出来的一种有效模型，我们可以借鉴的是从人类解决问题的具体方式中进行总结和归纳不失为一种有效的解决方案。</p>
<h1 id="Harnessing-Deep-Neural-Networks-with-Logic-Rules"><a href="#Harnessing-Deep-Neural-Networks-with-Logic-Rules" class="headerlink" title="Harnessing Deep Neural Networks with Logic Rules"></a><a href="http://aclweb.org/anthology/P/P16/P16-1228.pdf" target="_blank" rel="external">Harnessing Deep Neural Networks with Logic Rules</a></h1><h2 id="关键词-7"><a href="#关键词-7" class="headerlink" title="关键词"></a>关键词</h2><p>CNN、RNN、First-order Logic, Iterative Distillation Method</p>
<h2 id="来源-7"><a href="#来源-7" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-7"><a href="#问题-7" class="headerlink" title="问题"></a>问题</h2><p>如何将深度学习与逻辑规则结合使用？</p>
<h2 id="文章思路-7"><a href="#文章思路-7" class="headerlink" title="文章思路"></a>文章思路</h2><p><img src="media/14727734980533.png" alt=""></p>
<p>系统在构建正常神经网络(student)的同时，构建了一个基于逻辑规则的训练网络(teacher)。整个网络的目标还是优化神经网络的参数变量 θ，因为新的目标损失函数结合了二者的损失，通过这种方式，教师网络的逻辑信息就能够被转移到神经网络的θ上，从而加强神经网络的性能。 在这种结构里逻辑规则是用于辅助的可选项，通过调整权重，系统可以偏向某个网络。这种模型可以将监督学习扩展到无监督学习，比如图示中，无标记的数据通过教师子网之后提取有用信息，也可以用来训练监督学习的神经网络。</p>
<p>1、训练过程</p>
<p>假设输入数据为x, y。student神经网络的参数变量是θ, 输出层是softmax，对输入xn，输出预测概率分布σ(xn)。对teacher网络，在第ｔ次迭代中基于逻辑规则的预测结果表示为sn(t)，那么新的优化目标变成了</p>
<p><img src="media/14727735567000.png" alt=""></p>
<p>可以看出来自教师网络的反馈作为regularization加到了目标函数里，通过这种方式两个网络的信息就结合在了一起。注意教师网络在每次训练迭代中都要构建，因此整个过程被称之为iterative knowledge distillation.</p>
<p>2、教师网络</p>
<p>教师网络使用软逻辑(soft logic)来编码first-order logic的信息。soft logic在[0,1]之间的连续取值，而不是二元值{0, 1}。逻辑运算也用max, min, sum代替原来的与或非。</p>
<p>神经网络数学模型为pθ(y|x) 教师网络数学模型假设为q(y|x)。我们实际上是用基于逻辑规则的教师网络来模拟神经网络输出，因此我们希望能找到一个最优的q，使得输入尽可能满足逻辑规则的要求，同时q要尽可能接近pθ。详细推导可以参见原文，最后的优化结果就是</p>
<p><img src="media/14727736225787.png" alt=""></p>
<p>λl 是每个规则的自信度(confidence)，而rl, gl 是某个规则应用于某一输入时的逻辑结果，介于0,1之间。可以看到自信度比较高的规则可以使输入更容易通过规则。</p>
<p>3、应用</p>
<p>a. 基于CNN的情感分析<br>b. 基于BLSTM-CNN的NER任务</p>
<h2 id="相关工作-6"><a href="#相关工作-6" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、Neural-symbolic systems (Garcez et al., 2012) 从给定的规则构建推理网络<br>2、(Collobert 2011)， 利用领域知识domain knowledge提取额外特征，增强原始数据<br>3、Knowledge distillation (Hinton et al., 2015) (Bucilu et al. 2006)<br>4、Posterior regularization (PR) method (Ganchev et al., 2010)</p>
<h2 id="简评-7"><a href="#简评-7" class="headerlink" title="简评"></a>简评</h2><p>创新点在于将逻辑规则与神经网络结合，可以利用人已知的知识去引导机器学习。当数据量不足的，或者对数据进行补充时，可以将人类的知识用逻辑语言表达出来，然后通过本文提出的框架进行增强训练。本文的两个例子中都提到只用了少量规则，优化的结果虽然显示要比当前其他模型好，但是没有大幅度的提高。需要进一步验证如果使用更多的规则，能不能大幅度提高准确率。</p>
<h1 id="Easy-Questions-First-A-Case-Study-on-Curriculum-Learning-for-Question-Answering"><a href="#Easy-Questions-First-A-Case-Study-on-Curriculum-Learning-for-Question-Answering" class="headerlink" title="Easy Questions First? A Case Study on Curriculum Learning for Question Answering"></a><a href="http://aclweb.org/anthology/P/P16/P16-1043.pdf" target="_blank" rel="external">Easy Questions First? A Case Study on Curriculum Learning for Question Answering</a></h1><h2 id="关键词-8"><a href="#关键词-8" class="headerlink" title="关键词"></a>关键词</h2><p>Curriculum Learning、Self-paced Learning、Question Answering</p>
<h2 id="来源-8"><a href="#来源-8" class="headerlink" title="来源"></a>来源</h2><p>ACL2016</p>
<h2 id="问题-8"><a href="#问题-8" class="headerlink" title="问题"></a>问题</h2><p>文章讨论了Curriculum Learning在NLP领域, 尤其是在QA task里应用的可行性。</p>
<h2 id="文章思路-8"><a href="#文章思路-8" class="headerlink" title="文章思路"></a>文章思路</h2><p>文章首先对QA类型的task给出了比较general的定义: 我们可以把QA问题看做是一个经验风险最小化(ERM)问题, 我们需要最小化:</p>
<p><img src="media/14727739856834.jpg" alt=""></p>
<p>其中是a正确答案, f是给定背景知识以及问题, 模型选择出的最佳答案,Ω是regularizer. </p>
<p>之后, 作者对于Curriculum Learning, 尤其是Self-paced Learning做了介绍, 并且将其引入QA task, 进而将之前的ERM问题变为:</p>
<p><img src="media/14727740344982.jpg" alt=""></p>
<p>其中v是对问题进行采样时候的权值, g是self-paced regularizer, 其中λ代表’age’, 或者说’pace’. 训练初期, 模型趋向于对简单的问题进行训练, 而随着’age’的增加, 模型越来越多地加入更复杂的问题一起训练。</p>
<p>文章给出并分析了四种流行的self-paced regularizer如Table 1:</p>
<p><img src="media/14727745747996.jpg" alt=""></p>
<p>之后提出了7种新的heuristics:</p>
<p>1)    Greedy Optimal (GO): 将已有的Q和一系列新的Q一起训练, 选回答正确并且loss最低的。<br>2)    Change in Objective (CiO): 将已有的Q和一系列新的Q一起训练, 选择令loss改变最小的。<br>3)    Mini-max (M2 ): 当某个新的Q与其loss最大的一个candidate answer配对时, loss最小的. (通俗地讲, 就是最差情况都没有那么糟糕的一个)。<br>4)    Expected Change in Objective (ECiO): 只拿新的Q训练, 和之前的loss改变最小的. (相比于第二种的将已有的Q和新Q一起训练)。<br>5)    Change in Objective-Expected Change in Objective (CiO - ECiO): 2)和4)的值最接近的, 按照作者的意思, 这个值反应了model见到某个新Q时surprise的程度。<br>6)    Correctly Answered (CA): 将一系列新Q在当前model上测试, 选择用最小的loss正确回答的。<br>7)    Farthest from Decision Boundary (FfDB): 只用在latent structural SVMs上, 选择答案与decision boundary最远的一个新Q。</p>
<h2 id="资源-5"><a href="#资源-5" class="headerlink" title="资源"></a>资源</h2><p>MCTest: <a href="http://research.microsoft.com/en-us/um/redmond/projects/mctest/" target="_blank" rel="external">http://research.microsoft.com/en-us/um/redmond/projects/mctest/</a><br>Science Textbook: <a href="http://http://www.ck12.org/" target="_blank" rel="external">http://http://www.ck12.org/</a><br>Science question answering: <a href="http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip" target="_blank" rel="external">http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip</a><br>Simple English Wikipedia: <a href="https://dumps.wikimedia.org/simplewiki/20151102/" target="_blank" rel="external">https://dumps.wikimedia.org/simplewiki/20151102/</a><br>QANTA: <a href="https://cs.umd.edu/~miyyer/qblearn/" target="_blank" rel="external">https://cs.umd.edu/~miyyer/qblearn/</a></p>
<h2 id="相关工作-7"><a href="#相关工作-7" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、Curriculum Learning: </p>
<p>早在1958年[1], 就有认知科学的相关学者意识到, 对于人类学习过程, 相对于提供随机的知识,由浅及深的地给予有计划的训练样本, 可以得到更好的效果. 之后这一Curriculum Learning的想法也被引入到机器学习中[2], 其中Self-paced learning (SPL)[3][4][5]是比较常用的方法。 </p>
<p>2、QA:</p>
<p>Jurafsky和Martin[6]对于QA系列问题有一个非常好的叙述, 而这篇文章突出讨论Curriculum Learning在non-convex的QA模型上的应用, 着重介绍了基于配对的模型[7][8][9]和基于深度学习的模型[10][11].<br>基于配对的模型将每一个问题和问题附带的多个备选答案组成若干个QA对, 我们称之为假设, 然后在给定相关文章的情况下, 寻找有最可能是正确的一个假设作为答案. 基于深度学习的模型可以使用依赖关系树结构的递归神经网络, 对句子level的QA模型的结果取平均[10]; 也可以用RNN构建”长期”存储器, 通过学习对存储器进行读/写操作, 模拟一个动态的知识构建过程[11]。</p>
<h2 id="简评-8"><a href="#简评-8" class="headerlink" title="简评"></a>简评</h2><p>在QA task中引入Curriculum Learning旨在在训练过程中, 启发式地对于提供给模型的数据出现的顺序进行一些调整, 从而让模型从简单的, 易于学习的样本开始, 随着模型对数据的表述愈加成熟, 逐渐加入更复杂的样本. 理想状况下这会指导模型从得到一个普通的local minima, 变成得到一个”更”好的local minima, 进而利用全部数据得到一个”更更”好的local minima。</p>
<p>通常来说, 我们给予模型的heuristic并不一定能够真正帮助模型, 因为通常我们都在猜测数据以及模型的latent representation是什么, 但是这篇文章通过了一系列的实验验证, 本文阐述的heuristic确实可以帮助QA model获得更好的准确率. 这证明了引导模型由浅及深的这种思路是可行的, 我们也许可以思考一些更复杂的heuristic, 或者将其应用到其他的一些NLP tasks。</p>
<p>然而本文给出的大部分heuristic在新问题的选择上都需要比较大的时间复杂度, 对于类似MCTest这种总共只有660个文章的小型数据集来说还算比较现实, 但是对于更大更长的数据集(比如CNN数据集, 38万个文章, 很多文章都超过了一千五百个单词, 而且备选答案数量也远超MCTest的四个)时, 就显得不那么轻松了. 最简单的Attention Sum Reader[1] 在CNN数据集上, 每个epoch都需要10个多小时, 就更别说其他基于AS Reader的模型了。</p>
<p>总体来说, 相对于实用性, 这篇文章更多在于提供了一种新的思路, 也就是把Curriculum Learning相关的概念应用到QA乃至于其他NLP task中, 非常值得思考, 因此是一篇非常值得阅读的文章。</p>
<h1 id="The-LAMBADA-dataset-Word-prediction-requiring-a-broad-discourse-context"><a href="#The-LAMBADA-dataset-Word-prediction-requiring-a-broad-discourse-context" class="headerlink" title="The LAMBADA dataset:Word prediction requiring a broad discourse context"></a><a href="http://aclweb.org/anthology/P/P16/P16-1144.pdf" target="_blank" rel="external">The LAMBADA dataset:Word prediction requiring a broad discourse context</a></h1><h2 id="关键词-9"><a href="#关键词-9" class="headerlink" title="关键词"></a>关键词</h2><p>Machine Reading Comprehension、Dataset</p>
<h2 id="来源-9"><a href="#来源-9" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-9"><a href="#问题-9" class="headerlink" title="问题"></a>问题</h2><p>构建了一个难度更大的机器阅读理解数据集。</p>
<h2 id="构建思路"><a href="#构建思路" class="headerlink" title="构建思路"></a>构建思路</h2><p>以Book Corpus的小说作为数据源，构建了10222个passages，每个passage包括平均4.6句话的context和相邻着的一句target，定义的任务是通过理解context来预测target中最后一个词，平均每个passage包括约75个tokens。其中，超过80%的passage context中包括了target中需要预测的词，48%的target words是专有名词（proper nouns），37%的词是一般名词（common nouns），约7.7%的是动词。这里，专有名词和一般名词是最难猜出来的，动词有一定的概率可以不需要context，而直接从target sentence利用语言模型猜出来。</p>
<p>在处理原始数据时，作者做了一层过滤，将容易从target sentence中直接猜出target word的passages统统丢掉，将剩下的部分放在众包网站上进行人工筛选，筛选的过程比较长，目的是让留在数据集中的数据有下面的效果：通过分析passage的context可以给出正确的target word，而如果只是给定target sentence的话，是猜不出正确的target word。</p>
<h2 id="资源-6"><a href="#资源-6" class="headerlink" title="资源"></a>资源</h2><p>本文数据集Lambada dataset: <a href="http://clic.cimec.unitn.it/lambada/" target="_blank" rel="external">http://clic.cimec.unitn.it/lambada/</a><br>众包网站Crowdflower: <a href="http://www.crowdflower.com/" target="_blank" rel="external">http://www.crowdflower.com/</a><br>原始数据集Book Corpus: <a href="http://www.cs.toronto.edu/~mbweb/" target="_blank" rel="external">http://www.cs.toronto.edu/~mbweb/</a><br>CNN/Daily Mail dataset: <a href="https://github.com/deepmind/rc-data" target="_blank" rel="external">https://github.com/deepmind/rc-data</a><br>CBT dataset: <a href="http://fb.ai/babi/" target="_blank" rel="external">http://fb.ai/babi/</a><br>MSRCC dataset:  <a href="https://www.microsoft.com/en-us/research/publication/the-microsoft-research-sentence-completion-challenge/" target="_blank" rel="external">https://www.microsoft.com/en-us/research/publication/the-microsoft-research-sentence-completion-challenge/</a></p>
<h2 id="相关数据集"><a href="#相关数据集" class="headerlink" title="相关数据集"></a>相关数据集</h2><p><img src="media/1.png" alt="1"></p>
<h2 id="简评-9"><a href="#简评-9" class="headerlink" title="简评"></a>简评</h2><p>大型数据集是深度学习技术发展的重要基础，数据集的质量和难度也直接关系着模型的质量和实用性。机器阅读理解的数据集有很多，包括中文和英文的数据集，每一个的构建都会带来模型的创新，随着难度不断增加，对模型也提出了更高的要求。本文在构建数据集过程中为了保证任务的难度所采取的方法是值得借鉴的。</p>
<h1 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h1><p>本期的10篇文章由以下同学完成：</p>
<p>苏辉、Xiaoyu、胡小明、赵越、周青宇、韩晓伟、Eric Yuan、Zewei Chu、tonya、张俊。</p>
<p>感谢大家地辛勤付出。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/14727755950469.jpg" alt=""></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-26T16:20:19.000Z"><a href="/2016/08/26/cs-CL-weekly-2016-08-22-2016-08-26/">2016-08-26</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/26/cs-CL-weekly-2016-08-22-2016-08-26/">cs.CL weekly 2016.08.22-2016.08.26</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>这个栏目是将一周内arxiv cs.CL刷出的好文进行一个简单的汇总，并配有一句话总结，旨在帮助大家过滤掉cs.CL上的水文，并且为PaperWeekly团队选文提供高质量paper。</p>
<h1 id="Learning-Word-Embeddings-from-Intrinsic-and-Extrinsic-Views"><a href="#Learning-Word-Embeddings-from-Intrinsic-and-Extrinsic-Views" class="headerlink" title="Learning Word Embeddings from Intrinsic and Extrinsic Views"></a><a href="http://120.52.73.78/arxiv.org/pdf/1608.05852v1.pdf" target="_blank" rel="external">Learning Word Embeddings from Intrinsic and Extrinsic Views</a></h1><p>本文提出了一种依靠intrinsic (descriptive) and extrinsic (contextual) information来学习词向量的方法，有效解决了传统方法中对低频词学习存在的问题。 </p>
<h1 id="Context-Gates-for-Neural-Machine-Translation"><a href="#Context-Gates-for-Neural-Machine-Translation" class="headerlink" title="Context Gates for Neural Machine Translation"></a><a href="http://120.52.73.78/arxiv.org/pdf/1608.06043v1.pdf" target="_blank" rel="external">Context Gates for Neural Machine Translation</a></h1><p>本文提出了一种context gate来动态地控制机器翻译中source、target context对word generation的影响，实验证明在BLEU指标下比attention-based的方法提高了2.3。</p>
<h1 id="Topic-Sensitive-Neural-Headline-Generation"><a href="#Topic-Sensitive-Neural-Headline-Generation" class="headerlink" title="Topic Sensitive Neural Headline Generation"></a><a href="http://120.52.73.80/arxiv.org/pdf/1608.05777v1.pdf" target="_blank" rel="external">Topic Sensitive Neural Headline Generation</a></h1><p>本文针对传统模型中忽略topical similarities和differences of documents的问题，提出了一种新方案，先将documents按照topics分类，每一类中的pattern比较接近，然后再做sentence level summary，得到了更好的效果。 </p>
<h1 id="Towards-Machine-Comprehension-of-Spoken-Content-Initial-TOEFL-Listening-Comprehension-Test-by-Machine"><a href="#Towards-Machine-Comprehension-of-Spoken-Content-Initial-TOEFL-Listening-Comprehension-Test-by-Machine" class="headerlink" title="Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine"></a><a href="http://120.52.73.77/arxiv.org/pdf/1608.06378v1.pdf" target="_blank" rel="external">Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine</a></h1><p>本文以托福听力题作为数据集，尝试对多媒体信息进行理解。听力问题是听完一段话，理解之后，进行4选1，而不是之前常见的cloze-style理解任务。</p>
<h1 id="A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems"><a href="#A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems" class="headerlink" title="A Context-aware Natural Language Generator for Dialogue Systems"></a><a href="http://120.52.73.79/arxiv.org/pdf/1608.07076v1.pdf" target="_blank" rel="external">A Context-aware Natural Language Generator for Dialogue Systems</a></h1><p>本文的模型是一种端到端的模型，根据上下文和用户说话的方式来生成对话。是一篇SIGDIAL 2016 short paper。配套的代码已发布于<a href="https://github.com/UFAL-DSG/tgen" target="_blank" rel="external">Github</a></p>
<h1 id="About"><a href="#About" class="headerlink" title="About"></a>About</h1><p>对NLP高质量原创内容和讨论感兴趣的你，赶快来关注：</p>
<p>1、PaperWeekly<a href="http://weibo.com/2678093863/" target="_blank" rel="external">官方微博</a></p>
<p>2、PaperWeekly官方微信</p>
<p><img src="media/qrcode_for_gh_5138cebd4585_430.jpg" alt="qrcode_for_gh_5138cebd4585_430"></p>
<p>3、PaperWeekly<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">知乎专栏</a></p>
<p>4、PaperWeekly微信交流群（+微信zhangjun168305入群）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-22T02:05:52.000Z"><a href="/2016/08/21/从api-ai工作原理来看构建简单场景chatbot的一般方法/">2016-08-21</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/21/从api-ai工作原理来看构建简单场景chatbot的一般方法/">从api.ai工作原理来看构建简单场景chatbot的一般方法</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>chatbot无疑是当前非常火的一个研究领域和产品方向，简单地可以分为两类，开放域bot和封闭域bot，开放域bot倾向于解决所有的事情，而封闭域bot倾向于解决某一个细分领域中的事情，旨在用AI技术提高效率，提高生产力。现阶段的开放域bot我个人感觉更像是多个常用封闭域bot的叠加，当用户发起一个请求，系统会判断出属于哪个细分领域，然后转到相应的程序中去执行并给出反馈，顺着这个逻辑来看，研究简单场景下的chatbot是个重要的基础工作，这类研究或者产品的质量直接决定了复杂场景或者开放域bot的质量。当然逗乐型的bot并不属于本文讨论的范围。<br><img src="media/1.png" alt="1"><br>图片来自paper <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" target="_blank" rel="external">The Dialog State Tracking Challenge Series- A Review</a></p>
<p>chatbot是场交互革命，也是一个多技术融合的平台。上图给出了构建一个chatbot需要具备的组件，简单地说chatbot = NLU(Natural Language Understanding) + NLG(Natural Language Generation).(本文只关注NLP相关的技术，对语音识别并无讨论)</p>
<p>对于封闭域的chatbot，NLU的工作就是DST(Dialog State Tracker)，用户给出输入之后，系统可以给出下面的形式作为state：</p>
<p><b>Act(Slot=Value)</b></p>
<p>Act表示用户行为的类型，比如请求、查询、打招呼等等；Slot表示用户输入中包含的某种Act下的Entity，比如查询酒店的位置、价格这些实体；Value是指Slot中Entity对应的值，比如位置在北边，价格在500-800之间等等。每一句话中可能包括多个Act-Slot-Value对，chatbot需要做的事情就是准确地识别出Act，并且抽取出相应的Slot和Value。</p>
<p>紧接着是NLG的部分，前几天在<a href="http://rsarxiv.github.io/2016/08/16/PaperWeekly-%E7%AC%AC%E4%BA%8C%E6%9C%9F/">PaperWeekly第二期</a>中分享了三篇paper，其中两篇正是研究基于DST的NLG问题。</p>
<p>本文首先从<a href="api.ai">api.ai</a>这家企业提供的服务说起，通过研究其提供的封闭域bot构建技术，来提炼构建简单场景chatbot的一般方法，为构建复杂场景或者找出现有chatbot存在的技术问题和面临的技术难点打下基础。</p>
<h1 id="api-ai"><a href="#api-ai" class="headerlink" title="api.ai"></a>api.ai</h1><h2 id="api-ai公司介绍"><a href="#api-ai公司介绍" class="headerlink" title="api.ai公司介绍"></a>api.ai公司介绍</h2><blockquote>
<p>Api.ai provides developers and companies with the advanced tools they need to build conversational user interfaces for apps and hardware devices.</p>
</blockquote>
<p>这家公司是一家典型的B2D公司，提供了一些工具帮助开发者轻松地开发一款bot，并且可以轻松地发布到各种message平台上。商业模式也非常简单，免费用户有一定次数的调用权限，需要大量调用的话，则付费购买，不同的权限有不同的价格，该公司也提供高级定制化服务。</p>
<p>api.ai公司成立于2010年（数据来自<a href="https://www.crunchbase.com/organization/api-ai#/entity" target="_blank" rel="external">CrunchBase</a>），其早期业务不清楚，但可以从提供的服务中推断出早期攒了大量的用户数据，而且涉及的领域非常多，比如：<br><img src="media/2.png" alt="2"></p>
<p>每个领域都有一个知识库，如果你要开发某个常用领域内的chatbot，那么这个知识库将会非常有用。</p>
<h2 id="重要概念和工作原理"><a href="#重要概念和工作原理" class="headerlink" title="重要概念和工作原理"></a>重要概念和工作原理</h2><h3 id="重要概念"><a href="#重要概念" class="headerlink" title="重要概念"></a>重要概念</h3><p>1、Agents。这个是一个对外接口，与其他应用程序或你的app进行整合的部分。如下图：<br><img src="media/3.png" alt="3"></p>
<p>2、Entities。这里的实体和引言中提到的Slot类似，是指某个特定领域内的实体，是一类东西的抽象概括，比如HotelName这一实体，对应着很多的酒店名字，凯宾斯基、如家等等。有Entity，就一定有value，chatbot中重要的一步正是从user input中抽取出对应预先设定好entity的value，是一个典型的Named Entity Recognition任务。</p>
<p>这里经典的NER任务是识别出user input中的person、time、place等等几个基本元素，api.ai将这些常见的entity定义为system级的，即默认提供了训练好的识别器，当然不仅仅限于这几类基本的；而特定领域知识库的重要作用也正是在于识别该领域内的entity。除了system level的NER之外，需要developer自定义一些entity，比如菜名，而且要给定具体的菜名和相似的表达作为samples进行训练。</p>
<p>3、Intents。这个相当于是从user input到chatbot执行某个action之间的一个映射关系，用户输入一句话之后，chatbot就可以理解其意图，是在打招呼，还是查询，还是做些别的事情。这部分api.ai提供了训练器，但是需要developer定义一些标注好的examples，标注的形式如下：<br><img src="media/4.png" alt="4"></p>
<p>这里用户输入是book a ticket to Los Angeles on Monday，所谓标注包括两个level，一个是entity标注，一个是intent标注，前一个是为了训练NER工具，后一个是为了识别intent。这里因为LA是地名，Monday是时间，所以都会被api.ai的系统自动标注出来。</p>
<p>4、Actions。这个是由intents进行trigger的，actions就和引言中的Act类似，是一个具体的动作，比如说查询，但执行动作的时候一般都要带上具体的参数value，用户输入：“三里屯最近的阿迪达斯店在什么位置？”，chatbot首先会提取出place-&gt;三里屯，query-&gt;阿迪达斯店，然后转换为json丢给后台的查询服务，查询到结果后给出答案。这里的value抽取其实就是第二个概念提到的entity value。</p>
<p>5、Contexts。上下文是一个非常重要但却解决不是很好的点，api.ai提供的方式是自定义一些context condition，当condition满足时，自动trigger出context关联内容template，然后filling slots，生成response。</p>
<h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>以RSarXiv chatbot为例，简单介绍下工作原理。<br>（注：RSarXiv是我之前写的一个arxiv paper推荐系统）</p>
<p>step 1 自定义Entity，这里我定义了两个entities，一个是keywords和subject。keywords是为search功能提供value，而subject是为update new papers功能提供value。<br><img src="media/5.png" alt="5"><br>定义好subject entity之后，我给出了几个examples，同时也包括其synonyms，keywords entity类似。</p>
<p>step 2  自定义Intents，这里我定义了两个Intents，分别是update和search。下图是update的examples，是我自定义的几个例子。api.ai会根据我定义好的entity进行自动标注，比如cs.CL，today是系统默认的entity所以也进行了自动标注。自动标注是为了后台的机器学习算法对标注好的examples进行学习，以提高chatbot的NLU准确率。<br><img src="media/6.png" alt="6"></p>
<p>接下来，我需要定义下Actions，如下图：<br><img src="media/7.png" alt="7"><br>Action被称为update，必须包含的参数是subject，也就是我们上面讲到的一个entity，date参数并不是必须的。所以，这里如果用户的input被识别出是update intents的话，就必须包括subject参数，否则chatbot会trigger一个response，类似“请用户输入subject”这样的话。</p>
<p>step 3 简单测试，在界面的右侧有一个console，用来测试当前chatbot的效果，我输入update cs.CL，得到下面的效果：<br><img src="media/8.png" alt="8"><br>chatbot识别出Intent是Update，Action是update，Parameter是date和subject，并且subject的值是cs.CL，下面的Show JSON是api.ai为developer生成的，用来与developer自己的web service进行数据交换。</p>
<p>step 4 训练。训练包括两个部分，一是训练NER，二是训练Intent Classification。训练器是api.ai提供的，但是标注数据是developer自己提供的，当然训练数据越多，标注越准，分类器的准确率就越高，chatbot的NLU准确率越高。至于训练方法，docs中没有细说，我简单猜测一下，NER可以当做Sequence Labeling任务，和Intent Recognition类似，都可以看作是多分类问题，不管是传统的分类方法还是当下流行的deep learning方法都能得到不错的准确率。随着user logs的增多，训练数据会越来越多，chatbot通过学习就会变得越来越“聪明”。但这里有个问题，training data越多，需要标注或者修改标注的数据就会越多，也是一个麻烦事儿。</p>
<p>step 5 整合、发布。api.ai支持的平台非常多，包括当下流行的message平台，还有各种操作系统平台。在message平台上提供了一键整合的功能，在操作系统上提供了SDK。这里我用了slack平台，api.ai打通了和slack的接口，也提供了webhook，连接了我之前写好的web service，只需要按照它给定的消息接口进行定义即可。</p>
<h3 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h3><p>目前RSarXiv只提供两个简单的功能，一个是update今天最新的arxiv paper，你可以通过show me new papers in cs.CL等类似的话来获取cs.CL这个领域中最新的paper；一个是search功能，你可以通过search LSTM等类似的话来获取包括LSTM这个关键词的paper。由于是一个测试用的demo，就没做什么复杂的功能。<br><img src="media/10.png" alt="10"></p>
<p>大家如果感兴趣的话，可以留言给我或者发邮件给我(mcgrady150318@gmail.com/mcgrady150318@163.com)，我邀请大家到这个slack team中。</p>
<h1 id="简单场景chatbot构建方法"><a href="#简单场景chatbot构建方法" class="headerlink" title="简单场景chatbot构建方法"></a>简单场景chatbot构建方法</h1><p>介绍了下api.ai提供的服务，下面简单地提炼一下。</p>
<p>chatbot = NLU + NLG</p>
<p>api.ai解决的重点问题是NLU的问题，NLU也是Dialogue State Tracker(DST)的核心和基础，而DST是chatbot的核心。这里的NLU包括两个问题：</p>
<p>1、从user inputs中识别出user intent和对应的action。</p>
<p>2、从user inputs中抽取出预先设定好的entity value，作为action的parameter。</p>
<p>NLG在api.ai这里基本上通过developer在Intent中设定response，当识别出是哪个intent之后，response自然就有了，最多空一些slot，用结果进行填充。如果developer选择了webhook，即需要从自定义的web service中给定response。如下图：<br><img src="media/9.png" alt="9"></p>
<p>跑了一个简单场景的chatbot demo之后，简单归纳下构建方法：</p>
<p>1、从特定任务中归纳出Intents、Actions、Entities。</p>
<p>2、分别编写Intents、Entities的examples，两类examples是做DST的基础，用来训练chatbot准确地识别user intents和entity parameters，至于算法，自己写也可以，用api.ai也可以。</p>
<p>3、做好DST之后，chatbot就知道用户的意图和相应的参数，丢给后台的web service去执行，并得到执行的结果，然后填充预先定义好的templates，生成response，返回给用户。</p>
<h1 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h1><p>简单场景的chatbot关键之处在于做好DST，有一个叫Dialogue State Tracking Challenge的比赛正式为了解决这个问题而举办的。我们说，封闭域的chatbot涉及两个方面，一是NLU，一是NLG，前者通过大量的examples来学习一个分类器和抽取器，得到Dialogue State，而后者根据Dialogue State，生成合适的response。</p>
<p>NLU不是一个简单的事情，尤其是标注大量的examples不是那么容易；NLG同样也不是一个好解决的问题，预先定义的template会让chatbot受限制于template的多少，手工痕迹太重，需要一种更牛的解决方案来代替。（其实挺多paper都在做这件事情，PaperWeekly也分享过几篇相关的paper，data driven的NLG方案同样需要大量的examples做训练。）</p>
<p>Context是个挺难的事情，现有的、成熟的解决方案仍是手工来定义条件，然后根据条件来trigger。我在想，能否构建一个动态的DST，可以是一张动态hash table，也可以是一个动态graph，记录着某一个user方方面面的状态，而不仅仅是某一轮对话中抽取出的信息，而是多轮对话中的信息，不仅在intent识别中可以用到context，在生成response时也可以用到，多轮对话和个性化对话都将不是什么问题了。或者，用现在流行的表示学习思维来想这个问题的话，也许context可以是一个分布式表示，user profile也是一个表示，NLG时以context distribution为condition来做generatation。</p>
<p>本文介绍了构建简单场景下chatbot的一般方法，用api.ai确实很容易做一个chatbot，而对于复杂场景，我觉得用api.ai来开发也没有太大问题，最费时的可能是构建context trigger。api.ai因为是面向developer的，所以对于普通的用户并不适合，但对于有一定经验的developer来说，使用起来就非常简单，提供的web界面也很好用，如果说chatbot是一个平台的话，那么api.ai正像是一个开发工具，提高了开发chatbot的效率，虽然NLG和context这两个问题可以做的更好，但整体来说降低了开发chatbot的门槛，是个很有意义和钱景的服务。</p>
<h1 id="PaperWeekly招人广告"><a href="#PaperWeekly招人广告" class="headerlink" title="PaperWeekly招人广告"></a>PaperWeekly招人广告</h1><p>PaperWeekly每周会分享N篇当下最流行、最有趣的NLP paper，旨在用最精炼的话说明白paper的贡献和创新。目前运营在公众号和知乎专栏两个平台上，现在的形式是每周分享一篇NLP Paper周报，偶尔也会写一些NLP相关的博客，由于本人精力和水平有限，现邀请各位对NLP技术、NLP Paper感兴趣的童鞋加入一同运营，在推进国内NLP技术发展的路上贡献一份自己的力量。</p>
<p>微信公众号：PaperWeekly</p>
<p><img src="media/qrcode.jpg" alt="qrcode"></p>
<p>知乎专栏：<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">PaperWeekly</a></p>
<p>微信交流群：</p>
<p><img src="media/paperweekly.jpg" alt="paperweekly"></p>
<p>群已满100人，无法扫码加群，大家加zhangjun168305，我拉大家入群。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-16T23:53:50.000Z"><a href="/2016/08/16/PaperWeekly-第二期/">2016-08-16</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/16/PaperWeekly-第二期/">PaperWeekly 第二期</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p><img src="media/1.png" alt="1"><br>图片来自paper <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" target="_blank" rel="external">The Dialog State Tracking Challenge Series- A Review</a></p>
<p>人机对话系统通常包括上面的几个部分，task-oriented chatbot重点关注的是DST和NLG问题，其中DST是核心问题，没有太多关注这个比赛，但个人理解DST的作用类似于一张user conversation logs状态表，记录着用户当前的状态，以订机票为例，这张表的key是预先设定好的slots，比如目的地、出发地、出发时间等等，与系统背后的业务数据表中的attributes相关联，不断地从user conversation中抽取相应的values来填充这个表格，或者将其定义为一个多分类任务，不断地从对话中判断这句话中包括哪些slots和values（这里的values是多个分类结果），当状态表中的信息存在空白时，bot会根据空白的slots来提问并获取values，直到获取到足够的slots，给出用户suggestion，或者进行相应的服务。</p>
<p>DST的问题解决之后，就是NLG的问题。传统的NLG采用rule-based或者template-based的方法，需要很多的手动设置，横向扩展性较差，维护成本高。最近流行的end-to-end方案很适合解决这个问题，给定用户的query，结合着当前DST，自动生成response，完全的data driven，不需要什么人工干预。</p>
<p>生成response除了rule-based和end-to-end的方法之外，工业界中更加常见的是retrieve-based的方法，即从庞大的example base中进行retrieve，一方面避免了NLG生成response时常遇到的grammatical问题，另一方面当前的IR技术很容易集成到此类bot系统中，降低了门槛。</p>
<p>本期的三篇paper中前两篇都是关于task-oriented bot的NLG问题，第三篇是在retrieve-based bot的每个细小环节中应用了deep learning技术，并且将外部的非结构化文本作为数据源，从中select responses。</p>
<h1 id="Semantically-Conditioned-LSTM-based-Natural-Language-Generation-for-Spoken-Dialogue-Systems"><a href="#Semantically-Conditioned-LSTM-based-Natural-Language-Generation-for-Spoken-Dialogue-Systems" class="headerlink" title="Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems"></a><a href="http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP199.pdf" target="_blank" rel="external">Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems</a></h1><h2 id="关键词：NLG、bot、自定义LSTM"><a href="#关键词：NLG、bot、自定义LSTM" class="headerlink" title="关键词：NLG、bot、自定义LSTM"></a>关键词：NLG、bot、自定义LSTM</h2><h2 id="来源：EMNLP-2015"><a href="#来源：EMNLP-2015" class="headerlink" title="来源：EMNLP 2015"></a>来源：EMNLP 2015</h2><h2 id="问题：task-oriented-bot-NLG问题，给定了user-query和DST，如何生成一个更好的response？"><a href="#问题：task-oriented-bot-NLG问题，给定了user-query和DST，如何生成一个更好的response？" class="headerlink" title="问题：task-oriented bot NLG问题，给定了user query和DST，如何生成一个更好的response？"></a>问题：task-oriented bot NLG问题，给定了user query和DST，如何生成一个更好的response？</h2><h2 id="方法："><a href="#方法：" class="headerlink" title="方法："></a>方法：</h2><p>首先定义了两个概念delexicalisation和lexicalisation，前一个的意思是将句子中的slot-value用特定的token来替换，像是一种抽象，比如用food来代替对话中的各种食物名称；后一个的意思是将句子中的特定token还原回具体的value。</p>
<p>本文最大的亮点在于将传统的LSTM重新定义，针对这个具体问题在LSTM cell部分中添加了一层，Dialogue Act Cell，通过gate机制来保留合适的信息，比如slot keywords，如下图：</p>
<p><img src="media/2.png" alt="2"></p>
<p>这一层cell更像是一个keyword detectors，整个NLG仍是采用encoder-decoder框架。</p>
<h2 id="评论："><a href="#评论：" class="headerlink" title="评论："></a>评论：</h2><p>这层Dialogue Act Cell的目的是确保在decoding部分，不会遗漏任何一个slot，所以专门增加了一层cell来encoding act、slot-value信息，在生成时作为context vector。我觉得model的这个设计与attention机制有一点类似，只是attention更加地平滑，对每个word都有一个weight，而不是本文中的gate，非0即1。整体来说，自定义的cell是一个很有启发性的思路，针对具体问题的特点，修改现有的cell结构，也许会起到非常关键的作用。</p>
<h1 id="Natural-Language-Generation-in-Dialogue-using-Lexicalized-and-Delexicalized-Data"><a href="#Natural-Language-Generation-in-Dialogue-using-Lexicalized-and-Delexicalized-Data" class="headerlink" title="Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data"></a><a href="http://101.110.118.75/128.84.21.199/pdf/1606.03632v1.pdf" target="_blank" rel="external">Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data</a></h1><h2 id="关键词：NLG、bot、自定义LSTM-1"><a href="#关键词：NLG、bot、自定义LSTM-1" class="headerlink" title="关键词：NLG、bot、自定义LSTM"></a>关键词：NLG、bot、自定义LSTM</h2><h2 id="来源：arXiv-2016-06-11-cs-CL"><a href="#来源：arXiv-2016-06-11-cs-CL" class="headerlink" title="来源：arXiv 2016.06.11 cs.CL"></a>来源：arXiv 2016.06.11 cs.CL</h2><h2 id="问题：task-oriented-bot-NLG问题，是第一篇的升级版。"><a href="#问题：task-oriented-bot-NLG问题，是第一篇的升级版。" class="headerlink" title="问题：task-oriented bot NLG问题，是第一篇的升级版。"></a>问题：task-oriented bot NLG问题，是第一篇的升级版。</h2><h2 id="方法：-1"><a href="#方法：-1" class="headerlink" title="方法："></a>方法：</h2><p>本文是针对第一篇文章进行的改进版，改进的地方在于不仅仅利用了delexicalisation进行训练，而且利用了lexicalisation数据，从而提高了准确率，基本的模型框架与第一篇文章类似，不同的在于输入的处理，就是dialogue act的表示，如下图：</p>
<p><img src="media/3.png" alt="3"></p>
<p>每一个act representation由两部分组成，一部分是act、slots的one-hot表示，与文章一类似的结构，另一部分是由value的每个word embedding组合而成。</p>
<p>task-oriented bot NLG存在的一个更加现实的问题是data规模太小，cover的features太少，生成质量不高，本文针对这一问题，用相似domain的、大量的reviews或者其他相关数据作为corpus预训练出一个效果不错的LM，在decoding部分采用预训练好的LM模型权重进行NLG。</p>
<h2 id="评论：-1"><a href="#评论：-1" class="headerlink" title="评论："></a>评论：</h2><p>本文中最值得借鉴的地方在于transfer learning，虽然DL效果很好，但实际应用中常常遇到data规模太小的问题，DL难以发挥作用，但如果从大量相似的domain data中学习一些表示模型，然后迁移到待解决的问题上，这是一件幸事，也就是人们常说的举一反三。混合大量的相似domain数据，会cover到更丰富的features，为DL提供了广阔的舞台。</p>
<h1 id="DocChat-An-Information-Retrieval-Approach-for-Chatbot-Engines-Using-Unstructured-Documents"><a href="#DocChat-An-Information-Retrieval-Approach-for-Chatbot-Engines-Using-Unstructured-Documents" class="headerlink" title="DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents"></a><a href="http://aclweb.org/anthology/P16-1049" target="_blank" rel="external">DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents</a></h1><h2 id="关键词：Retrieve-Based-Bot，Unstructured-Documents"><a href="#关键词：Retrieve-Based-Bot，Unstructured-Documents" class="headerlink" title="关键词：Retrieve-Based Bot，Unstructured Documents"></a>关键词：Retrieve-Based Bot，Unstructured Documents</h2><h2 id="来源：ACL-2016"><a href="#来源：ACL-2016" class="headerlink" title="来源：ACL 2016"></a>来源：ACL 2016</h2><h2 id="问题：如何从大量非结构化文本中select出合适的response返回给用户？"><a href="#问题：如何从大量非结构化文本中select出合适的response返回给用户？" class="headerlink" title="问题：如何从大量非结构化文本中select出合适的response返回给用户？"></a>问题：如何从大量非结构化文本中select出合适的response返回给用户？</h2><h2 id="方法：-2"><a href="#方法：-2" class="headerlink" title="方法："></a>方法：</h2><p>本文研究的问题是给定大量的非结构化的documents和用户的query，从中选择并返回一个满意的response，典型的IR问题，作者将解决方案分为三步：</p>
<p>1、response检索，根据query，从documents中找到合适的N句话作为候选。</p>
<p>2、response排序，将候选中的utterances进行排序。</p>
<p>本文大多数的工作在ranking model上，提出了7种level的features来对candidate进行打分，通过实验发现sentence-level feature最有区分度。</p>
<p>3、response触发，并不是一定可以从documents找到合适的response，所以最后添加一个分类器，来判断最优的response是否合适，合适则输出，不合适则输出空。</p>
<h2 id="评论：-2"><a href="#评论：-2" class="headerlink" title="评论："></a>评论：</h2><p>本文解决的问题思路比较简单，但中间用到了很多复杂的DL model，个人感觉有点杀鸡用牛刀。本文的思路更加适合informative式的query，并不适合娱乐和闲聊。但用外部知识，尤其是大量的非结构化的、可能还带有噪声的资源来提供response，是一个很不错的思路，弥补了只用training data或者很有限的examples存在的局限性问题，如果可以将两者进行结合，是一个非常好的实用方案。</p>
<h1 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h1><p>引起大家的讨论是一件挺难的事情，所以这一期不再提出问题。之前有同学问如何读paper，这里简单分享一个简单的tip，后续的每一期可能都会分享一个tip。</p>
<p>1、如果刚刚进入一个领域，建议读一些这个领域的survey或review类型的paper，这类型的paper基本上会将最近的方法归类进行总结，从一个较高的层次来解读每一篇paper的贡献和优缺点，对快速了解一个领域很有帮助。如果你关注的这个领域没有survey，那么恭喜你，说明你可能走到了前沿，用关键词去google一篇或者几篇相关的new paper，读Related Work那一节，相信你会有所收获。（注：这个方法是从清华大学刘知远博士那里学来的）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-16T16:06:36.000Z"><a href="/2016/08/16/pat-baby-and-bot/">2016-08-16</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/16/pat-baby-and-bot/">pet,baby and bot</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文的想法来源于某一天对家里狗子Hare一些行为以及身边两个不到3岁的小朋友一些聪明行为的观察和思考，然后将这些行为和思考与当前流行的bot联系一下，形成了本文的内容。</p>
<p>首先，从pet聊起。我家养了一只聪明的小泰迪狗，心眼特别多，会撒娇会打滚会安慰人，非常聪明，他叫Hare。Hare从两个月大到了家里，从开始什么都不会，通过一天天地训练，学会了走、跑、跳、吃饭、喝水、上厕所、坐下、握手和哭。因为他的外婆（我的丈母娘）每天都和他说很多话，教他认识很多东西，所以他可以轻松地分辨出哪个玩具叫什么名字，可以轻松地理解我们说的很多话，不只是一些口令。当我说出门不带他玩的话，他会非常悲伤、可怜地开始哭泣（真的和小孩子哭一模一样）；当我说带他出去的时候，他就会非常兴奋地上蹿下跳；当我说我要出门办事不可以带他的时候，他就乖乖坐在门口目送你走，不哭不闹。所以，我在想Hare应该不是简单地通过观察我们的脸色和语气来识别我们的情绪，他可能真的听得明白很多的话，但一定不是全部，因为他的知识很有限，对这个世界的认识也很有限。Hare的学习绝大多数是监督学习，通过一些正例和负例进行训练，大多数的训练用正例效果非常明显，唯独训练他上厕所，用了不少负例，让他吃了不少苦头，这也带来不少的好处，监督学习很花费时间，样本的量级很重要，通过大量的训练+激励让Hare养成了良好的习惯，成为了一只听话的pet。</p>
<p>我一直在思考一个问题，pet在听主人说话的时候，是听懂了某些他可以理解的关键词还是他确实听懂了整句话，到底是字面意思还是semantic level呢？我想他应该有一定的自主学习能力，做到举一反三可能很难，但举一反二还是有可能的，而不仅仅是从大量的examples中进行学习，确实能够理解一些简单的话，同一个意思的不同说法他都可以理解。科学的解释需要做些实验来研究，这里我有一些简单的解释，第一，他有大脑，虽然没有人类发达，但智商可以和5、6岁的孩子相媲美；第二，他的监督学习不仅仅是从query-response pairs这样的examples中进行，而是更多的维度，包括每一次action之后的激励reward，做对一次动作之后赢得一个奖励，做错了受到惩罚，他不仅仅从主人的语言中来理解意思，还会结合别的因素，比如语调、语境、前一个时刻他的状态等等，而且他可以看到主人的表情和动作，这些因素都可以抽象成一种context。Hare如果前一秒刚刚犯了低级错误，这一秒如果我拿一个零食的叫他过来来吃的话，他就会明白，这其中一定有诈，他一定不会过来，虽然我并没有表现出生气的样子。</p>
<p>pet的事情我们先聊到这里，接下来聊一聊baby的事情。</p>
<p>身边正好可以接触到两个不到三岁的小宝宝，一个男孩一个女孩，他们有很多聪明的行为都让我感到吃惊。先从小男孩说起，小男孩每次来一起吃饭的时候，都会给大家表演他的绝技——认车牌。走在路上，你随意指一辆车，他几乎可以不出错地说出这辆车是本田还是丰田、还是起亚，这是一个典型的有监督多分类学习任务，他的父母有意无意地教他认识各种各样的车，经过一定时间和example的积累，他不断地将准确率提升，可能大脑的发育和将deep learning模型不断地复杂化道理类似吧。学习的过程是积累知识的过程，小男孩慢慢地认识了越来越多的车子，当然这需要不断地教和学，但无疑他本身就是一个知识库（knowledge base），而且认识很多我都不认识的车子，所以当我问他那是什么车的时候，他总是能够给我一个不错的答案。</p>
<p>说完小男孩的事情，再聊一聊小女孩的事情。小女孩语言能力很强，可以说很多的话，而且很多话都非常的funny。基本上和小女孩聊天，就是一个有趣的问答过程，这里的问答不只是我问她答，还有她问我答。小女孩经常和我妈妈在一起，妈妈会教她认识各种东西，因为妈妈信基督教，会教她做祷告，保佑自己一生平安，所以说她不仅仅可以回答一些基本的认知问题，而且有自己的特殊技能，表演“祷告”，而且做的有模有样。她是个求知欲非常强的问题宝宝，她总是指着一个东西，然后开始问我，“这是个什么东西？”，她主动学习的欲望很强，这意味着她的知识库积累地很快。以上都是比较常规的，最值得思考的是她的创造力。她认识很多的动物，也知道怎么称呼这些动物，她根据家里每一个人的名字，起了相应的动物外号，这个不是谁教她的，是她自己说出来的东西；之前提到的祷告词中，原话应该是希望上帝可以赐给她一些聪明智慧，那天在给我们“表演”的时候说出来的是“给她弄一些聪明智慧”，我想这个“弄一些”一定是其他的地方学来的，但她迁移到了这个语境中，这个迁移能力是值得思考的。我们都说理解一个东西不算厉害，如果能够掌握或者控制一个东西才算真正的厉害，她如果只是简单地重复已经学会的知识，也并不稀奇，但她偶尔会有意地装糊涂，故意地说一些错的东西看你能不能识别出来她的错误，她对一些信息的掌握程度很高。</p>
<p>小盆友的创造力让人惊奇，有很多值得思考的地方，相比于pet来说，baby的学习能力更强，带给人的惊喜度更大。chatbot，一个热门的topic，一个大家每天都在谈论的东西，确实还有很长的路要走，太多的地方不能令人满意。</p>
<p>1、最简单的一问一答现在都没有做的很好，example-based和rule-based虽然可以work，但限制太大，前者被example所限制，而后者被rule所限制，而paper中近一段时间流行的所谓generative式的bot看起来好像非常智能，读过paper之后会发现仍是基于example统计的，不管多么牛的模型，都是从example中学习features，example的规模和类型都会严重制约model，而且在生成response时面临着连贯性和语言学的问题，这也是被诟病最多的地方，也就是为什么example-based retrieve式的方法仍是主流的原因。</p>
<p>2、bot应该像人一样具有学习能力，尤其是主动学习能力。现在的bot有self-taught的能力，通常比较被动，并不具备主动学习的意识和能力。bot公司宣传的学习能力也通常是指对log的挖掘，从中找到一些有用的东西存在知识库里，丰富现有的example base。bot可以试着多提一些question，而不仅仅是做answer，主动地学习一些东西。</p>
<p>3、对context的利用和分析还有很长的路要走，context有很多种，如果是纯粹的语言bot，那么就是user之前说过的话，user的情绪，user的意图等等，如果不仅仅是语言的话，正如前面在说pet时提到的，context可以包括图像、语调等等。考虑的东西越多，bot的回答质量就会越高。</p>
<p>4、前几天看了几家科技媒体对新一代微软小冰的报道，说实话丢出挺多概念的，仔细看了下是用增强学习的思路来做，和训练pet比较类似，用一个reward作为牵引，带着bot学习programmer希望bot学习的action。</p>
<p>5、人会举一反三，聪明的动物会举一反二，迁移能力很重要，bot学习过类似的东西，就应该可以做类似的事情，而不是每次都需要重新从头开始学习，如何将已经学习到的知识迁移到新的领域也是一个非常有意义的topic。</p>
<p>从pet到baby，再到bot，从动物到人类，再到机器人，有着难以跨越的鸿沟，但pet、baby的行为可以带来启发和思考，给目前仍停留在初步阶段的bot带来一丝春风，一丝希望。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-05T18:22:47.000Z"><a href="/2016/08/05/PaperWeekly-2016-08-05-第一期/">2016-08-05</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/05/PaperWeekly-2016-08-05-第一期/">PaperWeekly 2016.08.05 第一期</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>学术界和工业界的需求和关注点不同，学术界更加注重未知领域的探索和方法的创新，研究的问题比较抽象，而工业界更加关注实际问题，方法不管是否创新，只要能够解决问题就是好方法，所面对的问题比paper中提炼出的数学问题更加具体，需要处理的细节更多。</p>
<p>paper的水平也是良莠不齐，尤其是arxiv上刷出来的paper更是水平各异。但整体来说，读paper会带来很多的启发，可以跟踪学术界对某一类问题的研究进展，不断地更新技术。关注工业界技术的应用和产品的更迭，可以不断地提炼出新的需求、新的数学问题，从而促进学术地发展，两者其实关系非常紧密。</p>
<p>本周开始，将paperweekly进行改版，从之前的每天一篇paper，改为每周一篇，内容包括多篇paper，这些paper可能相关、也可能不那么相关，但会说清每篇paper解决的问题和解决的方法，旨在拓宽视野，带来启发。本期是改版后的第一期，形式会一直不断地改进，希望工业界和学术界的朋友都能够有所收获。</p>
<h1 id="DeepIntent-Learning-Attentions-for-Online-Advertising-with-Recurrent-Neural-Networks"><a href="#DeepIntent-Learning-Attentions-for-Online-Advertising-with-Recurrent-Neural-Networks" class="headerlink" title="DeepIntent: Learning Attentions for Online Advertising with Recurrent Neural Networks"></a><a href="http://www.kdd.org/kdd2016/papers/files/rfp0289-zhaiA.pdf" target="_blank" rel="external">DeepIntent: Learning Attentions for Online Advertising with Recurrent Neural Networks</a></h1><h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>在线广告、RNN、Attention</p>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>kdd2016</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>如何用deep learning模型挖掘click logs来理解用户Intent？</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p><img src="media/1.png" alt="1"></p>
<p>对于一个(query,ad)数据对，分别用LSTM encode，然后用下图的方法计算一个attention，得到最终的query和ad vector，构造loss function，取logs中(query,ad)作为正例d+，将ad替换为其他无关ad作为负例d-，训练的目标是让d+的score尽量大，让d-的score尽量小。</p>
<p><img src="media/2.png" alt="2"></p>
<h2 id="评论"><a href="#评论" class="headerlink" title="评论"></a>评论</h2><p>工业界有着学术界无法比拟的数据，大规模的真实数据是做deep learning的基础，大型商业搜索引擎积累了大量的ad click logs，利用好这些logs可以赚到更多的钱。attention机制在2015年开始逐渐成为一种流行趋势，借鉴于人类的注意力机制，让model将更多的注意力放在需要注意的地方，而不是每一个地方。本文并没有太多model上的创新，只是简单地将流行的model应用了自己研究的领域中，对工业界更有参考价值。</p>
<h1 id="A-Neural-Knowledge-Language-Model"><a href="#A-Neural-Knowledge-Language-Model" class="headerlink" title="A Neural Knowledge Language Model"></a><a href="http://120.52.73.76/arxiv.org/pdf/1608.00318v1.pdf" target="_blank" rel="external">A Neural Knowledge Language Model</a></h1><h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>语言模型、知识图谱</p>
<h2 id="来源-1"><a href="#来源-1" class="headerlink" title="来源"></a>来源</h2><p>arXiv cs.CL 2016.08.01</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>在自然语言生成(NLG)问题中，出现次数非常少的entity该如何生成呢？</p>
<h2 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h2><p><img src="media/1-2.png" alt="1"></p>
<p>四个步骤：</p>
<p>1、Input Representation<br><img src="media/2-1.png" alt="2"></p>
<p>输入由三个部分拼接而成，第一部分是上一个time step的fact表示，第二部分是上一个time step的词表中的词表示，第三部分是上一个time step的fact description表示，这里fact就是(subject,relation,object)，知识图谱中的一条事实，而后两个部分一定会有一个全为0，因为是二选一的关系，但为了保证每一次的输入都是等长向量，所以用拼接来做。得到输入之后，用LSTM来encode。</p>
<p>2、Fact Prediction</p>
<p>通过1的结果来预测当前word可能相关的fact，得到的结果是一个index，然后从topic knowledge中获得相应的表示，这里的knowledge embedding都是用transE训练好的，在整个模型训练中并不更新。</p>
<p>3、Knowledge-Copy Switch</p>
<p>根据1和2的结果，共同来预测当前要生成的词是从词表中获取的高频词还是从knowledge中获取的entity，典型的二分类问题。</p>
<p>4、Word Generation</p>
<p>根据3的结果，来生成当前time step的词。对于词表中的高频词，和之前的生成方法一致；对于fact description中的entity词，通过预测词的position来copy这个词。</p>
<h2 id="评论-1"><a href="#评论-1" class="headerlink" title="评论"></a>评论</h2><p>语言模型是一个基本问题，传统的方法都有着一个尴尬之处是，会生成大量的<unk>出来，只要是涉及到NLU的问题，基本都会遇到这个问题。本文提供了一个很有启发性的方法，借助于知识图谱这种外部知识来帮助生成效果更好的话，单纯地靠model来提升效果是一件比较困难的事情，但增加一些外部信息进来则会带来更多的可能性。由于知识图谱的构建本身就是一件不易的事情，因此本文的学术意义远大于实际应用意义，为后续这种交叉式研究（知识图谱+深度学习）打开了一扇门，大家可以尝试更多的组合和可能。</unk></p>
<h1 id="Neural-Sentence-Ordering"><a href="#Neural-Sentence-Ordering" class="headerlink" title="Neural Sentence Ordering"></a><a href="https://arxiv.org/pdf/1607.06952v1.pdf" target="_blank" rel="external">Neural Sentence Ordering</a></h1><h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>句子排序</p>
<h2 id="来源-2"><a href="#来源-2" class="headerlink" title="来源"></a>来源</h2><p>arXiv cs.CL 2016.07.23</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>给定乱序的N句话，如何将其按照逻辑排列好？（貌似是英语考试中的一种题型）</p>
<h2 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h2><p><img src="media/1-3.png" alt="1"></p>
<p>本文定义的问题是给定n句话，找出最优排序，将这个问题降维到二维，就是如何排列两句话的顺序。上图给出了model的思路，对两句话分别进行encode，得到两个向量表示，然后进行打分，分数表示当前顺序是正确顺序的概率。这里的encode部分，分别用了每句话中word embeddings的加权平均、RNN和CNN来表示。</p>
<p>得到两两的排序之后，本文用beam search来得到整体最优的排序。</p>
<h2 id="评论-2"><a href="#评论-2" class="headerlink" title="评论"></a>评论</h2><p>多文档摘要问题中通用的一种做法是从每篇文档中都提取出一句或几句重要的话，然后进行排序。在英语考试中，有一种题型是给定你打乱顺序的几段话，然后根据逻辑将其排序。本文在学术上没有什么新的东西，但本文在构建neural model的时候，用到的数据集却非常容易构建，这意味着你在工程中应用这个方法来解决排序问题是可行的方案，所以本文更加适合有句子排序应用需求的工程人员来精读。</p>
<h1 id="提问"><a href="#提问" class="headerlink" title="提问"></a>提问</h1><p>计算机的会议非常多，各种level的都有，arXiv上每天都可以刷出一些paper，不同类型、不同level的paper适合不同需求的人来读，我觉得好东西的标准是适合而不是在某一个具体指标上达到最大，对你有用的东西才是适合你的好东西，有些特别牛逼的东西，有着极高学术价值的东西不见得适合工程人员来读，但也不应该是那种觉得学术上的东西离工程太远，没有什么具体用的态度，从各种各样的东西汲取养分，丰富和充实自己才是硬道理。读了一些paper，也该思考一些问题了，这里提出一些比较naive的问题，欢迎大家踊跃留言和讨论。</p>
<p>1、<unk>这种out-of-vocabulary的问题是一个非常常见的问题，有哪些不错的思路可以来解决这个问题呢？</unk></p>
<p>2、attention model几乎满大街都是，最早在机器翻译领域中开始用这种模型，虽然在其他nlp领域中都取得了不错的成绩，但目前的attention真的适合每一类具体问题吗？是不是有一点为了attention而attention的感觉？neural summarization和machine translation真的可以完全类比吗？或者说attention适合解决具有什么特征的问题呢？</p>
<p>3、信息越多，model的效果一定会越好。现在外部信息非常丰富，但是如何融合到当前流行的model中来呢？如何将特定领域内构建的知识图谱完美地与特定任务中的model进行结合呢？以task-oriented bot为例，能够将客户的领域知识与bot response功能结合起来，做成一个更加高级的bot呢？</p>
<p>这里，我抛个砖，引个玉，希望更多的人能够参与讨论和提出问题。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-02T18:54:22.000Z"><a href="/2016/08/02/旧幕落下，新幕升起/">2016-08-02</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/02/旧幕落下，新幕升起/">旧幕落下，新幕升起</a></h1>
  

    </header>
    <div class="entry">
      
        <p>从过年那会筹划一些婚礼的想法开始，到拍婚纱照、找婚庆、跟拍、摄像、化妆、服装、场地、喜宴、安排接送车辆、亲朋住宿以及最近一个月疯狂地在淘宝上购买各种所需的东西，花费的所有时间和精力随着2016.07.31这一天这一场婚礼一起完美谢幕了，整个婚礼结束之后，我带着我的新娘子坐着地铁回家，想想大概也没有谁了。</p>
<p><img src="media/1.pic.jpg" alt="1.pi"></p>
<p>两天过去了，仍然没有从7.31的那场梦里醒来。感谢各位来宾，感谢各位工作人员，感谢保障小组的几位童鞋，感谢烁哥的乐队，感谢祝福我们的每一位！</p>
<p>当时家里不建议7.31结婚，因为他们很迷信地说8.1或者7.29更加适合结婚，而且我妈提前半个月就看天气预报说31号那天有大雨（我早就断定天气预报不准，而且提前那么早看根本没用），但我们仍然坚持就是7.31，不管那天什么天气，都一定是这一天，因为2015.7.31这一天我们正式在法律层面上成为了夫妻，当时离七夕很近，但我们觉得非节日的一天更加适合作为我们的纪念日，于是就在那天领了证，当时我就对韵韵说，明年的今天就是我们大婚的日子，我们要办最有意思、最不一样的婚礼，她点头答应。我们的坚持、我们的固执证明了7.31这一天就是属于我们的，非常棒的天气让整个婚礼进行的非常顺利，非常完美。</p>
<p><img src="media/3.pic.jpg" alt="3.pi"></p>
<p>回礼的准备花费了我们太多的时间和精力，直到婚礼前三天才准备好所有的回礼。长沙这边的一般做法都是准备一盒烟、一袋槟榔和一盒喜糖，当时我们就说要做的不一样，于是韵韵开始了每天长达两小时的淘宝生涯，并且乐此不疲，一盆多肉、一盒果酱和一盒手工喜糖。150份回礼，需要种150盆花，手工装150个喜糖盒子，装150个果酱盒，多亏了几位小同学的帮忙，才能顺利地准备好这些东西，韵韵喜欢兔子，所以袋子也是兔子，多肉的包装上贴着一张兔子贴纸，是我们这次婚礼的logo，是婚庆专门设计的。其实完全可以没必要这么累，直接买现成的就好，但是韵韵坚持要手工做每一个细节，希望每一个细节都做到完美，给宾客们带来不一样的感觉。她做到了！大家都非常喜欢这份回礼。</p>
<p><img src="media/2.pic.jpg" alt="2.pi"></p>
<p>婚礼主持人希望我们两个在婚礼现场可以真情告白一下，于是婚礼前的一周就没有踏实地睡好过，有一天夜里想着我们在一起的这一年多时间，点点滴滴都历历在目，又失眠了！那一晚想了很多很多，每一件事情的每一个细节都记忆犹新，想了很多想要对她说的话，平时也不会说什么深情的话，因为我也不是一个懂浪漫的人。她一直在忙着买各种各样必须的东西，所以直到婚礼前一天晚上在酒店里等我睡着了才开始准备告白的话，2点钟才睡觉，5点就起来准备化妆了。婚礼正式开始了，我之前准备好的词基本上都忘记了，确实有些紧张，但当我看到美丽的新娘站在我的面前时，我就一点都不紧张了，很自然地说出了我内心最真实的感动，以致于第一位伴娘哭的稀里哗啦的，韵韵的台风比我好，一句一句地讲出了我们在一起的美好！</p>
<p><img src="media/4.pic.jpg" alt="4.pi"></p>
<p>我和韵韵正式在一起是在马頔的演唱会上，是在2015.03.18，是我们认识后的第十天，一切看起来都很自然而然，没有任何刻意的安排。我一直有一个心愿就是能够办一场live concert，为我心爱的人献上她最爱的歌曲。于是，我决定在婚礼结束后，安排一场民谣风live concert，邀请喜欢唱歌的同学们一起来嗨。concert很成功，氛围非常好，烁哥的现场没的说，在座的每一位都沉浸在了当时的氛围中，我唱了马頔的《南山南》，韵韵唱了hebe的《小幸运》，一切都是那么地棒！</p>
<p><img src="media/6.pic_hd.jpg" alt="6.pic_hd"></p>
<p>韵韵说她最幸福的时刻就是每天早上醒来，看到身边的我和hare正在酣睡。hare是我们家的小狗，但全家都没有把他当做狗狗来养，我和韵韵是他的爸爸和妈妈，他还有外婆、爷爷和奶奶，每个人都特别爱他，他也是全家的开心果。如果说婚礼有遗憾的话，那就是hare没能来到现场见证他爸爸妈妈最幸福的一刻了。hare之所叫这个名字，是因为他刚刚来家里那会，我正对Air Jordan的Hare球鞋痴迷，Hare本是兔八哥的名字，所以就给他取了这个名字，后来不断地有了很多的名字，张甜心、张甜甜、小黑、心心等等好多的名字，他有一阵子有一些凌乱，突然不知道自己叫什么了。</p>
<p><img src="media/6.pic.jpg" alt="6.pi"></p>
<p>伴郎和伴娘都非常地帅气和美丽，他们给了我们很多的帮助和支持。伴娘都是韵韵的好闺蜜，有陪她一起长大的，有陪她一起工作的，有一个是这个世界上的另外一个她，她们相似的经历，让她们无话不谈，婚礼现场也就是她哭的最厉害了。伴郎都是我的小兄弟，他们替我扛了很多抢亲时的折磨，替我挡了很多的酒，三位伴郎在敬酒时毫无保留，最后通通倒下，有一点遗憾，没有能够参加最后的concert。感谢你们，因为你们，我和韵韵才会更加幸福！</p>
<p><img src="media/7.pic.jpg" alt="7.pi"></p>
<p>婚礼结束了，新的生活开始了！今年27岁，也该有一份自己的事业了，不管现在困难有多少，阻碍有多大，我和韵韵都要开始为我们的事业奋斗了！我一直觉得韵韵不仅仅是生活上的伴侣，更是心灵的伴侣，她最懂我的心，也不顾一切地支持我想做的事业，也愿意和我一起来奋斗这份事业。她细心、聪明、好学、热爱生活、眼光独到，所有美好的标签贴在她身上都不为过，她让我看到了更大的世界，让我明白了生活的意义，走进了我的内心深处让我不再孤独，她的勇敢、知性、独立都让我钦佩，给了我莫大的勇气，让我可以更加自信地活在这个世界上，去勇敢地挑战一些更难的事情。人生就是一场奇遇，感谢上帝让我遇见你！谢谢你，韵韵，我爱你！</p>
<p>旧的一幕已经落下，新的一幕正在升起。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-26T00:06:49.000Z"><a href="/2016/07/25/如果我也做bot/">2016-07-25</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/25/如果我也做bot/">如果我也做bot</a></h1>
  

    </header>
    <div class="entry">
      
        <p>最近初步地研究了下bot这个领域，有了一点浅薄的理解，于是开始想，如果我也做bot的话，解决好哪些问题才会做好这件事情？</p>
<p>1、创业是一件严肃的事情，不是儿戏，需要做好充足的准备，调研和积累都是非常重要的，只有做好100分的准备，才可能在面对各种未知的困难时不慌乱。所以，第一步就是调研，研究bot，从方方面面，比如：</p>
<p>（1）bot为什么会火？<br>（2）国内哪些企业在做bot？他们的产品有哪些优缺点？<br>（3）国外哪些企业在做bot？有哪些优缺点？<br>（4）投资情况如何？投资人怎么看待这个方向？<br>（5）bot需要哪些技术积累？</p>
<p>2、从媒体、投资人的观点来看，bot整个大方向没有错，那么到底应该做哪个子领域呢？是客服？还是技术支持？技术平台？垂直私人助理？平台上应用？可做的事情其实很多，16年开始才井喷式地炒作bot这个概念，所以今年可以当做是bot元年，既然是刚刚起步的一个领域，就有一个天然的好处，蛋糕足够大，品类足够多，看你想吃哪一块？当然也有一个天然的坏处，就是无章可循，大家都是摸着石头过河。</p>
<p>（1）国内的情况是，客服已经有很多家企业在做了，做的模式大同小异，技术方面各有特色吧，可能起步早的现在规模大一些，晚的小一些，但整体来看差异化不大。如果选择这个方向的话，必须做出差异化，研究现有方案的缺点，之前写过一篇文章，简单剖析了现有方案的缺点和可改进的点，让目前的客服bot更进一步，要么就是做一家客服bot，产品更完美、技术更好，和大家分一杯羹；要么就是提供技术支持，帮现有的bot企业更进一步，赚他们的钱。</p>
<p>（2）如果是做技术支持，典型的SaaS+B2B，用自己的技术服务来为别的企业提供支持，response generation、user modeling、context modeling、information extraction都是不错的方向，每一个做好了都有广阔的前景，以为技术支持不直接面对业务，而是帮助改进现有企业提升算法和建模能力，应用的面比较广，可以用在各种类型的bot上以及其他应用背景上。</p>
<p>（3）平台上的应用，比如slack上的bot，做一个有趣的小功能，提高team的工作效率。这个在国外非常地火，平台也很多，就像是现在ios上开发app一样，每个app都有自己的功能。我觉得这块要是做的话，很容易做出差异化，现在已经有各式各样的startups做着各式各样的bot。但整体来说，技术门槛比较低，有一点API整合的意思，但如果你将自己的技术封装成API，在上面做一个bot提供服务也是一种不错的尝试，而且产品周期特别短，但终究卖点应该还是你的技术支持，而不是这个bot。</p>
<p>（4）技术平台的话，类似的有很多帮助企业或个人构建bot在各种平台上跑，假如微信现在开放了这一块，技术平台一定大有用处，这个属于基础的工具类产品，将很复杂的技术做成人人可以轻松使用的工具是一件很有意义的事情，像是IDE的感觉，不管什么背景，只要是有想法，就可以通过这个工具来实现一个bot，如果复杂的，可能需要定制。</p>
<p>（5）特定任务的私人助理，比如帮忙管理日程、制定旅行计划之类的，术业有专攻嘛，这个最好是之前在其他平台上做类似功能的企业转型到bot这里来，有着足够的积淀，融入一些新的交互和技术来提升产品体验。</p>
<p>上面的每个子领域在国外都有模板可以参考，国内的话还比较少，所以是很大的机会，关键在于判断，在于具体情况具体分析。因为有些东西并不适合做成bot这种聊天式的交互方式，简单的几个按钮操作就可以轻松完成的事情，为什么非要打很多的字来做呢？</p>
<p>3、壁垒。你的核心竞争力是什么？什么是你会别人不会的？如果腾讯也做这个事情，你们该怎么办？你的企业增长点在哪里？如何做大？</p>
<p>这些问题是投资人最关注的问题，其实也是创业前最应该想明白的问题，如果自己都想不明白，或者很多问题难以回答的话，说明现在的情况还不适合创业或者拿投资。我认为，无论什么时候人都是最核心的竞争力，技术和交互形式日新月异，更迭很快，团队只要具有很强的学习能力，永远都不会落于下风。没有什么技术一定是只有你一人才会的，工程上的技术壁垒不应是你提出了一个举世无双、天下无敌的算法，而是你在这个领域内实践各种各样算法的经验积累。为什么说一定要专注地做好一个事情，只做这一件事情，将这件事情做到精，因为对这么细小的领域理解地如此之深的人没有几个，这是你的技术壁垒，也是企业的生存之道，也是其他大公司难以抄袭的重要原因。这个问题一定要想清楚，最重要的是人，在技术层面上，不要想着找到一个独门秘籍来打天下，而是对你所研究的问题有非常深入地理解和见解，这是最基本的也是最核心的；接下来才是如何发展和壮大的问题，这个问题需要讲故事的能力，描绘出一幅美好画面的能力。</p>
<p>我觉得人的能力是最根本的壁垒，当然会有不同看法。有的企业快速扩张，积累客户，可能觉得积累的数据和客户资源是壁垒，但我觉得如果一个新的更好用的技术出来了，而你的企业技术却没跟上的话，很容易就会被取代的，不管你是5w+，还是10w+的客户。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-25T23:12:32.000Z"><a href="/2016/07/25/bot-bot/">2016-07-25</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/25/bot-bot/">bot,bot</a></h1>
  

    </header>
    <div class="entry">
      
        <p>科技媒体的文章有一个明显的好处，就是会报道很多不易被人发现、但却非常有意思的startups，帮助大家拓宽视野；同时也有一个明显的坏处，文章容易标题党，不够专业的编辑容易写出一些极端的结论，比如xxx一定会取代yyy，炒作概念。所以，这里借助了科技类媒体的优势，考察了下国外的bot startups所覆盖的业务和现状，总结如下：</p>
<p>1、外国的月亮比较圆。有一种常见的误区，也是由来很久的一种偏见，那就是国外的东西一定优质于国内的东西，单纯地从startups的主页来看，国外的风格整体更加清爽和小清新一点，而国内的主页整体来说，充满了一种网站模板没用心选的既视感，有些startups充满了乡土气息。但并不意味着，背后的技术一定比国内好，只是门脸做的不错，slogan喊得不错，每一个startup都有一个改变人类现有生活的理想，仔细看有可能只是一个驻扎在slack或者messenger平台上的小bot。</p>
<p>2、国外的bot startups种类比较多，各个level的企业都有，从最上面的应用层来说，slack、messenger、telegram、kik等各个message平台上都有大量的bot，包括各种各样的服务。这类bot门槛较低，缺乏核心技术，通常是一个idea来支撑整个企业，容易同质化，来源可能是各种bot比赛的产物，域名都是.ai，稍微大一点的支持多个平台，很多都是只在slack上使用，有一种bot成海的感觉，什么样的服务都可以用bot来做，强行改变交互方式。有的slack bot服务于team，有的是将slack与其他服务，比如google analytics，以bot的形式进行桥接。</p>
<p>3、有挺多的startups都在做app store的事情，聚合了大量不同类别的bot，统一进行管理，开发者开发好的bot都放在store中进行展示和销售。这类企业也是平台的性质，但没有自己独立的平台，所以做各大平台的聚合。</p>
<p>4、有的startups做的是降低开发bot门槛的事情，和平台提供接入服务不同，这类企业更具有技术性，将bot开发封装成简单的接口或者界面，供“开发者”甚至是小白来开发属于自己的bot，不管是新闻app还是天气、还是旅游都是几分钟配置的事情，完全没有难度。这类公司相比于平台上的简单bot来说，更加底层一些，也更有技术门槛，但结果却是让bot变得没有技术门槛了。</p>
<p>5、有的startups是独立于几大平台的，提供一种私人助理服务，包括会议、日程、旅行、金融各种服务，为了保证服务质量，常常采用AI+人工的模式。这类公司通常都有核心的技术和垂直领域的经验，对该领域地理解比较深，而且跟得上时代的潮流，用chat作为交互是一个大趋势，索性就早一点进入，确立市场地位。</p>
<p>6、有的startups专门做B2B的技术支持服务，提供NLP、知识抽取方面的服务，为上述的各类企业提供技术支撑，没有直接参与bot，但保证了bot的质量。</p>
<p>7、从各个startups成立时间和融资情况来看，平台上的bot都是2015年底或者2016年初开始热起来的，而2013、2014年就开始朝着这个方向做的企业，基本都是做技术平台、企业客服bot或者私人助理app的，相对来说技术壁垒大一些，门槛高，不容易被模仿和抄袭，所以融资情况较好，当然这个只是现在还存活的企业，死掉地可能也有很多。整体来看，slack之类的平台上做个好玩的bot难度不大，数量如雨后春笋般、井喷式地增长，质量良莠不齐，核心技术少，门槛低，从目前的融资情况看不是很好。而开始早并且技术壁垒大的startups有着更好的市场前景，融资情况也比较乐观。</p>
<p>8、可能是因为考察的startups还比较少，并没有发现像国内有那么多家bot企业都挤在客服这个领域，其他领域的bot企业相对较少，（也有可能是关注的比较少）。国内的微信并没有开放这么彻底，或者说没有一个类似的平台可以做类似的事情，所以各种小bot还没有井喷式地出现，但这是一个趋势，今后一定会有类似的平台出来。</p>
<p>9、bot在全球都很火，国内和国外的侧重点感觉不是很一样，国外的形式比较丰富，各个level的蛋糕都有人在吃，简直无孔不入，反观国内，大家都忙于抢客服这块大蛋糕，其他的蛋糕没有太多的人来吃，这样看来可能也是国内的一个机会，只要不做客服bot，做一些别的业务可能都会有几乎吧。</p>
<p>10、不是什么场景都适合用chatbot来解决的，很多时候我们简单操作下软件比和一个不怎么聪明的bot聊半天效率要高很多的，做bot的话，应该首先分析用哪个场景chat会比操作更加简单，而不是盲目地什么都搞成bot。这一点很重要，媒体的炒作，以及大公司的PR都容易蒙蔽双眼，失去理性判断，清醒地分析一下哪些方向是适合做bot的，而不是一味地去为了bot而bot。</p>
<p>注：所有的数据都是来自于<a href="https://www.crunchbase.com/" target="_blank" rel="external">CrouchBase</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-25T18:39:04.000Z"><a href="/2016/07/25/bot-startups/">2016-07-25</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/25/bot-startups/">bot startups</a></h1>
  

    </header>
    <div class="entry">
      
        <p>罗列下各种媒体上提到的bot startups，包括：业务范围和融资情况。</p>
<h1 id="motion-ai"><a href="#motion-ai" class="headerlink" title="motion.ai"></a><a href="motion.ai">motion.ai</a></h1><p>用可视化地手段进行构建、训练和发布一个bot。喊出的口号是，只要你会画流程图，你就可以构建一个bot，可以在各种平台上搭建属于自己的bot，比如：sms、web、email、Fb Messenger、Slack等平台。</p>
<p>成立时间：2015.11.05<br>融资情况：$700k 种子轮<br>公司主页：<a href="http://motion.ai" target="_blank" rel="external">http://motion.ai</a></p>
<h1 id="CareerLark"><a href="#CareerLark" class="headerlink" title="CareerLark"></a><a href="http://www.careerlark.com/" target="_blank" rel="external">CareerLark</a></h1><p>构建于Slack平台的一家bot企业，旨在通过micro-feedback来提高生产力。</p>
<p>成立时间：未知<br>融资情况：$50k 种子轮<br>公司主页：<a href="http://www.careerlark.com/" target="_blank" rel="external">http://www.careerlark.com/</a></p>
<h1 id="Carla"><a href="#Carla" class="headerlink" title="Carla"></a><a href="http://carla.io/" target="_blank" rel="external">Carla</a></h1><p>一款虚拟助手，用于提醒自己、朋友和家人，通过自然语言添加日程和追踪自己一天的生活。</p>
<p>成立时间：未知<br>融资情况：未知<br>公司主页：<a href="http://carla.io/" target="_blank" rel="external">http://carla.io/</a></p>
<h1 id="Dexter"><a href="#Dexter" class="headerlink" title="Dexter"></a><a href="https://rundexter.com/" target="_blank" rel="external">Dexter</a></h1><p>帮助企业用户快速构建bot引擎，打造属于自己的bot。</p>
<p>成立时间：未知<br>融资情况：未知<br>公司主页：<a href="https://rundexter.com/" target="_blank" rel="external">https://rundexter.com/</a></p>
<h1 id="kip"><a href="#kip" class="headerlink" title="kip"></a><a href="http://kipthis.com/" target="_blank" rel="external">kip</a></h1><p>办公室团购助手，将B2C搬进bot中，方便大家购物，支持多种平台。</p>
<p>成立时间：2014.05.13<br>融资情况：$317k 两轮<br>公司主页：<a href="http://kipthis.com/" target="_blank" rel="external">http://kipthis.com/</a></p>
<h1 id="Rollio"><a href="#Rollio" class="headerlink" title="Rollio"></a><a href="https://www.rollioforce.com/" target="_blank" rel="external">Rollio</a></h1><p>CRM智能助手，将你的销售变得更加简单，用NLP技术来挖掘客户反馈来文本和声音信息，简化CRM。</p>
<p>成立时间：2014<br>融资情况：$670k 种子轮<br>公司主页：<a href="https://www.rollioforce.com/" target="_blank" rel="external">https://www.rollioforce.com/</a></p>
<h1 id="Assist"><a href="#Assist" class="headerlink" title="Assist"></a><a href="http://www.assi.st/" target="_blank" rel="external">Assist</a></h1><p>将企业现有的业务搬进文本消息平台中，用bot来帮企业做生意。</p>
<p>成立时间：未知<br>融资情况：未知<br>公司主页：<a href="http://www.assi.st/" target="_blank" rel="external">http://www.assi.st/</a></p>
<h1 id="magic"><a href="#magic" class="headerlink" title="magic"></a><a href="https://www.getmagicnow.com/" target="_blank" rel="external">magic</a></h1><p>一个基于文本信息平台的通用bot助理，涵盖的面比较广。</p>
<p>成立时间：2015<br>融资情况：$12M 两轮<br>公司主页：<a href="https://www.getmagicnow.com/" target="_blank" rel="external">https://www.getmagicnow.com/</a></p>
<h1 id="Polly"><a href="#Polly" class="headerlink" title="Polly"></a><a href="https://www.polly.ai/" target="_blank" rel="external">Polly</a></h1><p>基于slack平台的bot服务，收集和分析team的数据，提供一些服务，可定制化。</p>
<p>成立时间：2015<br>融资情况：未知<br>公司主页：<a href="https://www.polly.ai/" target="_blank" rel="external">https://www.polly.ai/</a></p>
<h1 id="StatsBot"><a href="#StatsBot" class="headerlink" title="StatsBot"></a><a href="https://statsbot.co/" target="_blank" rel="external">StatsBot</a></h1><p>基于slack平台的bot服务，提供google analytics、mixpanel、salesforce服务。</p>
<p>成立时间：2015<br>融资情况：未知<br>公司主页：<a href="https://statsbot.co/" target="_blank" rel="external">https://statsbot.co/</a></p>
<h1 id="Birdly"><a href="#Birdly" class="headerlink" title="Birdly"></a><a href="https://www.getbirdly.com/" target="_blank" rel="external">Birdly</a></h1><p>基于slack平台的bot服务，沟通team和salesforce的桥梁。</p>
<p>成立时间：2014<br>融资情况：$120k 种子轮<br>公司主页：<a href="https://www.getbirdly.com/" target="_blank" rel="external">https://www.getbirdly.com/</a></p>
<h1 id="zoom-ai"><a href="#zoom-ai" class="headerlink" title="zoom.ai"></a><a href="http://www.zoom.ai/" target="_blank" rel="external">zoom.ai</a></h1><p>企业级的智能助手，支持多个平台和多项服务。</p>
<p>成立时间：2016.02.22<br>融资情况：未知<br>公司主页：<a href="http://www.zoom.ai/" target="_blank" rel="external">http://www.zoom.ai/</a></p>
<h1 id="HeyTaco"><a href="#HeyTaco" class="headerlink" title="HeyTaco!"></a><a href="https://www.heytaco.chat/" target="_blank" rel="external">HeyTaco!</a></h1><p>基于slack平台的bot服务，当你觉得team中一个人做了一件awesome的事情，可以@username + taco emoji，然后该服务会记录下team中每个成员的taco数，攒齐N个可以换一些gift。</p>
<p>成立时间：2016.02.06<br>融资情况：未知<br>公司主页：<a href="https://www.heytaco.chat/" target="_blank" rel="external">https://www.heytaco.chat/</a></p>
<h1 id="skylar"><a href="#skylar" class="headerlink" title="skylar"></a><a href="https://skylar.ai/" target="_blank" rel="external">skylar</a></h1><p>为团队提供多种服务的bot，整合了一些在线工具API，基于slack和messenger平台。</p>
<p>成立时间：2015.11.17<br>融资情况：未知<br>公司主页：<a href="https://skylar.ai/" target="_blank" rel="external">https://skylar.ai/</a></p>
<h1 id="DigitalGenius"><a href="#DigitalGenius" class="headerlink" title="DigitalGenius"></a><a href="http://digitalgenius.com/" target="_blank" rel="external">DigitalGenius</a></h1><p>bot+人工客服服务，多平台多渠道客服。</p>
<p>成立时间：2013.12.01<br>融资情况：$8.35M 三轮<br>公司主页：<a href="http://digitalgenius.com/" target="_blank" rel="external">http://digitalgenius.com/</a></p>
<h1 id="workbot"><a href="#workbot" class="headerlink" title="workbot"></a><a href="https://www.workato.com/workbot-slack" target="_blank" rel="external">workbot</a></h1><p>基于slack平台的bot服务，为团队提供一系列数据服务。</p>
<p>成立时间：2016.01<br>融资情况：未知<br>公司主页：<a href="https://www.workato.com/workbot-slack" target="_blank" rel="external">https://www.workato.com/workbot-slack</a></p>
<h1 id="poncho"><a href="#poncho" class="headerlink" title="poncho"></a><a href="http://poncho.is/" target="_blank" rel="external">poncho</a></h1><p>量身定做的天气和旅行助手。</p>
<p>成立时间：2013.04.01<br>融资情况：$2M 种子轮<br>公司主页：<a href="http://poncho.is/" target="_blank" rel="external">http://poncho.is/</a></p>
<h1 id="Pana"><a href="#Pana" class="headerlink" title="Pana"></a><a href="https://www.pana.com/" target="_blank" rel="external">Pana</a></h1><p>bot+AI旅行安排服务。</p>
<p>成立时间：2015<br>融资情况：$1.45M 两轮<br>公司主页：<a href="https://www.pana.com/" target="_blank" rel="external">https://www.pana.com/</a></p>
<h1 id="Penny"><a href="#Penny" class="headerlink" title="Penny"></a><a href="https://www.pennyapp.io/" target="_blank" rel="external">Penny</a></h1><p>私人财产顾问型bot。</p>
<p>成立时间：2015.07<br>融资情况：$1.2M 种子轮<br>公司主页：<a href="https://www.pennyapp.io/" target="_blank" rel="external">https://www.pennyapp.io/</a></p>
<h1 id="x-ai"><a href="#x-ai" class="headerlink" title="x.ai"></a><a href="https://x.ai" target="_blank" rel="external">x.ai</a></h1><p>帮你安排会议的私人助手。</p>
<p>成立时间：2014.04.14<br>融资情况：$34.3M 三轮<br>公司主页：<a href="https://x.ai" target="_blank" rel="external">https://x.ai</a></p>
<h1 id="viv-ai"><a href="#viv-ai" class="headerlink" title="viv.ai"></a><a href="http://viv.ai/" target="_blank" rel="external">viv.ai</a></h1><p>一个帮助开发者快速开发bot的技术平台，涵盖的面比较广。</p>
<p>成立时间：未知<br>融资情况：30M 三轮<br>公司主页：<a href="http://viv.ai/" target="_blank" rel="external">http://viv.ai/</a></p>
<h1 id="Kasisto"><a href="#Kasisto" class="headerlink" title="Kasisto"></a><a href="http://kasisto.com/kai/" target="_blank" rel="external">Kasisto</a></h1><p>bot技术平台，帮助开发者轻松搭建一个bot。</p>
<p>成立时间：2013<br>融资情况：$2.25M<br>公司主页：<a href="http://kasisto.com/kai/" target="_blank" rel="external">http://kasisto.com/kai/</a></p>
<p>startups信息来自<a href="crunchbase.com">CrunchBase</a>。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-24T20:20:12.000Z"><a href="/2016/07/24/再谈bot/">2016-07-24</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/24/再谈bot/">再谈bot</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文是一个TechCrunch最近一年有关bot新闻报道的survey，从原文中提炼了些核心观点，来研究下国外bot的发展。</p>
<h1 id="Forget-Apps-Now-The-Bots-Take-Over"><a href="#Forget-Apps-Now-The-Bots-Take-Over" class="headerlink" title="Forget Apps, Now The Bots Take Over"></a><a href="https://techcrunch.com/2015/09/29/forget-apps-now-the-bots-take-over/" target="_blank" rel="external">Forget Apps, Now The Bots Take Over</a></h1><p>Sep 29, 2015 TechCrunch</p>
<p>正如浏览器取代了操作系统的地位作为新的平台，网站取代了应用程序的地位，bots将会取代移动app的地位，今后将会是bot store，各种各样的bot，而不再是app store。</p>
<p>类似于微信、Line、Facebook、Slack这样的message平台，将会成为一个新的入口。在message平台上有各种各样的bot，用户通过message与各种bot进行交互，来体会之前在手机各种app上的服务。</p>
<p><img src="media/1.png" alt="1"></p>
<blockquote>
<p>It’s a brave new bot-filled world, with new possibilities and new risks.</p>
</blockquote>
<h1 id="Check-out-the-new-AI-powered-TechCrunch-news-bot-on-Telegram-messenger"><a href="#Check-out-the-new-AI-powered-TechCrunch-news-bot-on-Telegram-messenger" class="headerlink" title="Check out the new AI-powered TechCrunch news bot on Telegram messenger"></a><a href="https://techcrunch.com/2016/03/15/check-out-the-new-ai-powered-techcrunch-news-bot-on-telegram-messenger/" target="_blank" rel="external">Check out the new AI-powered TechCrunch news bot on Telegram messenger</a></h1><p>Mar 15, 2016 TechCrunch</p>
<p>Techcrunch在Telegram上用<a href="https://chatfuel.com/" target="_blank" rel="external">Chatfuel</a>构建了一个news bot，用户可以通过订阅不同的topic，authors和sections，bot根据订阅内容每天会推送两次trending stories digest给用户，另外也可以进行一些问答、聊天。</p>
<p><img src="media/2.gif" alt="2"></p>
<h1 id="Microsoft-is-bringing-bots-to-Skype-—-and-everywhere-else"><a href="#Microsoft-is-bringing-bots-to-Skype-—-and-everywhere-else" class="headerlink" title="Microsoft is bringing bots to Skype — and everywhere else"></a><a href="https://techcrunch.com/2016/03/30/microsoft-is-bringing-bots-to-skype-and-everywhere-else/" target="_blank" rel="external">Microsoft is bringing bots to Skype — and everywhere else</a></h1><p>Mar 30, 2016 TechCrunch</p>
<p>微软CEO Nadella说,bots是下一代应用，只需要用自然语言与bot进行talk就可以完成之前大量手机app和网站做的工作。微软在bot的研究上投入很大，成果也颇多，小冰、Tay、Cortana，和开源的bot framework，并且将很多好玩的deep learning应用与bot做了整合，比如image caption bot，bing music bot，bing news bot。</p>
<p><img src="media/3.jpg" alt="3"></p>
<h1 id="Chat-app-Kik-launches-a-bot-store-and-anyone-can-make-bots-for-it"><a href="#Chat-app-Kik-launches-a-bot-store-and-anyone-can-make-bots-for-it" class="headerlink" title="Chat app Kik launches a bot store and anyone can make bots for it"></a><a href="https://techcrunch.com/2016/04/05/chat-app-kik-launches-a-bot-store-and-anyone-can-make-bots-for-it/" target="_blank" rel="external">Chat app Kik launches a bot store and anyone can make bots for it</a></h1><p>Apr 5, 2016 TechCrunch</p>
<p>Kik是一个聊天app，构建了自己的bot store，chat被认为是下一代操作系统，而聊天app则是新型的浏览器，bots是新型的网站。bot和聊天的环境类似，增加了一些特殊的trigger，用来激发一些特殊的动作。</p>
<p><img src="media/4.png" alt="4"></p>
<h1 id="Botlist-is-an-app-store-for-bots"><a href="#Botlist-is-an-app-store-for-bots" class="headerlink" title="Botlist is an app store for bots"></a><a href="https://techcrunch.com/2016/04/11/botlist-is-an-app-store-for-bots/" target="_blank" rel="external">Botlist is an app store for bots</a></h1><p>Apr 11, 2016 TechCrunch</p>
<p>Botlist是一家做bot聚合的平台，和豌豆荚是类似的概念，聚合了各种message平台上的各种bot应用。</p>
<p><img src="media/5.png" alt="5"></p>
<h1 id="TechCrunch-launches-a-personalized-news-recommendations-bot-on-Facebook-Messenger"><a href="#TechCrunch-launches-a-personalized-news-recommendations-bot-on-Facebook-Messenger" class="headerlink" title="TechCrunch launches a personalized news recommendations bot on Facebook Messenger"></a><a href="https://techcrunch.com/2016/04/19/all-your-bots-are-belong-to-us/" target="_blank" rel="external">TechCrunch launches a personalized news recommendations bot on Facebook Messenger</a></h1><p>Apr 19, 2016 TechCrunch</p>
<p>TechCrunch在Fb平台上的bot具备一个简单的个性化推荐的功能，根据用户的喜欢来推荐可能感兴趣的文章。</p>
<h1 id="ToyTalk-renames-to-PullString-repositions-as-authoring-tool-for-bots"><a href="#ToyTalk-renames-to-PullString-repositions-as-authoring-tool-for-bots" class="headerlink" title="ToyTalk renames to PullString, repositions as authoring tool for bots"></a><a href="https://techcrunch.com/2016/04/26/pullstring-bot-authoring/" target="_blank" rel="external">ToyTalk renames to PullString, repositions as authoring tool for bots</a></h1><p>Apr 26, 2016 TechCrunch</p>
<p>PullString做儿童市场，因为孩子的词汇量非常有限，而且都很容易理解，关键是孩子对那些nonsense的回答并不介意。</p>
<p><img src="media/6.gif" alt="6"></p>
<h1 id="Bots-Messenger-and-the-future-of-customer-service"><a href="#Bots-Messenger-and-the-future-of-customer-service" class="headerlink" title="Bots, Messenger and the future of customer service"></a><a href="https://techcrunch.com/2016/05/07/bots-messenger-and-the-future-of-customer-service/" target="_blank" rel="external">Bots, Messenger and the future of customer service</a></h1><p>May 7, 2016 TechCrunch</p>
<p><img src="media/7.png" alt="7"></p>
<p> 传统的客服总是给人留下低效的印象，而随着AI研究水平地不断提高，用bot来替代或者辅助人工客服将是一种趋势和潮流。</p>
<h1 id="Penny-raises-1-2M-in-seed-funding-for-its-personal-finance-bot"><a href="#Penny-raises-1-2M-in-seed-funding-for-its-personal-finance-bot" class="headerlink" title="Penny raises $1.2M in seed funding for its personal finance bot"></a><a href="https://techcrunch.com/2016/05/23/penny-raises-1-2m-in-seed-funding-for-its-personal-finance-bot/" target="_blank" rel="external">Penny raises $1.2M in seed funding for its personal finance bot</a></h1><p> May 23, 2016 TechCrunch</p>
<p> Penny是一个personal finance bot，通过chat来帮助用户管理finance。不过chat只能通过pre-populated messages，而不是自然语言。尽管进入了一个bot时代，但chat的方式并不是解决所有问题的最好方法，在shopping领域，传统的电商网站比bot更好用。</p>
<p><img src="media/8.jpg" alt="8"></p>
<h1 id="Microsoft-tries-its-hand-at-a-news-bot-with-Rowe"><a href="#Microsoft-tries-its-hand-at-a-news-bot-with-Rowe" class="headerlink" title="Microsoft tries its hand at a news bot with Rowe"></a><a href="https://techcrunch.com/2016/05/24/microsoft-tries-its-hand-at-a-news-bot-with-rowe/" target="_blank" rel="external">Microsoft tries its hand at a news bot with Rowe</a></h1><p>May 24, 2016 TechCrunch</p>
<p>微软太钟爱bot了，在新闻领域开发了一款bot，整合了自家一个新闻App News Pro的功能，通过topic来获取相关news，获取今日头条，获取系统推荐的news。</p>
<p> <img src="media/9.png" alt="9"></p>
<h1 id="Workato-unveils-Personal-Workbot-to-silence-some-of-the-Slack-bot-noise"><a href="#Workato-unveils-Personal-Workbot-to-silence-some-of-the-Slack-bot-noise" class="headerlink" title="Workato unveils Personal Workbot to silence some of the Slack bot noise"></a><a href="https://techcrunch.com/2016/06/23/workato-unveils-personal-workbot-to-silence-some-of-the-slack-bot-noise/" target="_blank" rel="external">Workato unveils Personal Workbot to silence some of the Slack bot noise</a></h1><p>Jun 23, 2016 TechCrunch</p>
<p>Workato提供一个bot服务Personal Workbot，为slack用户过滤掉channel中无关的信息，提高效率。</p>
<p><img src="media/10.png" alt="10"></p>
<h1 id="Zoom-ai-believes-an-automated-assistant-is-the-fix-for-a-weighty-workload"><a href="#Zoom-ai-believes-an-automated-assistant-is-the-fix-for-a-weighty-workload" class="headerlink" title="Zoom.ai believes an automated assistant is the fix for a weighty workload"></a><a href="https://techcrunch.com/2016/07/14/zoom-ai/" target="_blank" rel="external">Zoom.ai believes an automated assistant is the fix for a weighty workload</a></h1><p>Jul 14, 2016 TechCrunch</p>
<p>Zoom.ai与之前的chat bot startups不同，目的客户是企业。创始人说，bot更像是一种UI，bot背后的技术才是真正需要解决的问题，NLP技术才是最关键的东西。</p>
<h1 id="Legion-Analytics-is-building-bots-to-automate-your-sales-pitch"><a href="#Legion-Analytics-is-building-bots-to-automate-your-sales-pitch" class="headerlink" title="Legion Analytics is building bots to automate your sales pitch"></a><a href="https://techcrunch.com/2016/07/15/legion-analytics-kylie/" target="_blank" rel="external">Legion Analytics is building bots to automate your sales pitch</a></h1><p>Jul 15, 2016 TechCrunch</p>
<p>Legion Analytics这家公司借助人工智能技术，帮助销售团队更加高效地工作。并不是说用bot来替代人工销售团队，而是帮助他们处理更加耗时的邮件咨询和demo演示。</p>
<h1 id="Bot-influencers-are-the-programmatic-future-of-conversational-advertising"><a href="#Bot-influencers-are-the-programmatic-future-of-conversational-advertising" class="headerlink" title="Bot influencers are the programmatic future of conversational advertising"></a><a href="https://techcrunch.com/2016/07/21/bot-influencers-the-programmatic-future-of-conversational-advertising/" target="_blank" rel="external">Bot influencers are the programmatic future of conversational advertising</a></h1><p>Jul 21, 2016 TechCrunch</p>
<p>conversational广告有望改善目前digital ads的缺陷，可以做的更加relevant、contextual和unobtrusive。</p>
<h1 id="Why-do-chatbots-suck"><a href="#Why-do-chatbots-suck" class="headerlink" title="Why do chatbots suck?"></a><a href="https://techcrunch.com/2016/05/29/why-do-chatbots-suck/" target="_blank" rel="external">Why do chatbots suck?</a></h1><p>May 29, 2016 TechCrunch</p>
<p>文中的观点基本同意，chatbot领域太广容易失败，不如做好特定领域内的服务。bot有智能的，比如微软的Tay，也有不智能的，比如Facebook平台上的CNN chatbot，设定一些button，绑定一些特定的事件。市面上没有一个真正好用的bot，很多领域为了bot而bot，用传统的app通过几个步骤就可以完成的事情，在bot中需要通过打很多的字才能完成，其实用户并不在意你的东西是不是智能，也不关心你产品背后的技术多牛，只在乎你的产品是不是简单好用效率高。一切以贴牌炒概念的bot产品都是耍流氓。现阶段，很多相关技术并不成熟，作者建议说在企业客服这个领域多做一些工作，比如把企业的产品FAQ bot做好，节约一些人力成本。（国内很多家做FAQ bot的公司）</p>
<h1 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h1><p>本文是考察国外bot文章系列的第一篇，全都来自TechCrunch。看了一天的新闻文章，从国外科技记者的角度看了下bot这个领域的发展和未来。</p>
<p>1、整体来说，比较乐观，从大公司、投资人、记者、用户多个角色来看，大家都比较看好bot的发展，相信bot是下一个app的形式，就像website取代了传统桌面程序一样，bot也会取代现在的手机app。</p>
<p>2、chat的形式就是大家来聊天，自然而然大的message平台，比如Facebook的Messenger，微信，Line，Slack，Telegram等等，就是成为bot的平台，就像现在的操作系统平台一样。</p>
<p>3、国外的bot公司很多很多，后缀带.ai多的数不清，从这些新闻中分享的bot应用，看得出大家现在还停留在一个比较初始的bot状态，有一点像arxiv上占坑的感觉，没有太多所谓的智能，只是有一个chatbot交互的UI，基本上实现具体的功能都靠事先定制好的button来trigger，更像是交互方式的革新，而非真的人工智能。</p>
<p>4、很多bot都在炒概念，往hot topic上靠，为了bot而bot，手机app用基本简单的点击操作就可以完成的任务，用bot却非要花费大量的时间来输入order或者人类语言，有点多此一举了。说白了，语义理解技术还不够成熟，大家将本该高度智能化的bot做成了step by step的引导，让用户使用了更加复杂的操作。当然，如果你的bot可以准确理解一句或几句简单的人话，然后完成复杂的业务处理，并反馈给用户结果，这样的bot才会让用户真的信服。</p>
<p>5、大伙儿基本上都把bot当成下一代app了，于是出现了很多家做bot聚合和分发的平台，类似app store，豌豆荚这种角色。一个市场雏形出来了之后，大家各自定位，各吃一块蛋糕。</p>
<p>6、客服bot是目前国内市场bot最活跃的一类，提供的功能基本上是企业产品或者业务的faq，差异化在于理解用户的query上，可能技术上略有差异。另外还有一种助手式的bot，提供了一些日常服务，比如查天气，订机票，订饭，打车等功能，基本上纯粹理解自然语言的很少，都是预先设定好套路，根据前一个context来trigger出后一个question，step by step地带着用户完成一个指定任务，因为涉及到多轮对话，context的理解和处理就显得非常重要，理解不好就显得bot非常弱智。这里，我觉得根据context做response的生成是个可以应用的点，虽然说可用的dataset规模很小，但可以考虑将已有的dataset做template化，通过template后的dataset来训练response generator。</p>
<p>今天是系列文章的第一篇，后续会读更多的news或者discussion，以及研究国外bot的产品形式和所用技术，做更多的分享，欢迎讨论。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-22T20:14:05.000Z"><a href="/2016/07/22/国内bot产品试用总结/">2016-07-22</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/22/国内bot产品试用总结/">国内bot产品试用总结</a></h1>
  

    </header>
    <div class="entry">
      
        <p>理想很丰满，现实却很骨感。用这句话来形容当前国内的bot客服机器人最合适不过。本文考察了国内规模较大的6家做bot企业客服业务的公司，从功能描述、客户范围到实际案例进行一下对比和总结。</p>
<h1 id="功能描述"><a href="#功能描述" class="headerlink" title="功能描述"></a>功能描述</h1><p>在各自的网站上都会介绍公司的优势，基本都会包括下面的字眼：</p>
<p>1、海量的知识库储备</p>
<p>2、精准的语义理解能力</p>
<p>3、快速部署能力</p>
<p>4、减轻人工客服压力，节约人力成本</p>
<p>5、无缝衔接人工客服</p>
<p>6、回答准确高极高</p>
<p>7、多渠道</p>
<p>看起来都是非常厉害，都是很牛的技术，理解语义没有任何难度，仿佛真正的bot已经实现了一样，但现实是这样的吗？可能还并不是，可能还需要多年的学术研究来推动这个行业的进步。</p>
<h1 id="客户范围"><a href="#客户范围" class="headerlink" title="客户范围"></a>客户范围</h1><p>客服是一个很大的市场，在各行各业都需要大量的客服人员来做售前和售后咨询，传统的客服面临着一个很尴尬的问题是，总是在回答大量重复的问题，效率很低。很多问题的答案其实可以在企业网站上的FAQ找到，但是消费者仍是喜欢去问客服。在这个背景下，客服bot应运而生，覆盖的行业领域包括：电子商务、游戏网站、政府网站、一般企业等等各行各业。</p>
<h1 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h1><p>使用了他们6家的案例，简单总结一下：</p>
<p>1、大家规模不同，但有一个共同的特点是，宣传中提到为多少多少客户提供服务，但是很多客户的网站中并不能找到相应的bot服务，而且bot公司的网站上并没有给出直接的链接过去，只是说这家客户在用他们的服务。这一点来说，我觉得水分比较大，不够透明。</p>
<p>2、采用的解决方案基本上都是example-based，即bot公司自己的通用知识库+客户的业务知识库。一个用户在使用企业的客服时，很少有无聊的人去调戏人家bot，都是来咨询相关问题的，所以一般来说，bot公司自己的知识库作用非常小，当企业的知识库回答不了现有的问题，bot公司的这种所谓“海量知识库”可以派上用场，和客户逗趣一会，但本质上没有意义。</p>
<p>example-based方案本质上就是信息检索，根据用户的query来找到最合适的example，然后将example中的response返回给用户。用这种方法做一个企业客服bot的话，核心就在构建业务知识库，主要的技术点也在这个地方，最简单的方法是将客户给的历史聊天记录和faq经过一定预处理，生成一个高可用的知识库，扯太多的新概念就有点过分了。明明“快速建知识库”才是核心技术，非要说自己拥有超强的“语义理解”能力。What a shame！</p>
<p>这种方案做出来的效果基本上是一个自动版的faq，可以回到非常有限的问题，如果是企业新遇到的问题，则需要添加知识库，编辑知识库就是个简单的数据库操作，并无高大上，在faq这个层面上，bot确实减少了人力成本。</p>
<p>大多数对用户提出的在知识库范围内的问题都是可以不错地回答，其他的都是在呵呵呵了。但如果在query的理解上有更加深入地研究，比如在语义层面上对query和example进行对比，而不是简单的keyword匹配，在某种程度上会更好地提高服务质量。</p>
<p>大多数的bot将faq写在右侧，鼓励大家选择这样的问法，这其实是一种trick，回避了自身理解query能力的欠缺。有一个网站做的不错，你每次提一个query，他会给你返回四个similar query，这四个都是example中的，让你从中选一个，4选1，正确的几率还是很大的，尤其是他的知识库做的不错的情况下。</p>
<p>3、完全依靠bot是不现实的，毕竟知识库有限，很容易遇到新的问题，每个公司bot都会和人工服务无缝衔接，用户发现bot不靠谱了，可以直接点击人工服务与人沟通。很多企业的bot客服基本上还是主要依靠人工服务，bot的作用太有限了。</p>
<p>4、大家的模式都差不多，可能有的公司技术稍微领先一点，资源多，拿到了一些大单子，行业的名气大，但实际效果来看，媒体的报道和其他一些场合的PR，只是在鼓吹，实际的体验还是很差的。虽然大家的单子很多，利润也可能不少，但能做的事情实在太有限了，一单接一单地做，都说自己是技术公司，但真正的前沿技术很难看到被应用上，用的技术和10年前的研究成果并无太大不同。比如，context的处理，是一个非常有必要但却没有一家做的很好的公司，用户和bot聊了几轮话了，什么信息量都保存和学习不到，只是做了个小型的搜索引擎就敢说是bot了？智能如何体现呢？有点讽刺啊！大家都说学术界太虚，出的paper难用，只能用10年前的技术来做，旧汤换新药而已，但学术界很多的研究都是前瞻性，也很有启发性，不能直接套用并不代表不能借鉴啊，一概而论地说paper无意义有一点短视，有一点为自己技术不过硬找借口了。如果只是这么简单、浮躁的bot解决方案，我觉得在市场上不会有太强的生命力和长远的发展，因为这点技术，大公司稍微做一下都会比这个强，SaaS的特点就是容易接入，技术但凡领先于现在的专业做bot的企业，自然就会取而代之。当然，如果只是为了赚点快钱，这样做是合理的。</p>
<p>5、关于机会，我觉得bot是一个很大的机会，很多人不看好bot的原因是目前做bot采用的技术太过陈旧，效果太差导致。这么说来，机会其实也是从这里来的，正是因为大家的技术都不是太先进，所以才有机会，专注地做好新技术的研发，改善现有bot存在的问题，带给企业客户更优质的服务。先赢都不算赢，最后赢的才是真的赢。</p>
<p>大家都很急着占一个又一个的客户，好像真的占领了这个市场一样。用了这几家的服务之后，感觉有点失望，欲速则不达。 </p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-22T00:27:46.000Z"><a href="/2016/07/21/Attention-with-Intention-for-a-Neural-Network-Conversation-Model-PaperWeekly/">2016-07-21</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/21/Attention-with-Intention-for-a-Neural-Network-Conversation-Model-PaperWeekly/">Attention with Intention for a Neural Network Conversation Model #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-21T18:35:27.000Z"><a href="/2016/07/21/Neural-Contextual-Conversation-Learning-with-Labeled-Question-Answering-Pairs-PaperWeekly/">2016-07-21</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/21/Neural-Contextual-Conversation-Learning-with-Labeled-Question-Answering-Pairs-PaperWeekly/">Neural Contextual Conversation Learning with Labeled Question-Answering Pairs #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-19T00:21:22.000Z"><a href="/2016/07/18/Attention-over-Attention-Neural-Networks-for-Reading-Comprehension-PaperWeekly/">2016-07-18</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/18/Attention-over-Attention-Neural-Networks-for-Reading-Comprehension-PaperWeekly/">Attention-over-Attention Neural Networks for Reading Comprehension #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文分享的文章是arxiv今天刚刚新鲜出炉的paper，来自哈工大讯飞联合实验室。前不久，他们构建了一个大型阅读理解语料，今天也发布出来了。(<a href="http://hfl.iflytek.com/chinese-rc/" target="_blank" rel="external">下载地址</a>)</p>
<p>Cloze-style Reading Comprehension这个领域竞争太过激烈了，半年时间把benchmark刷了一遍又一遍，今天的这篇paper又一次刷新了记录。如果对这个领域不太熟悉的话，可以读这篇<a href="http://rsarxiv.github.io/2016/06/18/%E6%95%99%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%98%85%E8%AF%BB/">教机器学习阅读</a>。</p>
<p>本文的模型被称作Attention over Attention(AoA)，和之前的工作不同，不仅仅考虑query-to-document attention，而且考虑了document-to-query attention。模型架构示意图如下：</p>
<p><img src="media/1.png" alt="1"></p>
<p><b>Contextual Embedding</b> 将query和document都embedding化，用Bi-GRU将query和document分别encode，将两个方向的hidden state拼接起来作为该词的state，此时document和query可以分别用一个Dxd和Qxd的矩阵来表示，这里D是document的词数，Q是query的词数，d是embedding的维度。</p>
<p><b>Pair-wise Matching Score</b> </p>
<p><img src="media/2.png" alt="2"></p>
<p>这一步是本质上就是对两个矩阵做矩阵乘法，得到所谓的Matching Score矩阵M，这里的M矩阵的维度是DxQ，矩阵中的每个元素表示对应document和query中的词之间的matching score。</p>
<p><b>Individual Attentions</b> 对M矩阵中的每一列做softmax归一化，得到所谓的query-to-document attention，即给定一个query词，对document中每个词的attention，本文用下式进行表示：</p>
<p><img src="media/3.png" alt="3"></p>
<p><b>Attention-over-Attention</b> 前三个步骤都是很多模型采用的通用做法，这一步是本文的亮点。首先，第三步是对M矩阵的每一列做了softmax归一化，这里对M矩阵的每一行做softmax归一化，即得到所谓的document-to-query attention，用下式来表示：</p>
<p><img src="media/4.png" alt="4"></p>
<p>然后，将document-to-query attention作平均得到最终的query-level attention，如下式：</p>
<p><img src="media/5.png" alt="5"></p>
<p>最后，用每个query-to-document attention和刚刚得到的query-level attention做点乘，得到document中每个词的score。</p>
<p><b>Final Predictions</b> 将相同词的score合并，得到每个词的score，如下式：</p>
<p><img src="media/6.png" alt="6"></p>
<p>从而得到最终的答案。</p>
<p>实验部分用了英文语料CNN和CBT，在没用pre-trained embedding情况下，单模型得到了state-of-the-art结果。</p>
<p><img src="media/7.png" alt="7"></p>
<p>本文模型最大的特点就是不仅仅考虑query到document的attention，而且考虑了document到query的attention，即所谓的attention over attention，在Cloze-style阅读理解任务中取得了更好的结果。同时，作者在未来的工作中，准备将该模型拓展到其他任务中。</p>
<p>attention是一个非常好的机制，将很多任务的benchmark都提高到了很高的水平，是一个革命性的模型。围绕attention的变种做工作，提出各种各样的attention，虽然可以刷新各种任务，但终究不再能够将研究水平提升一个level，需要一个新的机制、新的思想来推动nlp的发展。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-17T16:57:22.000Z"><a href="/2016/07/17/End-to-end-LSTM-based-dialog-control-optimized-with-supervised-and-reinforcement-learning-PaperWeekly/">2016-07-17</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/17/End-to-end-LSTM-based-dialog-control-optimized-with-supervised-and-reinforcement-learning-PaperWeekly/">End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文介绍的paper一个实用性非常强的解决方案，作者来自于微软研究院，毕业于剑桥大学Spoken Dialogue Group，研究bot很多很多年了。paper的题目是<a href="http://arxiv.org/pdf/1606.01269v1.pdf" target="_blank" rel="external">End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning</a>，最早发表于今年的6月3日。</p>
<p>文章的开头很有意思，先是从一个大家熟知的场景开始介绍，一个经验丰富的客服是如何带一个新入职的客服。四个阶段：</p>
<p>1、告诉新客服哪些”controls”是可用的，比如：如何查找客户的信息，如何确定客户身份等等。<br>2、新客服从老客服做出的good examples中模仿学习。<br>3、新客服开始试着服务客户，老客服及时纠正他的错误。<br>4、老客服放手不管，新客服独自服务客户，不断学习，不断积累经验。</p>
<p>本文的框架就是依照上面的过程进行设计的：</p>
<p>1、开发者提供一系列备选的actions，包括response模板和一些API函数，用来被bot调用。<br>2、由专家提供一系列example dialogues，用RNN来学习。<br>3、用一个模拟user随机产生query，bot进行response，专家进行纠正。<br>4、bot上线服务，与真实客户进行对话，通过反馈来提高bot服务质量。</p>
<p><img src="media/1.png" alt="1"></p>
<p>一个完整的工作流程由上图描述:</p>
<p><img src="media/2.png" alt="2"></p>
<p>本文在训练的时候是用一部分高质量的数据进行监督学习SL，用增强学习RL来优化模型，得到质量更高的结果。并且文中以打电话给指定联系人为应用场景，举了一个实际的例子，来帮助理解本文的思路。</p>
<p>一般来说，很多文章提到end-to-end的模型，都是基于大量训练数据用seq2seq来做response的生成，本文并不是这样，本文的神经网络模型是用来训练action selection的，包括后面用RL policy gradient来提升效果也都是为了选择action。虽然本文不是一个纯粹的end-to-end解决方案，但确实一个非常实用的解决方案，尤其是对于task-oriented bot的业务来说，这样的解决方案更加高效，值得复现，值得在一些细节的地方进行改善，从而真正地减少人工features和人工成本。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-17T05:02:39.000Z"><a href="/2016/07/16/也说bot/">2016-07-16</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/16/也说bot/">也说bot</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>chatbot是最近一段时间非常火的一个词或者一个应用，不仅仅各大新闻媒体在热炒bot的概念，各大巨头也投入巨大的资源进行研发，arxiv上刷出bot相关的paper也更是家常便饭。炒作归炒作，PR归PR，不得不说一个尴尬的事实是市面上确实难以找到一个真正好用的bot。bot按照涉及的领域，分为开放域(open-domain)和面向具体任务(task-oriented)的bot。开放域要做的事情很大，更像是一个什么都能搞的平台，不管你提什么样的需求，它都能够解决，有点true AI的意思，而面向任务的bot则专注做好一件事情，订机票，订餐，办护照等等。</p>
<p>说到开放域bot，大家接触最多的也就是一些回答非常无厘头的娱乐用bot，比如很多年前活跃在各大社交网站上的小黄鸡，现在市面上活跃着很多号称掌握了bot技术，在用深度学习解决bot技术的bot公司，都是这种，解决不了什么实际问题，就是能和大家聊上两句，而且很多时候回答都是牛头不对马嘴的，十分可笑。</p>
<p>再说task-oriented bot，市面上最多的就是客服机器人，银行也好，电商也罢，不想重复性地回答用户的问题，就用一个客服机器人来应对，且不说效果如何，开发一个具体task的bot需要费不少工夫，而且后期还要大量的维护，因为太多的hand crafted features被用到，整个bot的框架横向扩展性相对来说较差，换一个场景基本上就需要重新开发一套，人力成本太高了。</p>
<p>bot的理想非常丰满，大公司描绘的场景也确实很美，但现实的bot却狠狠地浇了一盆冷水下来。期望越高，失望越大。如果媒体一味地吹捧bot，仿佛整个世界明天就会是bot的了，对bot的发展并无益处，捧杀只会带来气泡，破裂之后，一切如初。</p>
<p>功能强大的、开放域的bot在短期内是比较难实现的，但是如果降低期望，将bot不应当做是一种技术层面的革命，而应当做交互层面的革新才是理性的态度，bot作为一种入口，可能大家都不再需要一个随身携带的终端，只需要找到一个可以识别身份，可以联网的硬件，比如一面镜子，就可以执行很多的task，订机票、买东西等等等等。bot这个时候起到的是一个操作的入口和背后执行各种不同task的黑箱，我们不需要看到整个执行过程，也不需要知道原理是什么，通过一些简单的语言交互，就能完成一些复杂的task，终端要做的事情就是反馈结果和接收输入，执行的过程都在云端，各种bot云。</p>
<p>而这一切的关键是解决好task-oriented bot，用更多data driven的解决方案来代替传统的人工features和templates。</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>bot是一个综合性的问题，涉及到下面三个主要问题：</p>
<p>1、response generation(selection)</p>
<p>对话生成是最后一个步骤，是输出的部分。简单总结下，有四种solutions：</p>
<p><b>solution 1</b> 直接根据context来生成对话，这方面最近的paper非常地多，尤其是seq2seq+attention框架席卷了NLP的很多任务之后，对话生成的benchmark也一次又一次地被各种model刷新着。对话生成的问题，被定义为基于某个条件下的生成模型，典型的根据context来predict words，涉及到句子生成的问题，评价问题就会是一个比较难的问题。</p>
<p><b>solution 2</b> 当然有的paper并不是将对话生成定义为语言模型问题，而是一个next utterance selection的问题，一个多选一的问题，给定一个context，给定一个utterance candidate list，从list中选择一个作为response，当然这类问题的难度会小很多，评价起来也非常容易，但是数据集准备起来要多花一些功夫，而且在实际应用中不好被借鉴。</p>
<p><b>solution 3</b> rule-based或者说template-based，response的最终形式其实是填充了一个模板而成的，大多数的东西是给定的，只有一些具体的value需要来填充。这一类解决方案很适合做task-oriented bot，但过多的人工features和templates导致了其难以移植到其他task上。</p>
<p><b>solution 4</b> query-based或者说example-based，response是来自于一个叫做知识库的数据库，里面包含了大量的、丰富的example，根据用户的query，找到最接近的example，将对应的response返回出来作为输出。这一类解决方案非常适合做娱乐、搞笑用的bot，核心技术在于找更多的数据来丰富知识库，来清洗知识库。但毕竟respnose是从别人那里拿出来的，可能会很搞笑，但大多数会牛头不对马嘴。</p>
<p>2、dialog state tracking(DST)</p>
<p>有的paper称DST为belief trackers，这个部件其实是bot的核心，它的作用在于理解或者捕捉user intention或者goal，只有当你真的知道用户需要什么，你才能做出正确的action或者response。关于这个部分，会有Dialog State Tracking Challenge比赛。一般来说都会给定一个state的范围，通过context来predict用户属于哪个state，有什么样的需求，是需要查询天气还是要查询火车票。</p>
<p>3、user modeling</p>
<p>bot面向具体的业务，都是和真实的user来打交道的，如果只是简单的FAQ bot，回答几个常见的问题可能不需要这块，但如果是其他更加复杂、细致的业务，都需要给用户建模，相同的问题，bot给每个人的response一定是不同的，这个道理非常简单。user modeling，需要涉及的不仅仅是简单的用户基本信息和用户的一些显式反馈信息，而更重要的是用户的history conversations，这些隐式的反馈信息。就像是推荐系统火起来之前，大家都是中规中矩地卖东西，但是有一些聪明人开始分析用户的行为，不仅是那些点赞行为，更多的是那些用户不经意间留下的“蛛丝马迹”，从而知道了用户对哪些东西潜在地感兴趣，也就是后来推荐系统在做的事情。对user进行建模，就是做一个个性化的bot，生成的每一个response都有这个user鲜明的特点。</p>
<h1 id="语料"><a href="#语料" class="headerlink" title="语料"></a>语料</h1><p>大型的语料都是用来训练开放域bot对话生成模型的，数据源一般都是来自社交网站。而对于task-oriented bot来说，客户的数据一般规模都非常地小，这也正是难以将data driven的方案直接套用到task-oriented bot上的一个主要原因。</p>
<p>[1]中给出了bot训练语料的survey，感兴趣的同学可以读一下这篇survey。</p>
<p><img src="media/1.png" alt="1"></p>
<p>图来自文章[13]，英文的语料确实比较多，Sina Weibo那个语料是华为诺亚方舟实验室release的[12]。从twitter或者微博上产生bot数据的话，“conversational in nature”效果不如从ubuntu chat logs这种聊天室产生的数据更加适合训练response生成模型，因为更加天然无公害。文章[5]也用了一个大型中文语料，数据来自百度贴吧。</p>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p> 研究bot的paper是在太多了，这是一个非常活跃的研究领域，细分的方向也非常的多，接下来按照所针对的研究问题来分别介绍一些模型。</p>
<h2 id="seq2seq生成模型"><a href="#seq2seq生成模型" class="headerlink" title="seq2seq生成模型"></a>seq2seq生成模型</h2><p> 现在最流行的解决方案是seq2seq+attention，encoder将user query feed进来，输出一个vector representation来表示整个query，然后作为decoder的condition，而decoder本质上就是一个语言模型，一步一步地生成response，[2]采用就是这种方案，google用了海量的参数训练出这么一个模型，得到了一个不错的bot。</p>
<p><img src="media/8.png" alt="8"></p>
<p> 而典型的seq2seq存在一个问题，就是说容易生成一些“呵呵”的response，即一些非常safe，grammatical但没有实际意义的response，比如”I don’t know!”之类的。原因在于传统的seq2seq在decoding过程中都是以MLE(Maximum Likelihood Estimate)为目标函数，即生成最grammatical的话，而不是最有用的话，这些safe句子大量地出现在训练语料中，模型学习了之后，无可避免地总是生成这样的response，而文章[3]借鉴了语音识别的一些经验，在decoding的时候用MMI（Maximum Mutual Information）作为目标函数，提高了response的diversity。</p>
<p> 文章[4]认为类似于RNNLM这样的语言模型在生成人话质量不高的根本原因在于，没有处理好隐藏在utterance中的随机feature或者说noise，从而在生成next token（short term goal）和future tokens（long term goal）效果一般。</p>
<p><img src="media/3.png" alt="3"></p>
<p> 在生成每一个utterance时，需要用到四个部分，encoder RNN、context RNN、latent variable、decoder RNN，按顺序依次输入和输出。这里的latent variable和IR中的LSI有一点异曲同工，latent表明我们说不清他们到底具体是什么，但可能是代表一种topic或者sentiment，是一种降维的表示。</p>
<p> 文章[5]提出了一种叫做content introducing的方法来生成短文本response。</p>
<p><img src="media/4.png" alt="4"></p>
<p><b>step 1</b> 给定query之后，预测一个keyword作为response的topic，这个topic词性是名词，这里的keyword并不能捕捉复杂的语义和语法，而只是根据query的每个词来预估出一个PMI（Pointwise Mutual Information）最高的名词作为keyword.</p>
<p><b>step 2</b> [5]的模型叫做Sequence To Backward and Forward Sequences，首先进行backward step，给定一个query，用encoder表示出来得到一个context，decoder的部分首先给定keyword作为第一个词，然后进行decoding，生成的这部分相当于keyword词前面的部分；接下来进行的是forward step，也是一个典型的seq2seq，用encoder将query表示成context，然后给定backward生成的话和keyword作为decoder的前半部分，继续decoding生成后半部分。整个的流程这样简单描述下：</p>
<p><b>step 1</b> query + keyword =&gt; backward sequence</p>
<p><b>step 2</b> query + keyword + backward sequence(reverse) =&gt; forward sequence</p>
<p><b>step 3</b> response = backward (reverse) sequence + keyword + forward sequence</p>
<h2 id="user-modeling模型"><a href="#user-modeling模型" class="headerlink" title="user modeling模型"></a>user modeling模型</h2><p>文章[6]针对的问题是多轮对话中response不一致的问题，将user identity（比如背景信息、用户画像，年龄等信息）考虑到model中，构建出一个个性化的seq2seq模型，为不同的user，以及同一个user对不同的请将中生成不同风格的response。</p>
<p><img src="media/2.png" alt="2"></p>
<p>[6]的模型叫Speaker Model，是一个典型的seq2seq模型，不同的地方在于在decoding部分增加了一个speaker embedding，类似于word embedding，只是说这里对用户进行建模。因为无法对用户的信息显式地进行建模，所以用了一种embedding的方法，通过训练来得到speaker向量，下面左边的图是speaker向量在二维平面上的表示，具有相似背景信息的user就会很接近，与word向量一个道理。</p>
<h2 id="reinforcement-learning模型"><a href="#reinforcement-learning模型" class="headerlink" title="reinforcement learning模型"></a>reinforcement learning模型</h2><p>用增强学习来解决人机对话问题具有很悠久的历史，只不过随着AlphaGo的炒作，deepmind公司将增强学习重新带回了舞台上面，结合着深度学习来解决一些更难的问题。</p>
<p>增强学习用long term reward作为目标函数，会使得模型通过训练之后可以predict出质量更高的response，文章[7]提出了一个模型框架，具有下面的能力：</p>
<p>1、整合开发者自定义的reward函数，来达到目标。</p>
<p>2、生成一个response之后，可以定量地描述这个response对后续阶段的影响。</p>
<p><img src="media/5.png" alt="5"></p>
<p>两个bot在对话，初始的时候给定一个input message，然后bot1根据input生成5个候选response，依次往下进行，因为每一个input都会产生5个response，随着turn的增加，response会指数增长，这里在每轮对话中，通过sample来选择出5个作为本轮的response。</p>
<p>在一个大型数据集上训练一个效果不错的seq2seq作为初始值，用增强学习来提升模型实现自定义reward函数的能力，以达到期待的效果。</p>
<p>文章[7]的模型可以生成更多轮数的对话，而不至于过早地陷入死循环中，而且生成的对话diversity非常好。</p>
<h2 id="task-oriented-seq2seq模型"><a href="#task-oriented-seq2seq模型" class="headerlink" title="task-oriented seq2seq模型"></a>task-oriented seq2seq模型</h2><p>现有的task-oriented bot多是采用rule-based、template-based或者example-based或者是综合起来用，用data driven的解决方案十分稀有。文章[8]和[9]就是尝试在bot的个别部件上采用深度学习的技术来做，并且给出了切实可行的方案。</p>
<p>文章[8]先是从一个大家熟知的场景开始介绍，一个经验丰富的客服是如何带一个新入职的客服，分为四个阶段：</p>
<p>1、告诉新客服哪些”controls”是可用的，比如：如何查找客户的信息，如何确定客户身份等等。</p>
<p>2、新客服从老客服做出的good examples中模仿学习。</p>
<p>3、新客服开始试着服务客户，老客服及时纠正他的错误。</p>
<p>4、老客服放手不管，新客服独自服务客户，不断学习，不断积累经验。</p>
<p>[8]的模型框架就是依照上面的过程进行设计的：</p>
<p>1、开发者提供一系列备选的actions，包括response模板和一些API函数，用来被bot调用。</p>
<p>2、由专家提供一系列example dialogues，用RNN来学习。</p>
<p>3、用一个模拟user随机产生query，bot进行response，专家进行纠正。</p>
<p>4、bot上线服务，与真实客户进行对话，通过反馈来提高bot服务质量。</p>
<p><img src="media/6.png" alt="6"></p>
<p>一个完整的工作流程由上图描述，具体步骤看下图：</p>
<p><img src="media/12.png" alt="12"></p>
<p>训练的时候是用一部分高质量的数据进行监督学习SL，用增强学习RL来优化模型，得到质量更高的结果。</p>
<p>文章[9]平衡了两种流行方案的优缺点，提出了一套有参考价值的、具有实际意义的seq2seq解决方案。</p>
<p><img src="media/10.png" alt="10"></p>
<p>一共五个组件：</p>
<p>1、 Intent Network</p>
<p>这个部分可以理解为seq2seq的encoder部分，将用户的输入encode成一个vector。</p>
<p>2、 Belief Trackers</p>
<p>又被称为Dialogue State Tracking(DST)，是task-oriented bot的核心部件。本文的Belief Trackers具有以下的作用：</p>
<ul>
<li>支持各种形式的自然语言被映射成一个有限slot-value对集合中的元素，用于在数据库中进行query。</li>
<li>追踪bot的state，避免去学习那些没有信息量的数据。</li>
<li>使用了一种weight tying strategy，可以极大地减少训练数据的需求。</li>
<li>易扩展新的组件。</li>
</ul>
<p>3、 Database Operator</p>
<p>数据库查询的输入来自于Belief Trackers的输出，即各种slot的概率分布，取最大的那个作为DB的输入，进行查询，获取到相应的值。</p>
<p>4、 Policy Network</p>
<p>这个组件是像一个胶水，起到粘合其他上面三个组件的作用。输入是上面三个组件的输出，输出是一个向量。</p>
<p>5、 Generation Network</p>
<p>最后一个组件是生成模型，本质上是一个语言模型，输入是Policy Network的输出，输出是生成的response，再经过一些处理之后可以返回给用户了。这里的处理主要是将response中的slot，比如s.food还原成真实的值。这一步和文章[8]的step 10一样，将具体的值还原到entity上。</p>
<p>完全用end-to-end来解决task-oriented是不可能的事情，一定是在一个框架或者体系内用这种seq2seq的解决方案来做这件事情，文章[8]和[9]给出了很大的启发。</p>
<h2 id="Knowledge-Sources-based模型"><a href="#Knowledge-Sources-based模型" class="headerlink" title="Knowledge Sources based模型"></a>Knowledge Sources based模型</h2><p>纯粹的seq2seq可以解决很多问题，但如果针对具体的任务，在seq2seq的基础上增加一个相关的knowledge sources会让效果好很多。这里的knowledge可以是非结构化的文本源，比如文章[10]中的ubuntu manpages，也可以是结构化的业务数据，比如文章[9]中的database，也可以是一个从源数据和业务数据中提取出的knowledge graph。</p>
<p>文章[10]作者将bot任务定义为next utterance classification，有一点像question answering任务，给定一个context和一个response candidate list作为备选答案，通过context来从candidate list中选择正确的response。本文的贡献在于在context的基础上，引入了task相关的外部专业知识库，并且这个知识库是非结构化的。</p>
<p><img src="media/11.png" alt="11"></p>
<p>模型是三个rnn encoder组成，一个rnn来encode context，一个rnn来encode response，还有一个rnn来encode knowledge，然后综合起来做预测，选出最合适的response。模型被称作knowledge encoder。因为数据集采用的是ubuntu technical support相关的数据集，外部资源就选用了ubuntu manpages。</p>
<h2 id="context-sensitive模型"><a href="#context-sensitive模型" class="headerlink" title="context sensitive模型"></a>context sensitive模型</h2><p>文章[11]的模型比较简单，但考虑的问题意义很大，history information的建模对于bot在解决实际工程应用的帮助很大，也直接决定了你的bot是否能够work。作者将history context用词袋模型表示，而不是我们经常采用的rnn，然后将context和用户query经过一个简单的FNN，得到一个输出。</p>
<p><img src="media/9.png" alt="9"> </p>
<h1 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h1><p>bot response评价很难，虽然说可以借鉴机器翻译的自动评价方法BLEU来做，但效果不会太好。几乎每篇paper都是会花钱雇人来做人工评价，设计一套评价机制来打分，人工的评价更具有说服力。对于实际工程应用更是如此，用户说好才是真的好。而不是简单地拿着自己提的、有偏的指标，和几个方法或者其他公司的bot进行对比，来说明自己好。</p>
<h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><p>读了一些paper，也和一线在做bot应用的工程师交流之后，有了一点思考，总结如下：</p>
<p>1、要不要做bot？流行一种说法是市面上没有好用的bot，要解决bot的问题需要很多技术同时进步，可能还需要非常长的一段时间，现在用这个东西来做business，简直荒谬。我个人的看法是，解决具体task的bot，结合当前先进的技术，做一些框架性的工具，并不是那么遥远的事情，虽然不容易，但却非常有意义，解决了垂直领域的bot问题，才有可能解决open domain的bot问题。也正是因为不容易，提高了门槛，才会出现真正的机会，诞生一些很牛的技术公司。</p>
<p>2、open domain还是task-oriented？如果是我，我会选后者，因为前者只是一个梦想，一个遥不可及的梦想，需要更多的技术层面上的大突破。task-oriented更加具体，更加实用，针对具体的业务，提供一些解决方案，已经有很多企业在做了，虽然一个通用性或者扩展性强的解决方案还没有出现，但一定是一个趋势，也是新一代做bot的公司的机会。</p>
<p>3、task-oriented bot为什么难，该朝哪个方向来发力？end-to-end是一种理想化的模型，用深度学习模型从大量训练数据中来“捕捉”一些features，“拟合”一些函数，虽然可以得到很不错的效果，而且使用起来确实很方便，但尴尬就尴尬在具体的task中是拿不到海量数据的，数据规模小了之后，纯粹的end-to-end就变得非常鸡肋了。然而真实的场景中，很多企业又有一定的数据，也有bot的需求，所以现在成熟的解决方案就是针对你的具体业务，来设计一些features，templates和rules，当客户的业务发生更改时，需要不断地维护现有的bot系统，十分费时费力。真实的场景中往往涉及到很多结构化的业务数据，纯粹地、暴力地直接根据context生成response是不可能做到的，文章[8][9]都给出了非常有启发性的解决方案，将end-to-end应用在局部，而非整体上，配合上Information Extraction和Knowledge Graph等技术，实现一个高可用的框架体系，这个应该是task-oriented bot的发展方向。</p>
<p>4、response的生成应该与哪些因素有关呢？response质量的好坏，需要联系到这几个features：（1）user query，用户的提问，用户在这轮对话中到底在问什么，准确地理解用户的意图，这是至关重要的。（2）user modeling，对用户进行建模，包括用户的基本信息，还有更重要的是用户history conversation logs的mining，这个工作很难，但同时也很见水平，也是一家技术公司证明自己技术牛逼的一种途径。logs的挖掘现在很常见，不见得大家都做的很好，而这里的logs不是一般的设定好的、结构化的指标，而是非结构化的文本logs，挖掘起来难度更大。另外一点，也是paper种看到的，user emotion，情感分析是nlp中研究比较多的task，用户的情绪直接关系到销售的成败，如果技术足够牛，可以考虑的因素就可以足够多，对user的分析也就足够清晰。将history生挂在模型中不是一个好办法，因为history是不断增长，会导致模型在捕捉信息时出现问题，更好的办法可能是build user profile之类的东西，将history沉淀出来，作为一个vector representation，或者一种knowledge graph来表征一个user。有了这种能力的bot，说的冠冕堂皇一点就是个性化的bot。（3）knowledge，外部知识源，涉及到具体业务的时候，业务数据也是一种knowledge，如何将knowledge建模到模型中，在生成对话的时候可以更加专业和准确也是一个非常重要的问题。bot是一个综合性的难题，不仅仅是系统框架上的难，而且是建模上的难。</p>
<p>5、我一直觉得做人和看问题都不可以极端，世界并非非黑即白，而是介于两者之间的连续值。不可能说要么做成一个open-domain巨无霸的bot，要么就是一个什么具体功能都没有的bot，不能只看到现有的bot不成熟，以及幻想中的bot遥不可及，就开始黑这个领域，还嘲笑人家能够居然拿到投资。争吵这些毫无意义，真正有意义的是深挖这个领域，找到痛点和难点，逐个击破，不断地推进这个领域的发展，而不是像一些街边看热闹的人一样，简直无趣！在很多领域突破之前，仿佛都看不到曙光，但几年之后很多当时难以解决的问题不都是红海一片，满大街都是了么？做一个通用的bot可能很长一段时间内都是一件比较困难的事情，但做一个高可用、扩展性不错的bot解决方案还是有盼头的，不必过度自信，也不必妄自菲薄，踏踏实实地做就是了。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://arxiv.org/pdf/1512.05742.pdf" target="_blank" rel="external">A Survey of Available Corpora for Building Data-Driven Dialogue Systems</a></p>
<p>[2] <a href="http://cn.arxiv.org/pdf/1506.05869.pdf" target="_blank" rel="external">A Neural Conversational Model</a></p>
<p>[3] <a href="http://arxiv.org/pdf/1510.03055v1.pdf" target="_blank" rel="external">A Diversity-Promoting Objective Function for Neural Conversation Models</a></p>
<p>[4] <a href="https://arxiv.org/pdf/1605.06069v3.pdf" target="_blank" rel="external">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</a></p>
<p>[5] <a href="http://cn.arxiv.org/pdf/1607.00970" target="_blank" rel="external">Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation</a></p>
<p>[6] <a href="https://arxiv.org/pdf/1603.06155.pdf" target="_blank" rel="external">A Persona-Based Neural Conversation Model</a></p>
<p>[7] <a href="http://arxiv.org/pdf/1606.01541v3.pdf" target="_blank" rel="external">Deep Reinforcement Learning for Dialogue Generation</a></p>
<p>[8] <a href="http://arxiv.org/pdf/1606.01269v1.pdf" target="_blank" rel="external">End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning</a></p>
<p>[9] <a href="http://arxiv.org/pdf/1604.04562v2.pdf" target="_blank" rel="external">A Network-based End-to-End Trainable Task-oriented Dialogue System</a></p>
<p>[10] <a href="http://media.wix.com/ugd/b6d786_137894b7b3a341a09ed0c0b45b46dbb6.pdf" target="_blank" rel="external">Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue Systems</a></p>
<p>[11] <a href="https://michaelauli.github.io/papers/chitchat.pdf" target="_blank" rel="external">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</a></p>
<p>[12] <a href="http://staff.ustc.edu.cn/~cheneh/paper_pdf/2013/HaoWang.pdf" target="_blank" rel="external">A Dataset for Research on Short-Text Conversation</a></p>
<p>[13] <a href="http://arxiv.org/pdf/1506.08909v3.pdf" target="_blank" rel="external">The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems</a></p>
<h1 id="研究组和研究人员"><a href="#研究组和研究人员" class="headerlink" title="研究组和研究人员"></a>研究组和研究人员</h1><p>bot是一个非常活跃的研究领域，全世界有很多的人都在做相关的研究。下面列的是最近所读paper的作者或者所在的group：</p>
<p>[1] <a href="http://mi.eng.cam.ac.uk/research/dialogue/" target="_blank" rel="external">Cambridge Dialogue Systems Group</a></p>
<p>[2] <a href="http://www.noahlab.com.hk/topics/ShortTextConversation" target="_blank" rel="external">Huawei NOAH’S ARK LAB</a></p>
<p>[3] <a href="http://web.stanford.edu/~jiweil/" target="_blank" rel="external">Jiwei Li</a></p>
<p>[4] <a href="http://cs.mcgill.ca/~rlowe1/" target="_blank" rel="external">Ryan Lowe</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-15T22:56:35.000Z"><a href="/2016/07/15/A-Neural-Network-Approach-to-Context-Sensitive-Generation-of-Conversational-Responses-PaperWeekly/">2016-07-15</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/15/A-Neural-Network-Approach-to-Context-Sensitive-Generation-of-Conversational-Responses-PaperWeekly/">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文分享的这篇paper是旨在训练一个data driven open-domain的bot，在生成response的时候不仅仅考虑user message（query），而且考虑past history作为context。paper的题目是<a href="https://michaelauli.github.io/papers/chitchat.pdf" target="_blank" rel="external">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</a>，作者来自蒙特利尔大学、乔治亚理工、facebook和微软研究院，本文最早发于2015年6月。</p>
<p>开放域的端到端response生成在今年已经不是什么新鲜事了，各种复杂的网络，考虑各种各样的信息，然而在去年的这个时候，本文就提出了一种data driven的解决方案，是一篇有开创性的paper。</p>
<p>bot的几大核心问题，包括：</p>
<p>1、response generation（或者selection）</p>
<p>2、dialogue state tracking</p>
<p>3、user modeling</p>
<p>不管是开域的还是闭域的bot都需要解决好以上三个问题才能做出一个高质量的bot。本文针对的问题是第一个，用的思路也是现在看来比较自然的一种，用语言模型来生成response。</p>
<p>考虑history utterances的responses生成问题，先定义一些参数，m表示message（query），c表示context，r表示response。本文要解决的其实是下面这个问题：</p>
<p><img src="media/1.png" alt="1"></p>
<p>1、Tripled Language Model </p>
<p>将c，m，r作为一句话来理解，给定c和m之后，不断地生成r的内容。<br>这个模型存在一个比较严重的问题是c如果过长的话，用BPTT训练不了RNNLM。（其实换作LSTM或者GRU单元就会好很多。）</p>
<p>2、Dynamic-Context Generative Model I </p>
<p><img src="media/2-1.png" alt="2"></p>
<p>将c和m用词袋模型表示，然后拼接起来，作为输入，通过一个简单的FNN，得到输出，即c和m vector representation。</p>
<p>3、Dynamic-Context Generative Model II</p>
<p><img src="media/3-1.png" alt="3"></p>
<p>与2不同的地方在于，将c和m单独作为输入，通过一个简单的FNN，得到c和m的vector representation。</p>
<p>这篇paper针对的问题很有意义，history information的建模对于bot在解决实际工程应用的时候意义重大，会让你的bot看起来更加的智能，和分析了用户日志的web应用会带来更好的服务是一个道理。本文的将具体的context包含到了模型中，在真正应用的时候，离线系统根据user conversation logs build一个user profile会更加实用，因为确实不可能把所有的history都丢到模型中一起来算。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-15T19:44:07.000Z"><a href="/2016/07/15/Incorporating-Unstructured-Textual-Knowledge-Sources-into-Neural-Dialogue-Systems-PaperWeekly/">2016-07-15</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/15/Incorporating-Unstructured-Textual-Knowledge-Sources-into-Neural-Dialogue-Systems-PaperWeekly/">Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue Systems #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文是Ubuntu Dialogue Corpus贡献者的一篇文章，是接着Ubuntu数据集benchmark的model继续改进了一下。本文的题目是<a href="http://media.wix.com/ugd/b6d786_137894b7b3a341a09ed0c0b45b46dbb6.pdf" target="_blank" rel="external">Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue</a>。作者是来自麦吉尔大学的博士生<a href="http://cs.mcgill.ca/~rlowe1/" target="_blank" rel="external">Ryan Lowe</a>。</p>
<p>作者将bot任务定义为next utterance classification，有一点像question answering任务，给定一个context和一个response candidate list作为备选答案，通过context来从candidate list中选择正确的response。本文的贡献在于在context的基础上，引入了task相关的外部专业知识库，并且这个知识库是非结构化的。</p>
<p><img src="media/2.png" alt="2"></p>
<p>这个模型是ubuntu corpus中的baseline模型，称为dual encoder，一个rnn来encode context，一个rnn来encode response，然后综合起来做预测。</p>
<p><img src="media/1.png" alt="1"></p>
<p>本文模型相当于在dual encoder基础上增加了一个knowledge部分。模型是三个rnn encoder组成，一个rnn来encode context，一个rnn来encode response，还有一个rnn来encode knowledge，然后综合起来做预测，选出最合适的response。模型被称作knowledge encoder。</p>
<p>因为是ubuntu technical support相关的数据集，外部资源就选用了Ubuntu Manpages，各种命令的手册，通过从context中提取entity来匹配最相关的command manpage，为了快速定位manpage，用了hash的方法，先做了一个command entity hashtable和relation hashtable，一个是为了完全匹配，一个是为了相关匹配。得到相关的manpage之后，所包括的文本就是knowledge。效果如下图：</p>
<p><img src="media/3.png" alt="3"></p>
<p>本文定义的问题太过简单，与实际应用相去甚远。但本文用非结构化的外部知识来解决task-oriented bot问题的思路值得借鉴，不仅仅是bot问题，在问答系统中，外部知识如何应用，如何与神经网络模型结合起来使用都是一个非常重要的topic，也是真正可以用来解决实际问题的一种重要手段。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-15T04:00:30.000Z"><a href="/2016/07/14/The-Ubuntu-Dialogue-Corpus-A-Large-Dataset-for-Research-in-Unstructured-Multi-Turn-Dialogue-Systems-PaperWeekly/">2016-07-14</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/14/The-Ubuntu-Dialogue-Corpus-A-Large-Dataset-for-Research-in-Unstructured-Multi-Turn-Dialogue-Systems-PaperWeekly/">The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文分享的paper构建了一组大型非结构化的、多轮的对话系统语料，使用的原始数据来自<a href="https://irclogs.ubuntu.com/" target="_blank" rel="external">Ubuntu IRC Logs</a>，是一些关于Ubuntu的讨论组聊天数据。paper的题目是<a href="http://arxiv.org/pdf/1506.08909v3.pdf" target="_blank" rel="external">The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems</a>，作者是来自蒙特利尔大学的博士生<a href="http://cs.mcgill.ca/~rlowe1/" target="_blank" rel="external">Ryan Lowe</a>。</p>
<p>数据规模在100万左右，平均每组数据有8轮对话，最少包括3轮对话。之前的bot语料包括：Dialogue State Tracking Challenge(DSTC)、SwitchBoard这类结构化的数据和Twitter、Sina Weibo这种非结构化的数据，前者专注于预测用户的需求和状态，而后者数据中包括了一定数量的非“conversational in nature”，做bot的训练数据并不那么合适。本文构建的数据集是一个特定领域内的数据，ubuntu technical conversations，规模很大，对话轮数很多，质量很高，也是后续很多paper在研究bot response问题时常常采用的corpus。</p>
<p><img src="media/1.png" alt="1"></p>
<p>语料的构建非常有意义，大型的语料可以训练更加复杂的、偏向open domain的bot model，小型的语料可以解决具体的工程应用问题，如何从杂乱无章的unstructured data中提取出有用的信息，构造出一个适合训练、测试的数据集是一个很难却十分有意义的工作。</p>
<p>本文需要的数据是多轮的、两人的对话数据，但原始的数据是多人无序的对话数据，作者采用了一些小的技巧，并且忽略了一些不合适的数据，将原始数据处理成一个四元组：</p>
<p>(time,sender,recipient,utterance)</p>
<p>在构造模型的训练和测试集时，作者将上面的四元组处理成下面的三元组：</p>
<p>(context,response,flag)</p>
<p>context类似于用户输入，flag表示response是否是context相关联的，关联则为1，否则为0。</p>
<p>给定了数据集，下面就是作者提供的benchmark model，三个非常简单的model，tf-idf，rnn和lstm，目的是为了从response candidates中选择k个最适合context的response作为答案，然后计算相应的准确率。paper中给的方法是selection的方法，而不是generation，后面的很多研究都是generation，真正地从user query生成response。</p>
<p>本文提供的ubuntu dialogue corpus对于task-oriented、response generation的研究有着非常重要的意义，相比于华为给的微博数据，有更强的conversational in nature特征，更加适合对话生成的研究。本文作者的另外一篇survey文章<a href="http://arxiv.org/pdf/1512.05742.pdf" target="_blank" rel="external">A Survey of Available Corpora for Building Data-Driven Dialogue Systems</a>,系统地介绍了各大数据集。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-14T17:28:16.000Z"><a href="/2016/07/14/随笔/">2016-07-14</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/14/随笔/">随笔</a></h1>
  

    </header>
    <div class="entry">
      
        <p>这篇文章的题目有些难产，一直想不出叫一个什么名字好。想写写最近看的东西的一点思考，也想写写一些别的东西，很纠结。以前写文章都喜欢用豆瓣fm推荐的第一首歌作为题目，然后开始写，虽然写的内容可能与题目毫无关系，但却不纠结。听着豆瓣fm，写着blog，是一种很多年的习惯了，习惯是一种可怕的东西，养成了之后就会一直这么做，一点都不能变，不然就会不舒服。</p>
<p>人之所以开心地活在这个世界上是因为大家有很多有意思的事情要做，人之所以害怕离开这个世界是因为很多有意思的事情还没做就结束了。不管现在的状况是怎样，心中充满希望就会不一样。有的人说生活不重要，家庭不重要，只有事业最重要，顾及儿女情长没有什么出息，实在不敢苟同，没有了坚实的地基，空中楼阁再漂亮又有何用？生活的目的就是生活本身，而不是虚伪地活给谁看，和谁比较，与谁相争，向谁证明。</p>
<p>我想用一个比喻来形容我遇到我的爱人可能会比较恰当。从前，有一只在一个无形的笼子里飞来飞去的鸟，他看着地上的人们心中总是有一种优越感，以为自己看得到整个世界，浑然不知自己身在牢笼中。后来来了另外一只鸟，一只特别好看的鸟，帮他打开了笼子，带着他飞向了一个真正广阔的天空，带着他到处飞翔，他才恍然大悟，原来世界可以这么大，于是他们开始了属于他们的旅途。世界很大，而我们很小，我们的格局很小，我们的心胸很小，我们看到的世界很小。世界很有趣，生活也不只是油盐酱醋，也不只是眼前的苟且，还有诗和远方。她用心准备婚礼的每一个细节，请帖用了一种古代西方信件的方式，用融化的蜡块来粘合信封，并且盖上我们俩专属的印章；回礼是一个精美的多肉植物，一盆一盆地种下、包好；喜糖是精心挑选的几种糖果，用一个手工纸袋包装好，过程很麻烦，但是她很享受，你要知道，可不是只做一份、十份，是要只做150份左右，她很享受这样的过程，因为她在用她的双手实现她感兴趣的事情，乐在其中。</p>
<p>世界可以灰暗，也可以很美好，决定于你是一个怎样的人，遇见一个怎样的人。很多人的生活每天都是在钱钱钱的争吵中度过的，永远没一个够，多少钱算多呢？人的欲望又能用多少钱来满足呢？生活可以很糟糕，也可以很美好，取决于你的追求，你所追求的是一种怎样的状态。欲望简单但不乏丰富多彩的生活才是真正高质量的生活，你内心保留地纯粹和纯真越多，生活质量就会越高，相反都会生活地很累，觉得生活都是负担。生活的目的就是生活本身，享受生活就是享受生活中的每一个细节，做一顿大餐，开一个小型音乐party，到录音棚录一首歌曲，看一场演唱会，听一场相声，看一场话剧，拍一些照片，吃一些好吃的垃圾食品，带着hare到处走走，吐槽一些烂剧，开始一场说走就走的旅行。生活中如果只有一个目的，只有工作这一件事情重要的话，那么生活本身就失去了意义，你赚钱也就失去了意义，有的人会说我不努力工作，不赚更多的钱怎么生活，完全可以40或50岁之后再开始享受生活。</p>
<p>最近看bot方面的paper，简单说一下对bot的一点naive的理解。bot火是不争的事实，也是一个必然的趋势，可能做成一个true ai的bot是一件遥不可及的事情，但做出一个能够解决实际问题，提升大家效率的bot是指日可待的事情。我觉得大家对bot的期许不应该是一个什么都能解决的通用工具或者通用技术，如果媒体地热炒加上民众过高的期待会造成新一轮的人工智能寒潮，对这个领域并不是好事。大家可以认为bot是一种新的交互方式，是一种新的操作入口，就像互联网，就像操作系统一样，是一种新的模式，在这种模式背后有大量先进的人工智能技术在做支撑。用户在任何一个地方都不再需要一个特定的终端来做一些常规的事情（不是所有的事情），只需要找一个联网的bot（可能是一个手机，可能是一面镜子，可能是一个电话亭，只要能联网并识别用户身份）就可以完成了，bot执行的过程不需要透明，只需要给出一个结果反馈就可以了，大家的生活围绕着各种各样垂直的bot来展开，只需要最简单的交互就可以完成之前需要复杂操作的事情，比如办个护照，买个机票。如果一个事情很难做的话，我们通常会将其分解成多个容易的事情，逐个攻破，不用期许过高，但相信bot一定会给大家的生活带来一次革命。</p>
<p>bot是一个很大的市场，如果真的能做成一个入口式的平台，相当于重新开辟了一个新的市场，重新定义了这个世界，任何的软件和应用都需要换一种形式，来为用户提供服务。bot确实是一个很美好的梦想，也不是那么遥不可及，但也不是那么容易，那么触手可及。还是需要大量的研究人员不断地努力，攻克难题。现在很多公司都在做bot领域的技术积累和市场占坑，以方便在日后新的一轮机会到来之时，分一杯羹。当前bot的平台有几家大企业在做，但整体来说还是将bot作为一种交互方式，将命令菜单化，并不是真正的对话，有一点iffft的感觉，但确实很多企业也在用这样的平台，大家都是在占坑。bot虽热，但并不是媒体热炒的那样，还是有很多的坑在里面，只有对其进行深入地思考和理解，保持一种冷静和独立地思考，才能真正地抓到痛点和需求，而不是一味地盲目跟随。技术的积累非常重要，因为真正要瓜分市场还是要很高门槛的，不是说你做一个简单的陪聊、逗乐用的机器人就掌握了bot核心技术，真的没有这么简单。周末的时候，准备对最近读bot paper的一些思考，写一篇survey。</p>
<p>美好的生活就是做喜欢的事情，比如亲手构建一个美好的世界，一个bot化的世界，一个更加简便、纯粹的世界。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-13T18:19:26.000Z"><a href="/2016/07/13/A-Hierarchical-Latent-Variable-Encoder-Decoder-Model-for-Generating-Dialogues-PaperWeekly/">2016-07-13</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/13/A-Hierarchical-Latent-Variable-Encoder-Decoder-Model-for-Generating-Dialogues-PaperWeekly/">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文分享的paper旨在解决语言模型生成部分存在的问题，并且以bot为应用背景进行了实验。paper的题目是<a href="https://arxiv.org/pdf/1605.06069v3.pdf" target="_blank" rel="external">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</a>，作者来自蒙特利尔大学和Maluuba公司，这家公司的研究水平非常地高，arxiv上常常可以刷出高质量的paper。</p>
<p>通常来讲，自然语言对话都会包含两个层次的结构，一个是utterance，由语言的局部统计信息来表征其含义，一个是topic，由一些随机的特征来表征。本文的工作就是对这些utterance中存在的随机特征进行建模，从而提高语言模型生成人类语言时的质量。本文认为，类似于RNNLM这样的语言模型在生成人话质量不高的根本原因在于，没有处理好隐藏在utterance中的随机feature或者说noise，从而在生成next token（short term goal）和future tokens（long term goal）效果一般。</p>
<p>本文的模型Latent Variable Hierarchical Recurrent Encoder Decoder(VHRED)，在生成过程中分为两步：</p>
<p>step 1 随机采样latent variables</p>
<p>step 2 生成输出序列</p>
<p>架构示意图见下图：</p>
<p><img src="media/1.png" alt="1"></p>
<p>在生成每一个utterance时，需要用到四个部分，encoder RNN、context RNN、latent variable、decoder RNN，按顺序依次输入和输出。这里的latent variable和IR中的LSI有一点异曲同工，latent表明我们说不清他们到底具体是什么，但可能是代表一种topic或者sentiment，是一种降维的表示。</p>
<p>实验部分，选择了bot作为应用背景，得到了不错的效果。见下图：</p>
<p><img src="media/2.png" alt="2"></p>
<p>本文解决的不仅仅是bot领域对话生成的问题，而是整个seq2seq框架中decoder的问题，只要涉及到decoder生成的部分都可以采用本文的思想来解决问题。latent topic是一个非常有意思的东西，在LSI、推荐系统中都有非常重要的意义，矩阵分解之后得到两个降维之后的矩阵，从一组两个维度映射到了两组两个维度，也就是多了所谓的latent topic，说不清这些topic是什么，但的确可以将相似的东西聚到了一起。本文也是用latent topic来描述隐藏在utterance中那些说不清道不明的随机noise，得到了更好的效果。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-12T22:11:19.000Z"><a href="/2016/07/12/A-Network-based-End-to-End-Trainable-Task-oriented-Dialogue-System-PaperWeekly/">2016-07-12</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/12/A-Network-based-End-to-End-Trainable-Task-oriented-Dialogue-System-PaperWeekly/">A Network-based End-to-End Trainable Task-oriented Dialogue System #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>构建一个task-oriented的bot，比如订票，技术支持服务等等，是一件非常难的事情，因为对于特定任务，训练数据会非常非常有限。在学术界，bot领域现在最流行的解决方案之一是seq2seq，在一个非常庞大的open-domain数据集上进行训练，得到一些效果不错的模型，但难以应用到具体task中，因为这类模型无法做到与数据库交互以及整合其他有用的信息，从而生成实用的response。还有一种非常流行的方案是reinforcement learning，上一篇分享的paper<a href="http://rsarxiv.github.io/2016/07/11/Deep-Reinforcement-Learning-for-Dialogue-Generation-PaperWeekly/">Deep Reinforcement Learning for Dialogue Generation</a>将两者有机地结合在了一起，增强学习可以使得response生成时考虑更长远的影响。</p>
<p>本文将分享的这篇paper，针对task-oriented的bot问题，平衡了两种流行方案的优缺点，提出了一套有参考价值的、具有实际意义的seq2seq解决方案。paper的题目是<a href="http://arxiv.org/pdf/1604.04562v2.pdf" target="_blank" rel="external">A Network-based End-to-End Trainable Task-oriented Dialogue System</a>，本文于2016年5月20日发表于arxiv上，作者是来自剑桥大学Dialogue System Group的博士生<a href="http://mi.eng.cam.ac.uk/~thw28/" target="_blank" rel="external">Tsung-Hsien Wen</a>，该组专门研究chatbot相关技术，发表过大量与之相关的paper，后续会更多地关注该组的工作。</p>
<p><img src="media/1.png" alt="1"></p>
<p>上图是本文方案的架构示意图，分为五个部分。下面分别进行介绍：</p>
<p>1、Intent Network</p>
<p>这个部分可以理解为seq2seq的encoder部分，将用户的输入encode成一个vector z(t)。encoder部分分别用了lstm和cnn两种模型对该输入进行建模。这两种句子表示的方法在之前的文章中都有介绍。</p>
<p>2、Belief Trackers</p>
<p>这个部分又被称作是Dialogue State Tracking(DST)，是task-oriented bot的核心部件。本文的Belief Trackers具有以下的作用：</p>
<ul>
<li><p>支持各种形式的自然语言被映射成一个有限slot-value对集合中的元素，用于在数据库中进行query。</p>
</li>
<li><p>追踪bot的state，避免去学习那些没有信息量的数据。</p>
</li>
<li><p>使用了一种weight tying strategy，可以极大地减少训练数据的需求。</p>
</li>
<li><p>易扩展新的组件。</p>
</li>
</ul>
<p><img src="media/2.png" alt="2"></p>
<p>这个组件的输入时用户的input，输出是一个informable slot和requestable slot的概率分布，这里的informable slot是指food，price range和area（以订餐为例），用来约束数据库中的查询，requestable slot是指address，phone，postcode等一些可以被询问的值。这里会定义一个针对具体task的知识图谱，来表示这些slot之间的关系，每个slot都会定义一个tracker，tracker的模型如上图所示，包括一个CNN特征提取模块和一个Jordan型的RNN模块，CNN不仅仅对当前的input进行处理，还对上一轮的user input进行处理，综合起来作为RNN的输入。</p>
<p>这个组件的意义在于获取到预先定好的知识图谱中每个slot的分布，就是说弄清楚用户在这轮对话中的需求是哪个词或者词组。</p>
<p>3、Database Operator</p>
<p>数据库查询的输入来自于Belief Trackers的输出，即各种slot的概率分布，取最大的那个作为DB的输入，进行查询，获取到相应的值。</p>
<p>4、Policy Network</p>
<p>这个组件是像一个胶水，起到粘合其他上面三个组件的作用。输入是上面三个组件的输出，输出是一个向量。</p>
<p>5、Generation Network </p>
<p>最后一个组件是生成模型，本质上是一个语言模型，输入是Policy Network的输出，输出是生成的response，再经过一些处理之后可以返回给用户了。这里的处理主要是将response中的slot，比如s.food还原成真实的值。生成部分用简单的LSTM-LM可以做，用Attention Model也可以做，效果会更好。</p>
<p>数据的准备这部分，利用了众包进行收集，一共采用了680轮对话作为训练数据，数据库中保存了99个饭馆，3个informable slots和7个requestable slots。</p>
<p>训练分为两个阶段，第一阶段是训练belief trackers，得到模型之后，更新参数，对生成网络中的语言模型进行训练，得到full model，batch size取1。</p>
<p>bot模型自动评价这块是一个非常难的事情，本文选择了BLEU score、entity matching rate和objective task success rate，本文模型均取得了不错的结果。另外，通过人工评价对本文模型和rule-based进行了对比，结果看下图：</p>
<p><img src="media/3.png" alt="3"></p>
<p>最后paper给出了一种生成的句子向量的二维图，如下图：</p>
<p><img src="media/4.png" alt="4"></p>
<p>几乎同一类话都被聚集到了相似的位置上，验证了模型的有效性。</p>
<p>开放域的bot只是根据query生成一句response，虽然质量可以做到很高，但实用价值不大。面向具体业务的闭域bot一直难以应用seq2seq的解决方案在于，无法将大量的专业信息建模到模型中来，包括：历史信息，用户身份信息，业务信息等等，本文打开了一扇窗，就是将具体的业务信息和历史信息加到了模型中，并且通过将对话中的slot词转换为一些slot表示，就好比构建了很多的模板，降低了对训练数据的需求，避免了seq2seq在应用时存在的问题。如果再考虑上Jiwei Li的那篇<a href="http://rsarxiv.github.io/2016/07/10/A-Persona-Based-Neural-Conversation-Model-PaperWeekly/">A Persona-Based Neural Conversation Model</a>中对用户信息的建模，bot的实用价值就会更大，用data来解决真正的业务问题就会更进一步。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-11T23:47:50.000Z"><a href="/2016/07/11/Deep-Reinforcement-Learning-for-Dialogue-Generation-PaperWeekly/">2016-07-11</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/11/Deep-Reinforcement-Learning-for-Dialogue-Generation-PaperWeekly/">Deep Reinforcement Learning for Dialogue Generation #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文将会分享一篇深度增强学习在bot中应用的文章，增强学习在很早的时候就应用于bot中来解决一些实际问题，最近几年开始流行深度增强学习，本文作者将其引入到最新的bot问题中。paper的题目是<a href="http://arxiv.org/pdf/1606.01541v3.pdf" target="_blank" rel="external">Deep Reinforcement Learning for Dialogue Generation</a>，作者是Jiwei Li，最早于2016年6月10日发在arxiv上。</p>
<p>现在学术界中bot领域流行的解决方案是seq2seq，本文针对这种方案抛出两个问题：</p>
<p>1、用MLE作为目标函数会导致容易生成类似于“呵呵呵”的reply，grammatical、safe但是没有营养，没有实际意义的话。</p>
<p>2、用MLE作为目标函数容易引起对话的死循环，如下图：</p>
<p><img src="media/1.png" alt="1"></p>
<p>解决这样的问题需要bot框架具备以下的能力：</p>
<p>1、整合开发者自定义的回报函数，来达到目标。</p>
<p>2、生成一个reply之后，可以定量地描述这个reply对后续阶段的影响。</p>
<p>所以，本文提出用seq2seq+增强学习的思路来解决这个问题。</p>
<p>说到增强学习，就不得不提增强学习的四元素：</p>
<ul>
<li>Action</li>
</ul>
<p>这里的action是指生成的reply，action空间是无限大的，因为可以reply可以是任意长度的文本序列。</p>
<ul>
<li>State</li>
</ul>
<p>这里的state是指[pi,qi]，即上一轮两个人的对话表示。</p>
<ul>
<li>Policy</li>
</ul>
<p>policy是指给定state之后各个action的概率分布。可以表示为：pRL(pi+1|pi, qi)</p>
<ul>
<li>Reward</li>
</ul>
<p>reward表示每个action获得的回报，本文自定义了三种reward。 </p>
<p>1、Ease of Answering</p>
<p>这个reward指标主要是说生成的reply一定是容易被回答的。本文用下面的公式来计算容易的程度：</p>
<p><img src="media/2.png" alt="2"></p>
<p>其实就是给定这个reply之后，生成的下一个reply是dull的概率大小。这里所谓的dull就是指一些“呵呵呵”的reply，比如“I don’t know what you are talking about”等没有什么营养的话，作者手动给出了这样的一个dull列表。</p>
<p>2、Information Flow</p>
<p>生成的reply尽量和之前的不要重复。</p>
<p><img src="media/3.png" alt="3"></p>
<p>这里的h是bot的reply表示，i和i+1表示该bot的前后两轮。这个式子表示同一个bot两轮的对话越像reward越小。</p>
<p>3、Semantic Coherence</p>
<p>这个指标是用来衡量生成reply是否grammatical和coherent。如果只有前两个指标，很有可能会得到更高的reward，但是生成的句子并不连贯或者说不成一个自然句子。</p>
<p><img src="media/4.png" alt="4"></p>
<p>这里采用互信息来确保生成的reply具有连贯性。</p>
<p>最终的reward由这三部分加权求和计算得到。</p>
<p>增强学习的几个要素介绍完之后，接下来就是如何仿真的问题，本文采用两个bot相互对话的方式进行。</p>
<p><b>step 1</b> 监督学习。将数据中的每轮对话当做target，将之前的两句对话当做source进行seq2seq训练得到模型，这一步的结果作为第二步的初值。</p>
<p><b>step 2</b> 增强学习。因为seq2seq会容易生成dull reply，如果直接用seq2seq的结果将会导致增强学习这部分产生的reply也不是非常的diversity，从而无法产生高质量的reply。所以，这里用MMI(Maximum Mutual Information，这里与之前Jiwei Li的两篇paper做法一致)来生成更加diversity的reply，然后将生成最大互信息reply的问题转换为一个增强学习问题，这里的互信息score作为reward的一部分（r3）。用第一步训练好的模型来初始化policy模型，给定输入[pi,qi]，生成一个候选列表作为action集合，集合中的每个reply都计算出其MMI score，这个score作为reward反向传播回seq2seq模型中，进行训练。整个仿真过程如下图：</p>
<p><img src="media/5.png" alt="5"></p>
<p>两个bot在对话，初始的时候给定一个input message，然后bot1根据input生成5个候选reply，依次往下进行，因为每一个input都会产生5个reply，随着turn的增加，reply会指数增长，这里在每轮对话中，通过sample来选择出5个作为本轮的reply。</p>
<p>接下来就是评价的部分，自动评价指标一共两个：</p>
<p>1、对话轮数。<br><img src="media/6.png" alt="6"></p>
<p>很明显，增强学习生成的对话轮数更多。</p>
<p>2、diversity。<br><img src="media/7.png" alt="7"><br>增强学习生成的词、词组更加丰富和多样。</p>
<p>下图给出了一个MMI seq2seq与RL方法的对比结果：</p>
<p><img src="media/8.png" alt="8"><br>RL不仅仅在回答上一个提问，而且常常能够提出一个新的问题，让对话继续下去，所以对话轮数就会增多。原因是，RL在选择最优action的时候回考虑长远的reward，而不仅仅是当前的reward。</p>
<p>本文是一篇探索性的文章，将seq2seq与RL整合在一起解决bot的问题是一个不错的思路，很有启发性，尤其是用RL可以将问题考虑地更加长远，获得更大的reward。用两个bot相互对话来产生大量的训练数据也非常有用，在实际工程应用背景下数据的缺乏是一个很严重的问题，如果有一定质量的bot可以不断地模拟真实用户来产生数据，将deep learning真正用在bot中解决实际问题就指日可待了。</p>
<p>RL解决bot问题的文章在之前出现过一些，但都是人工给出一些feature来进行增强学习，随着deepmind用seq2seq+RL的思路成功地解决video games的问题，这种seq2seq的思想与RL的结合就成为了一种趋势，朝着data driven的方向更进一步。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-11T20:03:05.000Z"><a href="/2016/07/11/Consensus-Attention-based-Neural-Networks-for-Chinese-Reading-Comprehension-PaperWeekly/">2016-07-11</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/11/Consensus-Attention-based-Neural-Networks-for-Chinese-Reading-Comprehension-PaperWeekly/">Consensus Attention-based Neural Networks for Chinese Reading Comprehension #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文分享的是今天刚刚刷出的一篇paper，是研究阅读理解的同学们的福音，因为要放出新的而且是中文的数据集。本文的题目是<a href="http://cn.arxiv.org/pdf/1607.02250" target="_blank" rel="external">Consensus Attention-based Neural Networks for Chinese Reading Comprehension</a>，作者均来自哈工大讯飞联合实验室。</p>
<p>对于机器阅读理解的基本内容就不作介绍了，感兴趣的同学可以参考之前写的一篇摘要<a href="http://rsarxiv.github.io/2016/06/18/%E6%95%99%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%98%85%E8%AF%BB/">教机器学习阅读</a>。本文最大的亮点在于构建了中文机器阅读语料，语料分为两个部分，一个是训练集和自测试集，一个是领域外的测试集，包括人工的提问和自动获取的提问两种。（<a href="http://hfl.iflytek.com/chinese-rc/" target="_blank" rel="external">语料地址</a>，可能过段时间会publish出来）</p>
<p>第一个部分是从人民日报获取的新闻语料，构建方法比较简单，先用POS工具对每篇新闻的词性进行标注，选择出现过两次以上的名词作为候选答案词。从候选词总随机选择一个词作为答案词，用包含答案词的句子作为问题query，剩下的部分作为document，从而构造出一个<document,query,answer>对。这种做法的好处是基于一个不太多的语料都可以构建出大量的<document,query,answer>对用来训练，这样也迎合了deep learning的需求。</document,query,answer></document,query,answer></p>
<p>第二个部分也是非常有意思的部分，就是提出了用一个训练数据领域外的数据集作为测试集，构造的方法分为两种，一种是自动的方法和第一部分相同，第二种是基于人工的提问，而且是对于机器来说难度较大的问题。之所以采用领域外的数据进行测试，是为了防止新闻数据中很多问题可以通过外部知识库来进行回答，导致问题变得简单，如果用一个儿童读物的数据作为测试集，就会将这个问题变得更加纯粹和有挑战性。</p>
<p>既然提出了新数据，baseline模型也省不了，本文提出的模型叫Consensus Attention Sum Reader，没有太多的新东西，效果也没有之前文章中Gate Attention Reader和Iterative Alternating Attention那么好，所以就不再介绍了。</p>
<p>训练数据的自动标注和生成是deep learning应用的关键，很多领域发展缓慢或者在工程中应用不好都是因为data的量不够多，且没有太多好的方法来生成或者标注。机器阅读这个领域，相对来说，dataset的自动构建还是很容易做的，操作也比较简单，抠掉一个核心词就可以。而bot，自动文摘，在实际的工程应用中都难以用流行的data driven方案来解决，因为代价太大了。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-11T18:06:42.000Z"><a href="/2016/07/11/A-Diversity-Promoting-Objective-Function-for-Neural-Conversation-Models-PaperWeekly/">2016-07-11</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/11/A-Diversity-Promoting-Objective-Function-for-Neural-Conversation-Models-PaperWeekly/">A Diversity-Promoting Objective Function for Neural Conversation Models #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本篇分享的文章是前一篇分享<a href="http://rsarxiv.github.io/2016/07/10/A-Persona-Based-Neural-Conversation-Model-PaperWeekly/">A Persona-Based Neural Conversation Model</a>的pre-paper，题目是<a href="http://arxiv.org/pdf/1510.03055v1.pdf" target="_blank" rel="external">A Diversity-Promoting Objective Function for Neural Conversation Models</a>，作者是Jiwei Li，最早于2015年10月11日发在arxiv上。</p>
<p>本文针对的问题是seq2seq方案在解决bot问题上容易生成一些“呵呵”的reply，比如“I don’t know”之类的非常safe，grammatical的reply，但是营养太少，没有太多实际的意义。造成这种情况的原因是目标函数不合适，在最近流行的自然语言生成任务中一般都采用MLE作为目标函数，这个目标函数可以保证生成出最自然的语言，但diversity太差，当然如果在decoding部分生成大量的N-best list的话，也是有很多不错的reply但都排名很靠后。</p>
<p>本文就是针对这样的一个问题，提出了用Maximum Mutual Information（MMI）作为目标函数来提高reply的diversity和实用性。MMI这个目标函数在Jiwei Li的多篇文章中都出现过，他很喜欢用这个来代替MLE作为目标函数来解决问题。互信息的方程如下：</p>
<p><img src="media/1.png" alt="1"></p>
<p>经过简单的推导，可得出下式作为目标函数：</p>
<p><img src="media/2.png" alt="2"></p>
<p>而，一般的seq2seq采用MLE，如下式：</p>
<p><img src="media/4.png" alt="4"></p>
<p>本文方法比传统seq2seq多了后面的一项。</p>
<p>p(T)其实是一个语言模型，为了在目标中控制reply的多样性，添加一个惩罚系数，如下式：</p>
<p><img src="media/3-1.png" alt="3"></p>
<p>这个式子记作(4)，经过简单的推导得到下式：</p>
<p><img src="media/5.png" alt="5"></p>
<p>记作(5)</p>
<p>作者根据式子(4)和(5)提出了两种MMI，分别是MMI-antiLM和MMI-bidi。</p>
<p>首先是antiLM，单看-log p(T)这一项，其实就是一个语言模型，anti表示反着的，因为有个负号。这一项不仅仅可以影响到你生成reply的diversity，同时也可以影响到你生成的reply是否是grammatical的，其实是一把双刃剑，需要做好控制，一般来说lambda小于1之后，后一项的影响相对较小了。</p>
<p>本文用一个带权重的语言模型U(T)来替换当前的p(T)，如下式：</p>
<p><img src="media/6.png" alt="6"></p>
<p>这里g(k)是权重，k是index，g(k)的特点是随着k的增加单调递减。这样做有两个目的：</p>
<p>1、decoding时对先生成的词的惩罚比后生成的词的惩罚对diversity的影响更大。</p>
<p>2、随着decoding部分的输入对后续生成影响的减弱，语言模型U(T)将会占主导地位，reply后面的部分也会非常grammatical。</p>
<p>bidi这个目标函数的思路是，先从第一项来生成N-Best List，然后用第二项对其进行排序，将diversity更好的reply放在前面。</p>
<p>在训练过程中，仍旧是采用MLE，但在测试的时候，用本文提到的MMI来做测试。</p>
<p>这个结果是由MMI-antiLM产生的：</p>
<p><img src="media/7.png" alt="7"></p>
<p>这个结果是MMI-bidi产生的：</p>
<p><img src="media/8.png" alt="8"></p>
<p>生成的reply确实seq2seq更加有营养。</p>
<p>本文解决问题的一个思路是很有借鉴意义的，正如abstractive summarization中有一篇paper用MRT来替换传统的MLE作为目标函数，将评价指标考虑进了目标函数中进行优化，起码在benchmark上得到非常好的结果。这其实是一条不错的路，就是将你当前的评价指标融入到你的优化目标中进行优化学习，自然会得到比单纯地用MLE来优化要好的多，也有很多的paper在用这样的思路解决问题。我们不仅仅满足于可以生成一个grammatical的reply，我们更需要的是有意义的、有实际使用价值的bot。另外就是具体到目标函数的建模，如果你希望目标中减小哪些因素对目标的影响，就增加一项惩罚项，这也是做优化时候的一般方案，但在解决具体问题时会非常有效。本文虽然针对的是bot reply的生成问题，其实可以推广到一般的自然语言生成问题上来，只是要涉及到MLE做生成都可以换成本文的方法来提升相应的指标。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-10T17:29:40.000Z"><a href="/2016/07/10/A-Persona-Based-Neural-Conversation-Model-PaperWeekly/">2016-07-10</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/10/A-Persona-Based-Neural-Conversation-Model-PaperWeekly/">A Persona-Based Neural Conversation Model #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文将分享的paper在生成对话时考虑了user identity，解决了多轮对话中response不一致的问题，如下图：</p>
<p><img src="media/1.png" alt="1"></p>
<p>同样的问题，换一种问法之后得到了不同的答案，而且答案不一致。paper的题目是<a href="https://arxiv.org/pdf/1603.06155.pdf" target="_blank" rel="external">A Persona-Based Neural Conversation Model</a>，作者是来自斯坦福的博士生Jiwei Li，他是一个非常高产的作者，很多文章质量都非常不错。文章最早在2016年6月8日在arxiv上发出。</p>
<p>本文针对的问题是开头说的多轮对话中response不一致的问题，这个问题很关键，多轮对话在工程应用中的意义更大，一致性是一个基础问题，解决不好，效果就会非常地差。本文针对这个问题，将user identity（比如背景信息、用户画像，年龄等信息）考虑到model中，构建出一个个性化的seq2seq模型，为不同的user，以及同一个user对不同的对象对话生成不同风格的response。</p>
<p><img src="media/2.png" alt="2"></p>
<p>本文一共提出两个模型，一个是Speaker Model，一个是Speaker-Addressee Model。</p>
<p>上图是Speaker Model的架构示意图，是一个典型的seq2seq模型，不同的地方在于在decoding部分增加了一个speaker embedding，类似于word embedding，只是说对用户进行建模。因为无法对用户的信息显式地进行建模，所以用了一种embedding的方法，通过训练来得到speaker向量，下面左边的图是speaker向量在二维平面上的表示，具有相似背景信息的user就会很接近，与word向量一个道理。decoding部分计算lstm各个gate用下式，vi表示speaker embedding。</p>
<p><img src="media/3.png" alt="3"></p>
<p>第二个模型是Speaker-Addressee Model，这个模型与上一个模型思想是一致的，只是考虑了一种更加细致的情况，在多人多轮对话（电视剧）中，每个人对不同的人说话style是不同的，所以应该在这类问题中需要考虑说话的对象，用V(i,j)来表示speaker i和j之间的这种关系，decoding部分计算如下式：</p>
<p><img src="media/4.png" alt="4"></p>
<p>seq2seq模型在最后的生成过程中，经常遇到一个问题，就是生成一些“呵呵”的话，就是指一些常见的、安全的但没有什么营养的话。针对这个问题，本文用beam search生成一个的N-Best List，用一些规则来重新排序得到更好的结果。</p>
<p>训练语料这块，第一个模型主要是依靠Twitter的数据，第二个模型是依靠电视剧的剧本数据。关于语料这块，它是一个非常重要的问题，甚至是决定了你能够用deep learning技术来解决某个具体问题的关键。开放域的bot数据充分，但模型还有待提高；闭域的bot数据匮乏，虽然可以解决实际问题，但开发成本太高，而且横向扩展性很差，基本上都是针对一个客户做一个系统，可复用的地方并不多，大量的人工feature需要花费大量的人力、物力、财力来做，所以这个问题也是bot在实际应用中难以使用deep learning的最大原因。有一种思路是用增强学习来造数据，但前提是你得有一个质量不错的生成模型，才能不断地自学习，这个问题便成了一个先有鸡先有蛋的问题，是一个死循环。</p>
<p>下图展示了Speaker Model在解决多轮对话一致性问题上的突出表现，User1采用了本文模型，User2是普通的seq2seq模型。</p>
<p><img src="media/5.png" alt="5"></p>
<p>将用户信息建模是一个必要的部分，从本文的结果来看确实有更好的效果。多轮对话不仅仅是考虑用户信息，还要考虑大量的上下文信息，或者说是历史信息，尤其是对于具体的企业客服来说，历史信息和用户信息都非常重要。当然如果是娱乐用的机器人，用户的情绪也是一个非常有意思的信息，情感分析已经有不错的正确率，所以考虑人的情绪也是一件非常好玩的事情。本文用了类似于word embedding的思路，对user infomation进行建模表示，同样的思路可以用于情绪、上下文信息中。我相信context的建模应该也有很多人在做，后续的paper也一定会读到，届时再分享。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-10T03:42:57.000Z"><a href="/2016/07/09/A-Dataset-for-Research-on-Short-Text-Conversation-PaperWeekly/">2016-07-09</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/09/A-Dataset-for-Research-on-Short-Text-Conversation-PaperWeekly/">A Dataset for Research on Short-Text Conversation #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文是一篇2013年的bot文章，题目是<a href="http://staff.ustc.edu.cn/~cheneh/paper_pdf/2013/HaoWang.pdf" target="_blank" rel="external">A Dataset for Research on Short-Text Conversation</a>，作者来自中科大和华为诺亚方舟实验室。</p>
<p>本文最大的贡献在于release出一个大型短文本对话语料，并且提出了一种基于检索的对话生成模型。到底是否是第一个用检索的方式来解决bot问题我不得而知，可以确定的一点是很多现在活跃在市面上的“逗逼”bot都是基于这个模型做的。</p>
<p>语料的数据来自于新浪微博，大概的收集过程如下图：</p>
<p><img src="media/1.png" alt="1"></p>
<p>首先选择10个NLP领域比较活跃的用户，然后依次作为种子用户，进行爬取，直到获得3200与NLP和ML相关的用户，然后抓取每个用户的微博和下面的评论，时间跨度为2个月。这样定向爬取的好处是选择的用户和所发表的微博涉及的领域比较窄，而不至于天马行空什么都有。</p>
<p><img src="media/2.png" alt="2"></p>
<p>数据准备好了之后，就是模型部分。模型一共分为两步，第一步是选择出评论候选列表，第二步是在候选列表中进行排序。候选列表选择一共分为三个baseline模型，如下：</p>
<p>1、Post-Response Semantic Matching</p>
<p>根据微博和评论之间的语义匹配程度选择出10个候选评论。</p>
<p>2、Post-Response Similarity</p>
<p>根据微博和评论之间的相似度选择出10个候选评论。</p>
<p>3、Post-Post Similarity</p>
<p>根据微博和微博之间的相似度选择出10个候选评论，即用相似微博的评论作为候选评论。</p>
<p>给定一条微博之后，模型会通过三个baseline各选择10条评论，构成一个&lt;=30的评论候选列表，然后进行标注。标注工作是将评论分为两类，即suitable和unsuitable，即正样和负样。判断一个评论是否是suitable一共有三个准则：（1）semantic relevance，这个准则是判断微博和评论是否语义相关；（2）logic consistency，这个准则是判断微博和评论是否在逻辑上是一致的；（3）speech act alignment，这个准则是判断微博和评论在act方面是否是对齐的。</p>
<p>接下来就是通过标注数据进行排序，排序学习的目标是让正例的score比负例的score更大。</p>
<p>基于检索的bot解决方案是一种常见的方案，这种方案的重点在于知识库的质量，也就是那个database，一个query对应多个reply。如果只是简单的对话，效果会不错，而且如果知识库很有特点的话，reply经常会有一些意想不到的好玩的话，小黄鸡当年在人人网上火了好一阵子。但稍微复杂的问题，知识库的应变能力差的缺点就暴露出来了，比如query中有named entity，并且这个entity在知识库中没有出现过，这时reply就会出现牛头不对马嘴的情况，解决单轮对话都存在很大的缺陷，那么解决多轮对话就会更困难。虽然说，可以通过做query和reply、query和query之间语义层面相似度的计算，比如用一些成熟的deep learning技术来做。但根本上并没有解决这种方法的弊端，倒是非常垂直的闭域bot可以考虑用这个方案加上一些策略来解决，比如企业客服bot，因为知识库规模小，根据企业的资料和一些过往的用户对话数据可以建设一个质量不错的知识库，从而得到质量不错的bot。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-10T01:08:36.000Z"><a href="/2016/07/09/Sequence-to-Backward-and-Forward-Sequences-A-Content-Introducing-Approach-to-Generative-Short-Text-Conversation-PaperWeekly/">2016-07-09</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/09/Sequence-to-Backward-and-Forward-Sequences-A-Content-Introducing-Approach-to-Generative-Short-Text-Conversation-PaperWeekly/">Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>从今天开始后面的paper都与bot有关，除非arXiv刷出一些好玩的paper。本文是<a href="http://cn.arxiv.org/pdf/1607.00970" target="_blank" rel="external">Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation</a>，2016年7月4日发在arxiv上，作者是来自北京大学的博士生<a href="http://sei.pku.edu.cn/~moull12/" target="_blank" rel="external">Lili Mou</a>。</p>
<p>这里所讲的bot是指chat bot，也是当下研究领域最火的应用之一。在实际的工程应用中使用的方法可以分为两类，基于rule、template的和基于database query的，应用范围比较窄，比如垂直领域的客服机器人，解决的问题通常都是一个闭域的问题；而真正的AI是应该可以解决开域问题的，无论问什么样的问题，都会得到一个满意的答案，当然，现在的研究水平还难以达到这样的境界。最近几年随着深度学习技术的火热，nlp领域中很多任务都得到了长足的进步，现在最流行的解决方案是seq2seq，尤其是在自然语言生成任务中得到了广泛的应用。简单bot的问题可以理解为给定一个query，生成一个reply，这样的bot是single turn，研究意义大于应用意义。更多的实际问题都是一个multi turn问题，以客服bot为例，单轮对话很难解决了客户的疑问，一般都是通过多轮对话来帮助用户得到满意的答复。关于多轮bot的文章，后面会慢慢涉及到，今天分享的paper是关于单轮、短文本的对话生成。</p>
<p>生成式的bot比起基于rule、template和database query的bot具有更加灵活的特点，不仅仅拘泥于现有的rule、template和database，而是可以生成更加多样性的reply。但生成式的bot也有一个非常显著的问题，就是经常生成一些非常“呵呵”的reply，比如“我不知道”，“我也是”等等没有营养但绝对“安全”的话，导致了这种bot没有什么实用价值。产生这个问题可能有两个原因：一是在decoder部分以log概率最大为目标，而不是别的目标，所以容易生成一些没有意义的人类语言，因为训练语料中这样无意义的reply会经常出现，用deep learning从data中抓feature的时候就会出现这样的问题；二是query的信息量太少，encoder捕捉的意思有限，导致了生成“呵呵”的reply。</p>
<p>本文旨在提出一种叫做content introducing的方法来生成短文本reply，一共分为两个step，如下图：</p>
<p><img src="media/1.png" alt="1"></p>
<p><b>step 1</b> 给定query之后，预测一个keyword作为reply的topic，这个topic词性是名词，这里的keyword并不能捕捉复杂的语义和语法，而只是根据query的每个词来预估出一个PMI（Pointwise Mutual Information）最高的名词作为keyword，两个单词之间的PMI由下式计算：</p>
<p><img src="media/2.png" alt="2"></p>
<p>每个单词与query之间的PMI由下式计算：</p>
<p><img src="media/3-1.png" alt="3"></p>
<p>虽然数学上不太严谨，但后面的实验表明用这个来计算结果还是不错的。</p>
<p><b>step 2</b> 本文的模型叫做Sequence To Backward and Forward Sequences，首先进行backward step，给定一个query，用encoder表示出来得到一个context，decoder的部分首先给定keyword作为第一个词，然后进行decoding，生成的这部分相当于keyword词前面的部分；接下来进行的是forward step，也是一个典型的seq2seq，用encoder将query表示成context，然后给定backward生成的话和keyword作为decoder的前半部分，继续decoding生成后半部分。整个的流程这样简单描述下：</p>
<p>query + keyword =&gt; backward sequence</p>
<p>query + keyword + backward sequence(reverse) =&gt; forward sequence</p>
<p>reply = backward (reverse) sequence + keyword + forward sequence</p>
<p>传统的seq2seq模型都是从第一个词生成到最后一个词，无法生成指定词，而本文的模型可以生成指定词，并且该词可以出现在reply的任意位置。</p>
<p>数据集是从百度贴吧上爬下来的对话数据，规模有500k的query reply pairs，PMI统计是由100M的query reply paris。结果是与seq2seq进行比较，本文模型得到了更好的结果。下图展示了本文的example：</p>
<p><img src="media/4.png" alt="4"></p>
<p>本文用keyword来做topic的思路是一个很好的思路，会让算法生成的reply更加有营养，这个在单轮的应用背景下可以取得不错的结果。但是本文用topic的思路和处理方法太多简单，如果考虑到多轮对话的问题，我想用上下文信息来预测topic，而不是只考虑该句query的信息，而且不仅仅用一个单词来做topic，可能还会是短语，也可能是语义层面上的topic，而不仅仅是从一个候选列表中选择单词来作为topic。文章的思路很有启发性，我个人认为生成式的bot在闭域中应用是一个大趋势，传统的rule、template、database都会被替代，但真实应用场景中的bot需要将context做好处理，然后作为先验知识，来生成reply。其实难点也就在context的处理上，包括user profile，dialogue history，user current state等等各种context信息。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-09T04:35:03.000Z"><a href="/2016/07/08/生活毕竟不是一场秀/">2016-07-08</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/08/生活毕竟不是一场秀/">生活毕竟不是一场秀</a></h1>
  

    </header>
    <div class="entry">
      
        <p>生活毕竟是生活，生活的本质应该是生活本身，而不是一场秀。事业再好，终究还是为了有一个更好的生活，而家庭是生活中最重要的环节，永远都是应该是最重要的，抛去家庭来谈事业，简直滑稽。</p>
<p>为什么要伪装自己，在别人的面前表现出一个不同的自己？人与人为什么会不平等，就因为你现在处在更好的位置？一堆长者围着一个年轻人转，就因为年轻人是领导的秘书？说好的人生而平等呢？人的特征那么多，为什么只在乎地位这一个feature呢？才华、修养都是人的重要feature，为什么大家在地位面前都变得那么地低三下四呢？这不是生活的意义。</p>
<p>在酒桌之上，在领导面前，在地位和权势面前，为什么大家都变了一个模样？都在表演自己的人生，都在说一些虚伪的假话，都在迎合着一些人的需求。</p>
<p>忘了吗？每个人其实都是独立的，是一个活生生的个体，独立地活在这个世界上。难道家庭和事业比起来不重要吗？我一点都不认同，我觉得人都是平等的、独立的。</p>
<p>感谢我的妻子，我一直觉得自己就像是一只牢笼里的小鸟，在一个非常狭窄的区域内飞来飞去，我自以为我是在广阔的天空里，后来遇到了另外一只美丽的小鸟，带着一起飞，飞向了真正的天空，看到了更大的世界，明白了真正的人生。</p>
<p>我希望自己以后的孩子可以自由自在、不卑不亢地活在这个世界上，并不会因为自己的富有或贫穷而对这个世界和这个世界上的人产生偏见，我希望他爱读书，希望他可以看到更大的世界、真正的世界，而不是为了一个目的和身份苟活在这个世界上。</p>
<p>自由不只是身体上的自由，更是心灵的自由，一种真正的独立和平等，大家不论身份的高低都可以坐在一起进行平等地交流，没有半点虚伪，没有半点惶恐，只有最简单的纯真。</p>
<p>此刻，我想哭，因为有太多的无奈，但此刻，我也想笑，因为未来的生活会更加美好，因为我知道了美好的世界是可以通过自身的努力得来的，而不需要谁的恩赐和施舍。</p>
<p>生活毕竟不是一场秀，而是自己最真实、最纯粹、最华丽的人生。</p>
<p>献给那些生活在种种挣扎中的人们。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-07T00:16:17.000Z"><a href="/2016/07/06/关于创业的几点思考/">2016-07-06</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/06/关于创业的几点思考/">关于创业的几点思考</a></h1>
  

    </header>
    <div class="entry">
      
        <p>北京之行非常充实，白天上课，晚上和业界一线的创业者们交流，收获颇丰。自己之前对创业有一些朦胧的感觉和认识，但并不成熟，这次交流之后，有了一个更加清晰的认识，在这里做个总结。</p>
<p>1、SaaS（Software as a Service）+ B2B的模式确实很棒，这里讲的SaaS服务比较狭隘，特指用一些算法和模型来帮助中小企业解决他们解决不了的问题，并不包括工具类的SaaS。这种商业模式对创业团队的学习能力和研发能力有非常高的要求，团队短小精悍，可以快速对问题进行建模，快速开发出原型系统和产品。这种模式可以做成Private解决方案式的业务，此种业务对需求的分析和对自身的定位非常重要，一定要做的非常精和细，抓住企业用户的需求来展开业务；还有一种是做Public，提供算法API供企业用户调用，算是一种平台。SaaS+B2B最关键的是技术能力，不需要太多无关的人。SaaS是一种趋势，你公司中的很多业务其实都是不需要自己来打理，只需要找到做相应工作的SaaS公司即可，比如：会计和税务，报账，HR等等。他们做这个比你更加专业，也比你花钱雇人更加实惠。所以，这个世界是合作的，你做好、做精你的事情，其他耗时但有用的事情可以找专业的人来做，各赚各的钱。</p>
<p>2、创业最难的是人才，是如何招到靠谱的人才。创业公司太多了，而且创业都是在用时间赌未来，不一定会成功，所以对人才的吸引力不如成熟的大公司那么大。初期的招人很难，也很重要，基本上就是从熟人下手，从身边的人下手，或者找一些志同道合的人才。我个人觉得，如果你不是特别急着追一个所谓的创业机会的话，招人这事是宁缺毋滥，就和找女朋友类似，看条件合适不合适根本没用，创业是很实在的事情，合适的人比牛逼的人更加重要，因为牛的人性格一般都不会那么地随性，都是有个性的人，性格合适会让这个团队走向一个正确的方向，而不是说凑了几个大牛校或者海龟，大家听起来title都不错，但合作起来却问题百出。说道人才，我觉得不论什么出身，什么专业背景，只要是学习能力特别强，这里不是说你GPA多少，高考分多少之类的，而是给你一个新的topic，你能在多短的时间对这个topic有一个不错的理解；动手能力特别强，毕竟产品需要编程实现，模型系统也需要编程实现，纸上学来终觉浅嘛；沟通能力特别强，听得懂别人在说什么，也让别人听得懂自己在说什么，谦虚谨慎才会有利于沟通和交流，才会让团队更加高效。</p>
<p>3、创业环境，这一点颠覆了之前的认识。一直不喜欢北京，一个像吸血鬼一样的城市，一个没有生活质量的城市。但不得不说，是最好的创业城市，因为资源都在这里。深圳虽然好，但人才方面相对匮乏，软件创业环境不如北京，可能硬件够好一些吧，做机器人创业的比较适合在那里。和来自硅谷的创业咖聊过之后，感觉美国的创业环境更加规范，毕竟人家做了那么多年，体制机制都非常规范，不会像中国这样出现一些诓骗的事情，违法的成本太高，所以大家都规规矩矩在一个框架内做事情，环境比较纯粹一些。当然，硅谷也面临着招人的问题，创业公司太多，大家都想要最好的人，所以都很难。现在的创业支持和各种资源都非常充分，环境非常好，难的不是找投资，不是组建公司，因为现在有很多的孵化器，各个阶段的孵化器，他们会帮你解决好各种各样的事情，难是难在你自己到底有没有这个能力，做好这件事情。</p>
<p>4、创业方向，我个人关注的是自然语言处理技术，所以对这个方向观察和思考的多一些。首先说，bot热，大热，从arxiv上paper的数量也可以看得出，bot这个领域是最火的，从各大公司对bot研发的投入力度来看，bot是下一个big thing，facebook甚至希望将bot作为入口，代替现在的操作系统，想一想都觉得这个世界是多么地美好和神奇。bot这个大理想非常丰满，现实中nlp技术的不成熟却显得非常骨感，bot paper发的热火朝天，但在工程应用上却难以被用到，世界上最远的距离就是从research到engineering的距离。bot是大趋势，但技术确实不成熟，所以带来了大量的机会，每个有积累、有准备的人都是公平的，大家都有机会在下一个big thing上分一杯羹。让机器来理解和灵活应用人类语言是一件非常难的事情，也是实现true AI中非常关键的一步，所以我看好这个方向。当然，如果你着急开始赚钱，nlp并不适合你，因为nlp是未来。</p>
<p>5、是否该创业，这个问题如果你犹豫了，那么其实也就有了明确的答案。太多的顾虑是做不成一件事情的，不如安心地做好现在的工作，一步一步地在现在的地方踏踏实实地混下去，混到更高的title，直到退休。如果你在这个问题上不犹豫，那么恭喜你，你是天生的创业者，但这离创业成功还有十万八千里。那天问了谷哥（clickstone）为什么创业这个问题，他是这么回答我的，就是想按照自己的方式去努力做成一件事情，得到一个不错的回报，这里的回报更多的是成就感，而不只是money。可能，我们踏踏实实在一家大公司工作，或者在体制内工作，会为很多举世瞩目的事情做出贡献，但个人太微不足道了，在这样的环境中，自己做的事情太小了，能够决策的东西也太少了，就像一颗螺丝钉一样，事情成功了，也没有什么成就感。所以说，做爱做的事情，并且做成。</p>
<p>6、厚积薄发，打好基础，放平心态，不要急着去和谁比较。谷哥说他的同学有的都已经是教授级别了，但近况没那么理想吧，创业者要耐得住寂寞，不去和人比，因为每个人都不一样，拿同一标尺来衡量是很幼稚的事情。既然，选择了这条路，就是要一直走下去，而不是瞻前顾后、犹豫不决。你过去放弃的、现在放弃的种种都会在未来的某一个时间换一种形式回报给你的。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-06T20:08:50.000Z"><a href="/2016/07/06/cips总结和思考/">2016-07-06</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/06/cips总结和思考/">cips总结和思考</a></h1>
  

    </header>
    <div class="entry">
      
        <p>前几天在北京参加了一个深度学习的“速成班”，由中文信息学会（cips）举办的。一共分为四天，上午由一名老师讲授理论和前沿技术的发展情况，下午由一名刚刚毕业的博士讲授用tensorflow来实现上午的部分内容。覆盖的范围包括神经网络与表示学习，以及应用于自然语言处理中的神经网络模型。都是国内一线的老师在讲，所以内容的质量非常高，来参加课程的同学也都非常的热情，去的晚了连个像样的座位都找不到，每次茶歇时间，老师都会被围得水泄不通。</p>
<p>深度学习非常火爆，很多人都在传言学会了深度学习就可以拿到高薪，甚至都可以to be someone，说的神乎其神，将深度学习等价于几十万、几百万的年薪。个人感觉这样的说法并不负责任，有点过度宣传的意思，与之相关的培训班也跟着水涨船高，且不论教学质量如何，确实涌现出了很多的教学、培训班来为学生们提供捷径，质量良莠不齐，学生们觉得上了你这个基础班、提高班之后就会有一份特别棒的工作和薪水。这样的事情有点像迷信神一样，传教士们将舆论造好，说的神乎其神，然后开始传教，让大家来信教，小白们本身就没有太多的判断力，只是单纯地相信传教士们，相信这个世界有捷径通往成功。其实，仔细想一想，怎么可能？不管火的是深度学习还是别的技术，让你能够找到一个不错的工作或者不错的薪水都是需要具备很强的数学基础和编程实现能力，以及超强的学习能力，从而跟得上技术的发展，而不是说跟着几个班学过之后，就能够如何如何。大家盲目地追逐捷径，却忽略了本质问题，实在是令人觉得可笑，微博上总能看到一些懂deep learning的人可以拿到多少多少薪水，会用什么工具或者开发过什么工具的人可以拿到多少多少薪水，这些言论会让大家变得浮躁。虽然说deep learning很火，大家也看的很热闹，那么到底有多少人可以从深层次的角度上或者说数学层面上理解了deep learning？</p>
<p>随波逐流不难，难的是坚持自我。tensorflow很火，所以大家都开始转tensorflow，mxnet在微博上被人转来转去，再加上“mxnet的主创人员都拿到了几百万的年薪”这一微博发出之后，有一种mxnet暗流涌动的感觉。这个问题，我是这么看的，流行确实有流行的原因，但公关的因素也不少，但是往往大家分不清真的好用还是大公司在公关，但工具毕竟是工具，选择了一个趁手的兵器就应该坚持用下去，而不是根据别人的言论而改变自己的初衷。因为工具只是工具，目的就是为了快速地实现模型，得到结果，torch、theano、tf、mxnet、caffee哪种用熟练了，用到了极致都是高手，不需要那么地盲目崇拜。</p>
<p>上面的言论是我自己的一些观点，并不针对特定的人和工具，世上没有偏见，只是角度不同、理解不同产生了偏见。对一个事物的认识和学习，都是要经历一个迷信和质疑的过程，所谓尽信书则不如无书，有自己的观点和态度不仅仅是一个严肃的媒体应该具备的特质，一个有独立思考能力的人都应该有自己的态度和认知。</p>
<p>这次的课程上午的内容都非常的棒，下午的内容个人觉得有一点鸡肋，用tf来实现一些model，像是编程实验课，但课时太短，大家没有太多动手和思考的时间，有一点点填鸭地感觉。编程从来都应该是一个实践课，编程能力都是自己一行一行写出来的，不是从谁那里听来的，从0开始学，照着docs和demo一边写一边学，遇到不懂的地方，在github上发起issue来讨论或者在其他的论坛上进行讨论，step by step地学习，或早或晚地一定会get到这个技能。我个人觉得下午的时间还不如将上午的内容进行更加深入地讲解，因为明显感觉地到上午老师讲的有一点点赶，讲的不够充分和透彻，时间快到了12点的时候，开始慌张地收尾，还真如下午继续讲呢。</p>
<p>学习这个事情，没有什么捷径，理解一个概念，理解一行代码，理解一个框架都需要你扎扎实实地去实践、去体会，不是谁能够给你的。这次所谓的“速成班”就是帮你打开一扇窗，让你在一个更大的空间里来理解这个世界，至于怎么理解和理解地怎么样都只有靠自己。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-06T18:49:03.000Z"><a href="/2016/07/06/Towards-Abstraction-from-Extraction-Multiple-Timescale-Gated-Recurrent-Unit-for-Summarization-PaperWeekly/">2016-07-06</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/06/Towards-Abstraction-from-Extraction-Multiple-Timescale-Gated-Recurrent-Unit-for-Summarization-PaperWeekly/">Towards Abstraction from Extraction: Multiple Timescale Gated Recurrent Unit for Summarization #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>前几天因为去北京参加中文信息学会组织的深度学习“速成班”，一直都没空更新博客。今天分享的paper是昨天刚刚刷出的一篇关于自动文摘的paper，题目是<a href="http://cn.arxiv.org/pdf/1607.00718v1" target="_blank" rel="external">Towards Abstraction from Extraction: Multiple Timescale Gated Recurrent Unit for Summarization</a>。</p>
<p>用seq2seq的思路来解决文本摘要问题仍停留在short text的生成水平上，最多到paragraph level。原因也比较简单，rnn也好，gru、lstm也罢，终究都面临着一个长程依赖的问题，虽然说gru、lstm等技术用gate机制在一定程度上缓解了长程依赖和梯度消失、爆炸的问题，但终究文本过长的话，神经网络的深度就会随之变得非常深，训练起来难度就会随之增加。所以，这也是为什么document level或者说multi document level的abstractive式的摘要生成问题至今都是一个难以解决的问题。确实，short text的理解、表示在一定程度上有了很大的突破，也可以在工程上有不错的应用，比如机器翻译。但text变了之后，一篇很长的文章如何更加准确地理解和表示是一个非常难的问题，attention是一个不错的解决方案，在decoder的部分不需要考虑encoder的全部，只需确定需要注意的几个点就可以了，其实人在看一篇长文的时候也是这样一种机制，从某种角度上来讲，attention在decoder时提供了一种降维的手段，让model更能捕捉到关键的信息。</p>
<p>对于document level的abstractive摘要问题，人是怎么做的呢？比如我写了一篇paper，最后写abstract的部分，基本上是从每个section中提炼出key sentences，组成一段abstract，其实这里有一点extractive的意思，但人和extractive不同的地方在于可以轻松地将each sentence连贯地表达出来，看起来不那么僵硬，更加地顺畅，当然也不会出现指示代词找不到实体的情况。本文的思路正是借鉴了人类在解决这个问题时所采用的一般思路，数据源是arxiv paper中的introduction和abstract部分。</p>
<p><img src="media/2.png" alt="2"></p>
<p>将document分解成多个paragraph，然后从每个paragraph中extract出key sentence作为该paragraph的target summary，每个document可以构造出多个(paragraph,key sentence) pair作为seq2seq的训练数据。生成摘要的过程正好相反，将document分解成paragraph，对每个paragraph用model生成summary，将所有的summary拼接起来形成abstract，然后与paper自身的abstract作对比。</p>
<p>这里从paragraph中提取key sentence用了最简单的TF-IDF来打分排序，当然给n个句子排序有很多的方法，比如textrank。(paragraph,key sentence) pair的训练是通过一个叫Multi Timescale Gated Recurrent Unit(MTGRU)模型来做的，这个模型乍一看好新鲜，其实是N年前一个叫做MTRNN模型将RNN替换为GRU的成果，gru、lstm的变种非常的多，本文的这个模型是其中一个，之所以选择用这个模型来解决问题，是因为多个timescale可以在收敛速度上有更大的优势，并且在自然语言这种层次性的问题上有天然的优势。model的结构如下图</p>
<p><img src="media/1.png" alt="1"></p>
<p>在GRU的基础上增加一个时间项tao，用来控制gru的时间尺度，tao越大，表示model可以越好地捕捉序列数据中的slow features，不知道理解的对比对，这里的slow features是不是可以理解为更大的context window，控制着context的颗粒度。MTGRU可以看作是GRU的一般表示，当tao=1时，自动退化为GRU。</p>
<p>与传统的GRU进行了对比实验，证明了该model在speed和performance上均有更好的表现。下图展示了生成的一些结果：</p>
<p><img src="media/3.png" alt="3"></p>
<p>输入的是本文的introduction部分，输出的是每段生成的summary。</p>
<p><img src="media/4.png" alt="4"></p>
<p>这个是本文算法生成的摘要和纯extractive方法的对比，明显比extractive的方法概括地更加全面。</p>
<p>本文是一篇占坑的文章，内容并不完整，提出了MTGRU model来替换一般的GRU，但并不是full data driven，用了一些extractive的手段来辅助进行训练，在文章的future work这部分作者也提到了下一步要做成一个真正的data driven的model，每个paragraph的target summary也是data driven的，而不是用extractive的提取出来的，我在想，是否可以构造一个hierarchy model，一个维度在训练paragraph到sentence的mapping，一个维度在训练document到abstract的mapping，这个idea可以认真琢磨下，也欢迎大家讨论。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-29T17:54:35.000Z"><a href="/2016/06/29/教机器学习表示/">2016-06-29</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/29/教机器学习表示/">教机器学习表示</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>让机器来理解人类语言一直都是人工智能的梦想，从词、短语、句子、段落到文档，每个层次的文本都承载着语义，机器对各个层次文本的理解都需要先对文本进行表示，用机器看的明白的形式来表示。那么，今天就来分享一篇关于表示的综述文章。</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>从人类理解文本的角度来看，理解一篇文档需要理解其中的每个段落，而理解段落需要理解每个段落的每句话，理解每句话就得理解每句话中的每个词。所以，表示一篇文档，需要从表示一个词、一句话开始。关于词的表示，在之前很长一段时间都流行的是one-hot模型，每一个词都用一个词表大小的向量表示，向量中该词所在的位置是1，其余都是0，而句子或者文档的表示，以前都是用bag-of-words模型，该文本用一个词表大小的向量表示，向量中的元素表示对应位置的词的个数。这两种经典的模型用了很久，有一些非常明显的缺点，比如：规模太大，太过稀疏，没有考虑词序信息，而词序又是一种非常有用的信息。</p>
<p>终于，在神经网络语言模型的帮助下，词向量（word embedding）出现了[1]，最初词向量是语言模型的一个副产物，后来随着word2vec的热潮，词向量几乎成了NLP中模型的标配，紧接着就是sentence2vec，document2vec，everything2vec，整个世界都被vector表示了。词向量与之前的one-hot模型不同，用了一些低维的、稠密的实数向量来表示，虽然说不清每个维度都表示什么，但用起来效果就是棒。</p>
<p>本文要探讨的问题是如何学习用低维的、稠密的实数向量来表示词、句子和文档。</p>
<h1 id="语料"><a href="#语料" class="headerlink" title="语料"></a>语料</h1><p>对于监督学习来说，需要找到一些分好类的语料进行训练，比如情感分析、新闻分类之类的数据。</p>
<p>对于无监督学习来说，只需要找到大量的文本进行训练即可。</p>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p>关于词、句子表示的模型实在是太多了，本文只选择PaperWeekly中读过的paper里的模型。</p>
<p>首先介绍的是词表示模型。</p>
<p><img src="media/14672414619993.png" alt=""></p>
<p>1、CBOW模型[2]</p>
<p>1、2都是word2vec的模型，整体的思路差不多，都是用context来预测word（skip-gram是用word来预测context，把context和word的概念对等交换一下都一样的。），典型的语言模型。之前Bengio[1]的文章提出用词向量来表示一个词，通过前面的n个词来预测下一个词，重点关注的是词的生成情况，并没有对词向量本身进行探讨。而word2vec的作者Tomas Mikolov重点研究的是词向量，并不在意语言模型的部分，所以这里在各种先前研究成果的基础上进行了大量地“偷工减料”，以达到快速求解词向量的目的。</p>
<p>如左图，该模型将每个词赋以一个n维向量初值，将context中的每个词向量求和来表示context，拿来预测目标词，不断地训练得到最终的词向量。</p>
<p>2、SKIP-GRAM模型[2]</p>
<p>如右图，该模型与CBOW类似，只是用word来预测context。</p>
<p>3、GloVe模型[3]</p>
<p>该模型的思路是将全局词-词共现矩阵进行分解，训练得到词向量。整体上的思路和推荐系统当年横扫Netflix百万美元比赛的LFM模型类似，也和信息检索中LSI的思路类似。不同的地方是，本文采用的词-词共现矩阵比起词-文档矩阵更加稠密，模型中对低频词和高频词的影响做了一定地弱化处理。模型的目标函数如下：<br><img src="media/14672420569666.png" alt=""></p>
<p>这里的f(x)是一个权重函数，具有以下的特点：</p>
<p>(a) f(0) = 0</p>
<p>(b) f(x)是增函数，这样低频词不会被over weight。</p>
<p>(c) 当x很大时，f(x)相对小一些，这样高频词也不会被over weight。</p>
<p>根据以上的特点，作者构造了下面的函数：</p>
<p><img src="media/14672421669446.png" alt=""></p>
<p>其次介绍的是句子表示模型。</p>
<p>1、PV-DM模型[4]</p>
<p><img src="media/14672421910018.png" alt=""></p>
<p>句子模型1和2是word2vec作者的进一步工作，乍一看模型和CBOW很像。不同的地方在于，输入中多了一个paragraph vector，可以看做是一个word vector，作用是用来记忆当前上下文所缺失的信息，或者说表征了该段落的主题。这里，所有的词向量在所有段落中都是共用的，而paragraph vector只在当前paragraph中做训练时才相同。后面的过程与word2vec无异。</p>
<p>2、PV-DBOW模型[4]</p>
<p><img src="media/14672422824272.png" alt=""></p>
<p>这个模型看着雨SKIP-GRAM很像。这两个模型都是无监督学习模型，在准备数据时需要给每个paragraph定义一个id，以区分不同的paragraph。</p>
<p>3、Skip Thought Vectors模型[5]</p>
<p><img src="media/14672423416074.png" alt=""></p>
<p>本模型是一个无监督句子表示模型，借鉴了word2vec中skip-gram模型，通过一句话来预测这句话的上一句和下一句。模型采用了当下流行的seq2seq框架，通过搜集了大量的小说作为训练数据集，将得到的模型中encoder部分作为feature extractor，可以给任意句子生成vector。</p>
<p>4、Sequence AutoEncoder LSTM模型[9]</p>
<p><img src="media/14672434462899.png" alt=""></p>
<p>该模型利用自编码器来进行sentence表示，从图中可以看得出是一种端到端的学习，只不过这里的input和target是同一句话。模型中用LSTM来对文本进行建模，整个过程和之前分享的seq2seq并无区别，属于比较简单的模型。</p>
<p>5、Hierarchical Attention AutoEncoder模型[8]</p>
<p><img src="media/14672435940204.png" alt=""></p>
<p>这个模型在模型4的基础上，用了分层和注意力的思想，更加复杂。在encoder部分，对每一个word进行表示，同时也对每一个sentence进行表示，用每句话最后一个词的state作为该句子的state，并且将每句话的表示综合起来作为整个输入的输出，也就是context。在decoder部分，生成词的时候会使用attention机制，在确定和input中哪句话的关系更加密切。</p>
<p>6、CNN模型[6]</p>
<p><img src="media/14672428840879.png" alt=""></p>
<p>这个模型是CNN在NLP中得到应用的一个比较早的模型，也是一个有监督模型。用一个k维向量表示一个词之后，很容易将一句话表示成一个矩阵，矩阵中的每一行都是一个词向量。那么既然得到了矩阵表示，很容易套用CNN在二维图像中的处理方法，一层层地堆叠起来，得到sentence的表示。只是说卷积窗口的选择，有两种思路，一种是窗口大小就是k，每一次卷积其实就相当于从n-gram中提取feature；另外一种思路是窗口大小小于k，和CNN处理图像类似的思路，从几个词的不同部分来提取feature。本模型采用的是第一种方式。</p>
<p>7、RCNN模型[7]</p>
<p><img src="media/14672425700988.png" alt=""></p>
<p>该模型是一个RNN和CNN的组合模型，CNN的卷积层用一个双向RNN模型来做，既用双向RNN弥补了CNN模型卷积窗口大小固定的问题，又利用了CNN提取feature的强大能力。这个模型也非常好地体现了deep learning模型的灵活性和组合性，不同类型的single模型通过一定的方式进行组合，可以衍生出多种多样的模型，很难从理论上讲哪个模型会更好，因为single模型都各有各的优点和缺点。该模型是一个有监督模型。</p>
<h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><p>本文只对比一下各个sentence表示模型的结果。</p>
<ul>
<li>Stanford Sentiment Treebank Dataset<br><img src="media/fig3.png" alt="fig3"></li>
</ul>
<p>在这个数据集上，居然是无监督的Paragraph Vector模型效果最好，虽然也好不到哪里去，但至少不比有监督学习的模型差。</p>
<ul>
<li><p>多种分类数据集<br><img src="media/fig2-1.png" alt="fig2"><br>这里的评价指标是分类正确率，从结果上看CNN作为一个有监督学习的模型好于另外两个无监督的模型，仅仅在SUBJ这个数据集上稍落后于skip thought vectors模型。</p>
</li>
<li><p>对比CNN和RCNN[7]<br><img src="media/fig1.png" alt="fig1"><br>这个对比结果来自RCNN模型的paper，很显然RCNN在作者选的几个数据集上都由于CNN，可以大胆推测一下，RCNN应该在第二类数据集上也能优于无监督模型。</p>
</li>
</ul>
<h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><p>词表示、句子表示等各种层次上的表示有着各种各样的模型，几乎在arxiv上每天都可以刷出一篇文章是做这方面的，都说自己的模型是state-of-the-art。对于这个领域，我有下面几点思考：</p>
<p>1、关于对比结果的事情。数据集的不同、数据规模的不同、模型的不同、模型超参数的不同都会导致不同的结果和结论，在对比的过程中，我们往往是用尽浑身解数调出最好的参数给出一个最好结果，而对于对比的模型，往往就没有这么上心了，复现别人的模型或者用别人开源的代码来对比的时候，可能很难调出该作者模型的最优参数，所以每篇paper的结果也总是有一些出入，从上面的结果中也能看得出，同一个数据集，在不同paper作者复现下结果也是不同的。而且，对比的结果与所选的数据集也有很大的关系，有的模型在某一些数据集上表现非常好，然而在另外一些上就不那么尽如人意了，这也是一个对比的技巧吧，但真正在工程应用上，还是需要在自己的数据上做对比实验，而不是用所谓的“理论”来剖析哪种模型更牛逼。因为毕竟deep learning是data driven的模型，效果的好坏与数据有着直接的关系。</p>
<p>2、读了一些paper之后，看过很多别人的思路和model，有一个感觉就是思维一定要更宽一些。单模型效果一般的时候，可以考虑试一下组合模型，比如RCNN，可以考虑下端到端模型，比如Autoencoder和skip thought vector，可以考虑下分层模型，比如Hierarchical Autoencoder。无监督模型效果一般的时候，可以考虑用无监督作初值，代入到有监督模型中进行训练，一般来说会比纯粹的有监督或者无监督模型效果更好一些。模型看多了，就会有一种感觉，做什么事情的时候，可选的东西就会特别多，思路就会特别多，所谓精神病人思路广吧。</p>
<p>3、词向量的用法，得到一个好的词表示之后，可以用来做什么呢？首先可以继续表示句子，段落，然后做分类也好，计算相似度也罢；其次，可能会有一些比较好玩的东西，比如我用word2vec给自己之前写的应用rsarxiv（一个arxiv paper的推荐系统）做了一个paper knowledge graph，把author，subject，keywords连成了一张大图，在推荐paper的同时可以推荐其他的一些metadata，带来了更好的用户体验。同样的道理，有的人用这个来做app推荐，也有不错的效果。所以，我在想，一个模型其实不仅仅是一个用于特定事情的模型，如果你有很强的抽象问题的能力，你可以看得穿问题的本质，就可以很容易地将特定领域的模型应用于其他领域，有可能还会形成突破。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://jmlr.org/papers/volume3/bengio03a/bengio03a.pdf" target="_blank" rel="external">A Neural Probabilistic Language Model</a></p>
<p>[2] <a href="http://cn.arxiv.org/pdf/1301.3781v3.pdf" target="_blank" rel="external">Efficient Estimation of Word Representations in Vector Space</a></p>
<p>[3] <a href="http://nlp.stanford.edu/pubs/glove.pdf" target="_blank" rel="external">GloVe: Global Vectors for Word Representation</a></p>
<p>[4] <a href="http://cn.arxiv.org/pdf/1405.4053.pdf" target="_blank" rel="external">Distributed Representations of Sentences and Documents</a></p>
<p>[5] <a href="http://cn.arxiv.org/pdf/1506.06726v1.pdf" target="_blank" rel="external">Skip-Thought Vectors</a></p>
<p>[6] <a href="http://cn.arxiv.org/pdf/1408.5882.pdf" target="_blank" rel="external">Convolutional Neural Networks for Sentence Classification</a></p>
<p>[7] <a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9745/9552" target="_blank" rel="external">Recurrent Convolutional Neural Networks for Text Classification</a></p>
<p>[8] <a href="http://arxiv.org/pdf/1506.01057.pdf" target="_blank" rel="external">A Hierarchical Neural Autoencoder for Paragraphs and Documents</a></p>
<p>[9] <a href="http://arxiv.org/pdf/1511.01432.pdf" target="_blank" rel="external">Semi-supervised Sequence Learning</a></p>
<p>如果大家觉得有写的不够清楚的地方或者错误的地方，欢迎留言交流。</p>
<h1 id="工具推荐"><a href="#工具推荐" class="headerlink" title="工具推荐"></a>工具推荐</h1><p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献，欢迎大家扫码关注。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="650" height="650">
<p>知乎专栏<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">paperweekly</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-28T23:40:40.000Z"><a href="/2016/06/28/Deep-Reinforcement-Learning-with-a-Natural-Language-Action-Space-PaperWeekly/">2016-06-28</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/28/Deep-Reinforcement-Learning-with-a-Natural-Language-Action-Space-PaperWeekly/">Deep Reinforcement Learning with a Natural Language Action Space #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文继续分享一篇深度增强学习在NLP中应用的paper，题目是<a href="http://arxiv.org/pdf/1511.04636v5.pdf" target="_blank" rel="external">Deep Reinforcement Learning with a Natural Language Action Space</a>，作者是来自微软的<a href="http://washington.academia.edu/JiHe" target="_blank" rel="external">Ji He</a>博士，文章最早于2015年11月发在arxiv上，2016年6月8号update。</p>
<p>通过前两篇文章的介绍，基本对DQN在NLP中应用有了一个清晰的认识，与DQN之前应用不同的地方在于两个方面：</p>
<p>1、actions的量级很大。</p>
<p>2、transition tuple的具体形式随着模型来变化。</p>
<p>本文也是以text games为研究背景，将输入从state变为(state,action)对，提出了Deep Reinforcement Relevant Network(DRRN)模型。</p>
<img src="/2016/06/28/Deep-Reinforcement-Learning-with-a-Natural-Language-Action-Space-PaperWeekly/fig1.png" width="600" height="600">
<p>上图中，前两个是baseline模型，第三个是本文模型，理解起来都比较简单。</p>
<p>(a) Max-action DQN</p>
<p>该模型适用于每一个transition中actions的最大数量是已知的情况，将每个transition中state和actions拼接成一个向量作为输入，通过一个Deep Network得到每个action的Q值。</p>
<p>(b) Per-action DQN</p>
<p>该模型将每一对(state,action)拼接成一个向量作为输入，通过network得到每个action的Q值。</p>
<p>(c) DRRN</p>
<p>本文模型分别将每对(state,action)中的state和action单独构建network，分别学习出不同的表示，然后用一种逐元素操作方法得到Q值，比如对两个向量作内积。这里，state往往是一个比较长的文本，可能是几句话，而action一般来说是一个动词短语，通过不同的网络结构进行学习，得到相同维度的表示，然后做内积，内积就是相似度的一种表征，也就是本文模型中的relevant。</p>
<p>其实，对比着看不同DRL paper，只需要仔细对比看算法流程图，就知道哪些地方不同了，本文的如下图：</p>
<img src="/2016/06/28/Deep-Reinforcement-Learning-with-a-Natural-Language-Action-Space-PaperWeekly/fig2.png" width="600" height="600">
<p>本文算法中还有一个不同的地方在于，在策略选择上的trade-off，一般的方法均采用ε-greedy策略，本文用了一种softmax selection的方法来做exploration（对应着ε）策略，根据下面计算出的概率来进行选择：</p>
<img src="/2016/06/28/Deep-Reinforcement-Learning-with-a-Natural-Language-Action-Space-PaperWeekly/fig3.png" width="200" height="200">
<p>本文模型最大的优点在于可以处理比较复杂的action，不像<a href="http://rsarxiv.github.io/2016/06/27/Language-Understanding-for-Text-based-Games-using-Deep-Reinforcement-Learning-PaperWeekly/">Language Understanding for Text-based Games using Deep Reinforcement Learning</a>文章中只能处理一个action word加一个object word组成的command。</p>
<p>本文考虑问题的角度不同，不是传统RL给定一个state，然后通过一个最优的Q来确定一个最优的action，而是将state和action放在一个层面上来做计算，虽然最后也是通过最优的Q来选择action，但通过用action和state的相关性来计算Q，使得其具有更广的应用前景。</p>
<p>这是DQN在NLP中应用系列的最后一篇文章，文章数量比较少，所以不写综述了。整体的感觉是，应用还不太多，也没有看到特别惊艳的表现。不过，可以无穷无尽地构造训练用的样本是一个非常大的优点。三篇文章有两篇是研究text games的，只有一篇是做text generation的，并且DQN的痕迹很重，都是依着同一个框架进行修改和适应，并没有很多特别的地方。很期待，后面的研究可以将Deep Reinforcement Learning在NLP的各个任务中进行应用，像seq2seq+attention模型那样横扫整个NLP任务。</p>
<p>如果大家觉得有写的不够清楚的地方或者错误的地方，欢迎留言交流。</p>
<h1 id="工具推荐"><a href="#工具推荐" class="headerlink" title="工具推荐"></a>工具推荐</h1><p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献，欢迎大家扫码关注。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="650" height="650">
<p>知乎专栏<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">paperweekly</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
  
    <a href="/page/2/" class="alignright next">下一页</a>
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:rsarxiv.github.io">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">标签</h3>
  <ul class="entry">
  
    <li><a href="/tags/Autoencoder/">Autoencoder</a><small>1</small></li>
  
    <li><a href="/tags/CNN/">CNN</a><small>2</small></li>
  
    <li><a href="/tags/DQN/">DQN</a><small>4</small></li>
  
    <li><a href="/tags/Memory-Network/">Memory Network</a><small>1</small></li>
  
    <li><a href="/tags/NLP/">NLP</a><small>2</small></li>
  
    <li><a href="/tags/PaperWeekly/">PaperWeekly</a><small>73</small></li>
  
    <li><a href="/tags/RNN/">RNN</a><small>1</small></li>
  
    <li><a href="/tags/RNNLM/">RNNLM</a><small>1</small></li>
  
    <li><a href="/tags/ROUGE/">ROUGE</a><small>1</small></li>
  
    <li><a href="/tags/RSarXiv/">RSarXiv</a><small>1</small></li>
  
    <li><a href="/tags/Reading-Comprehension/">Reading Comprehension</a><small>6</small></li>
  
    <li><a href="/tags/Representation/">Representation</a><small>1</small></li>
  
    <li><a href="/tags/Text-Comprehension/">Text Comprehension</a><small>1</small></li>
  
    <li><a href="/tags/api-ai/">api.ai</a><small>1</small></li>
  
    <li><a href="/tags/arXiv/">arXiv</a><small>2</small></li>
  
    <li><a href="/tags/arxiv/">arxiv</a><small>2</small></li>
  
    <li><a href="/tags/attention/">attention</a><small>3</small></li>
  
    <li><a href="/tags/bot/">bot</a><small>21</small></li>
  
    <li><a href="/tags/chatbot/">chatbot</a><small>2</small></li>
  
    <li><a href="/tags/dataset/">dataset</a><small>1</small></li>
  
    <li><a href="/tags/deep-learning/">deep learning</a><small>1</small></li>
  
    <li><a href="/tags/deeplearning/">deeplearning</a><small>1</small></li>
  
    <li><a href="/tags/language-model/">language model</a><small>1</small></li>
  
    <li><a href="/tags/nlp/">nlp</a><small>92</small></li>
  
    <li><a href="/tags/open-source/">open source</a><small>1</small></li>
  
    <li><a href="/tags/paper/">paper</a><small>7</small></li>
  
    <li><a href="/tags/paperweekly/">paperweekly</a><small>2</small></li>
  
    <li><a href="/tags/reading-comprehension/">reading comprehension</a><small>1</small></li>
  
    <li><a href="/tags/reinforcement-learning/">reinforcement learning</a><small>1</small></li>
  
    <li><a href="/tags/sentence-representations/">sentence representations</a><small>1</small></li>
  
    <li><a href="/tags/seq2seq/">seq2seq</a><small>17</small></li>
  
    <li><a href="/tags/text-comprehension/">text comprehension</a><small>1</small></li>
  
    <li><a href="/tags/torch/">torch</a><small>1</small></li>
  
    <li><a href="/tags/word-embedding/">word embedding</a><small>2</small></li>
  
    <li><a href="/tags/word-embeddings/">word embeddings</a><small>1</small></li>
  
    <li><a href="/tags/word2vec/">word2vec</a><small>1</small></li>
  
    <li><a href="/tags/创业/">创业</a><small>1</small></li>
  
    <li><a href="/tags/推荐系统/">推荐系统</a><small>2</small></li>
  
    <li><a href="/tags/综述/">综述</a><small>1</small></li>
  
    <li><a href="/tags/自动文摘/">自动文摘</a><small>16</small></li>
  
    <li><a href="/tags/随笔/">随笔</a><small>4</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- rsarxiv -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-7417238904018690"
     data-ad-slot="4681057960"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2016 PaperWeekly
  
</div>
<div class="clearfix"></div>
<!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a class="jiathis_button_xiaoyou"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END --></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>